{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3つの実験をしている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, metrics, losses, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 過去何ヶ月分みるか　分割数を決めている\n",
    "SPLIT_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力するためのデータを生成する関数\n",
    "def read_csv(csv_path):\n",
    "    # ここのdatasに要素を入れている\n",
    "    datas = list()\n",
    "\n",
    "    # csvを開いている\n",
    "    with open(csv_path, \"r\") as f:\n",
    "        r = csv.reader(f)\n",
    "\n",
    "        # 余分な文字列を空白に置換している\n",
    "        items = [R.replace(\"\\ufeff\", \"\") for R in next(iter(r))]\n",
    "\n",
    "        # Rは読み込んだcsvファイルを指している。enumerateはその中身の個数を数える関数\n",
    "        # 今回は、iには読み込んだcsvの個数 Rには中の要素が入っている\n",
    "        for i, R in enumerate(r):\n",
    "            # 数値をfloat型にしている\n",
    "            R = list(map(float, R))\n",
    "            \n",
    "            # 一番最新の月の要素をdatasに入れないようにする条件分岐\n",
    "            if i == 0:\n",
    "                tmp_peak = R[2]\n",
    "                continue\n",
    "            \n",
    "            # csvから読み込んだ要素を入れる\n",
    "            datas.append({\n",
    "                I:V for I, V in zip(items, R)\n",
    "            })\n",
    "            # 来月と今月の差(gain)を出す\n",
    "            datas[-1][\"gain\"] = tmp_peak - R[2]\n",
    "            # 来月のpeakをnext_peakとしてリストに追加\n",
    "            datas[-1][\"next_peak\"] = tmp_peak\n",
    "            # gainを比率にしたものをgain_percentとしてリストに追加\n",
    "            datas[-1][\"gain_percent\"] = (datas[-1][\"next_peak\"] - datas[-1][\"peak\"]) / datas[-1][\"peak\"] * 100\n",
    "            # \n",
    "            tmp_peak = R[2]\n",
    "\n",
    "            # データを昇順から降順にしたものを返す\n",
    "    return list(reversed(datas))\n",
    "\n",
    "# 標準化するための関数\n",
    "def standardize_datas(datas):\n",
    "\n",
    "    #要素名をitemsに入れている\n",
    "    items = list(datas[-1].keys())\n",
    "\n",
    "    # 平均の処理をしている\n",
    "    mean_items = {\n",
    "        I: np.average([D[I] for D in datas])  for I in items\n",
    "    }\n",
    "    # 標準偏差の処理をしている\n",
    "    std_items = {\n",
    "        I: np.std([D[I] for D in datas])  for I in items\n",
    "    }\n",
    "    # 標準化の処理を行っている\n",
    "    standardized_datas = [\n",
    "        # もし標準偏差の値が0の場合は0を入れる。それ以外は標準化の処理を行う\n",
    "        {I:0.0 if std_items[I] == 0 else (D[I] - mean_items[I]) / std_items[I] for I in items} for D in datas\n",
    "    ]\n",
    "\n",
    "    return standardized_datas, mean_items, std_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'year': 2013.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 31359.0,\n",
       "   'gain': 3879.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 189534301.0,\n",
       "   'next_peak': 35238.0,\n",
       "   'gain_percent': 12.369654644599636},\n",
       "  {'year': 2013.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 35238.0,\n",
       "   'gain': -3072.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 156301691.0,\n",
       "   'next_peak': 32166.0,\n",
       "   'gain_percent': -8.717861399625404},\n",
       "  {'year': 2013.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 32166.0,\n",
       "   'gain': -200.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 159335892.0,\n",
       "   'next_peak': 31966.0,\n",
       "   'gain_percent': -0.6217745445501461},\n",
       "  {'year': 2013.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 31966.0,\n",
       "   'gain': 21413.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 150894913.0,\n",
       "   'next_peak': 53379.0,\n",
       "   'gain_percent': 66.98679847337796},\n",
       "  {'year': 2013.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 53379.0,\n",
       "   'gain': -19679.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 152520560.0,\n",
       "   'next_peak': 33700.0,\n",
       "   'gain_percent': -36.86655800970419},\n",
       "  {'year': 2013.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 33700.0,\n",
       "   'gain': 8449.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 147325090.0,\n",
       "   'next_peak': 42149.0,\n",
       "   'gain_percent': 25.071216617210684},\n",
       "  {'year': 2013.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 42149.0,\n",
       "   'gain': 8362.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 159243497.0,\n",
       "   'next_peak': 50511.0,\n",
       "   'gain_percent': 19.839142091152816},\n",
       "  {'year': 2013.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 50511.0,\n",
       "   'gain': 1541.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 163625706.0,\n",
       "   'next_peak': 52052.0,\n",
       "   'gain_percent': 3.0508206133317497},\n",
       "  {'year': 2013.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 52052.0,\n",
       "   'gain': 1211.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 180492592.0,\n",
       "   'next_peak': 53263.0,\n",
       "   'gain_percent': 2.326519634211942},\n",
       "  {'year': 2013.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 53263.0,\n",
       "   'gain': 39016.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 187793453.0,\n",
       "   'next_peak': 92279.0,\n",
       "   'gain_percent': 73.25160054822297},\n",
       "  {'year': 2013.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 92279.0,\n",
       "   'gain': 4019.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 192019520.0,\n",
       "   'next_peak': 96298.0,\n",
       "   'gain_percent': 4.3552704298919585},\n",
       "  {'year': 2013.0,\n",
       "   'month': 12.0,\n",
       "   'peak': 96298.0,\n",
       "   'gain': 5786.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 210575680.0,\n",
       "   'next_peak': 102084.0,\n",
       "   'gain_percent': 6.008432158507965},\n",
       "  {'year': 2014.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 102084.0,\n",
       "   'gain': 17680.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 215374048.0,\n",
       "   'next_peak': 119764.0,\n",
       "   'gain_percent': 17.319070569335057},\n",
       "  {'year': 2014.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 119764.0,\n",
       "   'gain': 44731.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 187047218.0,\n",
       "   'next_peak': 164495.0,\n",
       "   'gain_percent': 37.34928693096423},\n",
       "  {'year': 2014.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 164495.0,\n",
       "   'gain': -21969.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 203940245.0,\n",
       "   'next_peak': 142526.0,\n",
       "   'gain_percent': -13.35542113742059},\n",
       "  {'year': 2014.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 142526.0,\n",
       "   'gain': 27611.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 191717596.0,\n",
       "   'next_peak': 170137.0,\n",
       "   'gain_percent': 19.37260570001263},\n",
       "  {'year': 2014.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 170137.0,\n",
       "   'gain': -6003.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 200047568.0,\n",
       "   'next_peak': 164134.0,\n",
       "   'gain_percent': -3.528333049248547},\n",
       "  {'year': 2014.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 164134.0,\n",
       "   'gain': 29479.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 207131104.0,\n",
       "   'next_peak': 193613.0,\n",
       "   'gain_percent': 17.96032510022299},\n",
       "  {'year': 2014.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 193613.0,\n",
       "   'gain': 83579.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 209067723.0,\n",
       "   'next_peak': 277192.0,\n",
       "   'gain_percent': 43.16807239183319},\n",
       "  {'year': 2014.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 277192.0,\n",
       "   'gain': -34698.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 202543340.0,\n",
       "   'next_peak': 242494.0,\n",
       "   'gain_percent': -12.517677277843516},\n",
       "  {'year': 2014.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 242494.0,\n",
       "   'gain': 18119.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 202281291.0,\n",
       "   'next_peak': 260613.0,\n",
       "   'gain_percent': 7.471937449998762},\n",
       "  {'year': 2014.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 260613.0,\n",
       "   'gain': 87405.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 216669754.0,\n",
       "   'next_peak': 348018.0,\n",
       "   'gain_percent': 33.538234853978885},\n",
       "  {'year': 2014.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 348018.0,\n",
       "   'gain': 19616.0,\n",
       "   'price': 115.0,\n",
       "   'steam_online': 212894074.0,\n",
       "   'next_peak': 367634.0,\n",
       "   'gain_percent': 5.6364900666057505},\n",
       "  {'year': 2014.0,\n",
       "   'month': 12.0,\n",
       "   'peak': 367634.0,\n",
       "   'gain': 75554.0,\n",
       "   'price': 1219.0,\n",
       "   'steam_online': 229914135.0,\n",
       "   'next_peak': 443188.0,\n",
       "   'gain_percent': 20.551417986366875},\n",
       "  {'year': 2015.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 443188.0,\n",
       "   'gain': 12320.0,\n",
       "   'price': 1408.0,\n",
       "   'steam_online': 248142190.0,\n",
       "   'next_peak': 455508.0,\n",
       "   'gain_percent': 2.779858660433044},\n",
       "  {'year': 2015.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 455508.0,\n",
       "   'gain': 139931.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 224509605.0,\n",
       "   'next_peak': 595439.0,\n",
       "   'gain_percent': 30.71976781966508},\n",
       "  {'year': 2015.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 595439.0,\n",
       "   'gain': -26883.0,\n",
       "   'price': 1360.0,\n",
       "   'steam_online': 260193756.0,\n",
       "   'next_peak': 568556.0,\n",
       "   'gain_percent': -4.5148201579003056},\n",
       "  {'year': 2015.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 568556.0,\n",
       "   'gain': 109145.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 256307044.0,\n",
       "   'next_peak': 677701.0,\n",
       "   'gain_percent': 19.19687770421911},\n",
       "  {'year': 2015.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 677701.0,\n",
       "   'gain': -67300.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 268017435.0,\n",
       "   'next_peak': 610401.0,\n",
       "   'gain_percent': -9.930633125818023},\n",
       "  {'year': 2015.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 610401.0,\n",
       "   'gain': -69220.0,\n",
       "   'price': 1208.0,\n",
       "   'steam_online': 275398132.0,\n",
       "   'next_peak': 541181.0,\n",
       "   'gain_percent': -11.340086271156174},\n",
       "  {'year': 2015.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 541181.0,\n",
       "   'gain': 278721.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 274316327.0,\n",
       "   'next_peak': 819902.0,\n",
       "   'gain_percent': 51.5023624258797},\n",
       "  {'year': 2015.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 819902.0,\n",
       "   'gain': -93963.0,\n",
       "   'price': 1336.0,\n",
       "   'steam_online': 280723676.0,\n",
       "   'next_peak': 725939.0,\n",
       "   'gain_percent': -11.460272081297521},\n",
       "  {'year': 2015.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 725939.0,\n",
       "   'gain': 6154.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 285319406.0,\n",
       "   'next_peak': 732093.0,\n",
       "   'gain_percent': 0.8477296301755382},\n",
       "  {'year': 2015.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 732093.0,\n",
       "   'gain': 54614.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 306848246.0,\n",
       "   'next_peak': 786707.0,\n",
       "   'gain_percent': 7.459981177254803},\n",
       "  {'year': 2015.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 786707.0,\n",
       "   'gain': 36987.0,\n",
       "   'price': 1332.0,\n",
       "   'steam_online': 312287411.0,\n",
       "   'next_peak': 823694.0,\n",
       "   'gain_percent': 4.701496236845483},\n",
       "  {'year': 2015.0,\n",
       "   'month': 12.0,\n",
       "   'peak': 823694.0,\n",
       "   'gain': -156262.0,\n",
       "   'price': 1193.0,\n",
       "   'steam_online': 319799868.0,\n",
       "   'next_peak': 667432.0,\n",
       "   'gain_percent': -18.970879962704597},\n",
       "  {'year': 2016.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 667432.0,\n",
       "   'gain': 71537.0,\n",
       "   'price': 1360.0,\n",
       "   'steam_online': 354205980.0,\n",
       "   'next_peak': 738969.0,\n",
       "   'gain_percent': 10.718245454218557},\n",
       "  {'year': 2016.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 738969.0,\n",
       "   'gain': -1370.0,\n",
       "   'price': 1295.0,\n",
       "   'steam_online': 332474919.0,\n",
       "   'next_peak': 737599.0,\n",
       "   'gain_percent': -0.18539343328339888},\n",
       "  {'year': 2016.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 737599.0,\n",
       "   'gain': 112886.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 351943255.0,\n",
       "   'next_peak': 850485.0,\n",
       "   'gain_percent': 15.304521833679274},\n",
       "  {'year': 2016.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 850485.0,\n",
       "   'gain': -181873.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 347096278.0,\n",
       "   'next_peak': 668612.0,\n",
       "   'gain_percent': -21.38462171584449},\n",
       "  {'year': 2016.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 668612.0,\n",
       "   'gain': -89502.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 349085617.0,\n",
       "   'next_peak': 579110.0,\n",
       "   'gain_percent': -13.386238954730098},\n",
       "  {'year': 2016.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 579110.0,\n",
       "   'gain': 56946.0,\n",
       "   'price': 1282.0,\n",
       "   'steam_online': 342460460.0,\n",
       "   'next_peak': 636056.0,\n",
       "   'gain_percent': 9.833364991107043},\n",
       "  {'year': 2016.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 636056.0,\n",
       "   'gain': -36961.0,\n",
       "   'price': 1360.0,\n",
       "   'steam_online': 346363534.0,\n",
       "   'next_peak': 599095.0,\n",
       "   'gain_percent': -5.810966330008679},\n",
       "  {'year': 2016.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 599095.0,\n",
       "   'gain': 39265.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 339754591.0,\n",
       "   'next_peak': 638360.0,\n",
       "   'gain_percent': 6.554052362313156},\n",
       "  {'year': 2016.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 638360.0,\n",
       "   'gain': 23625.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 338136102.0,\n",
       "   'next_peak': 661985.0,\n",
       "   'gain_percent': 3.7008897800614076},\n",
       "  {'year': 2016.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 661985.0,\n",
       "   'gain': -34861.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 362204081.0,\n",
       "   'next_peak': 627124.0,\n",
       "   'gain_percent': -5.266131407811355},\n",
       "  {'year': 2016.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 627124.0,\n",
       "   'gain': 35336.0,\n",
       "   'price': 1365.0,\n",
       "   'steam_online': 364127062.0,\n",
       "   'next_peak': 662460.0,\n",
       "   'gain_percent': 5.634611336832907},\n",
       "  {'year': 2016.0,\n",
       "   'month': 12.0,\n",
       "   'peak': 662460.0,\n",
       "   'gain': 152156.0,\n",
       "   'price': 1306.0,\n",
       "   'steam_online': 388609680.0,\n",
       "   'next_peak': 814616.0,\n",
       "   'gain_percent': 22.968330163330617},\n",
       "  {'year': 2017.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 814616.0,\n",
       "   'gain': -70148.0,\n",
       "   'price': 1416.0,\n",
       "   'steam_online': 403770973.0,\n",
       "   'next_peak': 744468.0,\n",
       "   'gain_percent': -8.611173853693028},\n",
       "  {'year': 2017.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 744468.0,\n",
       "   'gain': -2112.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 355481565.0,\n",
       "   'next_peak': 742356.0,\n",
       "   'gain_percent': -0.28369251599800127},\n",
       "  {'year': 2017.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 742356.0,\n",
       "   'gain': -32515.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 355283156.0,\n",
       "   'next_peak': 709841.0,\n",
       "   'gain_percent': -4.379974028633162},\n",
       "  {'year': 2017.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 709841.0,\n",
       "   'gain': -16875.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 372738458.0,\n",
       "   'next_peak': 692966.0,\n",
       "   'gain_percent': -2.377292943067532},\n",
       "  {'year': 2017.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 692966.0,\n",
       "   'gain': -78345.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 384904645.0,\n",
       "   'next_peak': 614621.0,\n",
       "   'gain_percent': -11.30574948843089},\n",
       "  {'year': 2017.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 614621.0,\n",
       "   'gain': 10164.0,\n",
       "   'price': 1333.0,\n",
       "   'steam_online': 384667873.0,\n",
       "   'next_peak': 624785.0,\n",
       "   'gain_percent': 1.6537020375158025},\n",
       "  {'year': 2017.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 624785.0,\n",
       "   'gain': -29004.0,\n",
       "   'price': 1369.0,\n",
       "   'steam_online': 397350674.0,\n",
       "   'next_peak': 595781.0,\n",
       "   'gain_percent': -4.642236929503749},\n",
       "  {'year': 2017.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 595781.0,\n",
       "   'gain': 69590.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 402100933.0,\n",
       "   'next_peak': 665371.0,\n",
       "   'gain_percent': 11.6804664801328},\n",
       "  {'year': 2017.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 665371.0,\n",
       "   'gain': -25403.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 413855215.0,\n",
       "   'next_peak': 639968.0,\n",
       "   'gain_percent': -3.8178700304040905},\n",
       "  {'year': 2017.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 639968.0,\n",
       "   'gain': -38087.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 461639493.0,\n",
       "   'next_peak': 601881.0,\n",
       "   'gain_percent': -5.951391319565978},\n",
       "  {'year': 2017.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 601881.0,\n",
       "   'gain': -3476.0,\n",
       "   'price': 1382.0,\n",
       "   'steam_online': 456531797.0,\n",
       "   'next_peak': 598405.0,\n",
       "   'gain_percent': -0.5775227993573481},\n",
       "  {'year': 2017.0,\n",
       "   'month': 12.0,\n",
       "   'peak': 598405.0,\n",
       "   'gain': 117445.0,\n",
       "   'price': 1274.0,\n",
       "   'steam_online': 503638824.0,\n",
       "   'next_peak': 715850.0,\n",
       "   'gain_percent': 19.626340020554643},\n",
       "  {'year': 2018.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 715850.0,\n",
       "   'gain': -29262.0,\n",
       "   'price': 1384.0,\n",
       "   'steam_online': 522357795.0,\n",
       "   'next_peak': 686588.0,\n",
       "   'gain_percent': -4.087727875951666},\n",
       "  {'year': 2018.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 686588.0,\n",
       "   'gain': -14086.0,\n",
       "   'price': 1374.0,\n",
       "   'steam_online': 371090512.0,\n",
       "   'next_peak': 672502.0,\n",
       "   'gain_percent': -2.0515942603133173},\n",
       "  {'year': 2018.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 672502.0,\n",
       "   'gain': -149240.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 510031006.0,\n",
       "   'next_peak': 523262.0,\n",
       "   'gain_percent': -22.191755563552228},\n",
       "  {'year': 2018.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 523262.0,\n",
       "   'gain': -68781.0,\n",
       "   'price': 1508.0,\n",
       "   'steam_online': 474062020.0,\n",
       "   'next_peak': 454481.0,\n",
       "   'gain_percent': -13.144657934266199},\n",
       "  {'year': 2018.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 454481.0,\n",
       "   'gain': -34220.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 474049371.0,\n",
       "   'next_peak': 420261.0,\n",
       "   'gain_percent': -7.529467678516815},\n",
       "  {'year': 2018.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 420261.0,\n",
       "   'gain': 5747.0,\n",
       "   'price': 1292.0,\n",
       "   'steam_online': 465287550.0,\n",
       "   'next_peak': 426008.0,\n",
       "   'gain_percent': 1.3674835399906249},\n",
       "  {'year': 2018.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 426008.0,\n",
       "   'gain': 28362.0,\n",
       "   'price': 1372.0,\n",
       "   'steam_online': 461230198.0,\n",
       "   'next_peak': 454370.0,\n",
       "   'gain_percent': 6.657621453118251},\n",
       "  {'year': 2018.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 454370.0,\n",
       "   'gain': 128659.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 452335748.0,\n",
       "   'next_peak': 583029.0,\n",
       "   'gain_percent': 28.315909941237315},\n",
       "  {'year': 2018.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 583029.0,\n",
       "   'gain': -17061.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 444109147.0,\n",
       "   'next_peak': 565968.0,\n",
       "   'gain_percent': -2.9262695337624716},\n",
       "  {'year': 2018.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 565968.0,\n",
       "   'gain': -19937.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 450878274.0,\n",
       "   'next_peak': 546031.0,\n",
       "   'gain_percent': -3.5226373222514344},\n",
       "  {'year': 2018.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 546031.0,\n",
       "   'gain': 200517.0,\n",
       "   'price': 1368.0,\n",
       "   'steam_online': 435691109.0,\n",
       "   'next_peak': 746548.0,\n",
       "   'gain_percent': 36.72264028965388},\n",
       "  {'year': 2018.0,\n",
       "   'month': 12.0,\n",
       "   'peak': 746548.0,\n",
       "   'gain': -62037.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 479130101.0,\n",
       "   'next_peak': 684511.0,\n",
       "   'gain_percent': -8.30984745789956},\n",
       "  {'year': 2019.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 684511.0,\n",
       "   'gain': -30442.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 487744486.0,\n",
       "   'next_peak': 654069.0,\n",
       "   'gain_percent': -4.44726235224854},\n",
       "  {'year': 2019.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 654069.0,\n",
       "   'gain': 26002.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 434108199.0,\n",
       "   'next_peak': 680071.0,\n",
       "   'gain_percent': 3.9754215533835118},\n",
       "  {'year': 2019.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 680071.0,\n",
       "   'gain': -58457.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 475948889.0,\n",
       "   'next_peak': 621614.0,\n",
       "   'gain_percent': -8.595720152748756},\n",
       "  {'year': 2019.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 621614.0,\n",
       "   'gain': -33161.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 459882969.0,\n",
       "   'next_peak': 588453.0,\n",
       "   'gain_percent': -5.334661059757342},\n",
       "  {'year': 2019.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 588453.0,\n",
       "   'gain': -729.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 475503683.0,\n",
       "   'next_peak': 587724.0,\n",
       "   'gain_percent': -0.12388415047590888},\n",
       "  {'year': 2019.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 587724.0,\n",
       "   'gain': -8791.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 459967446.0,\n",
       "   'next_peak': 578933.0,\n",
       "   'gain_percent': -1.4957701233912517},\n",
       "  {'year': 2019.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 578933.0,\n",
       "   'gain': 68528.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 468667503.0,\n",
       "   'next_peak': 647461.0,\n",
       "   'gain_percent': 11.83694831699005},\n",
       "  {'year': 2019.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 647461.0,\n",
       "   'gain': 72591.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 462667163.0,\n",
       "   'next_peak': 720052.0,\n",
       "   'gain_percent': 11.2116405466893},\n",
       "  {'year': 2019.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 720052.0,\n",
       "   'gain': 27885.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 443916276.0,\n",
       "   'next_peak': 747937.0,\n",
       "   'gain_percent': 3.872636976218384},\n",
       "  {'year': 2019.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 747937.0,\n",
       "   'gain': 10475.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 458972530.0,\n",
       "   'next_peak': 758412.0,\n",
       "   'gain_percent': 1.4005190276721167},\n",
       "  {'year': 2019.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 758412.0,\n",
       "   'gain': 8648.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 444037585.0,\n",
       "   'next_peak': 767060.0,\n",
       "   'gain_percent': 1.1402773162871895},\n",
       "  {'year': 2019.0,\n",
       "   'month': 12.0,\n",
       "   'peak': 767060.0,\n",
       "   'gain': 50169.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 489960904.0,\n",
       "   'next_peak': 817229.0,\n",
       "   'gain_percent': 6.540427085234532},\n",
       "  {'year': 2020.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 817229.0,\n",
       "   'gain': 99767.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 504227760.0,\n",
       "   'next_peak': 916996.0,\n",
       "   'gain_percent': 12.207961293590904},\n",
       "  {'year': 2020.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 916996.0,\n",
       "   'gain': 228976.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 494362025.0,\n",
       "   'next_peak': 1145972.0,\n",
       "   'gain_percent': 24.97022887777046},\n",
       "  {'year': 2020.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 1145972.0,\n",
       "   'gain': 159742.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 614637525.0,\n",
       "   'next_peak': 1305714.0,\n",
       "   'gain_percent': 13.939433075153667},\n",
       "  {'year': 2020.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 1305714.0,\n",
       "   'gain': -112355.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 707770424.0,\n",
       "   'next_peak': 1193359.0,\n",
       "   'gain_percent': -8.604870591875404},\n",
       "  {'year': 2020.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 1193359.0,\n",
       "   'gain': -183892.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 690919844.0,\n",
       "   'next_peak': 1009467.0,\n",
       "   'gain_percent': -15.409612698274366},\n",
       "  {'year': 2020.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 1009467.0,\n",
       "   'gain': -151907.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 617667675.0,\n",
       "   'next_peak': 857560.0,\n",
       "   'gain_percent': -15.048238327751179},\n",
       "  {'year': 2020.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 857560.0,\n",
       "   'gain': 67788.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 614835056.0,\n",
       "   'next_peak': 925348.0,\n",
       "   'gain_percent': 7.9047530201968375},\n",
       "  {'year': 2020.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 925348.0,\n",
       "   'gain': 52421.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 617654552.0,\n",
       "   'next_peak': 977769.0,\n",
       "   'gain_percent': 5.665003868814759},\n",
       "  {'year': 2020.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 977769.0,\n",
       "   'gain': -33893.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 630276320.0,\n",
       "   'next_peak': 943876.0,\n",
       "   'gain_percent': -3.4663606639195965},\n",
       "  {'year': 2020.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 943876.0,\n",
       "   'gain': 93588.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 677821596.0,\n",
       "   'next_peak': 1037464.0,\n",
       "   'gain_percent': 9.915285482415063},\n",
       "  {'year': 2020.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 1037464.0,\n",
       "   'gain': 126932.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 676323499.0,\n",
       "   'next_peak': 1164396.0,\n",
       "   'gain_percent': 12.23483417255924},\n",
       "  {'year': 2020.0,\n",
       "   'month': 12.0,\n",
       "   'peak': 1164396.0,\n",
       "   'gain': -39843.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 742721118.0,\n",
       "   'next_peak': 1124553.0,\n",
       "   'gain_percent': -3.4217740356373607},\n",
       "  {'year': 2021.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 1124553.0,\n",
       "   'gain': -1068.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 764912073.0,\n",
       "   'next_peak': 1123485.0,\n",
       "   'gain_percent': -0.09497106850455247},\n",
       "  {'year': 2021.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 1123485.0,\n",
       "   'gain': 75096.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 710744828.0,\n",
       "   'next_peak': 1198581.0,\n",
       "   'gain_percent': 6.684201391206825},\n",
       "  {'year': 2021.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 1198581.0,\n",
       "   'gain': -50504.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 795249278.0,\n",
       "   'next_peak': 1148077.0,\n",
       "   'gain_percent': -4.213649306972162},\n",
       "  {'year': 2021.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 1148077.0,\n",
       "   'gain': -60880.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 764329312.0,\n",
       "   'next_peak': 1087197.0,\n",
       "   'gain_percent': -5.302780214219081},\n",
       "  {'year': 2021.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 1087197.0,\n",
       "   'gain': -157257.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 763354617.0,\n",
       "   'next_peak': 929940.0,\n",
       "   'gain_percent': -14.464443886434566},\n",
       "  {'year': 2021.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 929940.0,\n",
       "   'gain': -166417.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 725029145.0,\n",
       "   'next_peak': 763523.0,\n",
       "   'gain_percent': -17.895455620792738},\n",
       "  {'year': 2021.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 763523.0,\n",
       "   'gain': 39021.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 728164057.0,\n",
       "   'next_peak': 802544.0,\n",
       "   'gain_percent': 5.11065154553301},\n",
       "  {'year': 2021.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 802544.0,\n",
       "   'gain': 139975.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 742779745.0,\n",
       "   'next_peak': 942519.0,\n",
       "   'gain_percent': 17.441411312027753},\n",
       "  {'year': 2021.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 942519.0,\n",
       "   'gain': -77553.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 712688157.0,\n",
       "   'next_peak': 864966.0,\n",
       "   'gain_percent': -8.228269138340979},\n",
       "  {'year': 2021.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 864966.0,\n",
       "   'gain': 70627.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 761030927.0,\n",
       "   'next_peak': 935593.0,\n",
       "   'gain_percent': 8.165292046161351},\n",
       "  {'year': 2021.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 935593.0,\n",
       "   'gain': 14993.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 746857217.0,\n",
       "   'next_peak': 950586.0,\n",
       "   'gain_percent': 1.602513058562858},\n",
       "  {'year': 2021.0,\n",
       "   'month': 12.0,\n",
       "   'peak': 950586.0,\n",
       "   'gain': 41039.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 790841123.0,\n",
       "   'next_peak': 991625.0,\n",
       "   'gain_percent': 4.317231686559659},\n",
       "  {'year': 2022.0,\n",
       "   'month': 1.0,\n",
       "   'peak': 991625.0,\n",
       "   'gain': 3538.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 841556186.0,\n",
       "   'next_peak': 995163.0,\n",
       "   'gain_percent': 0.3567881003403504},\n",
       "  {'year': 2022.0,\n",
       "   'month': 2.0,\n",
       "   'peak': 995163.0,\n",
       "   'gain': -7170.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 773919662.0,\n",
       "   'next_peak': 987993.0,\n",
       "   'gain_percent': -0.7204849858766855},\n",
       "  {'year': 2022.0,\n",
       "   'month': 3.0,\n",
       "   'peak': 987993.0,\n",
       "   'gain': 25244.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 842232292.0,\n",
       "   'next_peak': 1013237.0,\n",
       "   'gain_percent': 2.555078831530183},\n",
       "  {'year': 2022.0,\n",
       "   'month': 4.0,\n",
       "   'peak': 1013237.0,\n",
       "   'gain': -89241.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 811476339.0,\n",
       "   'next_peak': 923996.0,\n",
       "   'gain_percent': -8.807514924938587},\n",
       "  {'year': 2022.0,\n",
       "   'month': 5.0,\n",
       "   'peak': 923996.0,\n",
       "   'gain': -17326.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 814688015.0,\n",
       "   'next_peak': 906670.0,\n",
       "   'gain_percent': -1.8751163424949893},\n",
       "  {'year': 2022.0,\n",
       "   'month': 6.0,\n",
       "   'peak': 906670.0,\n",
       "   'gain': 21659.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 796942903.0,\n",
       "   'next_peak': 928329.0,\n",
       "   'gain_percent': 2.388851511575325},\n",
       "  {'year': 2022.0,\n",
       "   'month': 7.0,\n",
       "   'peak': 928329.0,\n",
       "   'gain': 111560.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 806821513.0,\n",
       "   'next_peak': 1039889.0,\n",
       "   'gain_percent': 12.017291283585884},\n",
       "  {'year': 2022.0,\n",
       "   'month': 8.0,\n",
       "   'peak': 1039889.0,\n",
       "   'gain': 60477.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 804512345.0,\n",
       "   'next_peak': 1100366.0,\n",
       "   'gain_percent': 5.815716869781294},\n",
       "  {'year': 2022.0,\n",
       "   'month': 9.0,\n",
       "   'peak': 1100366.0,\n",
       "   'gain': -21506.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 798181709.0,\n",
       "   'next_peak': 1078860.0,\n",
       "   'gain_percent': -1.9544406133959062},\n",
       "  {'year': 2022.0,\n",
       "   'month': 10.0,\n",
       "   'peak': 1078860.0,\n",
       "   'gain': 50235.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 849997689.0,\n",
       "   'next_peak': 1129095.0,\n",
       "   'gain_percent': 4.656303876313887},\n",
       "  {'year': 2022.0,\n",
       "   'month': 11.0,\n",
       "   'peak': 1129095.0,\n",
       "   'gain': -64016.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 852068535.0,\n",
       "   'next_peak': 1065079.0,\n",
       "   'gain_percent': -5.669673499572666}],\n",
       " 119)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの読み込みをしている\n",
    "csgo_datas = read_csv(\"dataset/csgo_dataset5.csv\")\n",
    "\n",
    "#データの形と長さの確認\n",
    "csgo_datas, len(csgo_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化したデータ、平均を出したデータ、標準偏差を出したデータにするように関数で呼び出しをしている\n",
    "standardized_csgo_datas, csgo_mean_items, csgo_std_items = standardize_datas(csgo_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 2017.4621848739496,\n",
       " 'month': 6.453781512605042,\n",
       " 'peak': 648259.2521008403,\n",
       " 'gain': 8686.72268907563,\n",
       " 'price': 570.5126050420168,\n",
       " 'steam_online': 450737855.26890755,\n",
       " 'next_peak': 656945.974789916,\n",
       " 'gain_percent': 4.1408098115332965}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csgo_mean_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': -1.5632529387114606,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': -1.9181081145309107,\n",
       "  'gain': -0.06108947074816852,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.2428713760952992,\n",
       "  'next_peak': -1.9502280281700042,\n",
       "  'gain_percent': 0.5105981069787495},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': -1.906047264578382,\n",
       "  'gain': -0.14941255812910118,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.4010003871554486,\n",
       "  'next_peak': -1.9598645468338716,\n",
       "  'gain_percent': -0.797877868871324},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': -1.9155989353837874,\n",
       "  'gain': -0.11291940506363742,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.3865629053119304,\n",
       "  'next_peak': -1.9604919243510506,\n",
       "  'gain_percent': -0.29551736675980744},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': -1.9162207889518479,\n",
       "  'gain': 0.16170681958952005,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.426727179548877,\n",
       "  'next_peak': -1.8933217504742947,\n",
       "  'gain_percent': 3.899580499197285},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': -1.849642036687476,\n",
       "  'gain': -0.3604298955100749,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.4189919474246802,\n",
       "  'next_peak': -1.9550525612771097,\n",
       "  'gain_percent': -2.5444986272639256},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': -1.9108293185167653,\n",
       "  'gain': -0.003020630389822639,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.443713283879827,\n",
       "  'next_peak': -1.9285489980638884,\n",
       "  'gain_percent': 1.298727380340172},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': -1.8845591145340597,\n",
       "  'gain': -0.0041260984666664224,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.3870025436664535,\n",
       "  'next_peak': -1.9023183440706397,\n",
       "  'gain_percent': 0.9740782463764441},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': -1.85855941685346,\n",
       "  'gain': -0.09079733699714285,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.3661509050070497,\n",
       "  'next_peak': -1.8974844003007767,\n",
       "  'gain_percent': -0.06763360259177559},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': -1.8537680351115557,\n",
       "  'gain': -0.09499049177137789,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.2858940728519985,\n",
       "  'next_peak': -1.8936856294342586,\n",
       "  'gain_percent': -0.11257632739992086},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': -1.8500027117569509,\n",
       "  'gain': 0.3853798604709123,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.2511547631854507,\n",
       "  'next_peak': -1.7712968233830046,\n",
       "  'gain_percent': 4.288310162340103},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': -1.7286915176997553,\n",
       "  'gain': -0.05931055660152335,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.2310460869369124,\n",
       "  'next_peak': -1.7586896721752951,\n",
       "  'gain_percent': 0.01330723667499516},\n",
       " {'year': -1.5632529387114606,\n",
       "  'month': 1.6172779126555643,\n",
       "  'peak': -1.7161953702495842,\n",
       "  'gain': -0.03685811876493754,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.1427512695911217,\n",
       "  'next_peak': -1.7405396406033105,\n",
       "  'gain_percent': 0.11588557741234384},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': -1.698205146525601,\n",
       "  'gain': 0.11427334452218849,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.1199194430646267,\n",
       "  'next_peak': -1.6850794680846986,\n",
       "  'gain_percent': 0.8177083336372194},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': -1.643233291109074,\n",
       "  'gain': 0.45799767724289187,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.2547055346285745,\n",
       "  'next_peak': -1.5447633494800583,\n",
       "  'gain_percent': 2.0605790845262684},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': -1.5041526313445561,\n",
       "  'gain': -0.38952784833734233,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.1743243171039082,\n",
       "  'next_peak': -1.6136776328545712,\n",
       "  'gain_percent': -1.085637484121806},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': -1.5724601365281354,\n",
       "  'gain': 0.24046189016742547,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.2324827163059366,\n",
       "  'next_peak': -1.5270650297204424,\n",
       "  'gain_percent': 0.9451297605336129},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': -1.486610142189576,\n",
       "  'gain': -0.18665539644207968,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.1928466409414458,\n",
       "  'next_peak': -1.5458957658985661,\n",
       "  'gain_percent': -0.4758687162418671},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': -1.5052750770349048,\n",
       "  'gain': 0.2641976874955196,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.1591414175933858,\n",
       "  'next_peak': -1.4534234567539868,\n",
       "  'gain_percent': 0.8574980436396761},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': -1.4136169703706627,\n",
       "  'gain': 0.9516209398776886,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.149926503469268,\n",
       "  'next_peak': -1.1912455292125228,\n",
       "  'gain_percent': 2.421633509722915},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': -1.15374747354612,\n",
       "  'gain': -0.5512692638562449,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.1809711379884242,\n",
       "  'next_peak': -1.300089254667885,\n",
       "  'gain_percent': -1.0336556522230835},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': -1.2616328490688946,\n",
       "  'gain': 0.11985151102488298,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.1822180322052582,\n",
       "  'next_peak': -1.2432519884990654,\n",
       "  'gain_percent': 0.20669577575097617},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': -1.2052960250704752,\n",
       "  'gain': 1.0002361221995772,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -1.1137541521529377,\n",
       "  'next_peak': -0.9690723290539698,\n",
       "  'gain_percent': 1.8241040973826552},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': -0.9335304694889396,\n",
       "  'gain': 0.1388731858643674,\n",
       "  'price': -0.6560531747757036,\n",
       "  'steam_online': -1.1317197752105184,\n",
       "  'next_peak': -0.9075391421690662,\n",
       "  'gain_percent': 0.09280664812352664},\n",
       " {'year': -1.2129194176066325,\n",
       "  'month': 1.6172779126555643,\n",
       "  'peak': -0.8725390715335892,\n",
       "  'gain': 0.8496510396860637,\n",
       "  'price': 0.9339856011777484,\n",
       "  'steam_online': -1.050734098367399,\n",
       "  'next_peak': -0.6705347375044045,\n",
       "  'gain_percent': 1.0182748172342968},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': -0.6376214491274643,\n",
       "  'gain': 0.046166345764916294,\n",
       "  'price': 1.2061933264089102,\n",
       "  'steam_online': -0.9640004860901805,\n",
       "  'next_peak': -0.6318882824461862,\n",
       "  'gain_percent': -0.08444673529995297},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': -0.5993152693349523,\n",
       "  'gain': 1.667659296961607,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -1.0764501942185798,\n",
       "  'next_peak': -0.19294046566440404,\n",
       "  'gain_percent': 1.6492188052794645},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': -0.1642323111737503,\n",
       "  'gain': -0.45196773488458775,\n",
       "  'price': 1.1370612057152818,\n",
       "  'steam_online': -0.9066561422873279,\n",
       "  'next_peak': -0.2772694146360018,\n",
       "  'gain_percent': -0.5370800357471874},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': -0.2478187585245703,\n",
       "  'gain': 1.2764760761143343,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.9251500831735723,\n",
       "  'next_peak': 0.06510618092643689,\n",
       "  'gain_percent': 0.9342258750168038},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': 0.0915422799051157,\n",
       "  'gain': -0.9655275424914292,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.8694291347449754,\n",
       "  'next_peak': -0.1460063536042528,\n",
       "  'gain_percent': -0.8731301017367421},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': -0.11771144574716216,\n",
       "  'gain': -0.9899240793597058,\n",
       "  'price': 0.918142823518792,\n",
       "  'steam_online': -0.8343099455646911,\n",
       "  'next_peak': -0.36314171229985964,\n",
       "  'gain_percent': -0.9605863756712129},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': -0.33293496565281855,\n",
       "  'gain': 3.4311985427679144,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.8394574424001765,\n",
       "  'next_peak': 0.5111747325281992,\n",
       "  'gain_percent': 2.9387744694474254},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': 0.5336832760638016,\n",
       "  'gain': -1.3043217417200017,\n",
       "  'price': 1.1024951453684675,\n",
       "  'steam_online': -0.8089696847161657,\n",
       "  'next_peak': 0.2164233642948085,\n",
       "  'gain_percent': -0.9680438801434429},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': 0.24152714198557007,\n",
       "  'gain': -0.03218211586518452,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.7871020601149243,\n",
       "  'next_peak': 0.23572777049840232,\n",
       "  'gain_percent': -0.20433493896663354},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': 0.2606615762747843,\n",
       "  'gain': 0.5835763094664219,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.6846624931211737,\n",
       "  'next_peak': 0.4070457491144363,\n",
       "  'gain_percent': 0.2059538915189323},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': 0.4304711301049998,\n",
       "  'gain': 0.35959831187417624,\n",
       "  'price': 1.0967341353106652,\n",
       "  'steam_online': -0.6587815953390562,\n",
       "  'next_peak': 0.5230698102539105,\n",
       "  'gain_percent': 0.03479047584208793},\n",
       " {'year': -0.8625858965018044,\n",
       "  'month': 1.6172779126555643,\n",
       "  'peak': 0.5454736197142241,\n",
       "  'gain': -2.095925830447483,\n",
       "  'price': 0.8965390358020331,\n",
       "  'steam_online': -0.6230354593587074,\n",
       "  'next_peak': 0.03289348230688782,\n",
       "  'gain_percent': -1.4340755339542146},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': 0.05961320845306159,\n",
       "  'gain': 0.7986089102069662,\n",
       "  'price': 1.1370612057152818,\n",
       "  'steam_online': -0.45932263436588455,\n",
       "  'next_peak': 0.25729700953901186,\n",
       "  'gain_percent': 0.40812851087364443},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': 0.28204090194469605,\n",
       "  'gain': -0.12778604471774346,\n",
       "  'price': 1.0434447922759933,\n",
       "  'steam_online': -0.5627244190953349,\n",
       "  'next_peak': 0.2529994735463366,\n",
       "  'gain_percent': -0.26844000974868304},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': 0.2777812050034833,\n",
       "  'gain': 1.3240112034186169,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.47008924182016143,\n",
       "  'next_peak': 0.6071101655676061,\n",
       "  'gain_percent': 0.6927060044270602},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': 0.6287740144237365,\n",
       "  'gain': -2.421352760516979,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.4931523620397677,\n",
       "  'next_peak': 0.03659500965824315,\n",
       "  'gain_percent': -1.5838477067063823},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': 0.06328214450461712,\n",
       "  'gain': -1.2476379130901152,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.48368659306365097,\n",
       "  'next_peak': -0.24416270305447285,\n",
       "  'gain_percent': -1.0875497232633464},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': -0.21500354573803032,\n",
       "  'gain': 0.6132079365376829,\n",
       "  'price': 1.0247215095881357,\n",
       "  'steam_online': -0.5152107353000936,\n",
       "  'next_peak': -0.06552950258813327,\n",
       "  'gain_percent': 0.3532218625490028},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': -0.037943179304232175,\n",
       "  'gain': -0.5800241403838021,\n",
       "  'price': 1.1370612057152818,\n",
       "  'steam_online': -0.49663893995466085,\n",
       "  'next_peak': -0.1814720046503743,\n",
       "  'gain_percent': -0.6175056356062233},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': -0.15286482794960873,\n",
       "  'gain': 0.38854378634601694,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.5280859319526682,\n",
       "  'next_peak': -0.05830211359023269,\n",
       "  'gain_percent': 0.14974119734976307},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': -0.030779426200177967,\n",
       "  'gain': 0.1898136631065137,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.535787104535313,\n",
       "  'next_peak': 0.0158068556265213,\n",
       "  'gain_percent': -0.027296946272333183},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': 0.04267702652694037,\n",
       "  'gain': -0.5533404281841247,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.4212656836331798,\n",
       "  'next_peak': -0.0935481825053416,\n",
       "  'gain_percent': -0.5836987422289175},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': -0.06571515965380344,\n",
       "  'gain': 0.33861983147338215,\n",
       "  'price': 1.1442624682875346,\n",
       "  'steam_online': -0.4121156624997973,\n",
       "  'next_peak': 0.01729687722982112,\n",
       "  'gain_percent': 0.09269007333265396},\n",
       " {'year': -0.5122523753969762,\n",
       "  'month': 1.6172779126555643,\n",
       "  'peak': 0.044153928751083496,\n",
       "  'gain': 1.822996621552587,\n",
       "  'price': 1.0592875699349498,\n",
       "  'steam_online': -0.29562128626803547,\n",
       "  'next_peak': 0.49459314474916166,\n",
       "  'gain_percent': 1.16824371412401},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': 0.517247686259969,\n",
       "  'gain': -1.0017157388460396,\n",
       "  'price': 1.2177153465245147,\n",
       "  'steam_online': -0.22348008915823384,\n",
       "  'next_peak': 0.2745467543738449,\n",
       "  'gain_percent': -0.7912579288801866},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': 0.29913876579851295,\n",
       "  'gain': -0.13721428969496288,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.45325308416885934,\n",
       "  'next_peak': 0.267921647792436,\n",
       "  'gain_percent': -0.27453944734533536},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': 0.2925719921197966,\n",
       "  'gain': -0.5235309096981992,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.45419716346192224,\n",
       "  'next_peak': 0.16592574793708126,\n",
       "  'gain_percent': -0.528712861528451},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': 0.19147414829239964,\n",
       "  'gain': -0.3248007864586959,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.3711405018570634,\n",
       "  'next_peak': 0.11299076992511413,\n",
       "  'gain_percent': -0.40444691753313616},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': 0.13900525348731513,\n",
       "  'gain': -1.1058711621321142,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.31325076287228776,\n",
       "  'next_peak': -0.13276868799177863,\n",
       "  'gain_percent': -0.9584557854589852},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': -0.10459033546109066,\n",
       "  'gain': 0.018771067906580684,\n",
       "  'price': 1.0981743878251158,\n",
       "  'steam_online': -0.31437738284606453,\n",
       "  'next_peak': -0.10088536256874847,\n",
       "  'gain_percent': -0.1543245190579505},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': -0.0729877371322682,\n",
       "  'gain': -0.4789182842062621,\n",
       "  'price': 1.1500234783453371,\n",
       "  'steam_online': -0.2540294661581284,\n",
       "  'next_peak': -0.19186765011002818,\n",
       "  'gain_percent': -0.5449862198711891},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': -0.16316894157236725,\n",
       "  'gain': 0.7738692970389794,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.23142655420057906,\n",
       "  'next_peak': 0.026428356992359566,\n",
       "  'gain_percent': 0.4678341250022177},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': 0.0532050074342006,\n",
       "  'gain': -0.43316207104862453,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': -0.17549676149449564,\n",
       "  'next_peak': -0.053257998352114574,\n",
       "  'gain_percent': -0.49383442558229634},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': -0.025779723512973467,\n",
       "  'gain': -0.5943316927346769,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': 0.05187269953680015,\n",
       "  'next_peak': -0.17273263583607265,\n",
       "  'gain_percent': -0.6262189769433146},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': -0.1442024077465293,\n",
       "  'gain': -0.1545459960951344,\n",
       "  'price': 1.1687467610331947,\n",
       "  'steam_online': 0.027569013570639782,\n",
       "  'next_peak': -0.1836364570846414,\n",
       "  'gain_percent': -0.2927715551927751},\n",
       " {'year': -0.1619188542921481,\n",
       "  'month': 1.6172779126555643,\n",
       "  'peak': -0.15501022275941662,\n",
       "  'gain': 1.381940271951155,\n",
       "  'price': 1.013199489472531,\n",
       "  'steam_online': 0.2517159461616627,\n",
       "  'next_peak': 0.1847753054407204,\n",
       "  'gain_percent': 0.9608739222443416},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': 0.2101577387447702,\n",
       "  'gain': -0.48219656884793677,\n",
       "  'price': 1.1716272660620959,\n",
       "  'steam_online': 0.340785458676437,\n",
       "  'next_peak': 0.09298370090227996,\n",
       "  'gain_percent': -0.5105790486594349},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': 0.1191743432018734,\n",
       "  'gain': -0.2893622753516004,\n",
       "  'price': 1.15722474091759,\n",
       "  'steam_online': -0.37898183816078823,\n",
       "  'next_peak': 0.04879750236737217,\n",
       "  'gain_percent': -0.38423738214470365},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': 0.0753771964033892,\n",
       "  'gain': -2.006700579463609,\n",
       "  'price': 1.3098915074493527,\n",
       "  'steam_online': 0.28213153549324055,\n",
       "  'next_peak': -0.4193516009515005,\n",
       "  'gain_percent': -1.63393019374782},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': -0.3886499360831776,\n",
       "  'gain': -0.9843459128570113,\n",
       "  'price': 1.350218577853969,\n",
       "  'steam_online': 0.11098216789868938,\n",
       "  'next_peak': -0.6351098659968997,\n",
       "  'gain_percent': -1.0725596712896848},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': -0.6025084874069417,\n",
       "  'gain': -0.5451955426984135,\n",
       "  'price': 1.3675016080273763,\n",
       "  'steam_online': 0.11092198081555327,\n",
       "  'next_peak': -0.7424541591862043,\n",
       "  'gain_percent': -0.724138286140929},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': -0.7089076329020524,\n",
       "  'gain': -0.0373536734200744,\n",
       "  'price': 1.0391240347326416,\n",
       "  'steam_online': 0.06923106066766092,\n",
       "  'next_peak': -0.7244264662300695,\n",
       "  'gain_percent': -0.17208431718069625},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': -0.6910386706238408,\n",
       "  'gain': 0.25000449391121493,\n",
       "  'price': 1.1543442358886888,\n",
       "  'steam_online': 0.04992517228625125,\n",
       "  'next_peak': -0.6354580605189339,\n",
       "  'gain_percent': 0.1561676378501469},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': -0.6028536161372152,\n",
       "  'gain': 1.524431295097433,\n",
       "  'price': 1.3675016080273763,\n",
       "  'steam_online': 0.007603170420495132,\n",
       "  'next_peak': -0.2318692406053529,\n",
       "  'gain_percent': 1.5000599248933584},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': -0.2028183250718895,\n",
       "  'gain': -0.32716420096781024,\n",
       "  'price': 1.3675016080273763,\n",
       "  'steam_online': -0.03154104005579414,\n",
       "  'next_peak': -0.28538767970829637,\n",
       "  'gain_percent': -0.4385108005775844},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': -0.2558655436952701,\n",
       "  'gain': -0.36370818015174955,\n",
       "  'price': 1.3675016080273763,\n",
       "  'steam_online': 0.0006681471928316986,\n",
       "  'next_peak': -0.347927807508272,\n",
       "  'gain_percent': -0.4755152975687008},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': -0.3178550166273572,\n",
       "  'gain': 2.437497100451923,\n",
       "  'price': 1.1485832258308866,\n",
       "  'steam_online': -0.07159615531778402,\n",
       "  'next_peak': 0.28107148055250514,\n",
       "  'gain_percent': 2.0216957910277777},\n",
       " {'year': 0.18841466681268002,\n",
       "  'month': 1.6172779126555643,\n",
       "  'peak': 0.3056060429063397,\n",
       "  'gain': -0.8986530771071898,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.13509735585722568,\n",
       "  'next_peak': 0.08646838538637741,\n",
       "  'gain_percent': -0.7725606888184193},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': 0.11271639389756759,\n",
       "  'gain': -0.4971902737982317,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.1760867389042203,\n",
       "  'next_peak': -0.009024746503418364,\n",
       "  'gain_percent': -0.5328880879857206},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': 0.018064062303115243,\n",
       "  'gain': 0.22001708401062492,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -0.07912803418306788,\n",
       "  'next_peak': 0.0725406045050065,\n",
       "  'gain_percent': -0.010262306950843927},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': 0.09891124468662979,\n",
       "  'gain': -0.853163701071549,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.1199603591683505,\n",
       "  'next_peak': -0.11083243310361945,\n",
       "  'gain_percent': -0.7902990299571866},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': -0.08284722545386362,\n",
       "  'gain': -0.5317393278320047,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.043514722145815275,\n",
       "  'next_peak': -0.21485476233946196,\n",
       "  'gain_percent': -0.5879509928504053},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': -0.18595365630609523,\n",
       "  'gain': -0.11964115923203238,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.11784195846199476,\n",
       "  'next_peak': -0.21714155338957894,\n",
       "  'gain_percent': -0.26462337156917537},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': -0.18822031256167487,\n",
       "  'gain': -0.2220812010195563,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.04391668469005505,\n",
       "  'next_peak': -0.24471793215717616,\n",
       "  'gain_percent': -0.34974861028390897},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': -0.21555388614576365,\n",
       "  'gain': 0.760374962583714,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.08531371638804476,\n",
       "  'next_peak': -0.02975329967100822,\n",
       "  'gain_percent': 0.47754379036798156},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': -0.0024819795855957846,\n",
       "  'gain': 0.8120015924252806,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.056762608598898597,\n",
       "  'next_peak': 0.19795650707664847,\n",
       "  'gain_percent': 0.43874357353661236},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': 0.22322288220971628,\n",
       "  'gain': 0.24394347928300245,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -0.03245876816960109,\n",
       "  'next_peak': 0.28542861740931236,\n",
       "  'gain_percent': -0.016640068543362512},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': 0.30992481593651816,\n",
       "  'gain': 0.02272279861805674,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.03918262729378315,\n",
       "  'next_peak': 0.3182875148715557,\n",
       "  'gain_percent': -0.17003447205474265},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': 0.34249439656367436,\n",
       "  'gain': -0.0004920309956627198,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': -0.03188154982284182,\n",
       "  'next_peak': 0.34541531871437003,\n",
       "  'gain_percent': -0.18618241601111674},\n",
       " {'year': 0.5387481879175081,\n",
       "  'month': 1.6172779126555643,\n",
       "  'peak': 0.36938334484660007,\n",
       "  'gain': 0.5270957853104378,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.1866330061530435,\n",
       "  'next_peak': 0.5027898320111036,\n",
       "  'gain_percent': 0.14889575174657818},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': 0.5253722031266762,\n",
       "  'gain': 1.1573142413483457,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.25451824990060223,\n",
       "  'next_peak': 0.8157476957930251,\n",
       "  'gain_percent': 0.5005650682459795},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': 0.8355745277500166,\n",
       "  'gain': 2.799112226876029,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.20757463280487903,\n",
       "  'next_peak': 1.5340196676607696,\n",
       "  'gain_percent': 1.2924611121540182},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': 1.5475222407508484,\n",
       "  'gain': 1.9193883552415174,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.7798753299142843,\n",
       "  'next_peak': 2.0351123644067046,\n",
       "  'gain_percent': 0.6080025314486524},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': 2.0442029040962595,\n",
       "  'gain': -1.5380202344707015,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.2230247911222596,\n",
       "  'next_peak': 1.682667359693545,\n",
       "  'gain_percent': -0.7908668127980194},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': 1.6948611158992062,\n",
       "  'gain': -2.4470072438175263,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.14284554696449,\n",
       "  'next_peak': 1.1058188277482615,\n",
       "  'gain_percent': -1.213099642373831},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': 1.1230916342105186,\n",
       "  'gain': -2.0405888939571994,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.7942935360938143,\n",
       "  'next_peak': 0.6293036452378086,\n",
       "  'gain_percent': -1.1906764379942414},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': 0.6507720843938682,\n",
       "  'gain': 0.7509721306657324,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.7808152314653127,\n",
       "  'next_peak': 0.8419469809104148,\n",
       "  'gain_percent': 0.2335518916818577},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': 0.8615431327522131,\n",
       "  'gain': 0.5557108900121872,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.7942310936009694,\n",
       "  'next_peak': 1.0063857650505823,\n",
       "  'gain_percent': 0.09457592360824388},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': 1.0245340622086478,\n",
       "  'gain': -0.5410405075130351,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 0.8542886001185327,\n",
       "  'next_peak': 0.9000672341018652,\n",
       "  'gain_percent': -0.4720233426474147},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': 0.9191516472973157,\n",
       "  'gain': 1.0788005948331993,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.080520830282274,\n",
       "  'next_peak': 1.1936422694905455,\n",
       "  'gain_percent': 0.3583050119622185},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': 1.2101418059354343,\n",
       "  'gain': 1.502487118445603,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.0733925127326691,\n",
       "  'next_peak': 1.591813684543287,\n",
       "  'gain_percent': 0.5022325247855858},\n",
       " {'year': 0.8890817090223363,\n",
       "  'month': 1.6172779126555643,\n",
       "  'peak': 1.6048073914405596,\n",
       "  'gain': -0.6166443587454549,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.3893288725075583,\n",
       "  'next_peak': 1.4668306724584985,\n",
       "  'gain_percent': -0.46925675165447317},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': 1.4809248328794347,\n",
       "  'gain': -0.12394867277283747,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.4949189470948472,\n",
       "  'next_peak': 1.4634804765167633,\n",
       "  'gain_percent': -0.2628293208584154},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': 1.477604134825993,\n",
       "  'gain': 0.8438314491206103,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.2371777439903415,\n",
       "  'next_peak': 1.6990481866670855,\n",
       "  'gain_percent': 0.15781691746921356},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': 1.7110977125612596,\n",
       "  'gain': -0.7521086710124845,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.6392709021467982,\n",
       "  'next_peak': 1.5406228160290771,\n",
       "  'gain_percent': -0.5183924472118976},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': 1.5540672495546826,\n",
       "  'gain': -0.8839516223381293,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.4921460255393502,\n",
       "  'next_peak': 1.3496490997998292,\n",
       "  'gain_percent': -0.5859727930288088},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': 1.3647750234371392,\n",
       "  'gain': -2.1085688274182828,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.487508184682575,\n",
       "  'next_peak': 0.8563515687048415,\n",
       "  'gain_percent': -1.1544521145748505},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': 0.8758208906748767,\n",
       "  'gain': -2.224960638727352,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.3051460715120042,\n",
       "  'next_peak': 0.3343201473230617,\n",
       "  'gain_percent': -1.3673456776598594},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': 0.35838586449545434,\n",
       "  'gain': 0.38544339311900677,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.320062761303164,\n",
       "  'next_peak': 0.4567246378122451,\n",
       "  'gain_percent': 0.06017847747710097},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': 0.4797126048918516,\n",
       "  'gain': 1.6682183842648384,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.3896078343324474,\n",
       "  'next_peak': 0.8958104776478065,\n",
       "  'gain_percent': 0.825299551225167},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': 0.9149323708380268,\n",
       "  'gain': -1.0958075906739502,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.246424585960759,\n",
       "  'next_peak': 0.6525354346989422,\n",
       "  'gain_percent': -0.7674987710909469},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': 0.6737993220191397,\n",
       "  'gain': 0.7870459682537726,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.4764514906188118,\n",
       "  'next_peak': 0.8740843942279023,\n",
       "  'gain_percent': 0.249718283945934},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': 0.8933975817761,\n",
       "  'gain': 0.08013089943622013,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.4090094586702724,\n",
       "  'next_peak': 0.9211157498032163,\n",
       "  'gain_percent': -0.1575007845340622},\n",
       " {'year': 1.2394152301271644,\n",
       "  'month': 1.6172779126555643,\n",
       "  'peak': 0.9400148345057374,\n",
       "  'gain': 0.411085169889935,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.6182958059762038,\n",
       "  'next_peak': 1.0498504794407344,\n",
       "  'gain_percent': 0.010946940578600673},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': -1.5903232807779717,\n",
       "  'peak': 1.0676160774038628,\n",
       "  'gain': -0.0654223973482114,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.859610669841641,\n",
       "  'next_peak': 1.0609487877196286,\n",
       "  'gain_percent': -0.23479775857939428},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': -1.298723172284014,\n",
       "  'peak': 1.0786166670228488,\n",
       "  'gain': -0.20148391650732905,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.5377792924184999,\n",
       "  'next_peak': 1.038457303728766,\n",
       "  'gain_percent': -0.30164232907260236},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': -1.0071230637900561,\n",
       "  'peak': 1.0563232166078884,\n",
       "  'gain': 0.21038553455950323,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.8628277500875752,\n",
       "  'next_peak': 1.117644893947083,\n",
       "  'gain_percent': -0.09839427683866495},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': -0.7155229552960982,\n",
       "  'peak': 1.1348135739684546,\n",
       "  'gain': -1.244321508859584,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.7164832880636045,\n",
       "  'next_peak': 0.8377059088942855,\n",
       "  'gain_percent': -0.8034408514329753},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': -0.42392284680214043,\n",
       "  'peak': 0.8573394026321257,\n",
       "  'gain': -0.33053143131681717,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.7317652400296286,\n",
       "  'next_peak': 0.7833561945810801,\n",
       "  'gain_percent': -0.373286964122541},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': -0.13232273830818259,\n",
       "  'peak': 0.8034682280310653,\n",
       "  'gain': 0.16483262587576797,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.6473295904760248,\n",
       "  'next_peak': 0.8512980428039658,\n",
       "  'gain_percent': -0.10870864739965096},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': 0.15927737018577523,\n",
       "  'peak': 0.8708118601841512,\n",
       "  'gain': 1.3071623451439633,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.694334470019007,\n",
       "  'next_peak': 1.2012492218863393,\n",
       "  'gain_percent': 0.4887340338613021},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': 0.4508774786797331,\n",
       "  'peak': 1.217681780448165,\n",
       "  'gain': 0.6580746926219978,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.6833468752375034,\n",
       "  'next_peak': 1.3909587724184718,\n",
       "  'gain_percent': 0.10392763390922954},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': 0.742477587173691,\n",
       "  'peak': 1.405720971626067,\n",
       "  'gain': -0.3836447251237944,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.6532241370576921,\n",
       "  'next_peak': 1.323496867996228,\n",
       "  'gain_percent': -0.37820901860055517},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': 1.0340776956676487,\n",
       "  'peak': 1.338853057452547,\n",
       "  'gain': 0.5279344162652848,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.8997774374007128,\n",
       "  'next_peak': 1.4810784158736305,\n",
       "  'gain_percent': 0.03198629928930976},\n",
       " {'year': 1.5897487512319926,\n",
       "  'month': 1.3256778041616066,\n",
       "  'peak': 1.4950471274100832,\n",
       "  'gain': -0.9237992992229811,\n",
       "  'price': -0.8216822139375214,\n",
       "  'steam_online': 1.909631036923527,\n",
       "  'next_peak': 1.280267420175018,\n",
       "  'gain_percent': -0.608738444923468}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_csgo_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力信号\n",
    "x = list()\n",
    "# 教師信号\n",
    "y = list()\n",
    "\n",
    "# 過去○ヶ月分から教師信号を取るためSPLIT_SIZEからデータ数回繰り返す\n",
    "for i in range(SPLIT_SIZE, len(standardized_csgo_datas)):\n",
    "    # 入力信号を一時的に補完する箱\n",
    "    tmp = list()\n",
    "    y_tmp = list()\n",
    "    # i - SPLIT_SIZEは前のfor文からみると0であり[0~データの個数]\n",
    "    for D in standardized_csgo_datas[i - SPLIT_SIZE : i]:\n",
    "        # \n",
    "        tmp_tmp = list()\n",
    "        # Kには特定の変数の値を取るためのKeyが渡されている\n",
    "        for K in D.keys():\n",
    "            # 入力信号に入れるKeyだった時、tmp_tmpに要素を入れる\n",
    "            if K in {\"peak\", \"steam_online\", \"price\"}:\n",
    "                tmp_tmp.append( D[K] )\n",
    "        # tmp_tmpに入れた全ての入力信号をtmpに入れる\n",
    "        tmp.append( tmp_tmp )\n",
    "        y_tmp.append(D[\"gain_percent\"])\n",
    "    # 入力信号に入れる\n",
    "    x.append( tmp )\n",
    "    # SPLIT_SIZEより前の教師信号は使わないので、それより後の教師信号を追加している\n",
    "    y.append( y_tmp )\n",
    "\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50223252, -0.46925675, -0.26282932,  0.15781692, -0.51839245,\n",
       "       -0.58597279, -1.15445211, -1.36734568,  0.06017848,  0.82529955,\n",
       "       -0.76749877,  0.24971828, -0.15750078,  0.01094694, -0.23479776,\n",
       "       -0.30164233, -0.09839428, -0.80344085, -0.37328696, -0.10870865,\n",
       "        0.48873403,  0.10392763, -0.37820902,  0.0319863 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104, 3, 3), (104, 3), (12, 3, 3), (12, 3))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの分割をしている　また分割した配列に番号付けをしている\n",
    "train_index, test_index = train_test_split(list(range(len(x))), test_size = 0.1, )\n",
    "# 番号付けをしたデータをもとにtrain_x,yの分割をしている\n",
    "train_x, train_y = x[train_index], y[train_index]\n",
    "# test_x,yも同様の動きを行っている\n",
    "test_x, test_y = x[test_index], y[test_index]\n",
    "\n",
    "#各問題とテストデータの形を出力している\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNで試す(1層)equence=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 3, 3)]            0         \n",
      "                                                                 \n",
      " simple_rnn_6 (SimpleRNN)    (None, 1024)              1052672   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,053,697\n",
      "Trainable params: 1,053,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 1.0385 - val_loss: 0.8964\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9882 - val_loss: 0.8881\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9523 - val_loss: 0.8913\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9283 - val_loss: 0.9042\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9126 - val_loss: 0.9244\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9025 - val_loss: 0.9491\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8967 - val_loss: 0.9740\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8941 - val_loss: 0.9948\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8934 - val_loss: 1.0086\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8928 - val_loss: 1.0144\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8913 - val_loss: 1.0126\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8882 - val_loss: 1.0047\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8835 - val_loss: 0.9924\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8779 - val_loss: 0.9775\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8721 - val_loss: 0.9615\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8666 - val_loss: 0.9458\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8620 - val_loss: 0.9311\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8582 - val_loss: 0.9183\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8552 - val_loss: 0.9076\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8528 - val_loss: 0.8993\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8507 - val_loss: 0.8931\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8490 - val_loss: 0.8888\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8473 - val_loss: 0.8860\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8455 - val_loss: 0.8847\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8435 - val_loss: 0.8846\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8412 - val_loss: 0.8857\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8388 - val_loss: 0.8878\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8364 - val_loss: 0.8909\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8342 - val_loss: 0.8950\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8324 - val_loss: 0.8998\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8310 - val_loss: 0.9047\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8297 - val_loss: 0.9092\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8286 - val_loss: 0.9128\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8276 - val_loss: 0.9149\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8267 - val_loss: 0.9153\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8258 - val_loss: 0.9140\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8247 - val_loss: 0.9112\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8236 - val_loss: 0.9074\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8226 - val_loss: 0.9029\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8217 - val_loss: 0.8983\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8209 - val_loss: 0.8940\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8201 - val_loss: 0.8904\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8195 - val_loss: 0.8875\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8190 - val_loss: 0.8858\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8185 - val_loss: 0.8851\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8180 - val_loss: 0.8855\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8174 - val_loss: 0.8869\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8168 - val_loss: 0.8891\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8163 - val_loss: 0.8919\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8158 - val_loss: 0.8948\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8153 - val_loss: 0.8974\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8149 - val_loss: 0.8994\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8145 - val_loss: 0.9006\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8141 - val_loss: 0.9008\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8137 - val_loss: 0.9002\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8133 - val_loss: 0.8987\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8129 - val_loss: 0.8968\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8125 - val_loss: 0.8948\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8122 - val_loss: 0.8928\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8118 - val_loss: 0.8913\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8115 - val_loss: 0.8903\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8112 - val_loss: 0.8899\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8108 - val_loss: 0.8901\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8105 - val_loss: 0.8909\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8102 - val_loss: 0.8919\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8099 - val_loss: 0.8930\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8096 - val_loss: 0.8941\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8093 - val_loss: 0.8949\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8090 - val_loss: 0.8953\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8087 - val_loss: 0.8953\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8084 - val_loss: 0.8950\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8081 - val_loss: 0.8945\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8078 - val_loss: 0.8938\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8076 - val_loss: 0.8930\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8073 - val_loss: 0.8924\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8070 - val_loss: 0.8919\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8068 - val_loss: 0.8916\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8065 - val_loss: 0.8915\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8062 - val_loss: 0.8917\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8060 - val_loss: 0.8920\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8058 - val_loss: 0.8924\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8055 - val_loss: 0.8928\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8053 - val_loss: 0.8932\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8050 - val_loss: 0.8935\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8048 - val_loss: 0.8936\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8046 - val_loss: 0.8934\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8043 - val_loss: 0.8930\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8041 - val_loss: 0.8926\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8039 - val_loss: 0.8922\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8037 - val_loss: 0.8920\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8035 - val_loss: 0.8919\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8032 - val_loss: 0.8919\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8030 - val_loss: 0.8921\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8028 - val_loss: 0.8923\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8026 - val_loss: 0.8924\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8024 - val_loss: 0.8925\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8022 - val_loss: 0.8925\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8020 - val_loss: 0.8925\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8018 - val_loss: 0.8923\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8016 - val_loss: 0.8921\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8014 - val_loss: 0.8919\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8012 - val_loss: 0.8919\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8010 - val_loss: 0.8920\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8008 - val_loss: 0.8922\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8006 - val_loss: 0.8923\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8004 - val_loss: 0.8924\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8002 - val_loss: 0.8923\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8000 - val_loss: 0.8921\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7998 - val_loss: 0.8920\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7996 - val_loss: 0.8918\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7994 - val_loss: 0.8918\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7992 - val_loss: 0.8919\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7990 - val_loss: 0.8920\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7988 - val_loss: 0.8920\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7986 - val_loss: 0.8919\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7985 - val_loss: 0.8917\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7983 - val_loss: 0.8915\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7981 - val_loss: 0.8914\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7979 - val_loss: 0.8914\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7977 - val_loss: 0.8914\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7976 - val_loss: 0.8915\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7974 - val_loss: 0.8916\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7972 - val_loss: 0.8916\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7970 - val_loss: 0.8917\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7969 - val_loss: 0.8917\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7967 - val_loss: 0.8917\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7965 - val_loss: 0.8916\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7963 - val_loss: 0.8915\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7962 - val_loss: 0.8914\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7960 - val_loss: 0.8915\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7958 - val_loss: 0.8916\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7957 - val_loss: 0.8919\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7955 - val_loss: 0.8922\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7953 - val_loss: 0.8921\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7952 - val_loss: 0.8917\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7950 - val_loss: 0.8914\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7948 - val_loss: 0.8912\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7947 - val_loss: 0.8911\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7945 - val_loss: 0.8913\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7943 - val_loss: 0.8915\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7942 - val_loss: 0.8917\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7940 - val_loss: 0.8917\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7938 - val_loss: 0.8915\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7937 - val_loss: 0.8913\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7935 - val_loss: 0.8911\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7934 - val_loss: 0.8910\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7932 - val_loss: 0.8911\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7930 - val_loss: 0.8913\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7929 - val_loss: 0.8913\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7927 - val_loss: 0.8912\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7926 - val_loss: 0.8911\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7924 - val_loss: 0.8911\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7922 - val_loss: 0.8911\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7921 - val_loss: 0.8911\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7919 - val_loss: 0.8909\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7918 - val_loss: 0.8908\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7916 - val_loss: 0.8908\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7914 - val_loss: 0.8910\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7913 - val_loss: 0.8911\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7911 - val_loss: 0.8909\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7910 - val_loss: 0.8906\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7908 - val_loss: 0.8903\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7907 - val_loss: 0.8903\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7905 - val_loss: 0.8904\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7904 - val_loss: 0.8906\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7902 - val_loss: 0.8908\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7901 - val_loss: 0.8907\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7899 - val_loss: 0.8905\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7898 - val_loss: 0.8904\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7896 - val_loss: 0.8903\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7895 - val_loss: 0.8903\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7893 - val_loss: 0.8903\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7892 - val_loss: 0.8903\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7890 - val_loss: 0.8905\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7888 - val_loss: 0.8906\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7887 - val_loss: 0.8905\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7885 - val_loss: 0.8904\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7884 - val_loss: 0.8902\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7883 - val_loss: 0.8900\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7881 - val_loss: 0.8901\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7880 - val_loss: 0.8903\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7878 - val_loss: 0.8904\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7877 - val_loss: 0.8905\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7875 - val_loss: 0.8903\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7874 - val_loss: 0.8901\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7872 - val_loss: 0.8900\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7871 - val_loss: 0.8901\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7869 - val_loss: 0.8903\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7868 - val_loss: 0.8903\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7866 - val_loss: 0.8901\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7865 - val_loss: 0.8901\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7863 - val_loss: 0.8902\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7862 - val_loss: 0.8904\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7861 - val_loss: 0.8904\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7859 - val_loss: 0.8902\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7858 - val_loss: 0.8900\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7856 - val_loss: 0.8900\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7855 - val_loss: 0.8901\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7854 - val_loss: 0.8903\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7852 - val_loss: 0.8902\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7851 - val_loss: 0.8901\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7849 - val_loss: 0.8901\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7848 - val_loss: 0.8902\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7847 - val_loss: 0.8902\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7845 - val_loss: 0.8905\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7844 - val_loss: 0.8905\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7843 - val_loss: 0.8903\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7841 - val_loss: 0.8900\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7840 - val_loss: 0.8900\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7838 - val_loss: 0.8902\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7837 - val_loss: 0.8904\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7836 - val_loss: 0.8903\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7834 - val_loss: 0.8903\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7833 - val_loss: 0.8905\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7832 - val_loss: 0.8904\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7830 - val_loss: 0.8902\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7829 - val_loss: 0.8901\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7828 - val_loss: 0.8903\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7826 - val_loss: 0.8905\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7825 - val_loss: 0.8906\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7824 - val_loss: 0.8906\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7823 - val_loss: 0.8904\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7821 - val_loss: 0.8903\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7820 - val_loss: 0.8904\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7819 - val_loss: 0.8906\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7818 - val_loss: 0.8908\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7816 - val_loss: 0.8908\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7815 - val_loss: 0.8906\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7814 - val_loss: 0.8905\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7813 - val_loss: 0.8906\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7811 - val_loss: 0.8908\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7810 - val_loss: 0.8909\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7809 - val_loss: 0.8907\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7808 - val_loss: 0.8906\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7807 - val_loss: 0.8907\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7805 - val_loss: 0.8909\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7804 - val_loss: 0.8909\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7803 - val_loss: 0.8907\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7802 - val_loss: 0.8906\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7800 - val_loss: 0.8906\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7799 - val_loss: 0.8907\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7798 - val_loss: 0.8908\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7797 - val_loss: 0.8908\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7796 - val_loss: 0.8907\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7795 - val_loss: 0.8908\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7793 - val_loss: 0.8910\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7792 - val_loss: 0.8909\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7791 - val_loss: 0.8908\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7790 - val_loss: 0.8912\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7789 - val_loss: 0.8912\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7788 - val_loss: 0.8906\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7787 - val_loss: 0.8907\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7785 - val_loss: 0.8910\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7784 - val_loss: 0.8911\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7783 - val_loss: 0.8910\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7782 - val_loss: 0.8910\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7781 - val_loss: 0.8914\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7780 - val_loss: 0.8914\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7779 - val_loss: 0.8914\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7778 - val_loss: 0.8912\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7777 - val_loss: 0.8909\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7776 - val_loss: 0.8912\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7774 - val_loss: 0.8916\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7773 - val_loss: 0.8914\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7772 - val_loss: 0.8910\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7771 - val_loss: 0.8914\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7770 - val_loss: 0.8916\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7769 - val_loss: 0.8915\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7768 - val_loss: 0.8910\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7767 - val_loss: 0.8910\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7766 - val_loss: 0.8914\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7765 - val_loss: 0.8914\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7764 - val_loss: 0.8912\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7763 - val_loss: 0.8915\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7762 - val_loss: 0.8918\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7761 - val_loss: 0.8914\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7760 - val_loss: 0.8913\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7758 - val_loss: 0.8918\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7757 - val_loss: 0.8916\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7756 - val_loss: 0.8915\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7755 - val_loss: 0.8917\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7754 - val_loss: 0.8917\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7753 - val_loss: 0.8910\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7752 - val_loss: 0.8920\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7751 - val_loss: 0.8916\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7750 - val_loss: 0.8913\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7749 - val_loss: 0.8912\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7748 - val_loss: 0.8924\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7747 - val_loss: 0.8908\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7747 - val_loss: 0.8919\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7746 - val_loss: 0.8912\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7744 - val_loss: 0.8917\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7743 - val_loss: 0.8914\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7742 - val_loss: 0.8911\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7741 - val_loss: 0.8916\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7740 - val_loss: 0.8907\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7740 - val_loss: 0.8926\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7738 - val_loss: 0.8906\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7737 - val_loss: 0.8915\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7736 - val_loss: 0.8918\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7735 - val_loss: 0.8906\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7734 - val_loss: 0.8924\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7733 - val_loss: 0.8912\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7732 - val_loss: 0.8912\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7731 - val_loss: 0.8915\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7730 - val_loss: 0.8914\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7729 - val_loss: 0.8912\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7728 - val_loss: 0.8909\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7727 - val_loss: 0.8923\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7726 - val_loss: 0.8909\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7725 - val_loss: 0.8922\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7724 - val_loss: 0.8914\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7723 - val_loss: 0.8911\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7722 - val_loss: 0.8918\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7721 - val_loss: 0.8909\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7720 - val_loss: 0.8911\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7719 - val_loss: 0.8918\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7718 - val_loss: 0.8916\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7717 - val_loss: 0.8907\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7717 - val_loss: 0.8928\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7716 - val_loss: 0.8898\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7715 - val_loss: 0.8925\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7714 - val_loss: 0.8908\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7713 - val_loss: 0.8915\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7712 - val_loss: 0.8911\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7711 - val_loss: 0.8927\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7711 - val_loss: 0.8895\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7710 - val_loss: 0.8939\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7709 - val_loss: 0.8900\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7708 - val_loss: 0.8911\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7707 - val_loss: 0.8922\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7706 - val_loss: 0.8910\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7705 - val_loss: 0.8910\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7704 - val_loss: 0.8917\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7703 - val_loss: 0.8914\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7702 - val_loss: 0.8905\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7701 - val_loss: 0.8925\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7700 - val_loss: 0.8894\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7699 - val_loss: 0.8934\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7699 - val_loss: 0.8896\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7699 - val_loss: 0.8940\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7699 - val_loss: 0.8882\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7699 - val_loss: 0.8949\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7697 - val_loss: 0.8885\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7695 - val_loss: 0.8923\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7693 - val_loss: 0.8919\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7692 - val_loss: 0.8892\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7692 - val_loss: 0.8946\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7692 - val_loss: 0.8883\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7691 - val_loss: 0.8932\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7689 - val_loss: 0.8914\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7688 - val_loss: 0.8901\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7687 - val_loss: 0.8933\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7687 - val_loss: 0.8894\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7687 - val_loss: 0.8938\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7686 - val_loss: 0.8894\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7684 - val_loss: 0.8926\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7683 - val_loss: 0.8914\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7682 - val_loss: 0.8905\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7682 - val_loss: 0.8936\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7681 - val_loss: 0.8892\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7680 - val_loss: 0.8931\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7679 - val_loss: 0.8901\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7678 - val_loss: 0.8921\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7677 - val_loss: 0.8910\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7676 - val_loss: 0.8913\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7676 - val_loss: 0.8921\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7675 - val_loss: 0.8901\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7674 - val_loss: 0.8931\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7674 - val_loss: 0.8890\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7673 - val_loss: 0.8942\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7672 - val_loss: 0.8886\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7672 - val_loss: 0.8935\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7671 - val_loss: 0.8900\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7670 - val_loss: 0.8922\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7669 - val_loss: 0.8907\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7668 - val_loss: 0.8922\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7667 - val_loss: 0.8907\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7666 - val_loss: 0.8918\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7665 - val_loss: 0.8917\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7664 - val_loss: 0.8905\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7664 - val_loss: 0.8925\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7663 - val_loss: 0.8901\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7662 - val_loss: 0.8925\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7662 - val_loss: 0.8890\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7661 - val_loss: 0.8949\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7661 - val_loss: 0.8865\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7662 - val_loss: 0.8989\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7663 - val_loss: 0.8842\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7664 - val_loss: 0.8983\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7663 - val_loss: 0.8882\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7659 - val_loss: 0.8910\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7656 - val_loss: 0.8942\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7655 - val_loss: 0.8876\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7657 - val_loss: 0.8953\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7657 - val_loss: 0.8889\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7655 - val_loss: 0.8934\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7652 - val_loss: 0.8912\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7651 - val_loss: 0.8899\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7652 - val_loss: 0.8949\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7652 - val_loss: 0.8875\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7651 - val_loss: 0.8954\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7649 - val_loss: 0.8907\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7648 - val_loss: 0.8900\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7647 - val_loss: 0.8953\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7647 - val_loss: 0.8872\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7647 - val_loss: 0.8952\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7646 - val_loss: 0.8903\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7644 - val_loss: 0.8905\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7644 - val_loss: 0.8942\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7643 - val_loss: 0.8892\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7643 - val_loss: 0.8939\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7642 - val_loss: 0.8898\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7642 - val_loss: 0.8936\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7641 - val_loss: 0.8906\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7640 - val_loss: 0.8927\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7639 - val_loss: 0.8919\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7638 - val_loss: 0.8919\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7638 - val_loss: 0.8933\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7637 - val_loss: 0.8902\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7637 - val_loss: 0.8952\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7636 - val_loss: 0.8888\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7635 - val_loss: 0.8956\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7635 - val_loss: 0.8901\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7634 - val_loss: 0.8946\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7633 - val_loss: 0.8912\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7633 - val_loss: 0.8946\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7632 - val_loss: 0.8903\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7631 - val_loss: 0.8954\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7631 - val_loss: 0.8896\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7630 - val_loss: 0.8965\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7630 - val_loss: 0.8887\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7629 - val_loss: 0.8963\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7629 - val_loss: 0.8897\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7629 - val_loss: 0.8971\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7628 - val_loss: 0.8885\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7628 - val_loss: 0.8990\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7628 - val_loss: 0.8874\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7627 - val_loss: 0.8983\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7626 - val_loss: 0.8894\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7624 - val_loss: 0.8954\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7623 - val_loss: 0.8933\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7622 - val_loss: 0.8927\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7621 - val_loss: 0.8949\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7621 - val_loss: 0.8914\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7621 - val_loss: 0.8954\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7620 - val_loss: 0.8904\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7620 - val_loss: 0.8978\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7620 - val_loss: 0.8891\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7620 - val_loss: 0.8990\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7620 - val_loss: 0.8886\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7619 - val_loss: 0.8996\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7619 - val_loss: 0.8887\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7617 - val_loss: 0.8977\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7616 - val_loss: 0.8922\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7615 - val_loss: 0.8940\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7614 - val_loss: 0.8944\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7613 - val_loss: 0.8929\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7613 - val_loss: 0.8969\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7612 - val_loss: 0.8914\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7612 - val_loss: 0.8992\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7613 - val_loss: 0.8888\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7613 - val_loss: 0.9018\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7614 - val_loss: 0.8873\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7614 - val_loss: 0.9021\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7613 - val_loss: 0.8887\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7611 - val_loss: 0.8966\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7608 - val_loss: 0.8954\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7607 - val_loss: 0.8912\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7607 - val_loss: 0.8991\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7608 - val_loss: 0.8894\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7608 - val_loss: 0.8999\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7608 - val_loss: 0.8904\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7607 - val_loss: 0.8976\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7605 - val_loss: 0.8932\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7603 - val_loss: 0.8952\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7603 - val_loss: 0.8958\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7602 - val_loss: 0.8926\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7602 - val_loss: 0.8993\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7602 - val_loss: 0.8903\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7602 - val_loss: 0.9007\n",
      "Epoch 482/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7602 - val_loss: 0.8903\n",
      "Epoch 483/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7601 - val_loss: 0.8987\n",
      "Epoch 484/1500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7600 - val_loss: 0.8931\n",
      "Epoch 485/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7599 - val_loss: 0.8955\n",
      "Epoch 486/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7598 - val_loss: 0.8969\n",
      "Epoch 487/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7597 - val_loss: 0.8933\n",
      "Epoch 488/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7597 - val_loss: 0.8987\n",
      "Epoch 489/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7597 - val_loss: 0.8924\n",
      "Epoch 490/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7596 - val_loss: 0.8988\n",
      "Epoch 491/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7596 - val_loss: 0.8919\n",
      "Epoch 492/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7596 - val_loss: 0.8996\n",
      "Epoch 493/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7596 - val_loss: 0.8915\n",
      "Epoch 494/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7596 - val_loss: 0.9011\n",
      "Epoch 495/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7595 - val_loss: 0.8902\n",
      "Epoch 496/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7594 - val_loss: 0.9014\n",
      "Epoch 497/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7594 - val_loss: 0.8917\n",
      "Epoch 498/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7592 - val_loss: 0.8991\n",
      "Epoch 499/1500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7591 - val_loss: 0.8948\n",
      "Epoch 500/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7591 - val_loss: 0.8964\n",
      "Epoch 501/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7590 - val_loss: 0.8974\n",
      "Epoch 502/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7589 - val_loss: 0.8952\n",
      "Epoch 503/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7589 - val_loss: 0.8982\n",
      "Epoch 504/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7588 - val_loss: 0.8951\n",
      "Epoch 505/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7588 - val_loss: 0.8986\n",
      "Epoch 506/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7588 - val_loss: 0.8937\n",
      "Epoch 507/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7588 - val_loss: 0.9009\n",
      "Epoch 508/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7588 - val_loss: 0.8908\n",
      "Epoch 509/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7589 - val_loss: 0.9059\n",
      "Epoch 510/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7591 - val_loss: 0.8871\n",
      "Epoch 511/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7593 - val_loss: 0.9114\n",
      "Epoch 512/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7595 - val_loss: 0.8865\n",
      "Epoch 513/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7593 - val_loss: 0.9043\n",
      "Epoch 514/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7588 - val_loss: 0.8966\n",
      "Epoch 515/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7584 - val_loss: 0.8921\n",
      "Epoch 516/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7584 - val_loss: 0.9056\n",
      "Epoch 517/1500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7586 - val_loss: 0.8906\n",
      "Epoch 518/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7588 - val_loss: 0.9029\n",
      "Epoch 519/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7587 - val_loss: 0.8961\n",
      "Epoch 520/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7584 - val_loss: 0.8965\n",
      "Epoch 521/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7581 - val_loss: 0.9005\n",
      "Epoch 522/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7581 - val_loss: 0.8951\n",
      "Epoch 523/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7583 - val_loss: 0.9023\n",
      "Epoch 524/1500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7583 - val_loss: 0.8935\n",
      "Epoch 525/1500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7582 - val_loss: 0.9033\n",
      "Epoch 526/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7580 - val_loss: 0.8945\n",
      "Epoch 527/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7578 - val_loss: 0.8989\n",
      "Epoch 528/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7578 - val_loss: 0.9010\n",
      "Epoch 529/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7578 - val_loss: 0.8928\n",
      "Epoch 530/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7578 - val_loss: 0.9056\n",
      "Epoch 531/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7578 - val_loss: 0.8936\n",
      "Epoch 532/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7577 - val_loss: 0.9006\n",
      "Epoch 533/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7575 - val_loss: 0.9003\n",
      "Epoch 534/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7575 - val_loss: 0.8949\n",
      "Epoch 535/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7575 - val_loss: 0.9039\n",
      "Epoch 536/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7575 - val_loss: 0.8943\n",
      "Epoch 537/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7575 - val_loss: 0.9016\n",
      "Epoch 538/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7574 - val_loss: 0.8987\n",
      "Epoch 539/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7574 - val_loss: 0.8992\n",
      "Epoch 540/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7573 - val_loss: 0.8999\n",
      "Epoch 541/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7572 - val_loss: 0.8993\n",
      "Epoch 542/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7572 - val_loss: 0.8996\n",
      "Epoch 543/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7571 - val_loss: 0.8985\n",
      "Epoch 544/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7571 - val_loss: 0.9015\n",
      "Epoch 545/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7571 - val_loss: 0.8963\n",
      "Epoch 546/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7571 - val_loss: 0.9045\n",
      "Epoch 547/1500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7571 - val_loss: 0.8946\n",
      "Epoch 548/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7571 - val_loss: 0.9053\n",
      "Epoch 549/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7570 - val_loss: 0.8960\n",
      "Epoch 550/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7570 - val_loss: 0.9024\n",
      "Epoch 551/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7569 - val_loss: 0.8991\n",
      "Epoch 552/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7568 - val_loss: 0.9013\n",
      "Epoch 553/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7568 - val_loss: 0.8994\n",
      "Epoch 554/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7567 - val_loss: 0.9017\n",
      "Epoch 555/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7567 - val_loss: 0.8984\n",
      "Epoch 556/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7566 - val_loss: 0.9022\n",
      "Epoch 557/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7566 - val_loss: 0.8987\n",
      "Epoch 558/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7565 - val_loss: 0.9016\n",
      "Epoch 559/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7565 - val_loss: 0.9001\n",
      "Epoch 560/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7565 - val_loss: 0.9011\n",
      "Epoch 561/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7564 - val_loss: 0.9017\n",
      "Epoch 562/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7564 - val_loss: 0.9004\n",
      "Epoch 563/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7564 - val_loss: 0.9011\n",
      "Epoch 564/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7563 - val_loss: 0.9010\n",
      "Epoch 565/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7563 - val_loss: 0.8999\n",
      "Epoch 566/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7562 - val_loss: 0.9038\n",
      "Epoch 567/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7562 - val_loss: 0.8979\n",
      "Epoch 568/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7562 - val_loss: 0.9079\n",
      "Epoch 569/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7563 - val_loss: 0.8933\n",
      "Epoch 570/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7565 - val_loss: 0.9152\n",
      "Epoch 571/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7569 - val_loss: 0.8875\n",
      "Epoch 572/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7575 - val_loss: 0.9216\n",
      "Epoch 573/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7582 - val_loss: 0.8886\n",
      "Epoch 574/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7582 - val_loss: 0.9109\n",
      "Epoch 575/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7572 - val_loss: 0.9022\n",
      "Epoch 576/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7561 - val_loss: 0.8962\n",
      "Epoch 577/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7562 - val_loss: 0.9132\n",
      "Epoch 578/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7571 - val_loss: 0.8939\n",
      "Epoch 579/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7570 - val_loss: 0.9089\n",
      "Epoch 580/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7561 - val_loss: 0.9022\n",
      "Epoch 581/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7559 - val_loss: 0.8972\n",
      "Epoch 582/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7563 - val_loss: 0.9140\n",
      "Epoch 583/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7565 - val_loss: 0.8934\n",
      "Epoch 584/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7561 - val_loss: 0.9081\n",
      "Epoch 585/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7558 - val_loss: 0.9060\n",
      "Epoch 586/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7558 - val_loss: 0.8938\n",
      "Epoch 587/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7561 - val_loss: 0.9146\n",
      "Epoch 588/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7560 - val_loss: 0.8985\n",
      "Epoch 589/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7556 - val_loss: 0.8999\n",
      "Epoch 590/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7555 - val_loss: 0.9117\n",
      "Epoch 591/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7558 - val_loss: 0.8955\n",
      "Epoch 592/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7557 - val_loss: 0.9060\n",
      "Epoch 593/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7555 - val_loss: 0.9061\n",
      "Epoch 594/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7554 - val_loss: 0.8977\n",
      "Epoch 595/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7555 - val_loss: 0.9100\n",
      "Epoch 596/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7555 - val_loss: 0.9017\n",
      "Epoch 597/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7554 - val_loss: 0.9025\n",
      "Epoch 598/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7553 - val_loss: 0.9074\n",
      "Epoch 599/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7553 - val_loss: 0.9008\n",
      "Epoch 600/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7553 - val_loss: 0.9055\n",
      "Epoch 601/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7553 - val_loss: 0.9032\n",
      "Epoch 602/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7552 - val_loss: 0.9037\n",
      "Epoch 603/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7551 - val_loss: 0.9041\n",
      "Epoch 604/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7551 - val_loss: 0.9027\n",
      "Epoch 605/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7551 - val_loss: 0.9067\n",
      "Epoch 606/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7551 - val_loss: 0.9017\n",
      "Epoch 607/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7551 - val_loss: 0.9079\n",
      "Epoch 608/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7550 - val_loss: 0.9029\n",
      "Epoch 609/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7550 - val_loss: 0.9046\n",
      "Epoch 610/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7549 - val_loss: 0.9071\n",
      "Epoch 611/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7549 - val_loss: 0.9009\n",
      "Epoch 612/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7549 - val_loss: 0.9082\n",
      "Epoch 613/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7549 - val_loss: 0.9023\n",
      "Epoch 614/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7548 - val_loss: 0.9048\n",
      "Epoch 615/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7548 - val_loss: 0.9066\n",
      "Epoch 616/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7547 - val_loss: 0.9018\n",
      "Epoch 617/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7547 - val_loss: 0.9093\n",
      "Epoch 618/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7547 - val_loss: 0.9027\n",
      "Epoch 619/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7547 - val_loss: 0.9068\n",
      "Epoch 620/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7547 - val_loss: 0.9046\n",
      "Epoch 621/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7546 - val_loss: 0.9053\n",
      "Epoch 622/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7546 - val_loss: 0.9058\n",
      "Epoch 623/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7545 - val_loss: 0.9049\n",
      "Epoch 624/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7545 - val_loss: 0.9064\n",
      "Epoch 625/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7545 - val_loss: 0.9050\n",
      "Epoch 626/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7545 - val_loss: 0.9080\n",
      "Epoch 627/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7545 - val_loss: 0.9029\n",
      "Epoch 628/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7545 - val_loss: 0.9097\n",
      "Epoch 629/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7544 - val_loss: 0.9023\n",
      "Epoch 630/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7544 - val_loss: 0.9090\n",
      "Epoch 631/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7544 - val_loss: 0.9044\n",
      "Epoch 632/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7543 - val_loss: 0.9073\n",
      "Epoch 633/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7543 - val_loss: 0.9058\n",
      "Epoch 634/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7543 - val_loss: 0.9068\n",
      "Epoch 635/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7542 - val_loss: 0.9062\n",
      "Epoch 636/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7542 - val_loss: 0.9071\n",
      "Epoch 637/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7542 - val_loss: 0.9057\n",
      "Epoch 638/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7541 - val_loss: 0.9081\n",
      "Epoch 639/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7541 - val_loss: 0.9059\n",
      "Epoch 640/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7541 - val_loss: 0.9078\n",
      "Epoch 641/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7541 - val_loss: 0.9067\n",
      "Epoch 642/1500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7540 - val_loss: 0.9071\n",
      "Epoch 643/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7540 - val_loss: 0.9068\n",
      "Epoch 644/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7540 - val_loss: 0.9074\n",
      "Epoch 645/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7540 - val_loss: 0.9068\n",
      "Epoch 646/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7540 - val_loss: 0.9085\n",
      "Epoch 647/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7539 - val_loss: 0.9058\n",
      "Epoch 648/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7539 - val_loss: 0.9118\n",
      "Epoch 649/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7540 - val_loss: 0.9023\n",
      "Epoch 650/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7540 - val_loss: 0.9163\n",
      "Epoch 651/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7541 - val_loss: 0.8991\n",
      "Epoch 652/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7543 - val_loss: 0.9205\n",
      "Epoch 653/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7546 - val_loss: 0.8963\n",
      "Epoch 654/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7548 - val_loss: 0.9213\n",
      "Epoch 655/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7549 - val_loss: 0.8985\n",
      "Epoch 656/1500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7545 - val_loss: 0.9137\n",
      "Epoch 657/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7540 - val_loss: 0.9067\n",
      "Epoch 658/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7537 - val_loss: 0.9056\n",
      "Epoch 659/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7537 - val_loss: 0.9145\n",
      "Epoch 660/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7540 - val_loss: 0.9004\n",
      "Epoch 661/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7542 - val_loss: 0.9189\n",
      "Epoch 662/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7543 - val_loss: 0.8997\n",
      "Epoch 663/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7540 - val_loss: 0.9139\n",
      "Epoch 664/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7537 - val_loss: 0.9078\n",
      "Epoch 665/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7535 - val_loss: 0.9053\n",
      "Epoch 666/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7536 - val_loss: 0.9161\n",
      "Epoch 667/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7538 - val_loss: 0.9011\n",
      "Epoch 668/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7539 - val_loss: 0.9180\n",
      "Epoch 669/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7539 - val_loss: 0.9030\n",
      "Epoch 670/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7537 - val_loss: 0.9124\n",
      "Epoch 671/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7535 - val_loss: 0.9095\n",
      "Epoch 672/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7534 - val_loss: 0.9059\n",
      "Epoch 673/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7534 - val_loss: 0.9135\n",
      "Epoch 674/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7535 - val_loss: 0.9045\n",
      "Epoch 675/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7535 - val_loss: 0.9140\n",
      "Epoch 676/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7536 - val_loss: 0.9047\n",
      "Epoch 677/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7535 - val_loss: 0.9124\n",
      "Epoch 678/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7534 - val_loss: 0.9077\n",
      "Epoch 679/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7533 - val_loss: 0.9093\n",
      "Epoch 680/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7532 - val_loss: 0.9112\n",
      "Epoch 681/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7532 - val_loss: 0.9064\n",
      "Epoch 682/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7533 - val_loss: 0.9150\n",
      "Epoch 683/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7533 - val_loss: 0.9044\n",
      "Epoch 684/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7533 - val_loss: 0.9162\n",
      "Epoch 685/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7533 - val_loss: 0.9052\n",
      "Epoch 686/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7532 - val_loss: 0.9131\n",
      "Epoch 687/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7531 - val_loss: 0.9087\n",
      "Epoch 688/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7531 - val_loss: 0.9095\n",
      "Epoch 689/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7530 - val_loss: 0.9112\n",
      "Epoch 690/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7530 - val_loss: 0.9085\n",
      "Epoch 691/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7530 - val_loss: 0.9128\n",
      "Epoch 692/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7530 - val_loss: 0.9077\n",
      "Epoch 693/1500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7530 - val_loss: 0.9137\n",
      "Epoch 694/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7530 - val_loss: 0.9069\n",
      "Epoch 695/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7530 - val_loss: 0.9145\n",
      "Epoch 696/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7531 - val_loss: 0.9063\n",
      "Epoch 697/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7530 - val_loss: 0.9156\n",
      "Epoch 698/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7530 - val_loss: 0.9059\n",
      "Epoch 699/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7530 - val_loss: 0.9156\n",
      "Epoch 700/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7529 - val_loss: 0.9074\n",
      "Epoch 701/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7529 - val_loss: 0.9138\n",
      "Epoch 702/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7528 - val_loss: 0.9085\n",
      "Epoch 703/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7528 - val_loss: 0.9122\n",
      "Epoch 704/1500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7528 - val_loss: 0.9094\n",
      "Epoch 705/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7528 - val_loss: 0.9134\n",
      "Epoch 706/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7528 - val_loss: 0.9087\n",
      "Epoch 707/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7527 - val_loss: 0.9142\n",
      "Epoch 708/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7527 - val_loss: 0.9079\n",
      "Epoch 709/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7527 - val_loss: 0.9156\n",
      "Epoch 710/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7527 - val_loss: 0.9061\n",
      "Epoch 711/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7528 - val_loss: 0.9179\n",
      "Epoch 712/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7528 - val_loss: 0.9048\n",
      "Epoch 713/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7530 - val_loss: 0.9200\n",
      "Epoch 714/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7531 - val_loss: 0.9033\n",
      "Epoch 715/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7532 - val_loss: 0.9223\n",
      "Epoch 716/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7533 - val_loss: 0.9024\n",
      "Epoch 717/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7533 - val_loss: 0.9216\n",
      "Epoch 718/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7531 - val_loss: 0.9054\n",
      "Epoch 719/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7528 - val_loss: 0.9159\n",
      "Epoch 720/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7526 - val_loss: 0.9117\n",
      "Epoch 721/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7525 - val_loss: 0.9086\n",
      "Epoch 722/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7525 - val_loss: 0.9184\n",
      "Epoch 723/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7527 - val_loss: 0.9042\n",
      "Epoch 724/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7528 - val_loss: 0.9225\n",
      "Epoch 725/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7529 - val_loss: 0.9038\n",
      "Epoch 726/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7529 - val_loss: 0.9204\n",
      "Epoch 727/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7528 - val_loss: 0.9079\n",
      "Epoch 728/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7526 - val_loss: 0.9139\n",
      "Epoch 729/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7524 - val_loss: 0.9136\n",
      "Epoch 730/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7523 - val_loss: 0.9098\n",
      "Epoch 731/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7524 - val_loss: 0.9180\n",
      "Epoch 732/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7525 - val_loss: 0.9068\n",
      "Epoch 733/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7526 - val_loss: 0.9192\n",
      "Epoch 734/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7526 - val_loss: 0.9072\n",
      "Epoch 735/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7526 - val_loss: 0.9176\n",
      "Epoch 736/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7525 - val_loss: 0.9092\n",
      "Epoch 737/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7524 - val_loss: 0.9159\n",
      "Epoch 738/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7522 - val_loss: 0.9110\n",
      "Epoch 739/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7522 - val_loss: 0.9130\n",
      "Epoch 740/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7522 - val_loss: 0.9144\n",
      "Epoch 741/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7522 - val_loss: 0.9099\n",
      "Epoch 742/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7522 - val_loss: 0.9184\n",
      "Epoch 743/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7523 - val_loss: 0.9074\n",
      "Epoch 744/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7523 - val_loss: 0.9214\n",
      "Epoch 745/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7524 - val_loss: 0.9058\n",
      "Epoch 746/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7524 - val_loss: 0.9206\n",
      "Epoch 747/1500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7524 - val_loss: 0.9085\n",
      "Epoch 748/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7523 - val_loss: 0.9168\n",
      "Epoch 749/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7522 - val_loss: 0.9122\n",
      "Epoch 750/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7521 - val_loss: 0.9148\n",
      "Epoch 751/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7521 - val_loss: 0.9130\n",
      "Epoch 752/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7520 - val_loss: 0.9138\n",
      "Epoch 753/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7520 - val_loss: 0.9136\n",
      "Epoch 754/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7520 - val_loss: 0.9124\n",
      "Epoch 755/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7520 - val_loss: 0.9168\n",
      "Epoch 756/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7520 - val_loss: 0.9095\n",
      "Epoch 757/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7521 - val_loss: 0.9214\n",
      "Epoch 758/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7522 - val_loss: 0.9064\n",
      "Epoch 759/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7523 - val_loss: 0.9242\n",
      "Epoch 760/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7523 - val_loss: 0.9061\n",
      "Epoch 761/1500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7523 - val_loss: 0.9213\n",
      "Epoch 762/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7522 - val_loss: 0.9103\n",
      "Epoch 763/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7521 - val_loss: 0.9167\n",
      "Epoch 764/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7520 - val_loss: 0.9138\n",
      "Epoch 765/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7519 - val_loss: 0.9146\n",
      "Epoch 766/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7518 - val_loss: 0.9153\n",
      "Epoch 767/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7518 - val_loss: 0.9131\n",
      "Epoch 768/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7518 - val_loss: 0.9168\n",
      "Epoch 769/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7519 - val_loss: 0.9115\n",
      "Epoch 770/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7520 - val_loss: 0.9203\n",
      "Epoch 771/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7520 - val_loss: 0.9070\n",
      "Epoch 772/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7521 - val_loss: 0.9250\n",
      "Epoch 773/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7522 - val_loss: 0.9055\n",
      "Epoch 774/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7522 - val_loss: 0.9248\n",
      "Epoch 775/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7521 - val_loss: 0.9092\n",
      "Epoch 776/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7519 - val_loss: 0.9189\n",
      "Epoch 777/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7518 - val_loss: 0.9147\n",
      "Epoch 778/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7517 - val_loss: 0.9136\n",
      "Epoch 779/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7517 - val_loss: 0.9183\n",
      "Epoch 780/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7517 - val_loss: 0.9115\n",
      "Epoch 781/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7517 - val_loss: 0.9196\n",
      "Epoch 782/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7518 - val_loss: 0.9110\n",
      "Epoch 783/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7518 - val_loss: 0.9210\n",
      "Epoch 784/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7519 - val_loss: 0.9100\n",
      "Epoch 785/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7519 - val_loss: 0.9232\n",
      "Epoch 786/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7519 - val_loss: 0.9087\n",
      "Epoch 787/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7519 - val_loss: 0.9231\n",
      "Epoch 788/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7518 - val_loss: 0.9099\n",
      "Epoch 789/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7517 - val_loss: 0.9199\n",
      "Epoch 790/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7516 - val_loss: 0.9142\n",
      "Epoch 791/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7515 - val_loss: 0.9151\n",
      "Epoch 792/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - val_loss: 0.9191\n",
      "Epoch 793/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7515 - val_loss: 0.9118\n",
      "Epoch 794/1500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7515 - val_loss: 0.9219\n",
      "Epoch 795/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7516 - val_loss: 0.9105\n",
      "Epoch 796/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7516 - val_loss: 0.9223\n",
      "Epoch 797/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7517 - val_loss: 0.9106\n",
      "Epoch 798/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7517 - val_loss: 0.9224\n",
      "Epoch 799/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7518 - val_loss: 0.9107\n",
      "Epoch 800/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7518 - val_loss: 0.9225\n",
      "Epoch 801/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7517 - val_loss: 0.9110\n",
      "Epoch 802/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7516 - val_loss: 0.9215\n",
      "Epoch 803/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7515 - val_loss: 0.9133\n",
      "Epoch 804/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7514 - val_loss: 0.9183\n",
      "Epoch 805/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7514 - val_loss: 0.9168\n",
      "Epoch 806/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7513 - val_loss: 0.9146\n",
      "Epoch 807/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7513 - val_loss: 0.9203\n",
      "Epoch 808/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7514 - val_loss: 0.9121\n",
      "Epoch 809/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7514 - val_loss: 0.9235\n",
      "Epoch 810/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7515 - val_loss: 0.9102\n",
      "Epoch 811/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7515 - val_loss: 0.9252\n",
      "Epoch 812/1500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7516 - val_loss: 0.9103\n",
      "Epoch 813/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7516 - val_loss: 0.9245\n",
      "Epoch 814/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7517 - val_loss: 0.9117\n",
      "Epoch 815/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7517 - val_loss: 0.9227\n",
      "Epoch 816/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7516 - val_loss: 0.9130\n",
      "Epoch 817/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7514 - val_loss: 0.9208\n",
      "Epoch 818/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7513 - val_loss: 0.9150\n",
      "Epoch 819/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7512 - val_loss: 0.9182\n",
      "Epoch 820/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7512 - val_loss: 0.9179\n",
      "Epoch 821/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7512 - val_loss: 0.9152\n",
      "Epoch 822/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7512 - val_loss: 0.9222\n",
      "Epoch 823/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7513 - val_loss: 0.9114\n",
      "Epoch 824/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7514 - val_loss: 0.9259\n",
      "Epoch 825/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7514 - val_loss: 0.9100\n",
      "Epoch 826/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7515 - val_loss: 0.9256\n",
      "Epoch 827/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7514 - val_loss: 0.9121\n",
      "Epoch 828/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7514 - val_loss: 0.9226\n",
      "Epoch 829/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7513 - val_loss: 0.9150\n",
      "Epoch 830/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7512 - val_loss: 0.9196\n",
      "Epoch 831/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7512 - val_loss: 0.9173\n",
      "Epoch 832/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7511 - val_loss: 0.9187\n",
      "Epoch 833/1500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7511 - val_loss: 0.9183\n",
      "Epoch 834/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7511 - val_loss: 0.9178\n",
      "Epoch 835/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7511 - val_loss: 0.9200\n",
      "Epoch 836/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7511 - val_loss: 0.9153\n",
      "Epoch 837/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7511 - val_loss: 0.9233\n",
      "Epoch 838/1500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7512 - val_loss: 0.9116\n",
      "Epoch 839/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7512 - val_loss: 0.9267\n",
      "Epoch 840/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7513 - val_loss: 0.9108\n",
      "Epoch 841/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7513 - val_loss: 0.9272\n",
      "Epoch 842/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7513 - val_loss: 0.9119\n",
      "Epoch 843/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7513 - val_loss: 0.9247\n",
      "Epoch 844/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7512 - val_loss: 0.9143\n",
      "Epoch 845/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7512 - val_loss: 0.9217\n",
      "Epoch 846/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7511 - val_loss: 0.9168\n",
      "Epoch 847/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7510 - val_loss: 0.9204\n",
      "Epoch 848/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7509 - val_loss: 0.9173\n",
      "Epoch 849/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7509 - val_loss: 0.9201\n",
      "Epoch 850/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7509 - val_loss: 0.9182\n",
      "Epoch 851/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7509 - val_loss: 0.9180\n",
      "Epoch 852/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7509 - val_loss: 0.9209\n",
      "Epoch 853/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7509 - val_loss: 0.9147\n",
      "Epoch 854/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7509 - val_loss: 0.9250\n",
      "Epoch 855/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7510 - val_loss: 0.9126\n",
      "Epoch 856/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7511 - val_loss: 0.9275\n",
      "Epoch 857/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7511 - val_loss: 0.9113\n",
      "Epoch 858/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7512 - val_loss: 0.9286\n",
      "Epoch 859/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7513 - val_loss: 0.9114\n",
      "Epoch 860/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7513 - val_loss: 0.9265\n",
      "Epoch 861/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7513 - val_loss: 0.9139\n",
      "Epoch 862/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7512 - val_loss: 0.9246\n",
      "Epoch 863/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7511 - val_loss: 0.9152\n",
      "Epoch 864/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7509 - val_loss: 0.9232\n",
      "Epoch 865/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7508 - val_loss: 0.9169\n",
      "Epoch 866/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7508 - val_loss: 0.9197\n",
      "Epoch 867/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7508 - val_loss: 0.9211\n",
      "Epoch 868/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7508 - val_loss: 0.9159\n",
      "Epoch 869/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7508 - val_loss: 0.9258\n",
      "Epoch 870/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7509 - val_loss: 0.9123\n",
      "Epoch 871/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7510 - val_loss: 0.9284\n",
      "Epoch 872/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7510 - val_loss: 0.9117\n",
      "Epoch 873/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7510 - val_loss: 0.9263\n",
      "Epoch 874/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7509 - val_loss: 0.9152\n",
      "Epoch 875/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7509 - val_loss: 0.9225\n",
      "Epoch 876/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7508 - val_loss: 0.9185\n",
      "Epoch 877/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7508 - val_loss: 0.9213\n",
      "Epoch 878/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7507 - val_loss: 0.9193\n",
      "Epoch 879/1500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7507 - val_loss: 0.9212\n",
      "Epoch 880/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7506 - val_loss: 0.9195\n",
      "Epoch 881/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7506 - val_loss: 0.9199\n",
      "Epoch 882/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7506 - val_loss: 0.9206\n",
      "Epoch 883/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7506 - val_loss: 0.9174\n",
      "Epoch 884/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7507 - val_loss: 0.9243\n",
      "Epoch 885/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7507 - val_loss: 0.9141\n",
      "Epoch 886/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7508 - val_loss: 0.9287\n",
      "Epoch 887/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7509 - val_loss: 0.9122\n",
      "Epoch 888/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7509 - val_loss: 0.9297\n",
      "Epoch 889/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7510 - val_loss: 0.9128\n",
      "Epoch 890/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7510 - val_loss: 0.9269\n",
      "Epoch 891/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7510 - val_loss: 0.9148\n",
      "Epoch 892/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7509 - val_loss: 0.9246\n",
      "Epoch 893/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7508 - val_loss: 0.9174\n",
      "Epoch 894/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7507 - val_loss: 0.9240\n",
      "Epoch 895/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7506 - val_loss: 0.9188\n",
      "Epoch 896/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7505 - val_loss: 0.9229\n",
      "Epoch 897/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7505 - val_loss: 0.9197\n",
      "Epoch 898/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7505 - val_loss: 0.9204\n",
      "Epoch 899/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7505 - val_loss: 0.9230\n",
      "Epoch 900/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7505 - val_loss: 0.9155\n",
      "Epoch 901/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7506 - val_loss: 0.9272\n",
      "Epoch 902/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7506 - val_loss: 0.9132\n",
      "Epoch 903/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7506 - val_loss: 0.9286\n",
      "Epoch 904/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7507 - val_loss: 0.9137\n",
      "Epoch 905/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7507 - val_loss: 0.9271\n",
      "Epoch 906/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7507 - val_loss: 0.9160\n",
      "Epoch 907/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7507 - val_loss: 0.9255\n",
      "Epoch 908/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7507 - val_loss: 0.9174\n",
      "Epoch 909/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7506 - val_loss: 0.9259\n",
      "Epoch 910/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7506 - val_loss: 0.9164\n",
      "Epoch 911/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7505 - val_loss: 0.9272\n",
      "Epoch 912/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7505 - val_loss: 0.9153\n",
      "Epoch 913/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7505 - val_loss: 0.9255\n",
      "Epoch 914/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7504 - val_loss: 0.9184\n",
      "Epoch 915/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7504 - val_loss: 0.9213\n",
      "Epoch 916/1500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7504 - val_loss: 0.9225\n",
      "Epoch 917/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7503 - val_loss: 0.9193\n",
      "Epoch 918/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7504 - val_loss: 0.9244\n",
      "Epoch 919/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7504 - val_loss: 0.9183\n",
      "Epoch 920/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7503 - val_loss: 0.9251\n",
      "Epoch 921/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7503 - val_loss: 0.9178\n",
      "Epoch 922/1500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7504 - val_loss: 0.9254\n",
      "Epoch 923/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7504 - val_loss: 0.9177\n",
      "Epoch 924/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7505 - val_loss: 0.9268\n",
      "Epoch 925/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7506 - val_loss: 0.9151\n",
      "Epoch 926/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7507 - val_loss: 0.9307\n",
      "Epoch 927/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7509 - val_loss: 0.9110\n",
      "Epoch 928/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7510 - val_loss: 0.9344\n",
      "Epoch 929/1500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7510 - val_loss: 0.9108\n",
      "Epoch 930/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7509 - val_loss: 0.9325\n",
      "Epoch 931/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7507 - val_loss: 0.9151\n",
      "Epoch 932/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7505 - val_loss: 0.9238\n",
      "Epoch 933/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7503 - val_loss: 0.9231\n",
      "Epoch 934/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7502 - val_loss: 0.9161\n",
      "Epoch 935/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7503 - val_loss: 0.9283\n",
      "Epoch 936/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7504 - val_loss: 0.9151\n",
      "Epoch 937/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7505 - val_loss: 0.9285\n",
      "Epoch 938/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7505 - val_loss: 0.9167\n",
      "Epoch 939/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7506 - val_loss: 0.9269\n",
      "Epoch 940/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7506 - val_loss: 0.9177\n",
      "Epoch 941/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7505 - val_loss: 0.9258\n",
      "Epoch 942/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7503 - val_loss: 0.9182\n",
      "Epoch 943/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7502 - val_loss: 0.9245\n",
      "Epoch 944/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7502 - val_loss: 0.9203\n",
      "Epoch 945/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7502 - val_loss: 0.9210\n",
      "Epoch 946/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7502 - val_loss: 0.9247\n",
      "Epoch 947/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7502 - val_loss: 0.9170\n",
      "Epoch 948/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7503 - val_loss: 0.9293\n",
      "Epoch 949/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7503 - val_loss: 0.9149\n",
      "Epoch 950/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7503 - val_loss: 0.9298\n",
      "Epoch 951/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7503 - val_loss: 0.9169\n",
      "Epoch 952/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7503 - val_loss: 0.9255\n",
      "Epoch 953/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7502 - val_loss: 0.9210\n",
      "Epoch 954/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7502 - val_loss: 0.9223\n",
      "Epoch 955/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7501 - val_loss: 0.9227\n",
      "Epoch 956/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7501 - val_loss: 0.9217\n",
      "Epoch 957/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7501 - val_loss: 0.9223\n",
      "Epoch 958/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7500 - val_loss: 0.9218\n",
      "Epoch 959/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7501 - val_loss: 0.9224\n",
      "Epoch 960/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7501 - val_loss: 0.9203\n",
      "Epoch 961/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7501 - val_loss: 0.9255\n",
      "Epoch 962/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7501 - val_loss: 0.9180\n",
      "Epoch 963/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7502 - val_loss: 0.9294\n",
      "Epoch 964/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7502 - val_loss: 0.9152\n",
      "Epoch 965/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7503 - val_loss: 0.9312\n",
      "Epoch 966/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7503 - val_loss: 0.9147\n",
      "Epoch 967/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7504 - val_loss: 0.9301\n",
      "Epoch 968/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7504 - val_loss: 0.9167\n",
      "Epoch 969/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7503 - val_loss: 0.9280\n",
      "Epoch 970/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7502 - val_loss: 0.9188\n",
      "Epoch 971/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7501 - val_loss: 0.9254\n",
      "Epoch 972/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7500 - val_loss: 0.9205\n",
      "Epoch 973/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7500 - val_loss: 0.9244\n",
      "Epoch 974/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7500 - val_loss: 0.9226\n",
      "Epoch 975/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7500 - val_loss: 0.9224\n",
      "Epoch 976/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7500 - val_loss: 0.9244\n",
      "Epoch 977/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7500 - val_loss: 0.9198\n",
      "Epoch 978/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7500 - val_loss: 0.9278\n",
      "Epoch 979/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7500 - val_loss: 0.9171\n",
      "Epoch 980/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7501 - val_loss: 0.9306\n",
      "Epoch 981/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7502 - val_loss: 0.9153\n",
      "Epoch 982/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7502 - val_loss: 0.9322\n",
      "Epoch 983/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7503 - val_loss: 0.9154\n",
      "Epoch 984/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7503 - val_loss: 0.9303\n",
      "Epoch 985/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7503 - val_loss: 0.9173\n",
      "Epoch 986/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7502 - val_loss: 0.9270\n",
      "Epoch 987/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7501 - val_loss: 0.9197\n",
      "Epoch 988/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7500 - val_loss: 0.9250\n",
      "Epoch 989/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7499 - val_loss: 0.9213\n",
      "Epoch 990/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7498 - val_loss: 0.9232\n",
      "Epoch 991/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7498 - val_loss: 0.9227\n",
      "Epoch 992/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7499 - val_loss: 0.9208\n",
      "Epoch 993/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7499 - val_loss: 0.9263\n",
      "Epoch 994/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7499 - val_loss: 0.9172\n",
      "Epoch 995/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7500 - val_loss: 0.9305\n",
      "Epoch 996/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7500 - val_loss: 0.9151\n",
      "Epoch 997/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7501 - val_loss: 0.9320\n",
      "Epoch 998/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7501 - val_loss: 0.9163\n",
      "Epoch 999/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7501 - val_loss: 0.9295\n",
      "Epoch 1000/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7501 - val_loss: 0.9180\n",
      "Epoch 1001/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7500 - val_loss: 0.9267\n",
      "Epoch 1002/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7500 - val_loss: 0.9200\n",
      "Epoch 1003/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7499 - val_loss: 0.9255\n",
      "Epoch 1004/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7498 - val_loss: 0.9217\n",
      "Epoch 1005/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7498 - val_loss: 0.9253\n",
      "Epoch 1006/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7498 - val_loss: 0.9229\n",
      "Epoch 1007/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7498 - val_loss: 0.9240\n",
      "Epoch 1008/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7498 - val_loss: 0.9253\n",
      "Epoch 1009/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7498 - val_loss: 0.9204\n",
      "Epoch 1010/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7498 - val_loss: 0.9283\n",
      "Epoch 1011/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7498 - val_loss: 0.9163\n",
      "Epoch 1012/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7499 - val_loss: 0.9304\n",
      "Epoch 1013/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7500 - val_loss: 0.9161\n",
      "Epoch 1014/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7500 - val_loss: 0.9298\n",
      "Epoch 1015/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7500 - val_loss: 0.9182\n",
      "Epoch 1016/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7500 - val_loss: 0.9287\n",
      "Epoch 1017/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7500 - val_loss: 0.9192\n",
      "Epoch 1018/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7499 - val_loss: 0.9275\n",
      "Epoch 1019/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7499 - val_loss: 0.9194\n",
      "Epoch 1020/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7498 - val_loss: 0.9270\n",
      "Epoch 1021/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7497 - val_loss: 0.9198\n",
      "Epoch 1022/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7497 - val_loss: 0.9257\n",
      "Epoch 1023/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7497 - val_loss: 0.9225\n",
      "Epoch 1024/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7496 - val_loss: 0.9224\n",
      "Epoch 1025/1500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7496 - val_loss: 0.9264\n",
      "Epoch 1026/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7497 - val_loss: 0.9193\n",
      "Epoch 1027/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7497 - val_loss: 0.9286\n",
      "Epoch 1028/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7497 - val_loss: 0.9175\n",
      "Epoch 1029/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7498 - val_loss: 0.9296\n",
      "Epoch 1030/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7498 - val_loss: 0.9169\n",
      "Epoch 1031/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7499 - val_loss: 0.9305\n",
      "Epoch 1032/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7500 - val_loss: 0.9174\n",
      "Epoch 1033/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7500 - val_loss: 0.9307\n",
      "Epoch 1034/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7500 - val_loss: 0.9175\n",
      "Epoch 1035/1500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7500 - val_loss: 0.9307\n",
      "Epoch 1036/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7499 - val_loss: 0.9168\n",
      "Epoch 1037/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7498 - val_loss: 0.9291\n",
      "Epoch 1038/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7497 - val_loss: 0.9199\n",
      "Epoch 1039/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7496 - val_loss: 0.9247\n",
      "Epoch 1040/1500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7495 - val_loss: 0.9245\n",
      "Epoch 1041/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7495 - val_loss: 0.9208\n",
      "Epoch 1042/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7496 - val_loss: 0.9292\n",
      "Epoch 1043/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7497 - val_loss: 0.9175\n",
      "Epoch 1044/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7497 - val_loss: 0.9321\n",
      "Epoch 1045/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7498 - val_loss: 0.9160\n",
      "Epoch 1046/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7499 - val_loss: 0.9314\n",
      "Epoch 1047/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7499 - val_loss: 0.9167\n",
      "Epoch 1048/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7499 - val_loss: 0.9298\n",
      "Epoch 1049/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7499 - val_loss: 0.9186\n",
      "Epoch 1050/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7497 - val_loss: 0.9281\n",
      "Epoch 1051/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7496 - val_loss: 0.9206\n",
      "Epoch 1052/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7495 - val_loss: 0.9251\n",
      "Epoch 1053/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7495 - val_loss: 0.9233\n",
      "Epoch 1054/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7495 - val_loss: 0.9214\n",
      "Epoch 1055/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7495 - val_loss: 0.9272\n",
      "Epoch 1056/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7496 - val_loss: 0.9183\n",
      "Epoch 1057/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7496 - val_loss: 0.9305\n",
      "Epoch 1058/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7497 - val_loss: 0.9157\n",
      "Epoch 1059/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7498 - val_loss: 0.9316\n",
      "Epoch 1060/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7498 - val_loss: 0.9165\n",
      "Epoch 1061/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7497 - val_loss: 0.9297\n",
      "Epoch 1062/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7497 - val_loss: 0.9197\n",
      "Epoch 1063/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7496 - val_loss: 0.9270\n",
      "Epoch 1064/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7495 - val_loss: 0.9224\n",
      "Epoch 1065/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7494 - val_loss: 0.9244\n",
      "Epoch 1066/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7494 - val_loss: 0.9241\n",
      "Epoch 1067/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7494 - val_loss: 0.9228\n",
      "Epoch 1068/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7494 - val_loss: 0.9259\n",
      "Epoch 1069/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7494 - val_loss: 0.9213\n",
      "Epoch 1070/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7495 - val_loss: 0.9277\n",
      "Epoch 1071/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7495 - val_loss: 0.9188\n",
      "Epoch 1072/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7495 - val_loss: 0.9294\n",
      "Epoch 1073/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7496 - val_loss: 0.9174\n",
      "Epoch 1074/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7496 - val_loss: 0.9311\n",
      "Epoch 1075/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7496 - val_loss: 0.9171\n",
      "Epoch 1076/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7496 - val_loss: 0.9302\n",
      "Epoch 1077/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7496 - val_loss: 0.9188\n",
      "Epoch 1078/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7495 - val_loss: 0.9276\n",
      "Epoch 1079/1500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7495 - val_loss: 0.9213\n",
      "Epoch 1080/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7494 - val_loss: 0.9253\n",
      "Epoch 1081/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7494 - val_loss: 0.9236\n",
      "Epoch 1082/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7493 - val_loss: 0.9234\n",
      "Epoch 1083/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7493 - val_loss: 0.9252\n",
      "Epoch 1084/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7493 - val_loss: 0.9221\n",
      "Epoch 1085/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7493 - val_loss: 0.9260\n",
      "Epoch 1086/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7494 - val_loss: 0.9209\n",
      "Epoch 1087/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7494 - val_loss: 0.9281\n",
      "Epoch 1088/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7494 - val_loss: 0.9188\n",
      "Epoch 1089/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7495 - val_loss: 0.9301\n",
      "Epoch 1090/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7495 - val_loss: 0.9171\n",
      "Epoch 1091/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7496 - val_loss: 0.9320\n",
      "Epoch 1092/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7496 - val_loss: 0.9165\n",
      "Epoch 1093/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7497 - val_loss: 0.9325\n",
      "Epoch 1094/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7497 - val_loss: 0.9163\n",
      "Epoch 1095/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7496 - val_loss: 0.9300\n",
      "Epoch 1096/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7496 - val_loss: 0.9191\n",
      "Epoch 1097/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7495 - val_loss: 0.9266\n",
      "Epoch 1098/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7493 - val_loss: 0.9234\n",
      "Epoch 1099/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7493 - val_loss: 0.9242\n",
      "Epoch 1100/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7492 - val_loss: 0.9264\n",
      "Epoch 1101/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7493 - val_loss: 0.9218\n",
      "Epoch 1102/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7493 - val_loss: 0.9286\n",
      "Epoch 1103/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7494 - val_loss: 0.9198\n",
      "Epoch 1104/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7495 - val_loss: 0.9316\n",
      "Epoch 1105/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7495 - val_loss: 0.9173\n",
      "Epoch 1106/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7496 - val_loss: 0.9336\n",
      "Epoch 1107/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7497 - val_loss: 0.9165\n",
      "Epoch 1108/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7496 - val_loss: 0.9324\n",
      "Epoch 1109/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7495 - val_loss: 0.9183\n",
      "Epoch 1110/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7494 - val_loss: 0.9283\n",
      "Epoch 1111/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7493 - val_loss: 0.9224\n",
      "Epoch 1112/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7492 - val_loss: 0.9235\n",
      "Epoch 1113/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7492 - val_loss: 0.9272\n",
      "Epoch 1114/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7492 - val_loss: 0.9201\n",
      "Epoch 1115/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7493 - val_loss: 0.9300\n",
      "Epoch 1116/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7493 - val_loss: 0.9189\n",
      "Epoch 1117/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7494 - val_loss: 0.9307\n",
      "Epoch 1118/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7494 - val_loss: 0.9184\n",
      "Epoch 1119/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7495 - val_loss: 0.9301\n",
      "Epoch 1120/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7495 - val_loss: 0.9191\n",
      "Epoch 1121/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7494 - val_loss: 0.9283\n",
      "Epoch 1122/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7493 - val_loss: 0.9210\n",
      "Epoch 1123/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7492 - val_loss: 0.9260\n",
      "Epoch 1124/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7491 - val_loss: 0.9231\n",
      "Epoch 1125/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7491 - val_loss: 0.9238\n",
      "Epoch 1126/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7491 - val_loss: 0.9262\n",
      "Epoch 1127/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7491 - val_loss: 0.9203\n",
      "Epoch 1128/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7492 - val_loss: 0.9297\n",
      "Epoch 1129/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7492 - val_loss: 0.9179\n",
      "Epoch 1130/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7493 - val_loss: 0.9316\n",
      "Epoch 1131/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7493 - val_loss: 0.9184\n",
      "Epoch 1132/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7494 - val_loss: 0.9305\n",
      "Epoch 1133/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7493 - val_loss: 0.9200\n",
      "Epoch 1134/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7493 - val_loss: 0.9279\n",
      "Epoch 1135/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7492 - val_loss: 0.9220\n",
      "Epoch 1136/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7492 - val_loss: 0.9263\n",
      "Epoch 1137/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7491 - val_loss: 0.9236\n",
      "Epoch 1138/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7491 - val_loss: 0.9254\n",
      "Epoch 1139/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7490 - val_loss: 0.9246\n",
      "Epoch 1140/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7491 - val_loss: 0.9241\n",
      "Epoch 1141/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7491 - val_loss: 0.9266\n",
      "Epoch 1142/1500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7491 - val_loss: 0.9219\n",
      "Epoch 1143/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7491 - val_loss: 0.9290\n",
      "Epoch 1144/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7491 - val_loss: 0.9198\n",
      "Epoch 1145/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7491 - val_loss: 0.9302\n",
      "Epoch 1146/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7492 - val_loss: 0.9188\n",
      "Epoch 1147/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7492 - val_loss: 0.9301\n",
      "Epoch 1148/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7492 - val_loss: 0.9198\n",
      "Epoch 1149/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7492 - val_loss: 0.9288\n",
      "Epoch 1150/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7492 - val_loss: 0.9209\n",
      "Epoch 1151/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7492 - val_loss: 0.9283\n",
      "Epoch 1152/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7491 - val_loss: 0.9215\n",
      "Epoch 1153/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7491 - val_loss: 0.9286\n",
      "Epoch 1154/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7491 - val_loss: 0.9209\n",
      "Epoch 1155/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7490 - val_loss: 0.9289\n",
      "Epoch 1156/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7490 - val_loss: 0.9205\n",
      "Epoch 1157/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7490 - val_loss: 0.9285\n",
      "Epoch 1158/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7490 - val_loss: 0.9215\n",
      "Epoch 1159/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7490 - val_loss: 0.9270\n",
      "Epoch 1160/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7490 - val_loss: 0.9234\n",
      "Epoch 1161/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7490 - val_loss: 0.9275\n",
      "Epoch 1162/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7490 - val_loss: 0.9234\n",
      "Epoch 1163/1500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7490 - val_loss: 0.9282\n",
      "Epoch 1164/1500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7490 - val_loss: 0.9216\n",
      "Epoch 1165/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7491 - val_loss: 0.9303\n",
      "Epoch 1166/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7491 - val_loss: 0.9187\n",
      "Epoch 1167/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7492 - val_loss: 0.9332\n",
      "Epoch 1168/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7492 - val_loss: 0.9170\n",
      "Epoch 1169/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7493 - val_loss: 0.9339\n",
      "Epoch 1170/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7493 - val_loss: 0.9169\n",
      "Epoch 1171/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7494 - val_loss: 0.9323\n",
      "Epoch 1172/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7494 - val_loss: 0.9179\n",
      "Epoch 1173/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7494 - val_loss: 0.9314\n",
      "Epoch 1174/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7492 - val_loss: 0.9207\n",
      "Epoch 1175/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7491 - val_loss: 0.9293\n",
      "Epoch 1176/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7490 - val_loss: 0.9234\n",
      "Epoch 1177/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7489 - val_loss: 0.9261\n",
      "Epoch 1178/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7489 - val_loss: 0.9257\n",
      "Epoch 1179/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7489 - val_loss: 0.9222\n",
      "Epoch 1180/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7490 - val_loss: 0.9298\n",
      "Epoch 1181/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7490 - val_loss: 0.9184\n",
      "Epoch 1182/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7491 - val_loss: 0.9337\n",
      "Epoch 1183/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7492 - val_loss: 0.9168\n",
      "Epoch 1184/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7492 - val_loss: 0.9347\n",
      "Epoch 1185/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7493 - val_loss: 0.9180\n",
      "Epoch 1186/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7492 - val_loss: 0.9315\n",
      "Epoch 1187/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7491 - val_loss: 0.9214\n",
      "Epoch 1188/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7490 - val_loss: 0.9279\n",
      "Epoch 1189/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7489 - val_loss: 0.9242\n",
      "Epoch 1190/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7488 - val_loss: 0.9262\n",
      "Epoch 1191/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7488 - val_loss: 0.9267\n",
      "Epoch 1192/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7488 - val_loss: 0.9245\n",
      "Epoch 1193/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7488 - val_loss: 0.9292\n",
      "Epoch 1194/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7489 - val_loss: 0.9220\n",
      "Epoch 1195/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7489 - val_loss: 0.9312\n",
      "Epoch 1196/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7490 - val_loss: 0.9194\n",
      "Epoch 1197/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7490 - val_loss: 0.9327\n",
      "Epoch 1198/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7491 - val_loss: 0.9181\n",
      "Epoch 1199/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7491 - val_loss: 0.9334\n",
      "Epoch 1200/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7491 - val_loss: 0.9196\n",
      "Epoch 1201/1500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7490 - val_loss: 0.9310\n",
      "Epoch 1202/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7489 - val_loss: 0.9221\n",
      "Epoch 1203/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7489 - val_loss: 0.9283\n",
      "Epoch 1204/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7488 - val_loss: 0.9243\n",
      "Epoch 1205/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7487 - val_loss: 0.9260\n",
      "Epoch 1206/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7487 - val_loss: 0.9268\n",
      "Epoch 1207/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7487 - val_loss: 0.9240\n",
      "Epoch 1208/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7487 - val_loss: 0.9287\n",
      "Epoch 1209/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7488 - val_loss: 0.9221\n",
      "Epoch 1210/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7488 - val_loss: 0.9303\n",
      "Epoch 1211/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7488 - val_loss: 0.9207\n",
      "Epoch 1212/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7489 - val_loss: 0.9319\n",
      "Epoch 1213/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7489 - val_loss: 0.9195\n",
      "Epoch 1214/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7489 - val_loss: 0.9328\n",
      "Epoch 1215/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7490 - val_loss: 0.9194\n",
      "Epoch 1216/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7490 - val_loss: 0.9317\n",
      "Epoch 1217/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7489 - val_loss: 0.9203\n",
      "Epoch 1218/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7489 - val_loss: 0.9306\n",
      "Epoch 1219/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7488 - val_loss: 0.9225\n",
      "Epoch 1220/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7488 - val_loss: 0.9285\n",
      "Epoch 1221/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7487 - val_loss: 0.9252\n",
      "Epoch 1222/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7487 - val_loss: 0.9261\n",
      "Epoch 1223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7487 - val_loss: 0.9271\n",
      "Epoch 1224/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7487 - val_loss: 0.9247\n",
      "Epoch 1225/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7487 - val_loss: 0.9280\n",
      "Epoch 1226/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7487 - val_loss: 0.9238\n",
      "Epoch 1227/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7487 - val_loss: 0.9295\n",
      "Epoch 1228/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7487 - val_loss: 0.9219\n",
      "Epoch 1229/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7488 - val_loss: 0.9312\n",
      "Epoch 1230/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7488 - val_loss: 0.9213\n",
      "Epoch 1231/1500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7488 - val_loss: 0.9321\n",
      "Epoch 1232/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7489 - val_loss: 0.9206\n",
      "Epoch 1233/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7489 - val_loss: 0.9327\n",
      "Epoch 1234/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7489 - val_loss: 0.9201\n",
      "Epoch 1235/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7489 - val_loss: 0.9323\n",
      "Epoch 1236/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7489 - val_loss: 0.9208\n",
      "Epoch 1237/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7488 - val_loss: 0.9314\n",
      "Epoch 1238/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7488 - val_loss: 0.9214\n",
      "Epoch 1239/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7487 - val_loss: 0.9302\n",
      "Epoch 1240/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7487 - val_loss: 0.9233\n",
      "Epoch 1241/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7486 - val_loss: 0.9278\n",
      "Epoch 1242/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7486 - val_loss: 0.9255\n",
      "Epoch 1243/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7486 - val_loss: 0.9252\n",
      "Epoch 1244/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7486 - val_loss: 0.9276\n",
      "Epoch 1245/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7486 - val_loss: 0.9241\n",
      "Epoch 1246/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7486 - val_loss: 0.9294\n",
      "Epoch 1247/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7486 - val_loss: 0.9231\n",
      "Epoch 1248/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7486 - val_loss: 0.9311\n",
      "Epoch 1249/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7487 - val_loss: 0.9216\n",
      "Epoch 1250/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7487 - val_loss: 0.9325\n",
      "Epoch 1251/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7488 - val_loss: 0.9202\n",
      "Epoch 1252/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7489 - val_loss: 0.9346\n",
      "Epoch 1253/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7490 - val_loss: 0.9186\n",
      "Epoch 1254/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7491 - val_loss: 0.9360\n",
      "Epoch 1255/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7491 - val_loss: 0.9175\n",
      "Epoch 1256/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7491 - val_loss: 0.9358\n",
      "Epoch 1257/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7490 - val_loss: 0.9185\n",
      "Epoch 1258/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7488 - val_loss: 0.9317\n",
      "Epoch 1259/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7486 - val_loss: 0.9230\n",
      "Epoch 1260/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7485 - val_loss: 0.9260\n",
      "Epoch 1261/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7485 - val_loss: 0.9287\n",
      "Epoch 1262/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7485 - val_loss: 0.9220\n",
      "Epoch 1263/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7486 - val_loss: 0.9331\n",
      "Epoch 1264/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7487 - val_loss: 0.9197\n",
      "Epoch 1265/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7488 - val_loss: 0.9346\n",
      "Epoch 1266/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7488 - val_loss: 0.9194\n",
      "Epoch 1267/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7489 - val_loss: 0.9331\n",
      "Epoch 1268/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7489 - val_loss: 0.9207\n",
      "Epoch 1269/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7488 - val_loss: 0.9310\n",
      "Epoch 1270/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7487 - val_loss: 0.9225\n",
      "Epoch 1271/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7486 - val_loss: 0.9289\n",
      "Epoch 1272/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7485 - val_loss: 0.9247\n",
      "Epoch 1273/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7485 - val_loss: 0.9271\n",
      "Epoch 1274/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7485 - val_loss: 0.9273\n",
      "Epoch 1275/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7485 - val_loss: 0.9244\n",
      "Epoch 1276/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7485 - val_loss: 0.9306\n",
      "Epoch 1277/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7485 - val_loss: 0.9219\n",
      "Epoch 1278/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7486 - val_loss: 0.9327\n",
      "Epoch 1279/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7486 - val_loss: 0.9206\n",
      "Epoch 1280/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7486 - val_loss: 0.9332\n",
      "Epoch 1281/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7487 - val_loss: 0.9208\n",
      "Epoch 1282/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7487 - val_loss: 0.9325\n",
      "Epoch 1283/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7486 - val_loss: 0.9216\n",
      "Epoch 1284/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7486 - val_loss: 0.9304\n",
      "Epoch 1285/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7486 - val_loss: 0.9231\n",
      "Epoch 1286/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7485 - val_loss: 0.9291\n",
      "Epoch 1287/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7485 - val_loss: 0.9247\n",
      "Epoch 1288/1500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7484 - val_loss: 0.9283\n",
      "Epoch 1289/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7484 - val_loss: 0.9258\n",
      "Epoch 1290/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7484 - val_loss: 0.9270\n",
      "Epoch 1291/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7484 - val_loss: 0.9270\n",
      "Epoch 1292/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7484 - val_loss: 0.9255\n",
      "Epoch 1293/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7484 - val_loss: 0.9290\n",
      "Epoch 1294/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7484 - val_loss: 0.9232\n",
      "Epoch 1295/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7484 - val_loss: 0.9313\n",
      "Epoch 1296/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7485 - val_loss: 0.9214\n",
      "Epoch 1297/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7485 - val_loss: 0.9330\n",
      "Epoch 1298/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7486 - val_loss: 0.9203\n",
      "Epoch 1299/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7486 - val_loss: 0.9336\n",
      "Epoch 1300/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7487 - val_loss: 0.9209\n",
      "Epoch 1301/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7487 - val_loss: 0.9331\n",
      "Epoch 1302/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7487 - val_loss: 0.9217\n",
      "Epoch 1303/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7486 - val_loss: 0.9330\n",
      "Epoch 1304/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7486 - val_loss: 0.9219\n",
      "Epoch 1305/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7485 - val_loss: 0.9324\n",
      "Epoch 1306/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7484 - val_loss: 0.9218\n",
      "Epoch 1307/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7484 - val_loss: 0.9308\n",
      "Epoch 1308/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7484 - val_loss: 0.9245\n",
      "Epoch 1309/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7483 - val_loss: 0.9274\n",
      "Epoch 1310/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7483 - val_loss: 0.9277\n",
      "Epoch 1311/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7483 - val_loss: 0.9246\n",
      "Epoch 1312/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7483 - val_loss: 0.9307\n",
      "Epoch 1313/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7483 - val_loss: 0.9226\n",
      "Epoch 1314/1500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7484 - val_loss: 0.9328\n",
      "Epoch 1315/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7484 - val_loss: 0.9224\n",
      "Epoch 1316/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7484 - val_loss: 0.9332\n",
      "Epoch 1317/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7485 - val_loss: 0.9216\n",
      "Epoch 1318/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7486 - val_loss: 0.9330\n",
      "Epoch 1319/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7486 - val_loss: 0.9208\n",
      "Epoch 1320/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7487 - val_loss: 0.9334\n",
      "Epoch 1321/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7487 - val_loss: 0.9205\n",
      "Epoch 1322/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7487 - val_loss: 0.9347\n",
      "Epoch 1323/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7486 - val_loss: 0.9199\n",
      "Epoch 1324/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7485 - val_loss: 0.9344\n",
      "Epoch 1325/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7484 - val_loss: 0.9210\n",
      "Epoch 1326/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7484 - val_loss: 0.9309\n",
      "Epoch 1327/1500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7483 - val_loss: 0.9259\n",
      "Epoch 1328/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7482 - val_loss: 0.9259\n",
      "Epoch 1329/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7482 - val_loss: 0.9302\n",
      "Epoch 1330/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7483 - val_loss: 0.9216\n",
      "Epoch 1331/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7483 - val_loss: 0.9325\n",
      "Epoch 1332/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7484 - val_loss: 0.9205\n",
      "Epoch 1333/1500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7484 - val_loss: 0.9340\n",
      "Epoch 1334/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7484 - val_loss: 0.9209\n",
      "Epoch 1335/1500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7485 - val_loss: 0.9341\n",
      "Epoch 1336/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7486 - val_loss: 0.9221\n",
      "Epoch 1337/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7486 - val_loss: 0.9330\n",
      "Epoch 1338/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7486 - val_loss: 0.9220\n",
      "Epoch 1339/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7485 - val_loss: 0.9326\n",
      "Epoch 1340/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7484 - val_loss: 0.9217\n",
      "Epoch 1341/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7483 - val_loss: 0.9317\n",
      "Epoch 1342/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7483 - val_loss: 0.9230\n",
      "Epoch 1343/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7482 - val_loss: 0.9284\n",
      "Epoch 1344/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7482 - val_loss: 0.9264\n",
      "Epoch 1345/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7482 - val_loss: 0.9253\n",
      "Epoch 1346/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7482 - val_loss: 0.9302\n",
      "Epoch 1347/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7482 - val_loss: 0.9221\n",
      "Epoch 1348/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7483 - val_loss: 0.9325\n",
      "Epoch 1349/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7483 - val_loss: 0.9204\n",
      "Epoch 1350/1500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7483 - val_loss: 0.9328\n",
      "Epoch 1351/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7484 - val_loss: 0.9206\n",
      "Epoch 1352/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7484 - val_loss: 0.9323\n",
      "Epoch 1353/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7484 - val_loss: 0.9214\n",
      "Epoch 1354/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7484 - val_loss: 0.9326\n",
      "Epoch 1355/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7484 - val_loss: 0.9220\n",
      "Epoch 1356/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7484 - val_loss: 0.9327\n",
      "Epoch 1357/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7483 - val_loss: 0.9221\n",
      "Epoch 1358/1500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7483 - val_loss: 0.9316\n",
      "Epoch 1359/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7482 - val_loss: 0.9232\n",
      "Epoch 1360/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7482 - val_loss: 0.9290\n",
      "Epoch 1361/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7481 - val_loss: 0.9260\n",
      "Epoch 1362/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7481 - val_loss: 0.9259\n",
      "Epoch 1363/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7481 - val_loss: 0.9293\n",
      "Epoch 1364/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7481 - val_loss: 0.9236\n",
      "Epoch 1365/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7482 - val_loss: 0.9312\n",
      "Epoch 1366/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7482 - val_loss: 0.9229\n",
      "Epoch 1367/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7482 - val_loss: 0.9318\n",
      "Epoch 1368/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7482 - val_loss: 0.9221\n",
      "Epoch 1369/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7483 - val_loss: 0.9320\n",
      "Epoch 1370/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7483 - val_loss: 0.9219\n",
      "Epoch 1371/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7483 - val_loss: 0.9325\n",
      "Epoch 1372/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7484 - val_loss: 0.9211\n",
      "Epoch 1373/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7484 - val_loss: 0.9336\n",
      "Epoch 1374/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7484 - val_loss: 0.9202\n",
      "Epoch 1375/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7483 - val_loss: 0.9336\n",
      "Epoch 1376/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7483 - val_loss: 0.9211\n",
      "Epoch 1377/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7482 - val_loss: 0.9316\n",
      "Epoch 1378/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7482 - val_loss: 0.9231\n",
      "Epoch 1379/1500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7481 - val_loss: 0.9290\n",
      "Epoch 1380/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7481 - val_loss: 0.9261\n",
      "Epoch 1381/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7480 - val_loss: 0.9265\n",
      "Epoch 1382/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7480 - val_loss: 0.9292\n",
      "Epoch 1383/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7480 - val_loss: 0.9249\n",
      "Epoch 1384/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7481 - val_loss: 0.9302\n",
      "Epoch 1385/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7481 - val_loss: 0.9240\n",
      "Epoch 1386/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7481 - val_loss: 0.9308\n",
      "Epoch 1387/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7481 - val_loss: 0.9232\n",
      "Epoch 1388/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7482 - val_loss: 0.9323\n",
      "Epoch 1389/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7482 - val_loss: 0.9220\n",
      "Epoch 1390/1500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7483 - val_loss: 0.9340\n",
      "Epoch 1391/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7484 - val_loss: 0.9203\n",
      "Epoch 1392/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7484 - val_loss: 0.9353\n",
      "Epoch 1393/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7485 - val_loss: 0.9187\n",
      "Epoch 1394/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7485 - val_loss: 0.9361\n",
      "Epoch 1395/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7484 - val_loss: 0.9193\n",
      "Epoch 1396/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7483 - val_loss: 0.9336\n",
      "Epoch 1397/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7482 - val_loss: 0.9234\n",
      "Epoch 1398/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7481 - val_loss: 0.9285\n",
      "Epoch 1399/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7480 - val_loss: 0.9280\n",
      "Epoch 1400/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7480 - val_loss: 0.9242\n",
      "Epoch 1401/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7480 - val_loss: 0.9314\n",
      "Epoch 1402/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7481 - val_loss: 0.9214\n",
      "Epoch 1403/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7482 - val_loss: 0.9339\n",
      "Epoch 1404/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7482 - val_loss: 0.9198\n",
      "Epoch 1405/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7483 - val_loss: 0.9350\n",
      "Epoch 1406/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7484 - val_loss: 0.9197\n",
      "Epoch 1407/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7484 - val_loss: 0.9339\n",
      "Epoch 1408/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7484 - val_loss: 0.9212\n",
      "Epoch 1409/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7483 - val_loss: 0.9322\n",
      "Epoch 1410/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7481 - val_loss: 0.9234\n",
      "Epoch 1411/1500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7480 - val_loss: 0.9288\n",
      "Epoch 1412/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7480 - val_loss: 0.9267\n",
      "Epoch 1413/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7480 - val_loss: 0.9251\n",
      "Epoch 1414/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7480 - val_loss: 0.9300\n",
      "Epoch 1415/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7480 - val_loss: 0.9215\n",
      "Epoch 1416/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7481 - val_loss: 0.9333\n",
      "Epoch 1417/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7482 - val_loss: 0.9201\n",
      "Epoch 1418/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7482 - val_loss: 0.9346\n",
      "Epoch 1419/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7482 - val_loss: 0.9208\n",
      "Epoch 1420/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7482 - val_loss: 0.9335\n",
      "Epoch 1421/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7482 - val_loss: 0.9231\n",
      "Epoch 1422/1500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7481 - val_loss: 0.9301\n",
      "Epoch 1423/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7480 - val_loss: 0.9252\n",
      "Epoch 1424/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7479 - val_loss: 0.9274\n",
      "Epoch 1425/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7479 - val_loss: 0.9260\n",
      "Epoch 1426/1500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7479 - val_loss: 0.9260\n",
      "Epoch 1427/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7479 - val_loss: 0.9275\n",
      "Epoch 1428/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7479 - val_loss: 0.9249\n",
      "Epoch 1429/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7479 - val_loss: 0.9302\n",
      "Epoch 1430/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7480 - val_loss: 0.9230\n",
      "Epoch 1431/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7480 - val_loss: 0.9321\n",
      "Epoch 1432/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7480 - val_loss: 0.9217\n",
      "Epoch 1433/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7481 - val_loss: 0.9336\n",
      "Epoch 1434/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7481 - val_loss: 0.9206\n",
      "Epoch 1435/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7481 - val_loss: 0.9336\n",
      "Epoch 1436/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7481 - val_loss: 0.9213\n",
      "Epoch 1437/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7481 - val_loss: 0.9316\n",
      "Epoch 1438/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7480 - val_loss: 0.9228\n",
      "Epoch 1439/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7480 - val_loss: 0.9299\n",
      "Epoch 1440/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7480 - val_loss: 0.9246\n",
      "Epoch 1441/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7479 - val_loss: 0.9286\n",
      "Epoch 1442/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7479 - val_loss: 0.9258\n",
      "Epoch 1443/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7478 - val_loss: 0.9268\n",
      "Epoch 1444/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7478 - val_loss: 0.9275\n",
      "Epoch 1445/1500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7478 - val_loss: 0.9256\n",
      "Epoch 1446/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7479 - val_loss: 0.9294\n",
      "Epoch 1447/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7479 - val_loss: 0.9232\n",
      "Epoch 1448/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7479 - val_loss: 0.9320\n",
      "Epoch 1449/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7480 - val_loss: 0.9214\n",
      "Epoch 1450/1500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7480 - val_loss: 0.9343\n",
      "Epoch 1451/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7481 - val_loss: 0.9199\n",
      "Epoch 1452/1500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7482 - val_loss: 0.9353\n",
      "Epoch 1453/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7482 - val_loss: 0.9188\n",
      "Epoch 1454/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7483 - val_loss: 0.9356\n",
      "Epoch 1455/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7483 - val_loss: 0.9193\n",
      "Epoch 1456/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7482 - val_loss: 0.9341\n",
      "Epoch 1457/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7481 - val_loss: 0.9215\n",
      "Epoch 1458/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7480 - val_loss: 0.9305\n",
      "Epoch 1459/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7479 - val_loss: 0.9243\n",
      "Epoch 1460/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7478 - val_loss: 0.9275\n",
      "Epoch 1461/1500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7478 - val_loss: 0.9279\n",
      "Epoch 1462/1500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7478 - val_loss: 0.9247\n",
      "Epoch 1463/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7478 - val_loss: 0.9313\n",
      "Epoch 1464/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7479 - val_loss: 0.9218\n",
      "Epoch 1465/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7479 - val_loss: 0.9336\n",
      "Epoch 1466/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7480 - val_loss: 0.9201\n",
      "Epoch 1467/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7481 - val_loss: 0.9344\n",
      "Epoch 1468/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7481 - val_loss: 0.9204\n",
      "Epoch 1469/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7481 - val_loss: 0.9333\n",
      "Epoch 1470/1500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7480 - val_loss: 0.9220\n",
      "Epoch 1471/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7480 - val_loss: 0.9304\n",
      "Epoch 1472/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7479 - val_loss: 0.9244\n",
      "Epoch 1473/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7478 - val_loss: 0.9275\n",
      "Epoch 1474/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7478 - val_loss: 0.9264\n",
      "Epoch 1475/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7477 - val_loss: 0.9259\n",
      "Epoch 1476/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7478 - val_loss: 0.9285\n",
      "Epoch 1477/1500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7478 - val_loss: 0.9241\n",
      "Epoch 1478/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7478 - val_loss: 0.9313\n",
      "Epoch 1479/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7479 - val_loss: 0.9223\n",
      "Epoch 1480/1500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7479 - val_loss: 0.9327\n",
      "Epoch 1481/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7479 - val_loss: 0.9210\n",
      "Epoch 1482/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7480 - val_loss: 0.9336\n",
      "Epoch 1483/1500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7480 - val_loss: 0.9206\n",
      "Epoch 1484/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7480 - val_loss: 0.9333\n",
      "Epoch 1485/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7479 - val_loss: 0.9215\n",
      "Epoch 1486/1500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7479 - val_loss: 0.9312\n",
      "Epoch 1487/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7478 - val_loss: 0.9236\n",
      "Epoch 1488/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7478 - val_loss: 0.9291\n",
      "Epoch 1489/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7477 - val_loss: 0.9253\n",
      "Epoch 1490/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7477 - val_loss: 0.9277\n",
      "Epoch 1491/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7477 - val_loss: 0.9274\n",
      "Epoch 1492/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7477 - val_loss: 0.9265\n",
      "Epoch 1493/1500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7477 - val_loss: 0.9287\n",
      "Epoch 1494/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7477 - val_loss: 0.9253\n",
      "Epoch 1495/1500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7477 - val_loss: 0.9294\n",
      "Epoch 1496/1500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7477 - val_loss: 0.9238\n",
      "Epoch 1497/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7477 - val_loss: 0.9305\n",
      "Epoch 1498/1500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7478 - val_loss: 0.9226\n",
      "Epoch 1499/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7478 - val_loss: 0.9322\n",
      "Epoch 1500/1500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7479 - val_loss: 0.9215\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.8842\n",
      "0.8841650485992432\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.SimpleRNN(units = 1024, activation = \"relu\", return_sequences = False)(input)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "model.summary()\n",
    "\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = len(x), epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdcac4e9fd0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM(1層)sequence=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 3, 3)]            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1024)              4210688   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,211,713\n",
      "Trainable params: 4,211,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0310 - val_loss: 0.8879\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1.0258 - val_loss: 0.8860\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 1.0207 - val_loss: 0.8842\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 1.0157 - val_loss: 0.8826\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 1.0108 - val_loss: 0.8810\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.0060 - val_loss: 0.8796\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.0014 - val_loss: 0.8783\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.9969 - val_loss: 0.8771\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.9925 - val_loss: 0.8761\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9883 - val_loss: 0.8751\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9842 - val_loss: 0.8743\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9802 - val_loss: 0.8735\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9764 - val_loss: 0.8729\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9726 - val_loss: 0.8724\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9690 - val_loss: 0.8721\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9656 - val_loss: 0.8718\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9622 - val_loss: 0.8716\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9590 - val_loss: 0.8716\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9558 - val_loss: 0.8716\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9528 - val_loss: 0.8718\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9499 - val_loss: 0.8721\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9471 - val_loss: 0.8726\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9444 - val_loss: 0.8731\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.9417 - val_loss: 0.8738\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.9392 - val_loss: 0.8745\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.9368 - val_loss: 0.8754\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9345 - val_loss: 0.8764\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9322 - val_loss: 0.8776\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9301 - val_loss: 0.8788\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.9280 - val_loss: 0.8802\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9260 - val_loss: 0.8817\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9241 - val_loss: 0.8833\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9223 - val_loss: 0.8850\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9205 - val_loss: 0.8868\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9188 - val_loss: 0.8887\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9172 - val_loss: 0.8908\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9156 - val_loss: 0.8929\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9142 - val_loss: 0.8952\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9128 - val_loss: 0.8975\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9114 - val_loss: 0.8999\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9102 - val_loss: 0.9024\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.9090 - val_loss: 0.9049\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9079 - val_loss: 0.9075\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9069 - val_loss: 0.9101\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9059 - val_loss: 0.9127\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9050 - val_loss: 0.9153\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9042 - val_loss: 0.9179\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.9035 - val_loss: 0.9205\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9028 - val_loss: 0.9230\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9021 - val_loss: 0.9254\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.9015 - val_loss: 0.9277\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9009 - val_loss: 0.9299\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9004 - val_loss: 0.9319\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.8999 - val_loss: 0.9338\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8994 - val_loss: 0.9355\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8989 - val_loss: 0.9370\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8985 - val_loss: 0.9383\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8980 - val_loss: 0.9395\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8975 - val_loss: 0.9404\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8971 - val_loss: 0.9411\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8966 - val_loss: 0.9416\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8961 - val_loss: 0.9419\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8956 - val_loss: 0.9421\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8951 - val_loss: 0.9421\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8946 - val_loss: 0.9419\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8941 - val_loss: 0.9415\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8936 - val_loss: 0.9411\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8931 - val_loss: 0.9405\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8925 - val_loss: 0.9398\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8920 - val_loss: 0.9390\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8915 - val_loss: 0.9382\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8909 - val_loss: 0.9374\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8904 - val_loss: 0.9364\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8898 - val_loss: 0.9355\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8893 - val_loss: 0.9346\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8887 - val_loss: 0.9336\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8882 - val_loss: 0.9327\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8877 - val_loss: 0.9318\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8871 - val_loss: 0.9309\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8866 - val_loss: 0.9300\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8861 - val_loss: 0.9292\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8855 - val_loss: 0.9285\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8850 - val_loss: 0.9277\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8845 - val_loss: 0.9270\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8840 - val_loss: 0.9264\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8834 - val_loss: 0.9258\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8829 - val_loss: 0.9252\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8824 - val_loss: 0.9247\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8819 - val_loss: 0.9243\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8813 - val_loss: 0.9239\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8808 - val_loss: 0.9235\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8803 - val_loss: 0.9231\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8798 - val_loss: 0.9229\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8792 - val_loss: 0.9226\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8787 - val_loss: 0.9223\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8782 - val_loss: 0.9221\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8776 - val_loss: 0.9219\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8771 - val_loss: 0.9217\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8766 - val_loss: 0.9216\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8761 - val_loss: 0.9214\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8755 - val_loss: 0.9213\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8750 - val_loss: 0.9212\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8745 - val_loss: 0.9210\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8740 - val_loss: 0.9209\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8734 - val_loss: 0.9208\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8729 - val_loss: 0.9206\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8724 - val_loss: 0.9205\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8719 - val_loss: 0.9203\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8714 - val_loss: 0.9201\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8709 - val_loss: 0.9199\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8703 - val_loss: 0.9197\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8698 - val_loss: 0.9195\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8693 - val_loss: 0.9192\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8688 - val_loss: 0.9190\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8683 - val_loss: 0.9187\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8678 - val_loss: 0.9184\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8673 - val_loss: 0.9181\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8668 - val_loss: 0.9178\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8663 - val_loss: 0.9175\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8659 - val_loss: 0.9172\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8654 - val_loss: 0.9168\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8649 - val_loss: 0.9165\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8644 - val_loss: 0.9162\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8639 - val_loss: 0.9159\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8635 - val_loss: 0.9155\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8630 - val_loss: 0.9152\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8626 - val_loss: 0.9149\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8621 - val_loss: 0.9146\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8617 - val_loss: 0.9143\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8612 - val_loss: 0.9140\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8608 - val_loss: 0.9137\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8604 - val_loss: 0.9134\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8599 - val_loss: 0.9132\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8595 - val_loss: 0.9129\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8591 - val_loss: 0.9126\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8587 - val_loss: 0.9124\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8583 - val_loss: 0.9121\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8579 - val_loss: 0.9119\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8575 - val_loss: 0.9116\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8571 - val_loss: 0.9114\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8567 - val_loss: 0.9112\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8563 - val_loss: 0.9110\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8559 - val_loss: 0.9109\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8555 - val_loss: 0.9107\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8552 - val_loss: 0.9105\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8548 - val_loss: 0.9104\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8544 - val_loss: 0.9102\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8541 - val_loss: 0.9100\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8537 - val_loss: 0.9099\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8534 - val_loss: 0.9097\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8530 - val_loss: 0.9095\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8527 - val_loss: 0.9094\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8523 - val_loss: 0.9092\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8520 - val_loss: 0.9091\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8517 - val_loss: 0.9089\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8514 - val_loss: 0.9088\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8510 - val_loss: 0.9086\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8507 - val_loss: 0.9085\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8504 - val_loss: 0.9084\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8501 - val_loss: 0.9082\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8498 - val_loss: 0.9081\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8495 - val_loss: 0.9080\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8492 - val_loss: 0.9079\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8489 - val_loss: 0.9078\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8486 - val_loss: 0.9076\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8483 - val_loss: 0.9075\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8480 - val_loss: 0.9074\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8477 - val_loss: 0.9073\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8474 - val_loss: 0.9073\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8471 - val_loss: 0.9072\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8468 - val_loss: 0.9071\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8465 - val_loss: 0.9070\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8463 - val_loss: 0.9069\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8460 - val_loss: 0.9069\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8457 - val_loss: 0.9068\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8454 - val_loss: 0.9067\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8451 - val_loss: 0.9067\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8449 - val_loss: 0.9066\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8446 - val_loss: 0.9066\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8443 - val_loss: 0.9066\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8440 - val_loss: 0.9065\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8438 - val_loss: 0.9065\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8435 - val_loss: 0.9065\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8432 - val_loss: 0.9064\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8430 - val_loss: 0.9064\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8427 - val_loss: 0.9064\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8424 - val_loss: 0.9063\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8422 - val_loss: 0.9063\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8419 - val_loss: 0.9063\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8416 - val_loss: 0.9062\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8414 - val_loss: 0.9062\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8411 - val_loss: 0.9062\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8408 - val_loss: 0.9062\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8406 - val_loss: 0.9061\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8403 - val_loss: 0.9061\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8400 - val_loss: 0.9061\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8398 - val_loss: 0.9061\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8395 - val_loss: 0.9061\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8393 - val_loss: 0.9061\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8390 - val_loss: 0.9060\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8387 - val_loss: 0.9060\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8385 - val_loss: 0.9060\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8382 - val_loss: 0.9060\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8380 - val_loss: 0.9060\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8377 - val_loss: 0.9060\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.8375 - val_loss: 0.9060\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8372 - val_loss: 0.9059\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8370 - val_loss: 0.9059\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8367 - val_loss: 0.9059\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8365 - val_loss: 0.9059\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8362 - val_loss: 0.9059\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8360 - val_loss: 0.9058\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8357 - val_loss: 0.9058\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8355 - val_loss: 0.9058\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8352 - val_loss: 0.9058\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8350 - val_loss: 0.9058\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8347 - val_loss: 0.9058\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8345 - val_loss: 0.9057\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8342 - val_loss: 0.9057\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8340 - val_loss: 0.9057\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8337 - val_loss: 0.9057\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8335 - val_loss: 0.9057\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8333 - val_loss: 0.9057\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8330 - val_loss: 0.9057\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8328 - val_loss: 0.9057\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8325 - val_loss: 0.9057\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8323 - val_loss: 0.9057\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8321 - val_loss: 0.9057\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8318 - val_loss: 0.9056\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8316 - val_loss: 0.9056\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8314 - val_loss: 0.9056\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8312 - val_loss: 0.9056\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8309 - val_loss: 0.9055\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8307 - val_loss: 0.9055\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8305 - val_loss: 0.9056\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8303 - val_loss: 0.9056\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8300 - val_loss: 0.9055\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8298 - val_loss: 0.9055\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8296 - val_loss: 0.9055\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8294 - val_loss: 0.9055\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8292 - val_loss: 0.9055\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8289 - val_loss: 0.9055\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8287 - val_loss: 0.9055\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8285 - val_loss: 0.9055\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8283 - val_loss: 0.9055\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8281 - val_loss: 0.9055\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8279 - val_loss: 0.9055\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8277 - val_loss: 0.9055\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8275 - val_loss: 0.9055\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8273 - val_loss: 0.9055\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8271 - val_loss: 0.9054\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8269 - val_loss: 0.9054\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8267 - val_loss: 0.9054\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8265 - val_loss: 0.9054\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8263 - val_loss: 0.9053\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8262 - val_loss: 0.9053\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8260 - val_loss: 0.9053\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8258 - val_loss: 0.9052\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8256 - val_loss: 0.9052\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8254 - val_loss: 0.9052\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8253 - val_loss: 0.9051\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8251 - val_loss: 0.9051\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8249 - val_loss: 0.9051\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8247 - val_loss: 0.9051\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8246 - val_loss: 0.9051\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8244 - val_loss: 0.9051\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8242 - val_loss: 0.9051\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8241 - val_loss: 0.9051\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8239 - val_loss: 0.9051\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8238 - val_loss: 0.9051\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8236 - val_loss: 0.9051\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8235 - val_loss: 0.9051\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8233 - val_loss: 0.9051\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8232 - val_loss: 0.9051\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8230 - val_loss: 0.9051\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8229 - val_loss: 0.9051\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8227 - val_loss: 0.9051\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8226 - val_loss: 0.9051\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8224 - val_loss: 0.9051\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8223 - val_loss: 0.9051\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8222 - val_loss: 0.9051\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8220 - val_loss: 0.9051\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8219 - val_loss: 0.9050\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8218 - val_loss: 0.9050\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8217 - val_loss: 0.9050\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8215 - val_loss: 0.9050\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8214 - val_loss: 0.9049\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8213 - val_loss: 0.9049\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.8212 - val_loss: 0.9049\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8210 - val_loss: 0.9048\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8209 - val_loss: 0.9048\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8208 - val_loss: 0.9047\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8207 - val_loss: 0.9047\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8206 - val_loss: 0.9046\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8205 - val_loss: 0.9046\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8204 - val_loss: 0.9045\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8202 - val_loss: 0.9045\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8201 - val_loss: 0.9044\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8200 - val_loss: 0.9044\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8199 - val_loss: 0.9044\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8198 - val_loss: 0.9043\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8197 - val_loss: 0.9043\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8196 - val_loss: 0.9043\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8195 - val_loss: 0.9043\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8194 - val_loss: 0.9042\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8193 - val_loss: 0.9042\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8192 - val_loss: 0.9042\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8191 - val_loss: 0.9041\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8190 - val_loss: 0.9041\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8189 - val_loss: 0.9041\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8188 - val_loss: 0.9041\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8187 - val_loss: 0.9041\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8186 - val_loss: 0.9040\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8185 - val_loss: 0.9040\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8184 - val_loss: 0.9039\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8183 - val_loss: 0.9039\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8182 - val_loss: 0.9039\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8181 - val_loss: 0.9038\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8180 - val_loss: 0.9037\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8179 - val_loss: 0.9037\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8178 - val_loss: 0.9036\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8178 - val_loss: 0.9036\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8177 - val_loss: 0.9036\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8176 - val_loss: 0.9035\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8175 - val_loss: 0.9035\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8174 - val_loss: 0.9035\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.8173 - val_loss: 0.9034\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8172 - val_loss: 0.9034\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8171 - val_loss: 0.9033\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8170 - val_loss: 0.9033\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8170 - val_loss: 0.9032\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8169 - val_loss: 0.9032\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.8168 - val_loss: 0.9032\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8167 - val_loss: 0.9031\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8166 - val_loss: 0.9031\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8165 - val_loss: 0.9030\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8164 - val_loss: 0.9030\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.8164 - val_loss: 0.9029\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.8163 - val_loss: 0.9029\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8162 - val_loss: 0.9029\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8161 - val_loss: 0.9029\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8160 - val_loss: 0.9029\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8159 - val_loss: 0.9028\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8159 - val_loss: 0.9028\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8158 - val_loss: 0.9028\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8157 - val_loss: 0.9027\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8156 - val_loss: 0.9027\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8155 - val_loss: 0.9026\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8155 - val_loss: 0.9025\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8154 - val_loss: 0.9025\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8153 - val_loss: 0.9024\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8152 - val_loss: 0.9024\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8151 - val_loss: 0.9023\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8150 - val_loss: 0.9023\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8150 - val_loss: 0.9023\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8149 - val_loss: 0.9022\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8148 - val_loss: 0.9021\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8147 - val_loss: 0.9021\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8146 - val_loss: 0.9020\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8146 - val_loss: 0.9020\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8145 - val_loss: 0.9019\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8144 - val_loss: 0.9019\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8143 - val_loss: 0.9019\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8142 - val_loss: 0.9018\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8141 - val_loss: 0.9018\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8141 - val_loss: 0.9018\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8140 - val_loss: 0.9017\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8139 - val_loss: 0.9017\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8138 - val_loss: 0.9017\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8137 - val_loss: 0.9016\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8137 - val_loss: 0.9016\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8136 - val_loss: 0.9016\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8135 - val_loss: 0.9016\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8134 - val_loss: 0.9015\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8133 - val_loss: 0.9014\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8132 - val_loss: 0.9014\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8132 - val_loss: 0.9013\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8131 - val_loss: 0.9013\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8130 - val_loss: 0.9012\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8129 - val_loss: 0.9012\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8128 - val_loss: 0.9011\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8128 - val_loss: 0.9011\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8127 - val_loss: 0.9010\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8126 - val_loss: 0.9010\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8125 - val_loss: 0.9009\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8124 - val_loss: 0.9008\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8124 - val_loss: 0.9008\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8123 - val_loss: 0.9007\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8122 - val_loss: 0.9007\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8121 - val_loss: 0.9007\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8120 - val_loss: 0.9006\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8119 - val_loss: 0.9006\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8119 - val_loss: 0.9005\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8118 - val_loss: 0.9005\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8117 - val_loss: 0.9004\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8116 - val_loss: 0.9004\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8115 - val_loss: 0.9004\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8115 - val_loss: 0.9003\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8114 - val_loss: 0.9003\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8113 - val_loss: 0.9002\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8112 - val_loss: 0.9002\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8111 - val_loss: 0.9001\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8111 - val_loss: 0.9001\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8110 - val_loss: 0.9000\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8109 - val_loss: 0.9000\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8108 - val_loss: 0.9000\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8107 - val_loss: 0.9000\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8106 - val_loss: 0.9000\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8106 - val_loss: 0.9000\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8105 - val_loss: 0.8999\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8104 - val_loss: 0.8999\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8103 - val_loss: 0.8998\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8102 - val_loss: 0.8997\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8102 - val_loss: 0.8996\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8101 - val_loss: 0.8996\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8100 - val_loss: 0.8996\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8099 - val_loss: 0.8995\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8098 - val_loss: 0.8995\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8098 - val_loss: 0.8994\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8097 - val_loss: 0.8994\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8096 - val_loss: 0.8994\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8095 - val_loss: 0.8993\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8094 - val_loss: 0.8992\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8093 - val_loss: 0.8992\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8093 - val_loss: 0.8991\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8092 - val_loss: 0.8990\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8091 - val_loss: 0.8990\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8090 - val_loss: 0.8989\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8089 - val_loss: 0.8988\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8089 - val_loss: 0.8988\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8088 - val_loss: 0.8987\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8087 - val_loss: 0.8987\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8086 - val_loss: 0.8987\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8085 - val_loss: 0.8987\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8084 - val_loss: 0.8987\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8084 - val_loss: 0.8986\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8083 - val_loss: 0.8986\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8082 - val_loss: 0.8985\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8081 - val_loss: 0.8984\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8080 - val_loss: 0.8983\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8079 - val_loss: 0.8983\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8079 - val_loss: 0.8982\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8078 - val_loss: 0.8982\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8077 - val_loss: 0.8981\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.8076 - val_loss: 0.8980\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8075 - val_loss: 0.8980\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8074 - val_loss: 0.8979\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8074 - val_loss: 0.8979\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8073 - val_loss: 0.8979\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8072 - val_loss: 0.8978\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8071 - val_loss: 0.8978\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8070 - val_loss: 0.8978\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8069 - val_loss: 0.8977\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8068 - val_loss: 0.8977\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8068 - val_loss: 0.8977\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8067 - val_loss: 0.8976\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8066 - val_loss: 0.8975\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8065 - val_loss: 0.8975\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8064 - val_loss: 0.8974\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8063 - val_loss: 0.8973\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8062 - val_loss: 0.8973\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8062 - val_loss: 0.8972\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8061 - val_loss: 0.8972\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8060 - val_loss: 0.8972\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8059 - val_loss: 0.8972\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8058 - val_loss: 0.8972\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8057 - val_loss: 0.8972\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8056 - val_loss: 0.8971\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8056 - val_loss: 0.8970\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8055 - val_loss: 0.8970\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.8054 - val_loss: 0.8970\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8053 - val_loss: 0.8969\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8052 - val_loss: 0.8969\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8051 - val_loss: 0.8969\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8050 - val_loss: 0.8969\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8050 - val_loss: 0.8968\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8049 - val_loss: 0.8968\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8048 - val_loss: 0.8967\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.8047 - val_loss: 0.8967\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8046 - val_loss: 0.8966\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8045 - val_loss: 0.8965\n",
      "Epoch 482/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8044 - val_loss: 0.8965\n",
      "Epoch 483/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8043 - val_loss: 0.8964\n",
      "Epoch 484/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8042 - val_loss: 0.8963\n",
      "Epoch 485/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8042 - val_loss: 0.8963\n",
      "Epoch 486/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8041 - val_loss: 0.8962\n",
      "Epoch 487/1500\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8040 - val_loss: 0.8962\n",
      "Epoch 488/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8039 - val_loss: 0.8962\n",
      "Epoch 489/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8038 - val_loss: 0.8962\n",
      "Epoch 490/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8037 - val_loss: 0.8961\n",
      "Epoch 491/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8036 - val_loss: 0.8961\n",
      "Epoch 492/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8035 - val_loss: 0.8961\n",
      "Epoch 493/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8034 - val_loss: 0.8960\n",
      "Epoch 494/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8033 - val_loss: 0.8959\n",
      "Epoch 495/1500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8032 - val_loss: 0.8959\n",
      "Epoch 496/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8031 - val_loss: 0.8959\n",
      "Epoch 497/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8030 - val_loss: 0.8959\n",
      "Epoch 498/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8029 - val_loss: 0.8958\n",
      "Epoch 499/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8029 - val_loss: 0.8958\n",
      "Epoch 500/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8028 - val_loss: 0.8956\n",
      "Epoch 501/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8027 - val_loss: 0.8955\n",
      "Epoch 502/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8026 - val_loss: 0.8954\n",
      "Epoch 503/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8025 - val_loss: 0.8954\n",
      "Epoch 504/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8024 - val_loss: 0.8954\n",
      "Epoch 505/1500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8023 - val_loss: 0.8954\n",
      "Epoch 506/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8022 - val_loss: 0.8953\n",
      "Epoch 507/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8021 - val_loss: 0.8953\n",
      "Epoch 508/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8020 - val_loss: 0.8952\n",
      "Epoch 509/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8019 - val_loss: 0.8952\n",
      "Epoch 510/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8018 - val_loss: 0.8951\n",
      "Epoch 511/1500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8017 - val_loss: 0.8951\n",
      "Epoch 512/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8016 - val_loss: 0.8950\n",
      "Epoch 513/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8016 - val_loss: 0.8951\n",
      "Epoch 514/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8015 - val_loss: 0.8950\n",
      "Epoch 515/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8014 - val_loss: 0.8951\n",
      "Epoch 516/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8013 - val_loss: 0.8949\n",
      "Epoch 517/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8012 - val_loss: 0.8949\n",
      "Epoch 518/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8011 - val_loss: 0.8948\n",
      "Epoch 519/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8010 - val_loss: 0.8948\n",
      "Epoch 520/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8009 - val_loss: 0.8948\n",
      "Epoch 521/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8008 - val_loss: 0.8948\n",
      "Epoch 522/1500\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8007 - val_loss: 0.8948\n",
      "Epoch 523/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8006 - val_loss: 0.8947\n",
      "Epoch 524/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8005 - val_loss: 0.8947\n",
      "Epoch 525/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8004 - val_loss: 0.8946\n",
      "Epoch 526/1500\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8003 - val_loss: 0.8946\n",
      "Epoch 527/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8002 - val_loss: 0.8946\n",
      "Epoch 528/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8001 - val_loss: 0.8946\n",
      "Epoch 529/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8000 - val_loss: 0.8945\n",
      "Epoch 530/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7999 - val_loss: 0.8944\n",
      "Epoch 531/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7998 - val_loss: 0.8944\n",
      "Epoch 532/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7997 - val_loss: 0.8944\n",
      "Epoch 533/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7996 - val_loss: 0.8945\n",
      "Epoch 534/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7995 - val_loss: 0.8944\n",
      "Epoch 535/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7994 - val_loss: 0.8944\n",
      "Epoch 536/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7993 - val_loss: 0.8942\n",
      "Epoch 537/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7992 - val_loss: 0.8942\n",
      "Epoch 538/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7991 - val_loss: 0.8940\n",
      "Epoch 539/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7990 - val_loss: 0.8941\n",
      "Epoch 540/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7989 - val_loss: 0.8940\n",
      "Epoch 541/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7988 - val_loss: 0.8941\n",
      "Epoch 542/1500\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7987 - val_loss: 0.8941\n",
      "Epoch 543/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7986 - val_loss: 0.8941\n",
      "Epoch 544/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7985 - val_loss: 0.8942\n",
      "Epoch 545/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7984 - val_loss: 0.8940\n",
      "Epoch 546/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7983 - val_loss: 0.8941\n",
      "Epoch 547/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7982 - val_loss: 0.8939\n",
      "Epoch 548/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7981 - val_loss: 0.8940\n",
      "Epoch 549/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7980 - val_loss: 0.8939\n",
      "Epoch 550/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7979 - val_loss: 0.8939\n",
      "Epoch 551/1500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7978 - val_loss: 0.8939\n",
      "Epoch 552/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7977 - val_loss: 0.8937\n",
      "Epoch 553/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7976 - val_loss: 0.8938\n",
      "Epoch 554/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7976 - val_loss: 0.8937\n",
      "Epoch 555/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7975 - val_loss: 0.8938\n",
      "Epoch 556/1500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7974 - val_loss: 0.8936\n",
      "Epoch 557/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7973 - val_loss: 0.8937\n",
      "Epoch 558/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7972 - val_loss: 0.8937\n",
      "Epoch 559/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7971 - val_loss: 0.8936\n",
      "Epoch 560/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7969 - val_loss: 0.8936\n",
      "Epoch 561/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7969 - val_loss: 0.8935\n",
      "Epoch 562/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7968 - val_loss: 0.8936\n",
      "Epoch 563/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7967 - val_loss: 0.8935\n",
      "Epoch 564/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7966 - val_loss: 0.8936\n",
      "Epoch 565/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7965 - val_loss: 0.8934\n",
      "Epoch 566/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7964 - val_loss: 0.8936\n",
      "Epoch 567/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7963 - val_loss: 0.8934\n",
      "Epoch 568/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7962 - val_loss: 0.8934\n",
      "Epoch 569/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7961 - val_loss: 0.8933\n",
      "Epoch 570/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7960 - val_loss: 0.8933\n",
      "Epoch 571/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7959 - val_loss: 0.8935\n",
      "Epoch 572/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7958 - val_loss: 0.8934\n",
      "Epoch 573/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7957 - val_loss: 0.8935\n",
      "Epoch 574/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7956 - val_loss: 0.8932\n",
      "Epoch 575/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7955 - val_loss: 0.8934\n",
      "Epoch 576/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7954 - val_loss: 0.8932\n",
      "Epoch 577/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7953 - val_loss: 0.8934\n",
      "Epoch 578/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7952 - val_loss: 0.8933\n",
      "Epoch 579/1500\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7951 - val_loss: 0.8933\n",
      "Epoch 580/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7950 - val_loss: 0.8933\n",
      "Epoch 581/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7949 - val_loss: 0.8932\n",
      "Epoch 582/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7948 - val_loss: 0.8933\n",
      "Epoch 583/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7947 - val_loss: 0.8932\n",
      "Epoch 584/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7946 - val_loss: 0.8933\n",
      "Epoch 585/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7945 - val_loss: 0.8931\n",
      "Epoch 586/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7944 - val_loss: 0.8933\n",
      "Epoch 587/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7943 - val_loss: 0.8930\n",
      "Epoch 588/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7942 - val_loss: 0.8932\n",
      "Epoch 589/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7941 - val_loss: 0.8930\n",
      "Epoch 590/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7940 - val_loss: 0.8931\n",
      "Epoch 591/1500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.7939 - val_loss: 0.8932\n",
      "Epoch 592/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7938 - val_loss: 0.8931\n",
      "Epoch 593/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7937 - val_loss: 0.8932\n",
      "Epoch 594/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7936 - val_loss: 0.8930\n",
      "Epoch 595/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7936 - val_loss: 0.8932\n",
      "Epoch 596/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7935 - val_loss: 0.8929\n",
      "Epoch 597/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7934 - val_loss: 0.8931\n",
      "Epoch 598/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7933 - val_loss: 0.8930\n",
      "Epoch 599/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7932 - val_loss: 0.8933\n",
      "Epoch 600/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7931 - val_loss: 0.8931\n",
      "Epoch 601/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7930 - val_loss: 0.8931\n",
      "Epoch 602/1500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7929 - val_loss: 0.8930\n",
      "Epoch 603/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7928 - val_loss: 0.8929\n",
      "Epoch 604/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7927 - val_loss: 0.8931\n",
      "Epoch 605/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7926 - val_loss: 0.8931\n",
      "Epoch 606/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7925 - val_loss: 0.8933\n",
      "Epoch 607/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7924 - val_loss: 0.8930\n",
      "Epoch 608/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7923 - val_loss: 0.8931\n",
      "Epoch 609/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7923 - val_loss: 0.8929\n",
      "Epoch 610/1500\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7922 - val_loss: 0.8932\n",
      "Epoch 611/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7921 - val_loss: 0.8929\n",
      "Epoch 612/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7920 - val_loss: 0.8931\n",
      "Epoch 613/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7919 - val_loss: 0.8930\n",
      "Epoch 614/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7917 - val_loss: 0.8930\n",
      "Epoch 615/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7917 - val_loss: 0.8932\n",
      "Epoch 616/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7916 - val_loss: 0.8930\n",
      "Epoch 617/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7915 - val_loss: 0.8932\n",
      "Epoch 618/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7914 - val_loss: 0.8929\n",
      "Epoch 619/1500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7913 - val_loss: 0.8932\n",
      "Epoch 620/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7912 - val_loss: 0.8931\n",
      "Epoch 621/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7911 - val_loss: 0.8932\n",
      "Epoch 622/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7910 - val_loss: 0.8932\n",
      "Epoch 623/1500\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7909 - val_loss: 0.8931\n",
      "Epoch 624/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7909 - val_loss: 0.8931\n",
      "Epoch 625/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7908 - val_loss: 0.8930\n",
      "Epoch 626/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7907 - val_loss: 0.8933\n",
      "Epoch 627/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7906 - val_loss: 0.8930\n",
      "Epoch 628/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7905 - val_loss: 0.8931\n",
      "Epoch 629/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7904 - val_loss: 0.8929\n",
      "Epoch 630/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7903 - val_loss: 0.8932\n",
      "Epoch 631/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7902 - val_loss: 0.8933\n",
      "Epoch 632/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7901 - val_loss: 0.8932\n",
      "Epoch 633/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7900 - val_loss: 0.8930\n",
      "Epoch 634/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7900 - val_loss: 0.8930\n",
      "Epoch 635/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7899 - val_loss: 0.8933\n",
      "Epoch 636/1500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7898 - val_loss: 0.8933\n",
      "Epoch 637/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7897 - val_loss: 0.8935\n",
      "Epoch 638/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7897 - val_loss: 0.8931\n",
      "Epoch 639/1500\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7896 - val_loss: 0.8934\n",
      "Epoch 640/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7895 - val_loss: 0.8932\n",
      "Epoch 641/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7894 - val_loss: 0.8935\n",
      "Epoch 642/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7893 - val_loss: 0.8934\n",
      "Epoch 643/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7892 - val_loss: 0.8934\n",
      "Epoch 644/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7891 - val_loss: 0.8933\n",
      "Epoch 645/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7890 - val_loss: 0.8932\n",
      "Epoch 646/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7890 - val_loss: 0.8936\n",
      "Epoch 647/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7889 - val_loss: 0.8934\n",
      "Epoch 648/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7888 - val_loss: 0.8936\n",
      "Epoch 649/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7887 - val_loss: 0.8934\n",
      "Epoch 650/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7886 - val_loss: 0.8935\n",
      "Epoch 651/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7885 - val_loss: 0.8935\n",
      "Epoch 652/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7884 - val_loss: 0.8935\n",
      "Epoch 653/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7884 - val_loss: 0.8937\n",
      "Epoch 654/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7883 - val_loss: 0.8936\n",
      "Epoch 655/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7882 - val_loss: 0.8937\n",
      "Epoch 656/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7881 - val_loss: 0.8933\n",
      "Epoch 657/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7881 - val_loss: 0.8938\n",
      "Epoch 658/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7880 - val_loss: 0.8938\n",
      "Epoch 659/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7879 - val_loss: 0.8939\n",
      "Epoch 660/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7878 - val_loss: 0.8936\n",
      "Epoch 661/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7877 - val_loss: 0.8936\n",
      "Epoch 662/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7876 - val_loss: 0.8939\n",
      "Epoch 663/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7875 - val_loss: 0.8940\n",
      "Epoch 664/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7875 - val_loss: 0.8939\n",
      "Epoch 665/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7874 - val_loss: 0.8935\n",
      "Epoch 666/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7874 - val_loss: 0.8939\n",
      "Epoch 667/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7873 - val_loss: 0.8937\n",
      "Epoch 668/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7872 - val_loss: 0.8942\n",
      "Epoch 669/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7871 - val_loss: 0.8938\n",
      "Epoch 670/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7870 - val_loss: 0.8938\n",
      "Epoch 671/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7869 - val_loss: 0.8939\n",
      "Epoch 672/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7868 - val_loss: 0.8940\n",
      "Epoch 673/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7868 - val_loss: 0.8940\n",
      "Epoch 674/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7867 - val_loss: 0.8938\n",
      "Epoch 675/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7866 - val_loss: 0.8941\n",
      "Epoch 676/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7866 - val_loss: 0.8940\n",
      "Epoch 677/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7865 - val_loss: 0.8942\n",
      "Epoch 678/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7864 - val_loss: 0.8938\n",
      "Epoch 679/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7863 - val_loss: 0.8941\n",
      "Epoch 680/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7863 - val_loss: 0.8942\n",
      "Epoch 681/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7862 - val_loss: 0.8942\n",
      "Epoch 682/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7861 - val_loss: 0.8940\n",
      "Epoch 683/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7860 - val_loss: 0.8940\n",
      "Epoch 684/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7859 - val_loss: 0.8944\n",
      "Epoch 685/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7859 - val_loss: 0.8943\n",
      "Epoch 686/1500\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7858 - val_loss: 0.8943\n",
      "Epoch 687/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7857 - val_loss: 0.8942\n",
      "Epoch 688/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7857 - val_loss: 0.8945\n",
      "Epoch 689/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7856 - val_loss: 0.8943\n",
      "Epoch 690/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7856 - val_loss: 0.8944\n",
      "Epoch 691/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7855 - val_loss: 0.8942\n",
      "Epoch 692/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7854 - val_loss: 0.8945\n",
      "Epoch 693/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7853 - val_loss: 0.8945\n",
      "Epoch 694/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7852 - val_loss: 0.8946\n",
      "Epoch 695/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7851 - val_loss: 0.8946\n",
      "Epoch 696/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7850 - val_loss: 0.8946\n",
      "Epoch 697/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7850 - val_loss: 0.8947\n",
      "Epoch 698/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7849 - val_loss: 0.8946\n",
      "Epoch 699/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7849 - val_loss: 0.8948\n",
      "Epoch 700/1500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7848 - val_loss: 0.8946\n",
      "Epoch 701/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7848 - val_loss: 0.8948\n",
      "Epoch 702/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7847 - val_loss: 0.8948\n",
      "Epoch 703/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7846 - val_loss: 0.8948\n",
      "Epoch 704/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7845 - val_loss: 0.8947\n",
      "Epoch 705/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7844 - val_loss: 0.8950\n",
      "Epoch 706/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7843 - val_loss: 0.8948\n",
      "Epoch 707/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7843 - val_loss: 0.8946\n",
      "Epoch 708/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7842 - val_loss: 0.8949\n",
      "Epoch 709/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7841 - val_loss: 0.8953\n",
      "Epoch 710/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7841 - val_loss: 0.8950\n",
      "Epoch 711/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7841 - val_loss: 0.8945\n",
      "Epoch 712/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7840 - val_loss: 0.8951\n",
      "Epoch 713/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7839 - val_loss: 0.8957\n",
      "Epoch 714/1500\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7838 - val_loss: 0.8950\n",
      "Epoch 715/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7837 - val_loss: 0.8944\n",
      "Epoch 716/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7836 - val_loss: 0.8950\n",
      "Epoch 717/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7836 - val_loss: 0.8956\n",
      "Epoch 718/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7835 - val_loss: 0.8949\n",
      "Epoch 719/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7834 - val_loss: 0.8945\n",
      "Epoch 720/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7834 - val_loss: 0.8955\n",
      "Epoch 721/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7833 - val_loss: 0.8955\n",
      "Epoch 722/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7833 - val_loss: 0.8950\n",
      "Epoch 723/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7832 - val_loss: 0.8946\n",
      "Epoch 724/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7832 - val_loss: 0.8952\n",
      "Epoch 725/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7831 - val_loss: 0.8953\n",
      "Epoch 726/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7830 - val_loss: 0.8948\n",
      "Epoch 727/1500\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7829 - val_loss: 0.8949\n",
      "Epoch 728/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7828 - val_loss: 0.8952\n",
      "Epoch 729/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7828 - val_loss: 0.8953\n",
      "Epoch 730/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7827 - val_loss: 0.8949\n",
      "Epoch 731/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7827 - val_loss: 0.8951\n",
      "Epoch 732/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7826 - val_loss: 0.8950\n",
      "Epoch 733/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7826 - val_loss: 0.8953\n",
      "Epoch 734/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7825 - val_loss: 0.8950\n",
      "Epoch 735/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7824 - val_loss: 0.8952\n",
      "Epoch 736/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7824 - val_loss: 0.8950\n",
      "Epoch 737/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7823 - val_loss: 0.8956\n",
      "Epoch 738/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7822 - val_loss: 0.8948\n",
      "Epoch 739/1500\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7821 - val_loss: 0.8952\n",
      "Epoch 740/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7821 - val_loss: 0.8951\n",
      "Epoch 741/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7820 - val_loss: 0.8951\n",
      "Epoch 742/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7819 - val_loss: 0.8957\n",
      "Epoch 743/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7819 - val_loss: 0.8948\n",
      "Epoch 744/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7818 - val_loss: 0.8955\n",
      "Epoch 745/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7818 - val_loss: 0.8951\n",
      "Epoch 746/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7817 - val_loss: 0.8957\n",
      "Epoch 747/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7817 - val_loss: 0.8952\n",
      "Epoch 748/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7816 - val_loss: 0.8952\n",
      "Epoch 749/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7815 - val_loss: 0.8959\n",
      "Epoch 750/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7815 - val_loss: 0.8953\n",
      "Epoch 751/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7814 - val_loss: 0.8948\n",
      "Epoch 752/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7813 - val_loss: 0.8958\n",
      "Epoch 753/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7812 - val_loss: 0.8953\n",
      "Epoch 754/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7812 - val_loss: 0.8960\n",
      "Epoch 755/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7811 - val_loss: 0.8946\n",
      "Epoch 756/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7811 - val_loss: 0.8955\n",
      "Epoch 757/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7810 - val_loss: 0.8954\n",
      "Epoch 758/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7809 - val_loss: 0.8949\n",
      "Epoch 759/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7808 - val_loss: 0.8955\n",
      "Epoch 760/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7808 - val_loss: 0.8944\n",
      "Epoch 761/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7807 - val_loss: 0.8964\n",
      "Epoch 762/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7807 - val_loss: 0.8942\n",
      "Epoch 763/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7806 - val_loss: 0.8949\n",
      "Epoch 764/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7806 - val_loss: 0.8954\n",
      "Epoch 765/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7805 - val_loss: 0.8952\n",
      "Epoch 766/1500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7805 - val_loss: 0.8945\n",
      "Epoch 767/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7804 - val_loss: 0.8952\n",
      "Epoch 768/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7804 - val_loss: 0.8945\n",
      "Epoch 769/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7804 - val_loss: 0.8958\n",
      "Epoch 770/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7803 - val_loss: 0.8933\n",
      "Epoch 771/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7803 - val_loss: 0.8967\n",
      "Epoch 772/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7802 - val_loss: 0.8937\n",
      "Epoch 773/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7800 - val_loss: 0.8940\n",
      "Epoch 774/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7799 - val_loss: 0.8958\n",
      "Epoch 775/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7799 - val_loss: 0.8937\n",
      "Epoch 776/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7799 - val_loss: 0.8955\n",
      "Epoch 777/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7798 - val_loss: 0.8937\n",
      "Epoch 778/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7798 - val_loss: 0.8950\n",
      "Epoch 779/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7797 - val_loss: 0.8946\n",
      "Epoch 780/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7796 - val_loss: 0.8937\n",
      "Epoch 781/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7795 - val_loss: 0.8953\n",
      "Epoch 782/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7794 - val_loss: 0.8941\n",
      "Epoch 783/1500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7794 - val_loss: 0.8940\n",
      "Epoch 784/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7794 - val_loss: 0.8945\n",
      "Epoch 785/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7793 - val_loss: 0.8946\n",
      "Epoch 786/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7793 - val_loss: 0.8937\n",
      "Epoch 787/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7792 - val_loss: 0.8951\n",
      "Epoch 788/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7791 - val_loss: 0.8933\n",
      "Epoch 789/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7791 - val_loss: 0.8958\n",
      "Epoch 790/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7790 - val_loss: 0.8929\n",
      "Epoch 791/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7789 - val_loss: 0.8949\n",
      "Epoch 792/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7789 - val_loss: 0.8945\n",
      "Epoch 793/1500\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7788 - val_loss: 0.8933\n",
      "Epoch 794/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7787 - val_loss: 0.8955\n",
      "Epoch 795/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7787 - val_loss: 0.8928\n",
      "Epoch 796/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7787 - val_loss: 0.8954\n",
      "Epoch 797/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7786 - val_loss: 0.8930\n",
      "Epoch 798/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7785 - val_loss: 0.8944\n",
      "Epoch 799/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7785 - val_loss: 0.8940\n",
      "Epoch 800/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7784 - val_loss: 0.8936\n",
      "Epoch 801/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7784 - val_loss: 0.8946\n",
      "Epoch 802/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7783 - val_loss: 0.8935\n",
      "Epoch 803/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7782 - val_loss: 0.8937\n",
      "Epoch 804/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7781 - val_loss: 0.8946\n",
      "Epoch 805/1500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7781 - val_loss: 0.8929\n",
      "Epoch 806/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7780 - val_loss: 0.8948\n",
      "Epoch 807/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7780 - val_loss: 0.8929\n",
      "Epoch 808/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7779 - val_loss: 0.8951\n",
      "Epoch 809/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7779 - val_loss: 0.8926\n",
      "Epoch 810/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7778 - val_loss: 0.8947\n",
      "Epoch 811/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7777 - val_loss: 0.8928\n",
      "Epoch 812/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7777 - val_loss: 0.8950\n",
      "Epoch 813/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7777 - val_loss: 0.8918\n",
      "Epoch 814/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7777 - val_loss: 0.8972\n",
      "Epoch 815/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7778 - val_loss: 0.8901\n",
      "Epoch 816/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7779 - val_loss: 0.8976\n",
      "Epoch 817/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7779 - val_loss: 0.8916\n",
      "Epoch 818/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7777 - val_loss: 0.8928\n",
      "Epoch 819/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7774 - val_loss: 0.8948\n",
      "Epoch 820/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7773 - val_loss: 0.8917\n",
      "Epoch 821/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7773 - val_loss: 0.8953\n",
      "Epoch 822/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7773 - val_loss: 0.8919\n",
      "Epoch 823/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7772 - val_loss: 0.8927\n",
      "Epoch 824/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7771 - val_loss: 0.8950\n",
      "Epoch 825/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7770 - val_loss: 0.8914\n",
      "Epoch 826/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7770 - val_loss: 0.8933\n",
      "Epoch 827/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7770 - val_loss: 0.8938\n",
      "Epoch 828/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7769 - val_loss: 0.8922\n",
      "Epoch 829/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7768 - val_loss: 0.8932\n",
      "Epoch 830/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7767 - val_loss: 0.8929\n",
      "Epoch 831/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7767 - val_loss: 0.8937\n",
      "Epoch 832/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7767 - val_loss: 0.8918\n",
      "Epoch 833/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7766 - val_loss: 0.8945\n",
      "Epoch 834/1500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7765 - val_loss: 0.8915\n",
      "Epoch 835/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7764 - val_loss: 0.8942\n",
      "Epoch 836/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7764 - val_loss: 0.8924\n",
      "Epoch 837/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7763 - val_loss: 0.8926\n",
      "Epoch 838/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7763 - val_loss: 0.8933\n",
      "Epoch 839/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7762 - val_loss: 0.8916\n",
      "Epoch 840/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7762 - val_loss: 0.8945\n",
      "Epoch 841/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7761 - val_loss: 0.8909\n",
      "Epoch 842/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7760 - val_loss: 0.8937\n",
      "Epoch 843/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7760 - val_loss: 0.8927\n",
      "Epoch 844/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7759 - val_loss: 0.8912\n",
      "Epoch 845/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7759 - val_loss: 0.8941\n",
      "Epoch 846/1500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7758 - val_loss: 0.8916\n",
      "Epoch 847/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7757 - val_loss: 0.8927\n",
      "Epoch 848/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7757 - val_loss: 0.8922\n",
      "Epoch 849/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7756 - val_loss: 0.8936\n",
      "Epoch 850/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7756 - val_loss: 0.8903\n",
      "Epoch 851/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7756 - val_loss: 0.8956\n",
      "Epoch 852/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7755 - val_loss: 0.8896\n",
      "Epoch 853/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7755 - val_loss: 0.8949\n",
      "Epoch 854/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7755 - val_loss: 0.8898\n",
      "Epoch 855/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7754 - val_loss: 0.8950\n",
      "Epoch 856/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7753 - val_loss: 0.8900\n",
      "Epoch 857/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7752 - val_loss: 0.8919\n",
      "Epoch 858/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7752 - val_loss: 0.8938\n",
      "Epoch 859/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7751 - val_loss: 0.8893\n",
      "Epoch 860/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7751 - val_loss: 0.8941\n",
      "Epoch 861/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7750 - val_loss: 0.8907\n",
      "Epoch 862/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7750 - val_loss: 0.8927\n",
      "Epoch 863/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7749 - val_loss: 0.8904\n",
      "Epoch 864/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7749 - val_loss: 0.8937\n",
      "Epoch 865/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7748 - val_loss: 0.8901\n",
      "Epoch 866/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7747 - val_loss: 0.8926\n",
      "Epoch 867/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7747 - val_loss: 0.8915\n",
      "Epoch 868/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7746 - val_loss: 0.8923\n",
      "Epoch 869/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7746 - val_loss: 0.8901\n",
      "Epoch 870/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7745 - val_loss: 0.8941\n",
      "Epoch 871/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7745 - val_loss: 0.8888\n",
      "Epoch 872/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7744 - val_loss: 0.8931\n",
      "Epoch 873/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7744 - val_loss: 0.8904\n",
      "Epoch 874/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7743 - val_loss: 0.8924\n",
      "Epoch 875/1500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7743 - val_loss: 0.8891\n",
      "Epoch 876/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7742 - val_loss: 0.8942\n",
      "Epoch 877/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7742 - val_loss: 0.8881\n",
      "Epoch 878/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7742 - val_loss: 0.8944\n",
      "Epoch 879/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7741 - val_loss: 0.8878\n",
      "Epoch 880/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7741 - val_loss: 0.8957\n",
      "Epoch 881/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7741 - val_loss: 0.8863\n",
      "Epoch 882/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7740 - val_loss: 0.8951\n",
      "Epoch 883/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7739 - val_loss: 0.8887\n",
      "Epoch 884/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7738 - val_loss: 0.8902\n",
      "Epoch 885/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7737 - val_loss: 0.8927\n",
      "Epoch 886/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7736 - val_loss: 0.8882\n",
      "Epoch 887/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7736 - val_loss: 0.8937\n",
      "Epoch 888/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7736 - val_loss: 0.8880\n",
      "Epoch 889/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7736 - val_loss: 0.8935\n",
      "Epoch 890/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7735 - val_loss: 0.8886\n",
      "Epoch 891/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7734 - val_loss: 0.8923\n",
      "Epoch 892/1500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7734 - val_loss: 0.8899\n",
      "Epoch 893/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7733 - val_loss: 0.8905\n",
      "Epoch 894/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7732 - val_loss: 0.8907\n",
      "Epoch 895/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7731 - val_loss: 0.8906\n",
      "Epoch 896/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7731 - val_loss: 0.8898\n",
      "Epoch 897/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7730 - val_loss: 0.8903\n",
      "Epoch 898/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7730 - val_loss: 0.8902\n",
      "Epoch 899/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7729 - val_loss: 0.8897\n",
      "Epoch 900/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7729 - val_loss: 0.8920\n",
      "Epoch 901/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7728 - val_loss: 0.8869\n",
      "Epoch 902/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7728 - val_loss: 0.8956\n",
      "Epoch 903/1500\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7728 - val_loss: 0.8844\n",
      "Epoch 904/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7729 - val_loss: 0.8967\n",
      "Epoch 905/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7729 - val_loss: 0.8852\n",
      "Epoch 906/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7728 - val_loss: 0.8926\n",
      "Epoch 907/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7726 - val_loss: 0.8896\n",
      "Epoch 908/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7725 - val_loss: 0.8872\n",
      "Epoch 909/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7725 - val_loss: 0.8938\n",
      "Epoch 910/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7725 - val_loss: 0.8855\n",
      "Epoch 911/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7724 - val_loss: 0.8925\n",
      "Epoch 912/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7723 - val_loss: 0.8889\n",
      "Epoch 913/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7722 - val_loss: 0.8881\n",
      "Epoch 914/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7722 - val_loss: 0.8924\n",
      "Epoch 915/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7722 - val_loss: 0.8864\n",
      "Epoch 916/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7721 - val_loss: 0.8919\n",
      "Epoch 917/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7720 - val_loss: 0.8883\n",
      "Epoch 918/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7719 - val_loss: 0.8888\n",
      "Epoch 919/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7719 - val_loss: 0.8901\n",
      "Epoch 920/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7719 - val_loss: 0.8889\n",
      "Epoch 921/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7718 - val_loss: 0.8882\n",
      "Epoch 922/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7718 - val_loss: 0.8916\n",
      "Epoch 923/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7717 - val_loss: 0.8854\n",
      "Epoch 924/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7717 - val_loss: 0.8943\n",
      "Epoch 925/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7717 - val_loss: 0.8838\n",
      "Epoch 926/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7717 - val_loss: 0.8937\n",
      "Epoch 927/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7716 - val_loss: 0.8863\n",
      "Epoch 928/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7714 - val_loss: 0.8891\n",
      "Epoch 929/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7714 - val_loss: 0.8907\n",
      "Epoch 930/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7713 - val_loss: 0.8858\n",
      "Epoch 931/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7713 - val_loss: 0.8922\n",
      "Epoch 932/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7712 - val_loss: 0.8861\n",
      "Epoch 933/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7712 - val_loss: 0.8903\n",
      "Epoch 934/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7711 - val_loss: 0.8877\n",
      "Epoch 935/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7711 - val_loss: 0.8905\n",
      "Epoch 936/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7711 - val_loss: 0.8860\n",
      "Epoch 937/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7711 - val_loss: 0.8930\n",
      "Epoch 938/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7711 - val_loss: 0.8837\n",
      "Epoch 939/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7710 - val_loss: 0.8945\n",
      "Epoch 940/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7710 - val_loss: 0.8838\n",
      "Epoch 941/1500\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7709 - val_loss: 0.8910\n",
      "Epoch 942/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7707 - val_loss: 0.8882\n",
      "Epoch 943/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7706 - val_loss: 0.8862\n",
      "Epoch 944/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7706 - val_loss: 0.8927\n",
      "Epoch 945/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7706 - val_loss: 0.8833\n",
      "Epoch 946/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7706 - val_loss: 0.8933\n",
      "Epoch 947/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7706 - val_loss: 0.8845\n",
      "Epoch 948/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7705 - val_loss: 0.8894\n",
      "Epoch 949/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7704 - val_loss: 0.8881\n",
      "Epoch 950/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7703 - val_loss: 0.8864\n",
      "Epoch 951/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7703 - val_loss: 0.8902\n",
      "Epoch 952/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7702 - val_loss: 0.8853\n",
      "Epoch 953/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7701 - val_loss: 0.8916\n",
      "Epoch 954/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7702 - val_loss: 0.8845\n",
      "Epoch 955/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7702 - val_loss: 0.8925\n",
      "Epoch 956/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7702 - val_loss: 0.8831\n",
      "Epoch 957/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7702 - val_loss: 0.8927\n",
      "Epoch 958/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7700 - val_loss: 0.8844\n",
      "Epoch 959/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7699 - val_loss: 0.8891\n",
      "Epoch 960/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7698 - val_loss: 0.8882\n",
      "Epoch 961/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7697 - val_loss: 0.8851\n",
      "Epoch 962/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7697 - val_loss: 0.8916\n",
      "Epoch 963/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7697 - val_loss: 0.8835\n",
      "Epoch 964/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7697 - val_loss: 0.8922\n",
      "Epoch 965/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7697 - val_loss: 0.8838\n",
      "Epoch 966/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7696 - val_loss: 0.8906\n",
      "Epoch 967/1500\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7695 - val_loss: 0.8859\n",
      "Epoch 968/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7694 - val_loss: 0.8872\n",
      "Epoch 969/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7693 - val_loss: 0.8893\n",
      "Epoch 970/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7693 - val_loss: 0.8845\n",
      "Epoch 971/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7693 - val_loss: 0.8921\n",
      "Epoch 972/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7693 - val_loss: 0.8829\n",
      "Epoch 973/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7693 - val_loss: 0.8926\n",
      "Epoch 974/1500\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7693 - val_loss: 0.8831\n",
      "Epoch 975/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7692 - val_loss: 0.8908\n",
      "Epoch 976/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7691 - val_loss: 0.8853\n",
      "Epoch 977/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7690 - val_loss: 0.8869\n",
      "Epoch 978/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7689 - val_loss: 0.8882\n",
      "Epoch 979/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7689 - val_loss: 0.8845\n",
      "Epoch 980/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7688 - val_loss: 0.8903\n",
      "Epoch 981/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7688 - val_loss: 0.8830\n",
      "Epoch 982/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7688 - val_loss: 0.8913\n",
      "Epoch 983/1500\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7688 - val_loss: 0.8829\n",
      "Epoch 984/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7688 - val_loss: 0.8911\n",
      "Epoch 985/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7687 - val_loss: 0.8830\n",
      "Epoch 986/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7686 - val_loss: 0.8901\n",
      "Epoch 987/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7685 - val_loss: 0.8849\n",
      "Epoch 988/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7684 - val_loss: 0.8872\n",
      "Epoch 989/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7684 - val_loss: 0.8881\n",
      "Epoch 990/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7683 - val_loss: 0.8845\n",
      "Epoch 991/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7683 - val_loss: 0.8900\n",
      "Epoch 992/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7683 - val_loss: 0.8831\n",
      "Epoch 993/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7683 - val_loss: 0.8915\n",
      "Epoch 994/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7683 - val_loss: 0.8811\n",
      "Epoch 995/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7683 - val_loss: 0.8935\n",
      "Epoch 996/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7683 - val_loss: 0.8806\n",
      "Epoch 997/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7682 - val_loss: 0.8908\n",
      "Epoch 998/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7681 - val_loss: 0.8845\n",
      "Epoch 999/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7680 - val_loss: 0.8860\n",
      "Epoch 1000/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7679 - val_loss: 0.8876\n",
      "Epoch 1001/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7678 - val_loss: 0.8842\n",
      "Epoch 1002/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7678 - val_loss: 0.8895\n",
      "Epoch 1003/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7678 - val_loss: 0.8823\n",
      "Epoch 1004/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7678 - val_loss: 0.8924\n",
      "Epoch 1005/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7678 - val_loss: 0.8799\n",
      "Epoch 1006/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7678 - val_loss: 0.8928\n",
      "Epoch 1007/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7678 - val_loss: 0.8814\n",
      "Epoch 1008/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7677 - val_loss: 0.8896\n",
      "Epoch 1009/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7676 - val_loss: 0.8846\n",
      "Epoch 1010/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7675 - val_loss: 0.8863\n",
      "Epoch 1011/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7674 - val_loss: 0.8874\n",
      "Epoch 1012/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7673 - val_loss: 0.8840\n",
      "Epoch 1013/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7673 - val_loss: 0.8898\n",
      "Epoch 1014/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7673 - val_loss: 0.8814\n",
      "Epoch 1015/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7674 - val_loss: 0.8923\n",
      "Epoch 1016/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7674 - val_loss: 0.8804\n",
      "Epoch 1017/1500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7674 - val_loss: 0.8918\n",
      "Epoch 1018/1500\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7673 - val_loss: 0.8819\n",
      "Epoch 1019/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7672 - val_loss: 0.8893\n",
      "Epoch 1020/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7671 - val_loss: 0.8842\n",
      "Epoch 1021/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7670 - val_loss: 0.8863\n",
      "Epoch 1022/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7669 - val_loss: 0.8875\n",
      "Epoch 1023/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7669 - val_loss: 0.8828\n",
      "Epoch 1024/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7669 - val_loss: 0.8912\n",
      "Epoch 1025/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7669 - val_loss: 0.8806\n",
      "Epoch 1026/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7669 - val_loss: 0.8925\n",
      "Epoch 1027/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7669 - val_loss: 0.8806\n",
      "Epoch 1028/1500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7668 - val_loss: 0.8909\n",
      "Epoch 1029/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7667 - val_loss: 0.8830\n",
      "Epoch 1030/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7666 - val_loss: 0.8880\n",
      "Epoch 1031/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7665 - val_loss: 0.8854\n",
      "Epoch 1032/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7665 - val_loss: 0.8846\n",
      "Epoch 1033/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7665 - val_loss: 0.8896\n",
      "Epoch 1034/1500\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7664 - val_loss: 0.8816\n",
      "Epoch 1035/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7665 - val_loss: 0.8924\n",
      "Epoch 1036/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7665 - val_loss: 0.8806\n",
      "Epoch 1037/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7665 - val_loss: 0.8926\n",
      "Epoch 1038/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7665 - val_loss: 0.8809\n",
      "Epoch 1039/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7664 - val_loss: 0.8909\n",
      "Epoch 1040/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7663 - val_loss: 0.8831\n",
      "Epoch 1041/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7662 - val_loss: 0.8869\n",
      "Epoch 1042/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7661 - val_loss: 0.8873\n",
      "Epoch 1043/1500\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7661 - val_loss: 0.8831\n",
      "Epoch 1044/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7660 - val_loss: 0.8910\n",
      "Epoch 1045/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7660 - val_loss: 0.8806\n",
      "Epoch 1046/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7661 - val_loss: 0.8923\n",
      "Epoch 1047/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7661 - val_loss: 0.8804\n",
      "Epoch 1048/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7661 - val_loss: 0.8921\n",
      "Epoch 1049/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7661 - val_loss: 0.8810\n",
      "Epoch 1050/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7660 - val_loss: 0.8897\n",
      "Epoch 1051/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7658 - val_loss: 0.8848\n",
      "Epoch 1052/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7657 - val_loss: 0.8844\n",
      "Epoch 1053/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7656 - val_loss: 0.8899\n",
      "Epoch 1054/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7656 - val_loss: 0.8812\n",
      "Epoch 1055/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7656 - val_loss: 0.8925\n",
      "Epoch 1056/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7657 - val_loss: 0.8801\n",
      "Epoch 1057/1500\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7657 - val_loss: 0.8934\n",
      "Epoch 1058/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7657 - val_loss: 0.8801\n",
      "Epoch 1059/1500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7657 - val_loss: 0.8923\n",
      "Epoch 1060/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7655 - val_loss: 0.8829\n",
      "Epoch 1061/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7654 - val_loss: 0.8878\n",
      "Epoch 1062/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7653 - val_loss: 0.8870\n",
      "Epoch 1063/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7652 - val_loss: 0.8837\n",
      "Epoch 1064/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7652 - val_loss: 0.8909\n",
      "Epoch 1065/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7653 - val_loss: 0.8810\n",
      "Epoch 1066/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7653 - val_loss: 0.8933\n",
      "Epoch 1067/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7654 - val_loss: 0.8800\n",
      "Epoch 1068/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7653 - val_loss: 0.8935\n",
      "Epoch 1069/1500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7653 - val_loss: 0.8810\n",
      "Epoch 1070/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7651 - val_loss: 0.8902\n",
      "Epoch 1071/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7650 - val_loss: 0.8854\n",
      "Epoch 1072/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7649 - val_loss: 0.8848\n",
      "Epoch 1073/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7649 - val_loss: 0.8903\n",
      "Epoch 1074/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7649 - val_loss: 0.8818\n",
      "Epoch 1075/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7649 - val_loss: 0.8925\n",
      "Epoch 1076/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7649 - val_loss: 0.8814\n",
      "Epoch 1077/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7649 - val_loss: 0.8926\n",
      "Epoch 1078/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7648 - val_loss: 0.8822\n",
      "Epoch 1079/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7648 - val_loss: 0.8916\n",
      "Epoch 1080/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7647 - val_loss: 0.8836\n",
      "Epoch 1081/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7646 - val_loss: 0.8883\n",
      "Epoch 1082/1500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7645 - val_loss: 0.8866\n",
      "Epoch 1083/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7645 - val_loss: 0.8854\n",
      "Epoch 1084/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7645 - val_loss: 0.8893\n",
      "Epoch 1085/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7644 - val_loss: 0.8842\n",
      "Epoch 1086/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7644 - val_loss: 0.8913\n",
      "Epoch 1087/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7644 - val_loss: 0.8825\n",
      "Epoch 1088/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7645 - val_loss: 0.8935\n",
      "Epoch 1089/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7645 - val_loss: 0.8802\n",
      "Epoch 1090/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7645 - val_loss: 0.8960\n",
      "Epoch 1091/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7645 - val_loss: 0.8798\n",
      "Epoch 1092/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7644 - val_loss: 0.8935\n",
      "Epoch 1093/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7643 - val_loss: 0.8841\n",
      "Epoch 1094/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7641 - val_loss: 0.8880\n",
      "Epoch 1095/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7640 - val_loss: 0.8888\n",
      "Epoch 1096/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7640 - val_loss: 0.8846\n",
      "Epoch 1097/1500\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7640 - val_loss: 0.8924\n",
      "Epoch 1098/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7640 - val_loss: 0.8812\n",
      "Epoch 1099/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7641 - val_loss: 0.8971\n",
      "Epoch 1100/1500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7642 - val_loss: 0.8781\n",
      "Epoch 1101/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7642 - val_loss: 0.8973\n",
      "Epoch 1102/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7641 - val_loss: 0.8819\n",
      "Epoch 1103/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7640 - val_loss: 0.8903\n",
      "Epoch 1104/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7638 - val_loss: 0.8885\n",
      "Epoch 1105/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7637 - val_loss: 0.8843\n",
      "Epoch 1106/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7637 - val_loss: 0.8929\n",
      "Epoch 1107/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7638 - val_loss: 0.8821\n",
      "Epoch 1108/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7638 - val_loss: 0.8936\n",
      "Epoch 1109/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7637 - val_loss: 0.8827\n",
      "Epoch 1110/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7636 - val_loss: 0.8916\n",
      "Epoch 1111/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7635 - val_loss: 0.8859\n",
      "Epoch 1112/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7635 - val_loss: 0.8876\n",
      "Epoch 1113/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7634 - val_loss: 0.8892\n",
      "Epoch 1114/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7634 - val_loss: 0.8848\n",
      "Epoch 1115/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7634 - val_loss: 0.8914\n",
      "Epoch 1116/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7634 - val_loss: 0.8843\n",
      "Epoch 1117/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7633 - val_loss: 0.8904\n",
      "Epoch 1118/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7633 - val_loss: 0.8848\n",
      "Epoch 1119/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7632 - val_loss: 0.8898\n",
      "Epoch 1120/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7632 - val_loss: 0.8850\n",
      "Epoch 1121/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7632 - val_loss: 0.8902\n",
      "Epoch 1122/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7632 - val_loss: 0.8845\n",
      "Epoch 1123/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7632 - val_loss: 0.8910\n",
      "Epoch 1124/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7632 - val_loss: 0.8831\n",
      "Epoch 1125/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7632 - val_loss: 0.8936\n",
      "Epoch 1126/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7633 - val_loss: 0.8803\n",
      "Epoch 1127/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7633 - val_loss: 0.8967\n",
      "Epoch 1128/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7633 - val_loss: 0.8787\n",
      "Epoch 1129/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7633 - val_loss: 0.8960\n",
      "Epoch 1130/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7631 - val_loss: 0.8817\n",
      "Epoch 1131/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7629 - val_loss: 0.8889\n",
      "Epoch 1132/1500\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7628 - val_loss: 0.8887\n",
      "Epoch 1133/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7628 - val_loss: 0.8825\n",
      "Epoch 1134/1500\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7628 - val_loss: 0.8938\n",
      "Epoch 1135/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7629 - val_loss: 0.8797\n",
      "Epoch 1136/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7630 - val_loss: 0.8957\n",
      "Epoch 1137/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7630 - val_loss: 0.8796\n",
      "Epoch 1138/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7629 - val_loss: 0.8935\n",
      "Epoch 1139/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7628 - val_loss: 0.8836\n",
      "Epoch 1140/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7626 - val_loss: 0.8865\n",
      "Epoch 1141/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7625 - val_loss: 0.8895\n",
      "Epoch 1142/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7625 - val_loss: 0.8820\n",
      "Epoch 1143/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7625 - val_loss: 0.8921\n",
      "Epoch 1144/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7625 - val_loss: 0.8816\n",
      "Epoch 1145/1500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7625 - val_loss: 0.8914\n",
      "Epoch 1146/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7625 - val_loss: 0.8832\n",
      "Epoch 1147/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7624 - val_loss: 0.8893\n",
      "Epoch 1148/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7624 - val_loss: 0.8849\n",
      "Epoch 1149/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7623 - val_loss: 0.8879\n",
      "Epoch 1150/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7623 - val_loss: 0.8854\n",
      "Epoch 1151/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7622 - val_loss: 0.8864\n",
      "Epoch 1152/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7621 - val_loss: 0.8871\n",
      "Epoch 1153/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7621 - val_loss: 0.8851\n",
      "Epoch 1154/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7621 - val_loss: 0.8883\n",
      "Epoch 1155/1500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7621 - val_loss: 0.8842\n",
      "Epoch 1156/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7621 - val_loss: 0.8891\n",
      "Epoch 1157/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7621 - val_loss: 0.8836\n",
      "Epoch 1158/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7621 - val_loss: 0.8909\n",
      "Epoch 1159/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7621 - val_loss: 0.8811\n",
      "Epoch 1160/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7621 - val_loss: 0.8939\n",
      "Epoch 1161/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7621 - val_loss: 0.8784\n",
      "Epoch 1162/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7621 - val_loss: 0.8949\n",
      "Epoch 1163/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7621 - val_loss: 0.8792\n",
      "Epoch 1164/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7620 - val_loss: 0.8912\n",
      "Epoch 1165/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7619 - val_loss: 0.8835\n",
      "Epoch 1166/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7618 - val_loss: 0.8862\n",
      "Epoch 1167/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7617 - val_loss: 0.8872\n",
      "Epoch 1168/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7617 - val_loss: 0.8840\n",
      "Epoch 1169/1500\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7617 - val_loss: 0.8897\n",
      "Epoch 1170/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7617 - val_loss: 0.8812\n",
      "Epoch 1171/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7617 - val_loss: 0.8947\n",
      "Epoch 1172/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7618 - val_loss: 0.8767\n",
      "Epoch 1173/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7619 - val_loss: 0.8980\n",
      "Epoch 1174/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7620 - val_loss: 0.8772\n",
      "Epoch 1175/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7619 - val_loss: 0.8927\n",
      "Epoch 1176/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7617 - val_loss: 0.8842\n",
      "Epoch 1177/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7615 - val_loss: 0.8845\n",
      "Epoch 1178/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7615 - val_loss: 0.8906\n",
      "Epoch 1179/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7615 - val_loss: 0.8803\n",
      "Epoch 1180/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7615 - val_loss: 0.8936\n",
      "Epoch 1181/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7615 - val_loss: 0.8796\n",
      "Epoch 1182/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7615 - val_loss: 0.8924\n",
      "Epoch 1183/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7614 - val_loss: 0.8828\n",
      "Epoch 1184/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7613 - val_loss: 0.8877\n",
      "Epoch 1185/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7613 - val_loss: 0.8872\n",
      "Epoch 1186/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7613 - val_loss: 0.8842\n",
      "Epoch 1187/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7612 - val_loss: 0.8893\n",
      "Epoch 1188/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7611 - val_loss: 0.8833\n",
      "Epoch 1189/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7611 - val_loss: 0.8898\n",
      "Epoch 1190/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7611 - val_loss: 0.8835\n",
      "Epoch 1191/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7611 - val_loss: 0.8902\n",
      "Epoch 1192/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7612 - val_loss: 0.8822\n",
      "Epoch 1193/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7612 - val_loss: 0.8927\n",
      "Epoch 1194/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7612 - val_loss: 0.8795\n",
      "Epoch 1195/1500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7611 - val_loss: 0.8941\n",
      "Epoch 1196/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7610 - val_loss: 0.8802\n",
      "Epoch 1197/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7610 - val_loss: 0.8897\n",
      "Epoch 1198/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7609 - val_loss: 0.8856\n",
      "Epoch 1199/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7608 - val_loss: 0.8846\n",
      "Epoch 1200/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7608 - val_loss: 0.8903\n",
      "Epoch 1201/1500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7608 - val_loss: 0.8819\n",
      "Epoch 1202/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7608 - val_loss: 0.8939\n",
      "Epoch 1203/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7609 - val_loss: 0.8789\n",
      "Epoch 1204/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7610 - val_loss: 0.8973\n",
      "Epoch 1205/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7610 - val_loss: 0.8771\n",
      "Epoch 1206/1500\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7610 - val_loss: 0.8964\n",
      "Epoch 1207/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7609 - val_loss: 0.8811\n",
      "Epoch 1208/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7607 - val_loss: 0.8887\n",
      "Epoch 1209/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7606 - val_loss: 0.8889\n",
      "Epoch 1210/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7605 - val_loss: 0.8821\n",
      "Epoch 1211/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7605 - val_loss: 0.8926\n",
      "Epoch 1212/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7606 - val_loss: 0.8814\n",
      "Epoch 1213/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7605 - val_loss: 0.8921\n",
      "Epoch 1214/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7606 - val_loss: 0.8825\n",
      "Epoch 1215/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7606 - val_loss: 0.8921\n",
      "Epoch 1216/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7605 - val_loss: 0.8828\n",
      "Epoch 1217/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7605 - val_loss: 0.8909\n",
      "Epoch 1218/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7604 - val_loss: 0.8846\n",
      "Epoch 1219/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7603 - val_loss: 0.8888\n",
      "Epoch 1220/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7602 - val_loss: 0.8858\n",
      "Epoch 1221/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7602 - val_loss: 0.8877\n",
      "Epoch 1222/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7602 - val_loss: 0.8861\n",
      "Epoch 1223/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7602 - val_loss: 0.8881\n",
      "Epoch 1224/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7601 - val_loss: 0.8865\n",
      "Epoch 1225/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7601 - val_loss: 0.8880\n",
      "Epoch 1226/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7601 - val_loss: 0.8876\n",
      "Epoch 1227/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7600 - val_loss: 0.8874\n",
      "Epoch 1228/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7600 - val_loss: 0.8883\n",
      "Epoch 1229/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7600 - val_loss: 0.8867\n",
      "Epoch 1230/1500\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7600 - val_loss: 0.8876\n",
      "Epoch 1231/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7600 - val_loss: 0.8869\n",
      "Epoch 1232/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7599 - val_loss: 0.8867\n",
      "Epoch 1233/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7599 - val_loss: 0.8882\n",
      "Epoch 1234/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7599 - val_loss: 0.8860\n",
      "Epoch 1235/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7598 - val_loss: 0.8912\n",
      "Epoch 1236/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7599 - val_loss: 0.8826\n",
      "Epoch 1237/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7599 - val_loss: 0.8971\n",
      "Epoch 1238/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7601 - val_loss: 0.8766\n",
      "Epoch 1239/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7603 - val_loss: 0.9046\n",
      "Epoch 1240/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7607 - val_loss: 0.8727\n",
      "Epoch 1241/1500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7609 - val_loss: 0.9039\n",
      "Epoch 1242/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7608 - val_loss: 0.8791\n",
      "Epoch 1243/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7603 - val_loss: 0.8886\n",
      "Epoch 1244/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7599 - val_loss: 0.8941\n",
      "Epoch 1245/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7599 - val_loss: 0.8785\n",
      "Epoch 1246/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7600 - val_loss: 0.8982\n",
      "Epoch 1247/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7600 - val_loss: 0.8824\n",
      "Epoch 1248/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7599 - val_loss: 0.8893\n",
      "Epoch 1249/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7598 - val_loss: 0.8910\n",
      "Epoch 1250/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7598 - val_loss: 0.8830\n",
      "Epoch 1251/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7597 - val_loss: 0.8953\n",
      "Epoch 1252/1500\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7596 - val_loss: 0.8826\n",
      "Epoch 1253/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7597 - val_loss: 0.8937\n",
      "Epoch 1254/1500\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7598 - val_loss: 0.8860\n",
      "Epoch 1255/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7597 - val_loss: 0.8896\n",
      "Epoch 1256/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7595 - val_loss: 0.8882\n",
      "Epoch 1257/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7593 - val_loss: 0.8876\n",
      "Epoch 1258/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7594 - val_loss: 0.8901\n",
      "Epoch 1259/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7595 - val_loss: 0.8855\n",
      "Epoch 1260/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7595 - val_loss: 0.8926\n",
      "Epoch 1261/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7594 - val_loss: 0.8836\n",
      "Epoch 1262/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7594 - val_loss: 0.8943\n",
      "Epoch 1263/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7593 - val_loss: 0.8848\n",
      "Epoch 1264/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7593 - val_loss: 0.8905\n",
      "Epoch 1265/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7592 - val_loss: 0.8893\n",
      "Epoch 1266/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7592 - val_loss: 0.8854\n",
      "Epoch 1267/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7592 - val_loss: 0.8932\n",
      "Epoch 1268/1500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7592 - val_loss: 0.8840\n",
      "Epoch 1269/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7592 - val_loss: 0.8932\n",
      "Epoch 1270/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7591 - val_loss: 0.8863\n",
      "Epoch 1271/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7591 - val_loss: 0.8903\n",
      "Epoch 1272/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7590 - val_loss: 0.8890\n",
      "Epoch 1273/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7590 - val_loss: 0.8897\n",
      "Epoch 1274/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7590 - val_loss: 0.8885\n",
      "Epoch 1275/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7589 - val_loss: 0.8907\n",
      "Epoch 1276/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7589 - val_loss: 0.8879\n",
      "Epoch 1277/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7589 - val_loss: 0.8906\n",
      "Epoch 1278/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7589 - val_loss: 0.8879\n",
      "Epoch 1279/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7589 - val_loss: 0.8911\n",
      "Epoch 1280/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7588 - val_loss: 0.8874\n",
      "Epoch 1281/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7588 - val_loss: 0.8915\n",
      "Epoch 1282/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7588 - val_loss: 0.8873\n",
      "Epoch 1283/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7588 - val_loss: 0.8919\n",
      "Epoch 1284/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7588 - val_loss: 0.8868\n",
      "Epoch 1285/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7588 - val_loss: 0.8944\n",
      "Epoch 1286/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7588 - val_loss: 0.8838\n",
      "Epoch 1287/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7589 - val_loss: 0.8987\n",
      "Epoch 1288/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7590 - val_loss: 0.8802\n",
      "Epoch 1289/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7590 - val_loss: 0.9004\n",
      "Epoch 1290/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7590 - val_loss: 0.8814\n",
      "Epoch 1291/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7590 - val_loss: 0.8959\n",
      "Epoch 1292/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7588 - val_loss: 0.8867\n",
      "Epoch 1293/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7587 - val_loss: 0.8900\n",
      "Epoch 1294/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7586 - val_loss: 0.8918\n",
      "Epoch 1295/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7586 - val_loss: 0.8871\n",
      "Epoch 1296/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7586 - val_loss: 0.8963\n",
      "Epoch 1297/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7587 - val_loss: 0.8825\n",
      "Epoch 1298/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7588 - val_loss: 0.9010\n",
      "Epoch 1299/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7590 - val_loss: 0.8795\n",
      "Epoch 1300/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7590 - val_loss: 0.9005\n",
      "Epoch 1301/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7590 - val_loss: 0.8827\n",
      "Epoch 1302/1500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7588 - val_loss: 0.8932\n",
      "Epoch 1303/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7585 - val_loss: 0.8904\n",
      "Epoch 1304/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7584 - val_loss: 0.8868\n",
      "Epoch 1305/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7584 - val_loss: 0.8960\n",
      "Epoch 1306/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7585 - val_loss: 0.8840\n",
      "Epoch 1307/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7586 - val_loss: 0.8980\n",
      "Epoch 1308/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7586 - val_loss: 0.8846\n",
      "Epoch 1309/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7585 - val_loss: 0.8955\n",
      "Epoch 1310/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7584 - val_loss: 0.8877\n",
      "Epoch 1311/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7583 - val_loss: 0.8913\n",
      "Epoch 1312/1500\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7582 - val_loss: 0.8916\n",
      "Epoch 1313/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7582 - val_loss: 0.8875\n",
      "Epoch 1314/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7583 - val_loss: 0.8954\n",
      "Epoch 1315/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7583 - val_loss: 0.8851\n",
      "Epoch 1316/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7583 - val_loss: 0.8976\n",
      "Epoch 1317/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7584 - val_loss: 0.8844\n",
      "Epoch 1318/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7583 - val_loss: 0.8967\n",
      "Epoch 1319/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7583 - val_loss: 0.8867\n",
      "Epoch 1320/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7582 - val_loss: 0.8930\n",
      "Epoch 1321/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7581 - val_loss: 0.8903\n",
      "Epoch 1322/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7581 - val_loss: 0.8895\n",
      "Epoch 1323/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7580 - val_loss: 0.8943\n",
      "Epoch 1324/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7581 - val_loss: 0.8863\n",
      "Epoch 1325/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7581 - val_loss: 0.8977\n",
      "Epoch 1326/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7581 - val_loss: 0.8844\n",
      "Epoch 1327/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7582 - val_loss: 0.8990\n",
      "Epoch 1328/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7582 - val_loss: 0.8843\n",
      "Epoch 1329/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7582 - val_loss: 0.8968\n",
      "Epoch 1330/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7581 - val_loss: 0.8874\n",
      "Epoch 1331/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7580 - val_loss: 0.8922\n",
      "Epoch 1332/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7579 - val_loss: 0.8918\n",
      "Epoch 1333/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7579 - val_loss: 0.8889\n",
      "Epoch 1334/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7579 - val_loss: 0.8953\n",
      "Epoch 1335/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7579 - val_loss: 0.8867\n",
      "Epoch 1336/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7579 - val_loss: 0.8983\n",
      "Epoch 1337/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7580 - val_loss: 0.8844\n",
      "Epoch 1338/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7581 - val_loss: 0.8995\n",
      "Epoch 1339/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7581 - val_loss: 0.8854\n",
      "Epoch 1340/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7580 - val_loss: 0.8969\n",
      "Epoch 1341/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7579 - val_loss: 0.8890\n",
      "Epoch 1342/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7578 - val_loss: 0.8923\n",
      "Epoch 1343/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7577 - val_loss: 0.8930\n",
      "Epoch 1344/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7577 - val_loss: 0.8889\n",
      "Epoch 1345/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7577 - val_loss: 0.8969\n",
      "Epoch 1346/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7578 - val_loss: 0.8857\n",
      "Epoch 1347/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7578 - val_loss: 0.9003\n",
      "Epoch 1348/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7579 - val_loss: 0.8840\n",
      "Epoch 1349/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7579 - val_loss: 0.9010\n",
      "Epoch 1350/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7579 - val_loss: 0.8853\n",
      "Epoch 1351/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7578 - val_loss: 0.8971\n",
      "Epoch 1352/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7577 - val_loss: 0.8898\n",
      "Epoch 1353/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7576 - val_loss: 0.8913\n",
      "Epoch 1354/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7575 - val_loss: 0.8948\n",
      "Epoch 1355/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7575 - val_loss: 0.8882\n",
      "Epoch 1356/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7575 - val_loss: 0.8981\n",
      "Epoch 1357/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7576 - val_loss: 0.8862\n",
      "Epoch 1358/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7577 - val_loss: 0.9000\n",
      "Epoch 1359/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7577 - val_loss: 0.8855\n",
      "Epoch 1360/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7577 - val_loss: 0.8994\n",
      "Epoch 1361/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7576 - val_loss: 0.8873\n",
      "Epoch 1362/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7576 - val_loss: 0.8966\n",
      "Epoch 1363/1500\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7575 - val_loss: 0.8905\n",
      "Epoch 1364/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7574 - val_loss: 0.8928\n",
      "Epoch 1365/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7573 - val_loss: 0.8942\n",
      "Epoch 1366/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7573 - val_loss: 0.8897\n",
      "Epoch 1367/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7573 - val_loss: 0.8975\n",
      "Epoch 1368/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7574 - val_loss: 0.8876\n",
      "Epoch 1369/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7574 - val_loss: 0.9000\n",
      "Epoch 1370/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7575 - val_loss: 0.8857\n",
      "Epoch 1371/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7575 - val_loss: 0.9004\n",
      "Epoch 1372/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7575 - val_loss: 0.8866\n",
      "Epoch 1373/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7575 - val_loss: 0.8981\n",
      "Epoch 1374/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7574 - val_loss: 0.8896\n",
      "Epoch 1375/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7573 - val_loss: 0.8937\n",
      "Epoch 1376/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7572 - val_loss: 0.8938\n",
      "Epoch 1377/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7572 - val_loss: 0.8901\n",
      "Epoch 1378/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7572 - val_loss: 0.8981\n",
      "Epoch 1379/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7572 - val_loss: 0.8874\n",
      "Epoch 1380/1500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7573 - val_loss: 0.9008\n",
      "Epoch 1381/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7574 - val_loss: 0.8862\n",
      "Epoch 1382/1500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7574 - val_loss: 0.9013\n",
      "Epoch 1383/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7574 - val_loss: 0.8873\n",
      "Epoch 1384/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7573 - val_loss: 0.8981\n",
      "Epoch 1385/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7572 - val_loss: 0.8911\n",
      "Epoch 1386/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7571 - val_loss: 0.8931\n",
      "Epoch 1387/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7570 - val_loss: 0.8954\n",
      "Epoch 1388/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7570 - val_loss: 0.8902\n",
      "Epoch 1389/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7570 - val_loss: 0.8979\n",
      "Epoch 1390/1500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7571 - val_loss: 0.8890\n",
      "Epoch 1391/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7571 - val_loss: 0.8987\n",
      "Epoch 1392/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7571 - val_loss: 0.8888\n",
      "Epoch 1393/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7571 - val_loss: 0.8989\n",
      "Epoch 1394/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7571 - val_loss: 0.8895\n",
      "Epoch 1395/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7570 - val_loss: 0.8985\n",
      "Epoch 1396/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7570 - val_loss: 0.8906\n",
      "Epoch 1397/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7569 - val_loss: 0.8971\n",
      "Epoch 1398/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7569 - val_loss: 0.8917\n",
      "Epoch 1399/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7568 - val_loss: 0.8955\n",
      "Epoch 1400/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7568 - val_loss: 0.8931\n",
      "Epoch 1401/1500\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7568 - val_loss: 0.8941\n",
      "Epoch 1402/1500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7568 - val_loss: 0.8944\n",
      "Epoch 1403/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7568 - val_loss: 0.8930\n",
      "Epoch 1404/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7568 - val_loss: 0.8964\n",
      "Epoch 1405/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7568 - val_loss: 0.8906\n",
      "Epoch 1406/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7568 - val_loss: 0.8998\n",
      "Epoch 1407/1500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7569 - val_loss: 0.8873\n",
      "Epoch 1408/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7569 - val_loss: 0.9036\n",
      "Epoch 1409/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7570 - val_loss: 0.8856\n",
      "Epoch 1410/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7570 - val_loss: 0.9047\n",
      "Epoch 1411/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7570 - val_loss: 0.8863\n",
      "Epoch 1412/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7570 - val_loss: 0.9013\n",
      "Epoch 1413/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7569 - val_loss: 0.8908\n",
      "Epoch 1414/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7567 - val_loss: 0.8952\n",
      "Epoch 1415/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7567 - val_loss: 0.8960\n",
      "Epoch 1416/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7567 - val_loss: 0.8912\n",
      "Epoch 1417/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7567 - val_loss: 0.8995\n",
      "Epoch 1418/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7567 - val_loss: 0.8892\n",
      "Epoch 1419/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7567 - val_loss: 0.9011\n",
      "Epoch 1420/1500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7567 - val_loss: 0.8892\n",
      "Epoch 1421/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7567 - val_loss: 0.9008\n",
      "Epoch 1422/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7567 - val_loss: 0.8902\n",
      "Epoch 1423/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7567 - val_loss: 0.8993\n",
      "Epoch 1424/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7567 - val_loss: 0.8917\n",
      "Epoch 1425/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7567 - val_loss: 0.8976\n",
      "Epoch 1426/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7566 - val_loss: 0.8930\n",
      "Epoch 1427/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7566 - val_loss: 0.8965\n",
      "Epoch 1428/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7565 - val_loss: 0.8940\n",
      "Epoch 1429/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7564 - val_loss: 0.8963\n",
      "Epoch 1430/1500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7564 - val_loss: 0.8936\n",
      "Epoch 1431/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7564 - val_loss: 0.8975\n",
      "Epoch 1432/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7564 - val_loss: 0.8925\n",
      "Epoch 1433/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7564 - val_loss: 0.8988\n",
      "Epoch 1434/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7564 - val_loss: 0.8908\n",
      "Epoch 1435/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7564 - val_loss: 0.9002\n",
      "Epoch 1436/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7564 - val_loss: 0.8901\n",
      "Epoch 1437/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7564 - val_loss: 0.9006\n",
      "Epoch 1438/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7564 - val_loss: 0.8909\n",
      "Epoch 1439/1500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7564 - val_loss: 0.8999\n",
      "Epoch 1440/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7564 - val_loss: 0.8913\n",
      "Epoch 1441/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7565 - val_loss: 0.9006\n",
      "Epoch 1442/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7565 - val_loss: 0.8901\n",
      "Epoch 1443/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7565 - val_loss: 0.9024\n",
      "Epoch 1444/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7565 - val_loss: 0.8889\n",
      "Epoch 1445/1500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7565 - val_loss: 0.9029\n",
      "Epoch 1446/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7565 - val_loss: 0.8896\n",
      "Epoch 1447/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7564 - val_loss: 0.9014\n",
      "Epoch 1448/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7563 - val_loss: 0.8911\n",
      "Epoch 1449/1500\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7563 - val_loss: 0.8994\n",
      "Epoch 1450/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7562 - val_loss: 0.8929\n",
      "Epoch 1451/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7562 - val_loss: 0.8982\n",
      "Epoch 1452/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7561 - val_loss: 0.8939\n",
      "Epoch 1453/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7561 - val_loss: 0.8979\n",
      "Epoch 1454/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7561 - val_loss: 0.8939\n",
      "Epoch 1455/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7561 - val_loss: 0.8974\n",
      "Epoch 1456/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7561 - val_loss: 0.8946\n",
      "Epoch 1457/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7561 - val_loss: 0.8972\n",
      "Epoch 1458/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7560 - val_loss: 0.8951\n",
      "Epoch 1459/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7560 - val_loss: 0.8979\n",
      "Epoch 1460/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7560 - val_loss: 0.8941\n",
      "Epoch 1461/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7560 - val_loss: 0.8999\n",
      "Epoch 1462/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7561 - val_loss: 0.8912\n",
      "Epoch 1463/1500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7561 - val_loss: 0.9045\n",
      "Epoch 1464/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7563 - val_loss: 0.8872\n",
      "Epoch 1465/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7564 - val_loss: 0.9089\n",
      "Epoch 1466/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7566 - val_loss: 0.8852\n",
      "Epoch 1467/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7566 - val_loss: 0.9089\n",
      "Epoch 1468/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7566 - val_loss: 0.8874\n",
      "Epoch 1469/1500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7565 - val_loss: 0.9025\n",
      "Epoch 1470/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7563 - val_loss: 0.8938\n",
      "Epoch 1471/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7561 - val_loss: 0.8947\n",
      "Epoch 1472/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7559 - val_loss: 0.9002\n",
      "Epoch 1473/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7559 - val_loss: 0.8908\n",
      "Epoch 1474/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7560 - val_loss: 0.9042\n",
      "Epoch 1475/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7561 - val_loss: 0.8898\n",
      "Epoch 1476/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7562 - val_loss: 0.9042\n",
      "Epoch 1477/1500\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7562 - val_loss: 0.8913\n",
      "Epoch 1478/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7561 - val_loss: 0.9013\n",
      "Epoch 1479/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7560 - val_loss: 0.8942\n",
      "Epoch 1480/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7559 - val_loss: 0.8971\n",
      "Epoch 1481/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7558 - val_loss: 0.8982\n",
      "Epoch 1482/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7558 - val_loss: 0.8934\n",
      "Epoch 1483/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7558 - val_loss: 0.9017\n",
      "Epoch 1484/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7559 - val_loss: 0.8921\n",
      "Epoch 1485/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7559 - val_loss: 0.9027\n",
      "Epoch 1486/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7559 - val_loss: 0.8919\n",
      "Epoch 1487/1500\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7559 - val_loss: 0.9031\n",
      "Epoch 1488/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7559 - val_loss: 0.8913\n",
      "Epoch 1489/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7558 - val_loss: 0.9026\n",
      "Epoch 1490/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7558 - val_loss: 0.8922\n",
      "Epoch 1491/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7557 - val_loss: 0.9000\n",
      "Epoch 1492/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7557 - val_loss: 0.8955\n",
      "Epoch 1493/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7556 - val_loss: 0.8963\n",
      "Epoch 1494/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7556 - val_loss: 0.8995\n",
      "Epoch 1495/1500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7556 - val_loss: 0.8929\n",
      "Epoch 1496/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7557 - val_loss: 0.9037\n",
      "Epoch 1497/1500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7557 - val_loss: 0.8902\n",
      "Epoch 1498/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7558 - val_loss: 0.9057\n",
      "Epoch 1499/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7558 - val_loss: 0.8894\n",
      "Epoch 1500/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7558 - val_loss: 0.9049\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8716\n",
      "0.871568500995636\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.LSTM(units = 1024, activation = \"relu\", return_sequences = False)(input)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "model.summary()\n",
    "\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = len(x), epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 197ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdc96418eb0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNで試す(多層)equence=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 3, 3)]            0         \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 3, 1024)           1052672   \n",
      "                                                                 \n",
      " simple_rnn_8 (SimpleRNN)    (None, 3, 1024)           2098176   \n",
      "                                                                 \n",
      " simple_rnn_9 (SimpleRNN)    (None, 3, 512)            786944    \n",
      "                                                                 \n",
      " simple_rnn_10 (SimpleRNN)   (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,463,105\n",
      "Trainable params: 4,463,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0585 - val_loss: 0.8652\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9479 - val_loss: 0.8839\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.9022 - val_loss: 0.9267\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.8813 - val_loss: 0.9737\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8753 - val_loss: 0.9959\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8712 - val_loss: 0.9868\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8624 - val_loss: 0.9590\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8518 - val_loss: 0.9266\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8428 - val_loss: 0.9002\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8372 - val_loss: 0.8825\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8342 - val_loss: 0.8743\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8313 - val_loss: 0.8756\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8276 - val_loss: 0.8838\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8234 - val_loss: 0.8964\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8198 - val_loss: 0.9102\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8174 - val_loss: 0.9207\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8157 - val_loss: 0.9248\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.8141 - val_loss: 0.9213\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8122 - val_loss: 0.9121\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8103 - val_loss: 0.9011\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8088 - val_loss: 0.8920\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8078 - val_loss: 0.8874\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8065 - val_loss: 0.8879\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8050 - val_loss: 0.8929\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8034 - val_loss: 0.9001\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8019 - val_loss: 0.9061\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8009 - val_loss: 0.9076\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7999 - val_loss: 0.9033\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7987 - val_loss: 0.8962\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7975 - val_loss: 0.8895\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7965 - val_loss: 0.8860\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7957 - val_loss: 0.8873\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7948 - val_loss: 0.8922\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7938 - val_loss: 0.8978\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7929 - val_loss: 0.9007\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7922 - val_loss: 0.8992\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7913 - val_loss: 0.8943\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7905 - val_loss: 0.8892\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7897 - val_loss: 0.8877\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7890 - val_loss: 0.8901\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7883 - val_loss: 0.8947\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7879 - val_loss: 0.8969\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7879 - val_loss: 0.8982\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7887 - val_loss: 0.8925\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7887 - val_loss: 0.8903\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7860 - val_loss: 0.8903\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7856 - val_loss: 0.8932\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7865 - val_loss: 0.8972\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7845 - val_loss: 0.8972\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7842 - val_loss: 0.8938\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7847 - val_loss: 0.8911\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7829 - val_loss: 0.8920\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7830 - val_loss: 0.8933\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7831 - val_loss: 0.8953\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7816 - val_loss: 0.8964\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7819 - val_loss: 0.8931\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7817 - val_loss: 0.8914\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7805 - val_loss: 0.8931\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7807 - val_loss: 0.8947\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7804 - val_loss: 0.8950\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7795 - val_loss: 0.8936\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7796 - val_loss: 0.8920\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7793 - val_loss: 0.8933\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7785 - val_loss: 0.8956\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7784 - val_loss: 0.8948\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7783 - val_loss: 0.8933\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7776 - val_loss: 0.8935\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7773 - val_loss: 0.8951\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7772 - val_loss: 0.8955\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7767 - val_loss: 0.8938\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7762 - val_loss: 0.8934\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7760 - val_loss: 0.8950\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7758 - val_loss: 0.8965\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7753 - val_loss: 0.8939\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7749 - val_loss: 0.8936\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7746 - val_loss: 0.8961\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7744 - val_loss: 0.8952\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7741 - val_loss: 0.8947\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7736 - val_loss: 0.8943\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7732 - val_loss: 0.8956\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7729 - val_loss: 0.8959\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7727 - val_loss: 0.8934\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7724 - val_loss: 0.8989\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7722 - val_loss: 0.8929\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7720 - val_loss: 0.8990\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7718 - val_loss: 0.8930\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7715 - val_loss: 0.9017\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7713 - val_loss: 0.8907\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7710 - val_loss: 0.9047\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7708 - val_loss: 0.8905\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7704 - val_loss: 0.9021\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7699 - val_loss: 0.8931\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7695 - val_loss: 0.9005\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7690 - val_loss: 0.8931\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7686 - val_loss: 0.9014\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7682 - val_loss: 0.8912\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7680 - val_loss: 0.9073\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7679 - val_loss: 0.8848\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7684 - val_loss: 0.9236\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7702 - val_loss: 0.8805\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7730 - val_loss: 0.9239\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7740 - val_loss: 0.8970\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7690 - val_loss: 0.8907\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7662 - val_loss: 0.9153\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7695 - val_loss: 0.8908\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7687 - val_loss: 0.9050\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7653 - val_loss: 0.9053\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7667 - val_loss: 0.8873\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7673 - val_loss: 0.9187\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7654 - val_loss: 0.8959\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7649 - val_loss: 0.8892\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7654 - val_loss: 0.9279\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7656 - val_loss: 0.8867\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7642 - val_loss: 0.8960\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7635 - val_loss: 0.9255\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7645 - val_loss: 0.8839\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7639 - val_loss: 0.9070\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7627 - val_loss: 0.9164\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7628 - val_loss: 0.8869\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7631 - val_loss: 0.9170\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7626 - val_loss: 0.9039\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7621 - val_loss: 0.8973\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7617 - val_loss: 0.9129\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7615 - val_loss: 0.8988\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7617 - val_loss: 0.9146\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7618 - val_loss: 0.8954\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7613 - val_loss: 0.9204\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7610 - val_loss: 0.8936\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7607 - val_loss: 0.9161\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7602 - val_loss: 0.9032\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7598 - val_loss: 0.9063\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7596 - val_loss: 0.9099\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7595 - val_loss: 0.9065\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7591 - val_loss: 0.9093\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7589 - val_loss: 0.9100\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7587 - val_loss: 0.9110\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7586 - val_loss: 0.9033\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7587 - val_loss: 0.9370\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7601 - val_loss: 0.8713\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7669 - val_loss: 1.0127\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7778 - val_loss: 0.8825\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7738 - val_loss: 0.8913\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7642 - val_loss: 0.9746\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7670 - val_loss: 0.9153\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7651 - val_loss: 0.8770\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7662 - val_loss: 0.9275\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7611 - val_loss: 0.9421\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7657 - val_loss: 0.8991\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7602 - val_loss: 0.9018\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7631 - val_loss: 0.9254\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7599 - val_loss: 0.9221\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7608 - val_loss: 0.9062\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7599 - val_loss: 0.9111\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7592 - val_loss: 0.9193\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7595 - val_loss: 0.9224\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7581 - val_loss: 0.9093\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7588 - val_loss: 0.9074\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7577 - val_loss: 0.9306\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7581 - val_loss: 0.9187\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7571 - val_loss: 0.9028\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7575 - val_loss: 0.9236\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7568 - val_loss: 0.9259\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7568 - val_loss: 0.9104\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7565 - val_loss: 0.9167\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7563 - val_loss: 0.9202\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7562 - val_loss: 0.9250\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7557 - val_loss: 0.9180\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7558 - val_loss: 0.9118\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7554 - val_loss: 0.9324\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7556 - val_loss: 0.9189\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7551 - val_loss: 0.9189\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7553 - val_loss: 0.9193\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7547 - val_loss: 0.9265\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7549 - val_loss: 0.9244\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7545 - val_loss: 0.9179\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7546 - val_loss: 0.9248\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7543 - val_loss: 0.9249\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7543 - val_loss: 0.9252\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7541 - val_loss: 0.9206\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7540 - val_loss: 0.9322\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7540 - val_loss: 0.9197\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7539 - val_loss: 0.9384\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7542 - val_loss: 0.9081\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7551 - val_loss: 0.9678\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7575 - val_loss: 0.8878\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7614 - val_loss: 0.9844\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7613 - val_loss: 0.9024\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7569 - val_loss: 0.9211\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7537 - val_loss: 0.9598\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7568 - val_loss: 0.9007\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7580 - val_loss: 0.9442\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7543 - val_loss: 0.9380\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7537 - val_loss: 0.9053\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7564 - val_loss: 0.9648\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7562 - val_loss: 0.9162\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7535 - val_loss: 0.9181\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7534 - val_loss: 0.9609\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7552 - val_loss: 0.9086\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7547 - val_loss: 0.9357\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7530 - val_loss: 0.9423\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7530 - val_loss: 0.9127\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7542 - val_loss: 0.9480\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7538 - val_loss: 0.9247\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7525 - val_loss: 0.9227\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7527 - val_loss: 0.9481\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7535 - val_loss: 0.9156\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7532 - val_loss: 0.9377\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7524 - val_loss: 0.9374\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7523 - val_loss: 0.9191\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7528 - val_loss: 0.9493\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7530 - val_loss: 0.9232\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7523 - val_loss: 0.9332\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7519 - val_loss: 0.9383\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7520 - val_loss: 0.9224\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7523 - val_loss: 0.9467\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7524 - val_loss: 0.9225\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7522 - val_loss: 0.9428\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7519 - val_loss: 0.9292\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7517 - val_loss: 0.9328\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7515 - val_loss: 0.9406\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7516 - val_loss: 0.9262\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7517 - val_loss: 0.9466\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7519 - val_loss: 0.9260\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7518 - val_loss: 0.9471\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7518 - val_loss: 0.9278\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7516 - val_loss: 0.9450\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7514 - val_loss: 0.9317\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7513 - val_loss: 0.9406\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7512 - val_loss: 0.9347\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7511 - val_loss: 0.9388\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7510 - val_loss: 0.9364\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7510 - val_loss: 0.9395\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7510 - val_loss: 0.9365\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7509 - val_loss: 0.9414\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7509 - val_loss: 0.9343\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7509 - val_loss: 0.9480\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7511 - val_loss: 0.9261\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7516 - val_loss: 0.9643\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7528 - val_loss: 0.9118\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7549 - val_loss: 0.9892\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7575 - val_loss: 0.9039\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7583 - val_loss: 0.9676\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7545 - val_loss: 0.9339\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7513 - val_loss: 0.9156\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7526 - val_loss: 0.9684\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7549 - val_loss: 0.9182\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7535 - val_loss: 0.9417\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7510 - val_loss: 0.9476\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7514 - val_loss: 0.9207\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7532 - val_loss: 0.9649\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7530 - val_loss: 0.9243\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7514 - val_loss: 0.9400\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7507 - val_loss: 0.9545\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7514 - val_loss: 0.9195\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7522 - val_loss: 0.9615\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7519 - val_loss: 0.9306\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7507 - val_loss: 0.9353\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7504 - val_loss: 0.9540\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7509 - val_loss: 0.9252\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7514 - val_loss: 0.9556\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7513 - val_loss: 0.9330\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7507 - val_loss: 0.9405\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7502 - val_loss: 0.9466\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7504 - val_loss: 0.9316\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7508 - val_loss: 0.9552\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7509 - val_loss: 0.9282\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7508 - val_loss: 0.9532\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7505 - val_loss: 0.9366\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7501 - val_loss: 0.9393\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7500 - val_loss: 0.9497\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7502 - val_loss: 0.9310\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7504 - val_loss: 0.9526\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7504 - val_loss: 0.9336\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7503 - val_loss: 0.9484\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7502 - val_loss: 0.9370\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7499 - val_loss: 0.9450\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7498 - val_loss: 0.9424\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7498 - val_loss: 0.9409\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7498 - val_loss: 0.9491\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7499 - val_loss: 0.9352\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7500 - val_loss: 0.9553\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7501 - val_loss: 0.9308\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7503 - val_loss: 0.9590\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7506 - val_loss: 0.9288\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7507 - val_loss: 0.9596\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7508 - val_loss: 0.9291\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7506 - val_loss: 0.9571\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7503 - val_loss: 0.9318\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7500 - val_loss: 0.9496\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7497 - val_loss: 0.9418\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7495 - val_loss: 0.9412\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7495 - val_loss: 0.9510\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7496 - val_loss: 0.9352\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7498 - val_loss: 0.9573\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7501 - val_loss: 0.9292\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7505 - val_loss: 0.9648\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7510 - val_loss: 0.9240\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7515 - val_loss: 0.9687\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7517 - val_loss: 0.9237\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7513 - val_loss: 0.9605\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7505 - val_loss: 0.9331\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7497 - val_loss: 0.9452\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7493 - val_loss: 0.9467\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7493 - val_loss: 0.9333\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7497 - val_loss: 0.9602\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7502 - val_loss: 0.9254\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7508 - val_loss: 0.9669\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7511 - val_loss: 0.9243\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7510 - val_loss: 0.9598\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7505 - val_loss: 0.9318\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7497 - val_loss: 0.9458\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7492 - val_loss: 0.9464\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7491 - val_loss: 0.9358\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7495 - val_loss: 0.9601\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7500 - val_loss: 0.9269\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7506 - val_loss: 0.9693\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7512 - val_loss: 0.9211\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7514 - val_loss: 0.9659\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7509 - val_loss: 0.9291\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7500 - val_loss: 0.9462\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7492 - val_loss: 0.9469\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7490 - val_loss: 0.9316\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7495 - val_loss: 0.9600\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7502 - val_loss: 0.9266\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7507 - val_loss: 0.9654\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7509 - val_loss: 0.9260\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7505 - val_loss: 0.9595\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7498 - val_loss: 0.9350\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7491 - val_loss: 0.9424\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7488 - val_loss: 0.9524\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7491 - val_loss: 0.9304\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7496 - val_loss: 0.9630\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7500 - val_loss: 0.9289\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7500 - val_loss: 0.9588\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7496 - val_loss: 0.9359\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7492 - val_loss: 0.9477\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7488 - val_loss: 0.9447\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7486 - val_loss: 0.9397\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7487 - val_loss: 0.9512\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7490 - val_loss: 0.9336\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7492 - val_loss: 0.9581\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7494 - val_loss: 0.9287\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7495 - val_loss: 0.9615\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7496 - val_loss: 0.9295\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7494 - val_loss: 0.9543\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7490 - val_loss: 0.9392\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7487 - val_loss: 0.9419\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7485 - val_loss: 0.9487\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7486 - val_loss: 0.9353\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7488 - val_loss: 0.9564\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7491 - val_loss: 0.9301\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7496 - val_loss: 0.9638\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7501 - val_loss: 0.9256\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7503 - val_loss: 0.9640\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7501 - val_loss: 0.9281\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7495 - val_loss: 0.9537\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7488 - val_loss: 0.9404\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7484 - val_loss: 0.9405\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7484 - val_loss: 0.9557\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7488 - val_loss: 0.9292\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7493 - val_loss: 0.9676\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7500 - val_loss: 0.9229\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7506 - val_loss: 0.9679\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7506 - val_loss: 0.9270\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7500 - val_loss: 0.9534\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7491 - val_loss: 0.9395\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7484 - val_loss: 0.9388\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7483 - val_loss: 0.9538\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7488 - val_loss: 0.9302\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7495 - val_loss: 0.9649\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7500 - val_loss: 0.9243\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7500 - val_loss: 0.9632\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7495 - val_loss: 0.9305\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7487 - val_loss: 0.9445\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7481 - val_loss: 0.9484\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7482 - val_loss: 0.9295\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7487 - val_loss: 0.9624\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7493 - val_loss: 0.9267\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7496 - val_loss: 0.9631\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7496 - val_loss: 0.9314\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7492 - val_loss: 0.9530\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7487 - val_loss: 0.9397\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7481 - val_loss: 0.9421\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7480 - val_loss: 0.9479\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7481 - val_loss: 0.9357\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7484 - val_loss: 0.9559\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7487 - val_loss: 0.9289\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7488 - val_loss: 0.9619\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7489 - val_loss: 0.9277\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7487 - val_loss: 0.9554\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7483 - val_loss: 0.9377\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7480 - val_loss: 0.9439\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7479 - val_loss: 0.9475\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7479 - val_loss: 0.9370\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7479 - val_loss: 0.9534\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7480 - val_loss: 0.9340\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7482 - val_loss: 0.9560\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7485 - val_loss: 0.9311\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7487 - val_loss: 0.9598\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7490 - val_loss: 0.9271\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7490 - val_loss: 0.9599\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7488 - val_loss: 0.9295\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7484 - val_loss: 0.9514\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7479 - val_loss: 0.9401\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7477 - val_loss: 0.9407\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7476 - val_loss: 0.9511\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7478 - val_loss: 0.9318\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7481 - val_loss: 0.9607\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7486 - val_loss: 0.9247\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7492 - val_loss: 0.9671\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7497 - val_loss: 0.9227\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7499 - val_loss: 0.9622\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7495 - val_loss: 0.9312\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7486 - val_loss: 0.9484\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7478 - val_loss: 0.9435\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7475 - val_loss: 0.9381\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7478 - val_loss: 0.9546\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7483 - val_loss: 0.9285\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7488 - val_loss: 0.9666\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7493 - val_loss: 0.9198\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7498 - val_loss: 0.9673\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7495 - val_loss: 0.9246\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7486 - val_loss: 0.9472\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7477 - val_loss: 0.9449\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7476 - val_loss: 0.9308\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7479 - val_loss: 0.9629\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7486 - val_loss: 0.9251\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7494 - val_loss: 0.9691\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7499 - val_loss: 0.9251\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7499 - val_loss: 0.9574\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7491 - val_loss: 0.9326\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7480 - val_loss: 0.9395\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7474 - val_loss: 0.9479\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7478 - val_loss: 0.9316\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7485 - val_loss: 0.9614\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7489 - val_loss: 0.9241\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7490 - val_loss: 0.9662\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7488 - val_loss: 0.9255\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7483 - val_loss: 0.9502\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7475 - val_loss: 0.9435\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7473 - val_loss: 0.9313\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7476 - val_loss: 0.9578\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7479 - val_loss: 0.9282\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7481 - val_loss: 0.9575\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7480 - val_loss: 0.9324\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7480 - val_loss: 0.9503\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7478 - val_loss: 0.9370\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7475 - val_loss: 0.9437\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7472 - val_loss: 0.9415\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7471 - val_loss: 0.9414\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7472 - val_loss: 0.9465\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7473 - val_loss: 0.9368\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7473 - val_loss: 0.9528\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7474 - val_loss: 0.9288\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7476 - val_loss: 0.9573\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7477 - val_loss: 0.9279\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7476 - val_loss: 0.9516\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7474 - val_loss: 0.9369\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7472 - val_loss: 0.9445\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7471 - val_loss: 0.9432\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7470 - val_loss: 0.9414\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7469 - val_loss: 0.9442\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7469 - val_loss: 0.9389\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7470 - val_loss: 0.9482\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7471 - val_loss: 0.9330\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7473 - val_loss: 0.9573\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7476 - val_loss: 0.9251\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7480 - val_loss: 0.9651\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7484 - val_loss: 0.9202\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7488 - val_loss: 0.9647\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7486 - val_loss: 0.9251\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7481 - val_loss: 0.9519\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7475 - val_loss: 0.9376\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7471 - val_loss: 0.9427\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7468 - val_loss: 0.9456\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7468 - val_loss: 0.9380\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7470 - val_loss: 0.9534\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7473 - val_loss: 0.9279\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7478 - val_loss: 0.9641\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7483 - val_loss: 0.9187\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7487 - val_loss: 0.9658\n",
      "Epoch 482/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7486 - val_loss: 0.9218\n",
      "Epoch 483/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7480 - val_loss: 0.9502\n",
      "Epoch 484/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7472 - val_loss: 0.9390\n",
      "Epoch 485/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7468 - val_loss: 0.9359\n",
      "Epoch 486/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7468 - val_loss: 0.9543\n",
      "Epoch 487/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7471 - val_loss: 0.9279\n",
      "Epoch 488/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7476 - val_loss: 0.9648\n",
      "Epoch 489/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7483 - val_loss: 0.9213\n",
      "Epoch 490/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7490 - val_loss: 0.9663\n",
      "Epoch 491/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7491 - val_loss: 0.9219\n",
      "Epoch 492/1500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7486 - val_loss: 0.9536\n",
      "Epoch 493/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7476 - val_loss: 0.9352\n",
      "Epoch 494/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7467 - val_loss: 0.9381\n",
      "Epoch 495/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7466 - val_loss: 0.9530\n",
      "Epoch 496/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7472 - val_loss: 0.9259\n",
      "Epoch 497/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7480 - val_loss: 0.9681\n",
      "Epoch 498/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7487 - val_loss: 0.9167\n",
      "Epoch 499/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7490 - val_loss: 0.9666\n",
      "Epoch 500/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7485 - val_loss: 0.9242\n",
      "Epoch 501/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7475 - val_loss: 0.9407\n",
      "Epoch 502/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7467 - val_loss: 0.9501\n",
      "Epoch 503/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7468 - val_loss: 0.9245\n",
      "Epoch 504/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7475 - val_loss: 0.9629\n",
      "Epoch 505/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7480 - val_loss: 0.9240\n",
      "Epoch 506/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7482 - val_loss: 0.9602\n",
      "Epoch 507/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7479 - val_loss: 0.9301\n",
      "Epoch 508/1500\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7474 - val_loss: 0.9468\n",
      "Epoch 509/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7468 - val_loss: 0.9395\n",
      "Epoch 510/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7465 - val_loss: 0.9340\n",
      "Epoch 511/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7466 - val_loss: 0.9502\n",
      "Epoch 512/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7469 - val_loss: 0.9287\n",
      "Epoch 513/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7473 - val_loss: 0.9570\n",
      "Epoch 514/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7474 - val_loss: 0.9253\n",
      "Epoch 515/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7474 - val_loss: 0.9569\n",
      "Epoch 516/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7471 - val_loss: 0.9292\n",
      "Epoch 517/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7467 - val_loss: 0.9462\n",
      "Epoch 518/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7464 - val_loss: 0.9412\n",
      "Epoch 519/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7463 - val_loss: 0.9345\n",
      "Epoch 520/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7464 - val_loss: 0.9511\n",
      "Epoch 521/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7465 - val_loss: 0.9303\n",
      "Epoch 522/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7467 - val_loss: 0.9556\n",
      "Epoch 523/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7469 - val_loss: 0.9278\n",
      "Epoch 524/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7470 - val_loss: 0.9561\n",
      "Epoch 525/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7472 - val_loss: 0.9282\n",
      "Epoch 526/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7471 - val_loss: 0.9520\n",
      "Epoch 527/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7469 - val_loss: 0.9335\n",
      "Epoch 528/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7466 - val_loss: 0.9444\n",
      "Epoch 529/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7463 - val_loss: 0.9403\n",
      "Epoch 530/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7462 - val_loss: 0.9383\n",
      "Epoch 531/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7463 - val_loss: 0.9485\n",
      "Epoch 532/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7464 - val_loss: 0.9305\n",
      "Epoch 533/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7467 - val_loss: 0.9572\n",
      "Epoch 534/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7469 - val_loss: 0.9232\n",
      "Epoch 535/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7472 - val_loss: 0.9602\n",
      "Epoch 536/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7472 - val_loss: 0.9244\n",
      "Epoch 537/1500\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7470 - val_loss: 0.9529\n",
      "Epoch 538/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7466 - val_loss: 0.9349\n",
      "Epoch 539/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7463 - val_loss: 0.9406\n",
      "Epoch 540/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7461 - val_loss: 0.9462\n",
      "Epoch 541/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7461 - val_loss: 0.9338\n",
      "Epoch 542/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7462 - val_loss: 0.9534\n",
      "Epoch 543/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7465 - val_loss: 0.9284\n",
      "Epoch 544/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7468 - val_loss: 0.9578\n",
      "Epoch 545/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7471 - val_loss: 0.9243\n",
      "Epoch 546/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7473 - val_loss: 0.9567\n",
      "Epoch 547/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7472 - val_loss: 0.9260\n",
      "Epoch 548/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7469 - val_loss: 0.9517\n",
      "Epoch 549/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7465 - val_loss: 0.9313\n",
      "Epoch 550/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7462 - val_loss: 0.9461\n",
      "Epoch 551/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7460 - val_loss: 0.9404\n",
      "Epoch 552/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7460 - val_loss: 0.9384\n",
      "Epoch 553/1500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7460 - val_loss: 0.9499\n",
      "Epoch 554/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7461 - val_loss: 0.9301\n",
      "Epoch 555/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7463 - val_loss: 0.9575\n",
      "Epoch 556/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7466 - val_loss: 0.9216\n",
      "Epoch 557/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7471 - val_loss: 0.9641\n",
      "Epoch 558/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7475 - val_loss: 0.9184\n",
      "Epoch 559/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7477 - val_loss: 0.9606\n",
      "Epoch 560/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7475 - val_loss: 0.9268\n",
      "Epoch 561/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7471 - val_loss: 0.9484\n",
      "Epoch 562/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7466 - val_loss: 0.9408\n",
      "Epoch 563/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7461 - val_loss: 0.9393\n",
      "Epoch 564/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7459 - val_loss: 0.9494\n",
      "Epoch 565/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7461 - val_loss: 0.9322\n",
      "Epoch 566/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7466 - val_loss: 0.9593\n",
      "Epoch 567/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7471 - val_loss: 0.9220\n",
      "Epoch 568/1500\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7477 - val_loss: 0.9678\n",
      "Epoch 569/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7479 - val_loss: 0.9162\n",
      "Epoch 570/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7478 - val_loss: 0.9588\n",
      "Epoch 571/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7469 - val_loss: 0.9305\n",
      "Epoch 572/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7460 - val_loss: 0.9355\n",
      "Epoch 573/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7459 - val_loss: 0.9545\n",
      "Epoch 574/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7464 - val_loss: 0.9209\n",
      "Epoch 575/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7471 - val_loss: 0.9659\n",
      "Epoch 576/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7474 - val_loss: 0.9208\n",
      "Epoch 577/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7475 - val_loss: 0.9573\n",
      "Epoch 578/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7472 - val_loss: 0.9315\n",
      "Epoch 579/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7467 - val_loss: 0.9419\n",
      "Epoch 580/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7462 - val_loss: 0.9446\n",
      "Epoch 581/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7458 - val_loss: 0.9356\n",
      "Epoch 582/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7459 - val_loss: 0.9522\n",
      "Epoch 583/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7463 - val_loss: 0.9321\n",
      "Epoch 584/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7466 - val_loss: 0.9556\n",
      "Epoch 585/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7466 - val_loss: 0.9280\n",
      "Epoch 586/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7464 - val_loss: 0.9550\n",
      "Epoch 587/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7462 - val_loss: 0.9272\n",
      "Epoch 588/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7461 - val_loss: 0.9490\n",
      "Epoch 589/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7459 - val_loss: 0.9366\n",
      "Epoch 590/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7456 - val_loss: 0.9386\n",
      "Epoch 591/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7456 - val_loss: 0.9489\n",
      "Epoch 592/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7457 - val_loss: 0.9313\n",
      "Epoch 593/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7459 - val_loss: 0.9558\n",
      "Epoch 594/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7460 - val_loss: 0.9292\n",
      "Epoch 595/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7461 - val_loss: 0.9561\n",
      "Epoch 596/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7463 - val_loss: 0.9273\n",
      "Epoch 597/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7465 - val_loss: 0.9543\n",
      "Epoch 598/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7465 - val_loss: 0.9277\n",
      "Epoch 599/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7464 - val_loss: 0.9525\n",
      "Epoch 600/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7461 - val_loss: 0.9304\n",
      "Epoch 601/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7459 - val_loss: 0.9506\n",
      "Epoch 602/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7457 - val_loss: 0.9354\n",
      "Epoch 603/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7456 - val_loss: 0.9439\n",
      "Epoch 604/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7455 - val_loss: 0.9406\n",
      "Epoch 605/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7454 - val_loss: 0.9375\n",
      "Epoch 606/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7454 - val_loss: 0.9482\n",
      "Epoch 607/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7455 - val_loss: 0.9308\n",
      "Epoch 608/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7457 - val_loss: 0.9548\n",
      "Epoch 609/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7459 - val_loss: 0.9247\n",
      "Epoch 610/1500\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7462 - val_loss: 0.9609\n",
      "Epoch 611/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7466 - val_loss: 0.9216\n",
      "Epoch 612/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7470 - val_loss: 0.9610\n",
      "Epoch 613/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7470 - val_loss: 0.9246\n",
      "Epoch 614/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7468 - val_loss: 0.9557\n",
      "Epoch 615/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7464 - val_loss: 0.9305\n",
      "Epoch 616/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7459 - val_loss: 0.9488\n",
      "Epoch 617/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7455 - val_loss: 0.9366\n",
      "Epoch 618/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7454 - val_loss: 0.9408\n",
      "Epoch 619/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7454 - val_loss: 0.9446\n",
      "Epoch 620/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7455 - val_loss: 0.9313\n",
      "Epoch 621/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7456 - val_loss: 0.9556\n",
      "Epoch 622/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7459 - val_loss: 0.9217\n",
      "Epoch 623/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7464 - val_loss: 0.9643\n",
      "Epoch 624/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7467 - val_loss: 0.9170\n",
      "Epoch 625/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7470 - val_loss: 0.9645\n",
      "Epoch 626/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7470 - val_loss: 0.9215\n",
      "Epoch 627/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7467 - val_loss: 0.9501\n",
      "Epoch 628/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7461 - val_loss: 0.9367\n",
      "Epoch 629/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7456 - val_loss: 0.9346\n",
      "Epoch 630/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7454 - val_loss: 0.9494\n",
      "Epoch 631/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7455 - val_loss: 0.9282\n",
      "Epoch 632/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7460 - val_loss: 0.9588\n",
      "Epoch 633/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7466 - val_loss: 0.9220\n",
      "Epoch 634/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7471 - val_loss: 0.9643\n",
      "Epoch 635/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7471 - val_loss: 0.9183\n",
      "Epoch 636/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7469 - val_loss: 0.9567\n",
      "Epoch 637/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7461 - val_loss: 0.9309\n",
      "Epoch 638/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7454 - val_loss: 0.9359\n",
      "Epoch 639/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7453 - val_loss: 0.9524\n",
      "Epoch 640/1500\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7457 - val_loss: 0.9217\n",
      "Epoch 641/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7463 - val_loss: 0.9648\n",
      "Epoch 642/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7468 - val_loss: 0.9160\n",
      "Epoch 643/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7472 - val_loss: 0.9628\n",
      "Epoch 644/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7468 - val_loss: 0.9239\n",
      "Epoch 645/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7461 - val_loss: 0.9428\n",
      "Epoch 646/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7454 - val_loss: 0.9462\n",
      "Epoch 647/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7453 - val_loss: 0.9278\n",
      "Epoch 648/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7456 - val_loss: 0.9585\n",
      "Epoch 649/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7460 - val_loss: 0.9266\n",
      "Epoch 650/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7463 - val_loss: 0.9564\n",
      "Epoch 651/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7462 - val_loss: 0.9285\n",
      "Epoch 652/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7459 - val_loss: 0.9481\n",
      "Epoch 653/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7454 - val_loss: 0.9345\n",
      "Epoch 654/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7451 - val_loss: 0.9395\n",
      "Epoch 655/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7451 - val_loss: 0.9450\n",
      "Epoch 656/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7452 - val_loss: 0.9331\n",
      "Epoch 657/1500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7454 - val_loss: 0.9536\n",
      "Epoch 658/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7455 - val_loss: 0.9274\n",
      "Epoch 659/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7456 - val_loss: 0.9552\n",
      "Epoch 660/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7456 - val_loss: 0.9248\n",
      "Epoch 661/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7455 - val_loss: 0.9487\n",
      "Epoch 662/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7453 - val_loss: 0.9337\n",
      "Epoch 663/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7450 - val_loss: 0.9380\n",
      "Epoch 664/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7450 - val_loss: 0.9477\n",
      "Epoch 665/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7451 - val_loss: 0.9304\n",
      "Epoch 666/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7452 - val_loss: 0.9543\n",
      "Epoch 667/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7454 - val_loss: 0.9255\n",
      "Epoch 668/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7457 - val_loss: 0.9569\n",
      "Epoch 669/1500\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7460 - val_loss: 0.9230\n",
      "Epoch 670/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7462 - val_loss: 0.9575\n",
      "Epoch 671/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7460 - val_loss: 0.9256\n",
      "Epoch 672/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7458 - val_loss: 0.9520\n",
      "Epoch 673/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7453 - val_loss: 0.9347\n",
      "Epoch 674/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7450 - val_loss: 0.9406\n",
      "Epoch 675/1500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7449 - val_loss: 0.9457\n",
      "Epoch 676/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7450 - val_loss: 0.9300\n",
      "Epoch 677/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7452 - val_loss: 0.9547\n",
      "Epoch 678/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7455 - val_loss: 0.9246\n",
      "Epoch 679/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7456 - val_loss: 0.9577\n",
      "Epoch 680/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7456 - val_loss: 0.9250\n",
      "Epoch 681/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7455 - val_loss: 0.9522\n",
      "Epoch 682/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7452 - val_loss: 0.9328\n",
      "Epoch 683/1500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7449 - val_loss: 0.9412\n",
      "Epoch 684/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7448 - val_loss: 0.9422\n",
      "Epoch 685/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7448 - val_loss: 0.9347\n",
      "Epoch 686/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7448 - val_loss: 0.9515\n",
      "Epoch 687/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7450 - val_loss: 0.9298\n",
      "Epoch 688/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7453 - val_loss: 0.9591\n",
      "Epoch 689/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7456 - val_loss: 0.9228\n",
      "Epoch 690/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7460 - val_loss: 0.9610\n",
      "Epoch 691/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7460 - val_loss: 0.9222\n",
      "Epoch 692/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7460 - val_loss: 0.9566\n",
      "Epoch 693/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7457 - val_loss: 0.9270\n",
      "Epoch 694/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7453 - val_loss: 0.9490\n",
      "Epoch 695/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7450 - val_loss: 0.9366\n",
      "Epoch 696/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7447 - val_loss: 0.9381\n",
      "Epoch 697/1500\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7447 - val_loss: 0.9466\n",
      "Epoch 698/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7448 - val_loss: 0.9302\n",
      "Epoch 699/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7450 - val_loss: 0.9549\n",
      "Epoch 700/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7452 - val_loss: 0.9265\n",
      "Epoch 701/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7454 - val_loss: 0.9588\n",
      "Epoch 702/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7455 - val_loss: 0.9232\n",
      "Epoch 703/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7456 - val_loss: 0.9586\n",
      "Epoch 704/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7455 - val_loss: 0.9247\n",
      "Epoch 705/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7453 - val_loss: 0.9527\n",
      "Epoch 706/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7451 - val_loss: 0.9323\n",
      "Epoch 707/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7448 - val_loss: 0.9427\n",
      "Epoch 708/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7446 - val_loss: 0.9437\n",
      "Epoch 709/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7446 - val_loss: 0.9328\n",
      "Epoch 710/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7447 - val_loss: 0.9527\n",
      "Epoch 711/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7450 - val_loss: 0.9251\n",
      "Epoch 712/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7453 - val_loss: 0.9615\n",
      "Epoch 713/1500\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7458 - val_loss: 0.9177\n",
      "Epoch 714/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7465 - val_loss: 0.9678\n",
      "Epoch 715/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7468 - val_loss: 0.9158\n",
      "Epoch 716/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7468 - val_loss: 0.9588\n",
      "Epoch 717/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7460 - val_loss: 0.9299\n",
      "Epoch 718/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7451 - val_loss: 0.9390\n",
      "Epoch 719/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7446 - val_loss: 0.9480\n",
      "Epoch 720/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7447 - val_loss: 0.9266\n",
      "Epoch 721/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7452 - val_loss: 0.9587\n",
      "Epoch 722/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7457 - val_loss: 0.9211\n",
      "Epoch 723/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7461 - val_loss: 0.9605\n",
      "Epoch 724/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7461 - val_loss: 0.9232\n",
      "Epoch 725/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7457 - val_loss: 0.9516\n",
      "Epoch 726/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7449 - val_loss: 0.9379\n",
      "Epoch 727/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7445 - val_loss: 0.9358\n",
      "Epoch 728/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7446 - val_loss: 0.9539\n",
      "Epoch 729/1500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7450 - val_loss: 0.9245\n",
      "Epoch 730/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7455 - val_loss: 0.9637\n",
      "Epoch 731/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7459 - val_loss: 0.9180\n",
      "Epoch 732/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7461 - val_loss: 0.9625\n",
      "Epoch 733/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7457 - val_loss: 0.9252\n",
      "Epoch 734/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7451 - val_loss: 0.9450\n",
      "Epoch 735/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7445 - val_loss: 0.9476\n",
      "Epoch 736/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7445 - val_loss: 0.9263\n",
      "Epoch 737/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7450 - val_loss: 0.9626\n",
      "Epoch 738/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7455 - val_loss: 0.9185\n",
      "Epoch 739/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7460 - val_loss: 0.9641\n",
      "Epoch 740/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7461 - val_loss: 0.9229\n",
      "Epoch 741/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7456 - val_loss: 0.9491\n",
      "Epoch 742/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7449 - val_loss: 0.9441\n",
      "Epoch 743/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7445 - val_loss: 0.9329\n",
      "Epoch 744/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7446 - val_loss: 0.9583\n",
      "Epoch 745/1500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7449 - val_loss: 0.9266\n",
      "Epoch 746/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7454 - val_loss: 0.9570\n",
      "Epoch 747/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7455 - val_loss: 0.9265\n",
      "Epoch 748/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7452 - val_loss: 0.9483\n",
      "Epoch 749/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7447 - val_loss: 0.9352\n",
      "Epoch 750/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7443 - val_loss: 0.9393\n",
      "Epoch 751/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7443 - val_loss: 0.9480\n",
      "Epoch 752/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7445 - val_loss: 0.9324\n",
      "Epoch 753/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7447 - val_loss: 0.9557\n",
      "Epoch 754/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7449 - val_loss: 0.9262\n",
      "Epoch 755/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7449 - val_loss: 0.9548\n",
      "Epoch 756/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7448 - val_loss: 0.9275\n",
      "Epoch 757/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7446 - val_loss: 0.9465\n",
      "Epoch 758/1500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7443 - val_loss: 0.9395\n",
      "Epoch 759/1500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7442 - val_loss: 0.9362\n",
      "Epoch 760/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7442 - val_loss: 0.9524\n",
      "Epoch 761/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7444 - val_loss: 0.9289\n",
      "Epoch 762/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7446 - val_loss: 0.9564\n",
      "Epoch 763/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7447 - val_loss: 0.9266\n",
      "Epoch 764/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7448 - val_loss: 0.9542\n",
      "Epoch 765/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7447 - val_loss: 0.9326\n",
      "Epoch 766/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7445 - val_loss: 0.9458\n",
      "Epoch 767/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7443 - val_loss: 0.9410\n",
      "Epoch 768/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7442 - val_loss: 0.9373\n",
      "Epoch 769/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7441 - val_loss: 0.9458\n",
      "Epoch 770/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7442 - val_loss: 0.9340\n",
      "Epoch 771/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7443 - val_loss: 0.9497\n",
      "Epoch 772/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7444 - val_loss: 0.9324\n",
      "Epoch 773/1500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7444 - val_loss: 0.9520\n",
      "Epoch 774/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7444 - val_loss: 0.9310\n",
      "Epoch 775/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7444 - val_loss: 0.9530\n",
      "Epoch 776/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7444 - val_loss: 0.9276\n",
      "Epoch 777/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7444 - val_loss: 0.9540\n",
      "Epoch 778/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7444 - val_loss: 0.9263\n",
      "Epoch 779/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7444 - val_loss: 0.9530\n",
      "Epoch 780/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7444 - val_loss: 0.9308\n",
      "Epoch 781/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7443 - val_loss: 0.9498\n",
      "Epoch 782/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7442 - val_loss: 0.9345\n",
      "Epoch 783/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7442 - val_loss: 0.9450\n",
      "Epoch 784/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7441 - val_loss: 0.9387\n",
      "Epoch 785/1500\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7440 - val_loss: 0.9409\n",
      "Epoch 786/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7439 - val_loss: 0.9412\n",
      "Epoch 787/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7439 - val_loss: 0.9391\n",
      "Epoch 788/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7439 - val_loss: 0.9435\n",
      "Epoch 789/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7440 - val_loss: 0.9356\n",
      "Epoch 790/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7440 - val_loss: 0.9483\n",
      "Epoch 791/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7441 - val_loss: 0.9301\n",
      "Epoch 792/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7442 - val_loss: 0.9567\n",
      "Epoch 793/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7444 - val_loss: 0.9222\n",
      "Epoch 794/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7449 - val_loss: 0.9669\n",
      "Epoch 795/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7455 - val_loss: 0.9134\n",
      "Epoch 796/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7462 - val_loss: 0.9737\n",
      "Epoch 797/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7466 - val_loss: 0.9136\n",
      "Epoch 798/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7468 - val_loss: 0.9658\n",
      "Epoch 799/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7463 - val_loss: 0.9260\n",
      "Epoch 800/1500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7455 - val_loss: 0.9447\n",
      "Epoch 801/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7448 - val_loss: 0.9445\n",
      "Epoch 802/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7443 - val_loss: 0.9317\n",
      "Epoch 803/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7442 - val_loss: 0.9561\n",
      "Epoch 804/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7446 - val_loss: 0.9275\n",
      "Epoch 805/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7452 - val_loss: 0.9600\n",
      "Epoch 806/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7455 - val_loss: 0.9291\n",
      "Epoch 807/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7452 - val_loss: 0.9554\n",
      "Epoch 808/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7445 - val_loss: 0.9349\n",
      "Epoch 809/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7440 - val_loss: 0.9469\n",
      "Epoch 810/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7439 - val_loss: 0.9456\n",
      "Epoch 811/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7441 - val_loss: 0.9365\n",
      "Epoch 812/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7442 - val_loss: 0.9567\n",
      "Epoch 813/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7443 - val_loss: 0.9255\n",
      "Epoch 814/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7446 - val_loss: 0.9629\n",
      "Epoch 815/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7447 - val_loss: 0.9253\n",
      "Epoch 816/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7446 - val_loss: 0.9584\n",
      "Epoch 817/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7442 - val_loss: 0.9364\n",
      "Epoch 818/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7439 - val_loss: 0.9461\n",
      "Epoch 819/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7438 - val_loss: 0.9459\n",
      "Epoch 820/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7438 - val_loss: 0.9376\n",
      "Epoch 821/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7438 - val_loss: 0.9496\n",
      "Epoch 822/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7438 - val_loss: 0.9356\n",
      "Epoch 823/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7438 - val_loss: 0.9506\n",
      "Epoch 824/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7438 - val_loss: 0.9346\n",
      "Epoch 825/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7439 - val_loss: 0.9529\n",
      "Epoch 826/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7441 - val_loss: 0.9306\n",
      "Epoch 827/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7442 - val_loss: 0.9598\n",
      "Epoch 828/1500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7444 - val_loss: 0.9233\n",
      "Epoch 829/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7447 - val_loss: 0.9669\n",
      "Epoch 830/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7450 - val_loss: 0.9189\n",
      "Epoch 831/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7452 - val_loss: 0.9646\n",
      "Epoch 832/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7449 - val_loss: 0.9255\n",
      "Epoch 833/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7444 - val_loss: 0.9487\n",
      "Epoch 834/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7439 - val_loss: 0.9433\n",
      "Epoch 835/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7437 - val_loss: 0.9348\n",
      "Epoch 836/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7438 - val_loss: 0.9563\n",
      "Epoch 837/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7440 - val_loss: 0.9271\n",
      "Epoch 838/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7443 - val_loss: 0.9625\n",
      "Epoch 839/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7447 - val_loss: 0.9234\n",
      "Epoch 840/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7450 - val_loss: 0.9638\n",
      "Epoch 841/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7450 - val_loss: 0.9247\n",
      "Epoch 842/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7447 - val_loss: 0.9589\n",
      "Epoch 843/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7442 - val_loss: 0.9360\n",
      "Epoch 844/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7438 - val_loss: 0.9461\n",
      "Epoch 845/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7435 - val_loss: 0.9490\n",
      "Epoch 846/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7436 - val_loss: 0.9337\n",
      "Epoch 847/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7438 - val_loss: 0.9562\n",
      "Epoch 848/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7441 - val_loss: 0.9260\n",
      "Epoch 849/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7443 - val_loss: 0.9622\n",
      "Epoch 850/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7444 - val_loss: 0.9240\n",
      "Epoch 851/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7445 - val_loss: 0.9614\n",
      "Epoch 852/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7443 - val_loss: 0.9290\n",
      "Epoch 853/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7440 - val_loss: 0.9502\n",
      "Epoch 854/1500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7437 - val_loss: 0.9426\n",
      "Epoch 855/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7435 - val_loss: 0.9379\n",
      "Epoch 856/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7435 - val_loss: 0.9554\n",
      "Epoch 857/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7437 - val_loss: 0.9301\n",
      "Epoch 858/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7440 - val_loss: 0.9620\n",
      "Epoch 859/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7443 - val_loss: 0.9233\n",
      "Epoch 860/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7447 - val_loss: 0.9639\n",
      "Epoch 861/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7448 - val_loss: 0.9247\n",
      "Epoch 862/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7446 - val_loss: 0.9575\n",
      "Epoch 863/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7441 - val_loss: 0.9373\n",
      "Epoch 864/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7436 - val_loss: 0.9447\n",
      "Epoch 865/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7434 - val_loss: 0.9495\n",
      "Epoch 866/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7435 - val_loss: 0.9347\n",
      "Epoch 867/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7437 - val_loss: 0.9591\n",
      "Epoch 868/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7441 - val_loss: 0.9279\n",
      "Epoch 869/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7443 - val_loss: 0.9642\n",
      "Epoch 870/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7445 - val_loss: 0.9242\n",
      "Epoch 871/1500\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7445 - val_loss: 0.9640\n",
      "Epoch 872/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7444 - val_loss: 0.9284\n",
      "Epoch 873/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7440 - val_loss: 0.9556\n",
      "Epoch 874/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7436 - val_loss: 0.9417\n",
      "Epoch 875/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7434 - val_loss: 0.9437\n",
      "Epoch 876/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7433 - val_loss: 0.9535\n",
      "Epoch 877/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7434 - val_loss: 0.9339\n",
      "Epoch 878/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7436 - val_loss: 0.9591\n",
      "Epoch 879/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7438 - val_loss: 0.9281\n",
      "Epoch 880/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7440 - val_loss: 0.9625\n",
      "Epoch 881/1500\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7442 - val_loss: 0.9263\n",
      "Epoch 882/1500\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7442 - val_loss: 0.9616\n",
      "Epoch 883/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7442 - val_loss: 0.9283\n",
      "Epoch 884/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7440 - val_loss: 0.9555\n",
      "Epoch 885/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7437 - val_loss: 0.9370\n",
      "Epoch 886/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7434 - val_loss: 0.9466\n",
      "Epoch 887/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7433 - val_loss: 0.9475\n",
      "Epoch 888/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7432 - val_loss: 0.9390\n",
      "Epoch 889/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7433 - val_loss: 0.9553\n",
      "Epoch 890/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7435 - val_loss: 0.9323\n",
      "Epoch 891/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7437 - val_loss: 0.9645\n",
      "Epoch 892/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7440 - val_loss: 0.9259\n",
      "Epoch 893/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7445 - val_loss: 0.9727\n",
      "Epoch 894/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7448 - val_loss: 0.9223\n",
      "Epoch 895/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7450 - val_loss: 0.9699\n",
      "Epoch 896/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7446 - val_loss: 0.9298\n",
      "Epoch 897/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7440 - val_loss: 0.9509\n",
      "Epoch 898/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7434 - val_loss: 0.9466\n",
      "Epoch 899/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7432 - val_loss: 0.9367\n",
      "Epoch 900/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7433 - val_loss: 0.9596\n",
      "Epoch 901/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7436 - val_loss: 0.9284\n",
      "Epoch 902/1500\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7441 - val_loss: 0.9654\n",
      "Epoch 903/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7444 - val_loss: 0.9253\n",
      "Epoch 904/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7445 - val_loss: 0.9626\n",
      "Epoch 905/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7443 - val_loss: 0.9327\n",
      "Epoch 906/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7438 - val_loss: 0.9524\n",
      "Epoch 907/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7434 - val_loss: 0.9458\n",
      "Epoch 908/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7431 - val_loss: 0.9413\n",
      "Epoch 909/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7432 - val_loss: 0.9555\n",
      "Epoch 910/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7434 - val_loss: 0.9345\n",
      "Epoch 911/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7437 - val_loss: 0.9627\n",
      "Epoch 912/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7440 - val_loss: 0.9264\n",
      "Epoch 913/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7443 - val_loss: 0.9693\n",
      "Epoch 914/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7445 - val_loss: 0.9225\n",
      "Epoch 915/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7445 - val_loss: 0.9663\n",
      "Epoch 916/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7441 - val_loss: 0.9320\n",
      "Epoch 917/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7436 - val_loss: 0.9514\n",
      "Epoch 918/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7432 - val_loss: 0.9493\n",
      "Epoch 919/1500\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7431 - val_loss: 0.9374\n",
      "Epoch 920/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7433 - val_loss: 0.9625\n",
      "Epoch 921/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7436 - val_loss: 0.9287\n",
      "Epoch 922/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7439 - val_loss: 0.9655\n",
      "Epoch 923/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7441 - val_loss: 0.9285\n",
      "Epoch 924/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7440 - val_loss: 0.9596\n",
      "Epoch 925/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7437 - val_loss: 0.9378\n",
      "Epoch 926/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7434 - val_loss: 0.9478\n",
      "Epoch 927/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7432 - val_loss: 0.9479\n",
      "Epoch 928/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7430 - val_loss: 0.9390\n",
      "Epoch 929/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7431 - val_loss: 0.9544\n",
      "Epoch 930/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7432 - val_loss: 0.9349\n",
      "Epoch 931/1500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7434 - val_loss: 0.9598\n",
      "Epoch 932/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7437 - val_loss: 0.9311\n",
      "Epoch 933/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7439 - val_loss: 0.9660\n",
      "Epoch 934/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7440 - val_loss: 0.9265\n",
      "Epoch 935/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7442 - val_loss: 0.9686\n",
      "Epoch 936/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7441 - val_loss: 0.9296\n",
      "Epoch 937/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7437 - val_loss: 0.9601\n",
      "Epoch 938/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7433 - val_loss: 0.9429\n",
      "Epoch 939/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7430 - val_loss: 0.9452\n",
      "Epoch 940/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7429 - val_loss: 0.9557\n",
      "Epoch 941/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7431 - val_loss: 0.9332\n",
      "Epoch 942/1500\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7433 - val_loss: 0.9620\n",
      "Epoch 943/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7436 - val_loss: 0.9280\n",
      "Epoch 944/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7437 - val_loss: 0.9631\n",
      "Epoch 945/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7437 - val_loss: 0.9323\n",
      "Epoch 946/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7436 - val_loss: 0.9596\n",
      "Epoch 947/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7434 - val_loss: 0.9399\n",
      "Epoch 948/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7432 - val_loss: 0.9521\n",
      "Epoch 949/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7430 - val_loss: 0.9450\n",
      "Epoch 950/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7429 - val_loss: 0.9464\n",
      "Epoch 951/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7428 - val_loss: 0.9503\n",
      "Epoch 952/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7428 - val_loss: 0.9414\n",
      "Epoch 953/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7429 - val_loss: 0.9564\n",
      "Epoch 954/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7431 - val_loss: 0.9346\n",
      "Epoch 955/1500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7433 - val_loss: 0.9637\n",
      "Epoch 956/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7436 - val_loss: 0.9268\n",
      "Epoch 957/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7440 - val_loss: 0.9734\n",
      "Epoch 958/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7444 - val_loss: 0.9224\n",
      "Epoch 959/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7446 - val_loss: 0.9722\n",
      "Epoch 960/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7444 - val_loss: 0.9296\n",
      "Epoch 961/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7437 - val_loss: 0.9535\n",
      "Epoch 962/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7431 - val_loss: 0.9496\n",
      "Epoch 963/1500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7429 - val_loss: 0.9378\n",
      "Epoch 964/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7431 - val_loss: 0.9648\n",
      "Epoch 965/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7435 - val_loss: 0.9255\n",
      "Epoch 966/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7440 - val_loss: 0.9717\n",
      "Epoch 967/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7446 - val_loss: 0.9210\n",
      "Epoch 968/1500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7449 - val_loss: 0.9701\n",
      "Epoch 969/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7449 - val_loss: 0.9318\n",
      "Epoch 970/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7443 - val_loss: 0.9550\n",
      "Epoch 971/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7437 - val_loss: 0.9502\n",
      "Epoch 972/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7432 - val_loss: 0.9409\n",
      "Epoch 973/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7430 - val_loss: 0.9622\n",
      "Epoch 974/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7432 - val_loss: 0.9324\n",
      "Epoch 975/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7438 - val_loss: 0.9691\n",
      "Epoch 976/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7445 - val_loss: 0.9284\n",
      "Epoch 977/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7447 - val_loss: 0.9691\n",
      "Epoch 978/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7445 - val_loss: 0.9308\n",
      "Epoch 979/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7438 - val_loss: 0.9592\n",
      "Epoch 980/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7431 - val_loss: 0.9428\n",
      "Epoch 981/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7428 - val_loss: 0.9439\n",
      "Epoch 982/1500\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7429 - val_loss: 0.9605\n",
      "Epoch 983/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7433 - val_loss: 0.9322\n",
      "Epoch 984/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7437 - val_loss: 0.9729\n",
      "Epoch 985/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7441 - val_loss: 0.9258\n",
      "Epoch 986/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7442 - val_loss: 0.9708\n",
      "Epoch 987/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7438 - val_loss: 0.9342\n",
      "Epoch 988/1500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7431 - val_loss: 0.9512\n",
      "Epoch 989/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7427 - val_loss: 0.9561\n",
      "Epoch 990/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7428 - val_loss: 0.9331\n",
      "Epoch 991/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7433 - val_loss: 0.9699\n",
      "Epoch 992/1500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7437 - val_loss: 0.9272\n",
      "Epoch 993/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7438 - val_loss: 0.9647\n",
      "Epoch 994/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7435 - val_loss: 0.9386\n",
      "Epoch 995/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7430 - val_loss: 0.9501\n",
      "Epoch 996/1500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7428 - val_loss: 0.9587\n",
      "Epoch 997/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7429 - val_loss: 0.9368\n",
      "Epoch 998/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7431 - val_loss: 0.9682\n",
      "Epoch 999/1500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7434 - val_loss: 0.9318\n",
      "Epoch 1000/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7435 - val_loss: 0.9641\n",
      "Epoch 1001/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7435 - val_loss: 0.9387\n",
      "Epoch 1002/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7432 - val_loss: 0.9545\n",
      "Epoch 1003/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7429 - val_loss: 0.9495\n",
      "Epoch 1004/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7426 - val_loss: 0.9455\n",
      "Epoch 1005/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7426 - val_loss: 0.9548\n",
      "Epoch 1006/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7427 - val_loss: 0.9404\n",
      "Epoch 1007/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7430 - val_loss: 0.9598\n",
      "Epoch 1008/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7431 - val_loss: 0.9382\n",
      "Epoch 1009/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7430 - val_loss: 0.9637\n",
      "Epoch 1010/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7430 - val_loss: 0.9388\n",
      "Epoch 1011/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7428 - val_loss: 0.9596\n",
      "Epoch 1012/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7427 - val_loss: 0.9436\n",
      "Epoch 1013/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7426 - val_loss: 0.9509\n",
      "Epoch 1014/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7425 - val_loss: 0.9523\n",
      "Epoch 1015/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7425 - val_loss: 0.9426\n",
      "Epoch 1016/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7426 - val_loss: 0.9601\n",
      "Epoch 1017/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7427 - val_loss: 0.9369\n",
      "Epoch 1018/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7428 - val_loss: 0.9638\n",
      "Epoch 1019/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7430 - val_loss: 0.9360\n",
      "Epoch 1020/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7430 - val_loss: 0.9633\n",
      "Epoch 1021/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7429 - val_loss: 0.9423\n",
      "Epoch 1022/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7427 - val_loss: 0.9576\n",
      "Epoch 1023/1500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7427 - val_loss: 0.9472\n",
      "Epoch 1024/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7425 - val_loss: 0.9521\n",
      "Epoch 1025/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7424 - val_loss: 0.9505\n",
      "Epoch 1026/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7424 - val_loss: 0.9494\n",
      "Epoch 1027/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7424 - val_loss: 0.9532\n",
      "Epoch 1028/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7424 - val_loss: 0.9470\n",
      "Epoch 1029/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7425 - val_loss: 0.9578\n",
      "Epoch 1030/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7425 - val_loss: 0.9422\n",
      "Epoch 1031/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7426 - val_loss: 0.9636\n",
      "Epoch 1032/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7427 - val_loss: 0.9353\n",
      "Epoch 1033/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7430 - val_loss: 0.9720\n",
      "Epoch 1034/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7433 - val_loss: 0.9269\n",
      "Epoch 1035/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7437 - val_loss: 0.9766\n",
      "Epoch 1036/1500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7439 - val_loss: 0.9286\n",
      "Epoch 1037/1500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7437 - val_loss: 0.9671\n",
      "Epoch 1038/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7433 - val_loss: 0.9452\n",
      "Epoch 1039/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7428 - val_loss: 0.9501\n",
      "Epoch 1040/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7426 - val_loss: 0.9606\n",
      "Epoch 1041/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7426 - val_loss: 0.9377\n",
      "Epoch 1042/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7428 - val_loss: 0.9692\n",
      "Epoch 1043/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7433 - val_loss: 0.9299\n",
      "Epoch 1044/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7438 - val_loss: 0.9740\n",
      "Epoch 1045/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7440 - val_loss: 0.9333\n",
      "Epoch 1046/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7439 - val_loss: 0.9709\n",
      "Epoch 1047/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7435 - val_loss: 0.9425\n",
      "Epoch 1048/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7428 - val_loss: 0.9541\n",
      "Epoch 1049/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7424 - val_loss: 0.9552\n",
      "Epoch 1050/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7424 - val_loss: 0.9415\n",
      "Epoch 1051/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7427 - val_loss: 0.9662\n",
      "Epoch 1052/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7432 - val_loss: 0.9323\n",
      "Epoch 1053/1500\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7435 - val_loss: 0.9721\n",
      "Epoch 1054/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7437 - val_loss: 0.9290\n",
      "Epoch 1055/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7436 - val_loss: 0.9733\n",
      "Epoch 1056/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7435 - val_loss: 0.9334\n",
      "Epoch 1057/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7431 - val_loss: 0.9627\n",
      "Epoch 1058/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7427 - val_loss: 0.9468\n",
      "Epoch 1059/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7423 - val_loss: 0.9458\n",
      "Epoch 1060/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7423 - val_loss: 0.9631\n",
      "Epoch 1061/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7426 - val_loss: 0.9367\n",
      "Epoch 1062/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7429 - val_loss: 0.9701\n",
      "Epoch 1063/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7431 - val_loss: 0.9363\n",
      "Epoch 1064/1500\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7430 - val_loss: 0.9659\n",
      "Epoch 1065/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7428 - val_loss: 0.9411\n",
      "Epoch 1066/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7426 - val_loss: 0.9545\n",
      "Epoch 1067/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7424 - val_loss: 0.9517\n",
      "Epoch 1068/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7423 - val_loss: 0.9455\n",
      "Epoch 1069/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7423 - val_loss: 0.9605\n",
      "Epoch 1070/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7424 - val_loss: 0.9398\n",
      "Epoch 1071/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7426 - val_loss: 0.9664\n",
      "Epoch 1072/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7428 - val_loss: 0.9365\n",
      "Epoch 1073/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7430 - val_loss: 0.9689\n",
      "Epoch 1074/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7431 - val_loss: 0.9358\n",
      "Epoch 1075/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7430 - val_loss: 0.9676\n",
      "Epoch 1076/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7429 - val_loss: 0.9384\n",
      "Epoch 1077/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7427 - val_loss: 0.9633\n",
      "Epoch 1078/1500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7425 - val_loss: 0.9454\n",
      "Epoch 1079/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7423 - val_loss: 0.9553\n",
      "Epoch 1080/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7422 - val_loss: 0.9532\n",
      "Epoch 1081/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7422 - val_loss: 0.9477\n",
      "Epoch 1082/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7422 - val_loss: 0.9601\n",
      "Epoch 1083/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7423 - val_loss: 0.9421\n",
      "Epoch 1084/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7424 - val_loss: 0.9663\n",
      "Epoch 1085/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7426 - val_loss: 0.9386\n",
      "Epoch 1086/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7426 - val_loss: 0.9667\n",
      "Epoch 1087/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7426 - val_loss: 0.9390\n",
      "Epoch 1088/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7426 - val_loss: 0.9652\n",
      "Epoch 1089/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7426 - val_loss: 0.9427\n",
      "Epoch 1090/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7424 - val_loss: 0.9608\n",
      "Epoch 1091/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7424 - val_loss: 0.9456\n",
      "Epoch 1092/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7423 - val_loss: 0.9583\n",
      "Epoch 1093/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7422 - val_loss: 0.9467\n",
      "Epoch 1094/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7422 - val_loss: 0.9576\n",
      "Epoch 1095/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7422 - val_loss: 0.9469\n",
      "Epoch 1096/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7422 - val_loss: 0.9593\n",
      "Epoch 1097/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7422 - val_loss: 0.9461\n",
      "Epoch 1098/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7422 - val_loss: 0.9612\n",
      "Epoch 1099/1500\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7422 - val_loss: 0.9415\n",
      "Epoch 1100/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7423 - val_loss: 0.9652\n",
      "Epoch 1101/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7425 - val_loss: 0.9389\n",
      "Epoch 1102/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7427 - val_loss: 0.9734\n",
      "Epoch 1103/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7430 - val_loss: 0.9342\n",
      "Epoch 1104/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7432 - val_loss: 0.9774\n",
      "Epoch 1105/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7436 - val_loss: 0.9322\n",
      "Epoch 1106/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7434 - val_loss: 0.9718\n",
      "Epoch 1107/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7431 - val_loss: 0.9441\n",
      "Epoch 1108/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7426 - val_loss: 0.9587\n",
      "Epoch 1109/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7423 - val_loss: 0.9560\n",
      "Epoch 1110/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7421 - val_loss: 0.9464\n",
      "Epoch 1111/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7422 - val_loss: 0.9655\n",
      "Epoch 1112/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7424 - val_loss: 0.9376\n",
      "Epoch 1113/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7428 - val_loss: 0.9751\n",
      "Epoch 1114/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7433 - val_loss: 0.9334\n",
      "Epoch 1115/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7436 - val_loss: 0.9787\n",
      "Epoch 1116/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7437 - val_loss: 0.9362\n",
      "Epoch 1117/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7433 - val_loss: 0.9687\n",
      "Epoch 1118/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7428 - val_loss: 0.9484\n",
      "Epoch 1119/1500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7423 - val_loss: 0.9511\n",
      "Epoch 1120/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7421 - val_loss: 0.9630\n",
      "Epoch 1121/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7423 - val_loss: 0.9410\n",
      "Epoch 1122/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7426 - val_loss: 0.9739\n",
      "Epoch 1123/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7432 - val_loss: 0.9315\n",
      "Epoch 1124/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7437 - val_loss: 0.9810\n",
      "Epoch 1125/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7442 - val_loss: 0.9289\n",
      "Epoch 1126/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7441 - val_loss: 0.9777\n",
      "Epoch 1127/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7435 - val_loss: 0.9453\n",
      "Epoch 1128/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7425 - val_loss: 0.9545\n",
      "Epoch 1129/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7421 - val_loss: 0.9706\n",
      "Epoch 1130/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7424 - val_loss: 0.9399\n",
      "Epoch 1131/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7429 - val_loss: 0.9768\n",
      "Epoch 1132/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7433 - val_loss: 0.9392\n",
      "Epoch 1133/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7431 - val_loss: 0.9668\n",
      "Epoch 1134/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7427 - val_loss: 0.9550\n",
      "Epoch 1135/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7423 - val_loss: 0.9544\n",
      "Epoch 1136/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7422 - val_loss: 0.9672\n",
      "Epoch 1137/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7422 - val_loss: 0.9435\n",
      "Epoch 1138/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7425 - val_loss: 0.9697\n",
      "Epoch 1139/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7427 - val_loss: 0.9407\n",
      "Epoch 1140/1500\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7429 - val_loss: 0.9711\n",
      "Epoch 1141/1500\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7428 - val_loss: 0.9474\n",
      "Epoch 1142/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7425 - val_loss: 0.9646\n",
      "Epoch 1143/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7422 - val_loss: 0.9552\n",
      "Epoch 1144/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7420 - val_loss: 0.9543\n",
      "Epoch 1145/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7420 - val_loss: 0.9644\n",
      "Epoch 1146/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7422 - val_loss: 0.9478\n",
      "Epoch 1147/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7424 - val_loss: 0.9729\n",
      "Epoch 1148/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7427 - val_loss: 0.9380\n",
      "Epoch 1149/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7430 - val_loss: 0.9786\n",
      "Epoch 1150/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7432 - val_loss: 0.9349\n",
      "Epoch 1151/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7430 - val_loss: 0.9703\n",
      "Epoch 1152/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7425 - val_loss: 0.9496\n",
      "Epoch 1153/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7420 - val_loss: 0.9501\n",
      "Epoch 1154/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7420 - val_loss: 0.9697\n",
      "Epoch 1155/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7424 - val_loss: 0.9383\n",
      "Epoch 1156/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7427 - val_loss: 0.9756\n",
      "Epoch 1157/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7429 - val_loss: 0.9407\n",
      "Epoch 1158/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7427 - val_loss: 0.9674\n",
      "Epoch 1159/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7423 - val_loss: 0.9545\n",
      "Epoch 1160/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7420 - val_loss: 0.9534\n",
      "Epoch 1161/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7420 - val_loss: 0.9665\n",
      "Epoch 1162/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7421 - val_loss: 0.9431\n",
      "Epoch 1163/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7423 - val_loss: 0.9704\n",
      "Epoch 1164/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7425 - val_loss: 0.9418\n",
      "Epoch 1165/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7426 - val_loss: 0.9724\n",
      "Epoch 1166/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7426 - val_loss: 0.9457\n",
      "Epoch 1167/1500\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7424 - val_loss: 0.9663\n",
      "Epoch 1168/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7423 - val_loss: 0.9511\n",
      "Epoch 1169/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7420 - val_loss: 0.9554\n",
      "Epoch 1170/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7419 - val_loss: 0.9611\n",
      "Epoch 1171/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7419 - val_loss: 0.9509\n",
      "Epoch 1172/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7421 - val_loss: 0.9697\n",
      "Epoch 1173/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7423 - val_loss: 0.9438\n",
      "Epoch 1174/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7425 - val_loss: 0.9753\n",
      "Epoch 1175/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7427 - val_loss: 0.9406\n",
      "Epoch 1176/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7427 - val_loss: 0.9711\n",
      "Epoch 1177/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7424 - val_loss: 0.9484\n",
      "Epoch 1178/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7421 - val_loss: 0.9581\n",
      "Epoch 1179/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7419 - val_loss: 0.9606\n",
      "Epoch 1180/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7419 - val_loss: 0.9477\n",
      "Epoch 1181/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7421 - val_loss: 0.9708\n",
      "Epoch 1182/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7423 - val_loss: 0.9424\n",
      "Epoch 1183/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7426 - val_loss: 0.9784\n",
      "Epoch 1184/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7429 - val_loss: 0.9349\n",
      "Epoch 1185/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7433 - val_loss: 0.9810\n",
      "Epoch 1186/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7434 - val_loss: 0.9377\n",
      "Epoch 1187/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7428 - val_loss: 0.9641\n",
      "Epoch 1188/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7421 - val_loss: 0.9605\n",
      "Epoch 1189/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7419 - val_loss: 0.9458\n",
      "Epoch 1190/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7423 - val_loss: 0.9753\n",
      "Epoch 1191/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7426 - val_loss: 0.9403\n",
      "Epoch 1192/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7427 - val_loss: 0.9695\n",
      "Epoch 1193/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7426 - val_loss: 0.9475\n",
      "Epoch 1194/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7423 - val_loss: 0.9598\n",
      "Epoch 1195/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7421 - val_loss: 0.9605\n",
      "Epoch 1196/1500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7420 - val_loss: 0.9503\n",
      "Epoch 1197/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7420 - val_loss: 0.9658\n",
      "Epoch 1198/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7421 - val_loss: 0.9459\n",
      "Epoch 1199/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7421 - val_loss: 0.9667\n",
      "Epoch 1200/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7422 - val_loss: 0.9502\n",
      "Epoch 1201/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7422 - val_loss: 0.9644\n",
      "Epoch 1202/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7421 - val_loss: 0.9530\n",
      "Epoch 1203/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7420 - val_loss: 0.9613\n",
      "Epoch 1204/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7419 - val_loss: 0.9533\n",
      "Epoch 1205/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7418 - val_loss: 0.9620\n",
      "Epoch 1206/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7418 - val_loss: 0.9545\n",
      "Epoch 1207/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7419 - val_loss: 0.9617\n",
      "Epoch 1208/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7419 - val_loss: 0.9545\n",
      "Epoch 1209/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7418 - val_loss: 0.9591\n",
      "Epoch 1210/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7418 - val_loss: 0.9563\n",
      "Epoch 1211/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7418 - val_loss: 0.9574\n",
      "Epoch 1212/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7418 - val_loss: 0.9590\n",
      "Epoch 1213/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7418 - val_loss: 0.9566\n",
      "Epoch 1214/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7418 - val_loss: 0.9616\n",
      "Epoch 1215/1500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7418 - val_loss: 0.9545\n",
      "Epoch 1216/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7418 - val_loss: 0.9645\n",
      "Epoch 1217/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7418 - val_loss: 0.9500\n",
      "Epoch 1218/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7419 - val_loss: 0.9707\n",
      "Epoch 1219/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7421 - val_loss: 0.9429\n",
      "Epoch 1220/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7425 - val_loss: 0.9827\n",
      "Epoch 1221/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7431 - val_loss: 0.9312\n",
      "Epoch 1222/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7439 - val_loss: 0.9925\n",
      "Epoch 1223/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7446 - val_loss: 0.9317\n",
      "Epoch 1224/1500\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7441 - val_loss: 0.9767\n",
      "Epoch 1225/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7431 - val_loss: 0.9577\n",
      "Epoch 1226/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7423 - val_loss: 0.9479\n",
      "Epoch 1227/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7424 - val_loss: 0.9826\n",
      "Epoch 1228/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7431 - val_loss: 0.9381\n",
      "Epoch 1229/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7429 - val_loss: 0.9693\n",
      "Epoch 1230/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7427 - val_loss: 0.9549\n",
      "Epoch 1231/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7423 - val_loss: 0.9499\n",
      "Epoch 1232/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7426 - val_loss: 0.9790\n",
      "Epoch 1233/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7432 - val_loss: 0.9372\n",
      "Epoch 1234/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7433 - val_loss: 0.9786\n",
      "Epoch 1235/1500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7432 - val_loss: 0.9376\n",
      "Epoch 1236/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7426 - val_loss: 0.9621\n",
      "Epoch 1237/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7425 - val_loss: 0.9648\n",
      "Epoch 1238/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7426 - val_loss: 0.9505\n",
      "Epoch 1239/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7429 - val_loss: 0.9801\n",
      "Epoch 1240/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7428 - val_loss: 0.9425\n",
      "Epoch 1241/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7424 - val_loss: 0.9677\n",
      "Epoch 1242/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7424 - val_loss: 0.9585\n",
      "Epoch 1243/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7425 - val_loss: 0.9556\n",
      "Epoch 1244/1500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7427 - val_loss: 0.9750\n",
      "Epoch 1245/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7425 - val_loss: 0.9501\n",
      "Epoch 1246/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7420 - val_loss: 0.9646\n",
      "Epoch 1247/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7421 - val_loss: 0.9530\n",
      "Epoch 1248/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7423 - val_loss: 0.9574\n",
      "Epoch 1249/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7424 - val_loss: 0.9666\n",
      "Epoch 1250/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7421 - val_loss: 0.9573\n",
      "Epoch 1251/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7418 - val_loss: 0.9680\n",
      "Epoch 1252/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7420 - val_loss: 0.9525\n",
      "Epoch 1253/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7423 - val_loss: 0.9725\n",
      "Epoch 1254/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7426 - val_loss: 0.9459\n",
      "Epoch 1255/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7426 - val_loss: 0.9822\n",
      "Epoch 1256/1500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7426 - val_loss: 0.9422\n",
      "Epoch 1257/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7426 - val_loss: 0.9786\n",
      "Epoch 1258/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7425 - val_loss: 0.9516\n",
      "Epoch 1259/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7420 - val_loss: 0.9602\n",
      "Epoch 1260/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7417 - val_loss: 0.9721\n",
      "Epoch 1261/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7420 - val_loss: 0.9472\n",
      "Epoch 1262/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7422 - val_loss: 0.9769\n",
      "Epoch 1263/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7423 - val_loss: 0.9480\n",
      "Epoch 1264/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7420 - val_loss: 0.9651\n",
      "Epoch 1265/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7418 - val_loss: 0.9642\n",
      "Epoch 1266/1500\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7418 - val_loss: 0.9509\n",
      "Epoch 1267/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7420 - val_loss: 0.9738\n",
      "Epoch 1268/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7421 - val_loss: 0.9466\n",
      "Epoch 1269/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7421 - val_loss: 0.9702\n",
      "Epoch 1270/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7422 - val_loss: 0.9521\n",
      "Epoch 1271/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7420 - val_loss: 0.9679\n",
      "Epoch 1272/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7419 - val_loss: 0.9603\n",
      "Epoch 1273/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7417 - val_loss: 0.9634\n",
      "Epoch 1274/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7417 - val_loss: 0.9630\n",
      "Epoch 1275/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7417 - val_loss: 0.9578\n",
      "Epoch 1276/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7418 - val_loss: 0.9671\n",
      "Epoch 1277/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7418 - val_loss: 0.9559\n",
      "Epoch 1278/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7418 - val_loss: 0.9708\n",
      "Epoch 1279/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7418 - val_loss: 0.9526\n",
      "Epoch 1280/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7418 - val_loss: 0.9687\n",
      "Epoch 1281/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7418 - val_loss: 0.9535\n",
      "Epoch 1282/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7417 - val_loss: 0.9641\n",
      "Epoch 1283/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7417 - val_loss: 0.9610\n",
      "Epoch 1284/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7417 - val_loss: 0.9602\n",
      "Epoch 1285/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7417 - val_loss: 0.9634\n",
      "Epoch 1286/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7417 - val_loss: 0.9559\n",
      "Epoch 1287/1500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7417 - val_loss: 0.9675\n",
      "Epoch 1288/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7417 - val_loss: 0.9557\n",
      "Epoch 1289/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7418 - val_loss: 0.9718\n",
      "Epoch 1290/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7419 - val_loss: 0.9521\n",
      "Epoch 1291/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7419 - val_loss: 0.9721\n",
      "Epoch 1292/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7419 - val_loss: 0.9523\n",
      "Epoch 1293/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7418 - val_loss: 0.9683\n",
      "Epoch 1294/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7417 - val_loss: 0.9607\n",
      "Epoch 1295/1500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7416 - val_loss: 0.9595\n",
      "Epoch 1296/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7416 - val_loss: 0.9681\n",
      "Epoch 1297/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7417 - val_loss: 0.9521\n",
      "Epoch 1298/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7418 - val_loss: 0.9731\n",
      "Epoch 1299/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7419 - val_loss: 0.9516\n",
      "Epoch 1300/1500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7419 - val_loss: 0.9738\n",
      "Epoch 1301/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7419 - val_loss: 0.9521\n",
      "Epoch 1302/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7418 - val_loss: 0.9670\n",
      "Epoch 1303/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7417 - val_loss: 0.9586\n",
      "Epoch 1304/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7416 - val_loss: 0.9596\n",
      "Epoch 1305/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7416 - val_loss: 0.9699\n",
      "Epoch 1306/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7417 - val_loss: 0.9543\n",
      "Epoch 1307/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7418 - val_loss: 0.9736\n",
      "Epoch 1308/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7420 - val_loss: 0.9496\n",
      "Epoch 1309/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7420 - val_loss: 0.9757\n",
      "Epoch 1310/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7421 - val_loss: 0.9503\n",
      "Epoch 1311/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7420 - val_loss: 0.9699\n",
      "Epoch 1312/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7418 - val_loss: 0.9586\n",
      "Epoch 1313/1500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7416 - val_loss: 0.9583\n",
      "Epoch 1314/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7416 - val_loss: 0.9724\n",
      "Epoch 1315/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7418 - val_loss: 0.9513\n",
      "Epoch 1316/1500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7420 - val_loss: 0.9764\n",
      "Epoch 1317/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7422 - val_loss: 0.9494\n",
      "Epoch 1318/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7420 - val_loss: 0.9716\n",
      "Epoch 1319/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7419 - val_loss: 0.9582\n",
      "Epoch 1320/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7417 - val_loss: 0.9583\n",
      "Epoch 1321/1500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7416 - val_loss: 0.9721\n",
      "Epoch 1322/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7418 - val_loss: 0.9507\n",
      "Epoch 1323/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7420 - val_loss: 0.9769\n",
      "Epoch 1324/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7422 - val_loss: 0.9489\n",
      "Epoch 1325/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7421 - val_loss: 0.9715\n",
      "Epoch 1326/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7419 - val_loss: 0.9604\n",
      "Epoch 1327/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7417 - val_loss: 0.9589\n",
      "Epoch 1328/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7416 - val_loss: 0.9706\n",
      "Epoch 1329/1500\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7418 - val_loss: 0.9505\n",
      "Epoch 1330/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7419 - val_loss: 0.9721\n",
      "Epoch 1331/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7420 - val_loss: 0.9549\n",
      "Epoch 1332/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7419 - val_loss: 0.9695\n",
      "Epoch 1333/1500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7418 - val_loss: 0.9609\n",
      "Epoch 1334/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7416 - val_loss: 0.9623\n",
      "Epoch 1335/1500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7416 - val_loss: 0.9651\n",
      "Epoch 1336/1500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7416 - val_loss: 0.9574\n",
      "Epoch 1337/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7417 - val_loss: 0.9724\n",
      "Epoch 1338/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7418 - val_loss: 0.9555\n",
      "Epoch 1339/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7419 - val_loss: 0.9776\n",
      "Epoch 1340/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7420 - val_loss: 0.9491\n",
      "Epoch 1341/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7420 - val_loss: 0.9769\n",
      "Epoch 1342/1500\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7421 - val_loss: 0.9516\n",
      "Epoch 1343/1500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7418 - val_loss: 0.9665\n",
      "Epoch 1344/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7416 - val_loss: 0.9710\n",
      "Epoch 1345/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7417 - val_loss: 0.9533\n",
      "Epoch 1346/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7419 - val_loss: 0.9770\n",
      "Epoch 1347/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7421 - val_loss: 0.9486\n",
      "Epoch 1348/1500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7420 - val_loss: 0.9713\n",
      "Epoch 1349/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7418 - val_loss: 0.9640\n",
      "Epoch 1350/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7417 - val_loss: 0.9587\n",
      "Epoch 1351/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7417 - val_loss: 0.9712\n",
      "Epoch 1352/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7418 - val_loss: 0.9503\n",
      "Epoch 1353/1500\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7418 - val_loss: 0.9671\n",
      "Epoch 1354/1500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7418 - val_loss: 0.9619\n",
      "Epoch 1355/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7417 - val_loss: 0.9663\n",
      "Epoch 1356/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7417 - val_loss: 0.9670\n",
      "Epoch 1357/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7417 - val_loss: 0.9609\n",
      "Epoch 1358/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7416 - val_loss: 0.9658\n",
      "Epoch 1359/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7416 - val_loss: 0.9599\n",
      "Epoch 1360/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7417 - val_loss: 0.9707\n",
      "Epoch 1361/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7418 - val_loss: 0.9584\n",
      "Epoch 1362/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7418 - val_loss: 0.9770\n",
      "Epoch 1363/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7419 - val_loss: 0.9478\n",
      "Epoch 1364/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7422 - val_loss: 0.9889\n",
      "Epoch 1365/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7429 - val_loss: 0.9368\n",
      "Epoch 1366/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7433 - val_loss: 0.9954\n",
      "Epoch 1367/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7436 - val_loss: 0.9427\n",
      "Epoch 1368/1500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7428 - val_loss: 0.9707\n",
      "Epoch 1369/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7420 - val_loss: 0.9718\n",
      "Epoch 1370/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7420 - val_loss: 0.9463\n",
      "Epoch 1371/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7424 - val_loss: 0.9791\n",
      "Epoch 1372/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7423 - val_loss: 0.9555\n",
      "Epoch 1373/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7419 - val_loss: 0.9550\n",
      "Epoch 1374/1500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7420 - val_loss: 0.9777\n",
      "Epoch 1375/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7423 - val_loss: 0.9494\n",
      "Epoch 1376/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7422 - val_loss: 0.9737\n",
      "Epoch 1377/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7419 - val_loss: 0.9584\n",
      "Epoch 1378/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7418 - val_loss: 0.9603\n",
      "Epoch 1379/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7419 - val_loss: 0.9701\n",
      "Epoch 1380/1500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7421 - val_loss: 0.9557\n",
      "Epoch 1381/1500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7420 - val_loss: 0.9730\n",
      "Epoch 1382/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7418 - val_loss: 0.9552\n",
      "Epoch 1383/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7418 - val_loss: 0.9713\n",
      "Epoch 1384/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7420 - val_loss: 0.9573\n",
      "Epoch 1385/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7421 - val_loss: 0.9715\n",
      "Epoch 1386/1500\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7421 - val_loss: 0.9574\n",
      "Epoch 1387/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7419 - val_loss: 0.9722\n",
      "Epoch 1388/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7418 - val_loss: 0.9548\n",
      "Epoch 1389/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7418 - val_loss: 0.9732\n",
      "Epoch 1390/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7418 - val_loss: 0.9579\n",
      "Epoch 1391/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7417 - val_loss: 0.9690\n",
      "Epoch 1392/1500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7416 - val_loss: 0.9656\n",
      "Epoch 1393/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7416 - val_loss: 0.9612\n",
      "Epoch 1394/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7416 - val_loss: 0.9714\n",
      "Epoch 1395/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7417 - val_loss: 0.9581\n",
      "Epoch 1396/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7417 - val_loss: 0.9686\n",
      "Epoch 1397/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7416 - val_loss: 0.9649\n",
      "Epoch 1398/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7416 - val_loss: 0.9632\n",
      "Epoch 1399/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7416 - val_loss: 0.9694\n",
      "Epoch 1400/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7416 - val_loss: 0.9591\n",
      "Epoch 1401/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7416 - val_loss: 0.9718\n",
      "Epoch 1402/1500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7417 - val_loss: 0.9584\n",
      "Epoch 1403/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7417 - val_loss: 0.9732\n",
      "Epoch 1404/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7417 - val_loss: 0.9578\n",
      "Epoch 1405/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7417 - val_loss: 0.9715\n",
      "Epoch 1406/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7417 - val_loss: 0.9604\n",
      "Epoch 1407/1500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7417 - val_loss: 0.9678\n",
      "Epoch 1408/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7416 - val_loss: 0.9667\n",
      "Epoch 1409/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7415 - val_loss: 0.9627\n",
      "Epoch 1410/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7416 - val_loss: 0.9694\n",
      "Epoch 1411/1500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7416 - val_loss: 0.9586\n",
      "Epoch 1412/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7417 - val_loss: 0.9762\n",
      "Epoch 1413/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7418 - val_loss: 0.9538\n",
      "Epoch 1414/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7419 - val_loss: 0.9822\n",
      "Epoch 1415/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7421 - val_loss: 0.9481\n",
      "Epoch 1416/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7421 - val_loss: 0.9795\n",
      "Epoch 1417/1500\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7421 - val_loss: 0.9557\n",
      "Epoch 1418/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7417 - val_loss: 0.9656\n",
      "Epoch 1419/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7416 - val_loss: 0.9742\n",
      "Epoch 1420/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7417 - val_loss: 0.9545\n",
      "Epoch 1421/1500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7418 - val_loss: 0.9765\n",
      "Epoch 1422/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7419 - val_loss: 0.9534\n",
      "Epoch 1423/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7418 - val_loss: 0.9666\n",
      "Epoch 1424/1500\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7417 - val_loss: 0.9701\n",
      "Epoch 1425/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7417 - val_loss: 0.9580\n",
      "Epoch 1426/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7417 - val_loss: 0.9752\n",
      "Epoch 1427/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7418 - val_loss: 0.9513\n",
      "Epoch 1428/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7419 - val_loss: 0.9750\n",
      "Epoch 1429/1500\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7420 - val_loss: 0.9567\n",
      "Epoch 1430/1500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7420 - val_loss: 0.9716\n",
      "Epoch 1431/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7419 - val_loss: 0.9622\n",
      "Epoch 1432/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7417 - val_loss: 0.9641\n",
      "Epoch 1433/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7416 - val_loss: 0.9662\n",
      "Epoch 1434/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7416 - val_loss: 0.9600\n",
      "Epoch 1435/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7417 - val_loss: 0.9708\n",
      "Epoch 1436/1500\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7418 - val_loss: 0.9592\n",
      "Epoch 1437/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7418 - val_loss: 0.9753\n",
      "Epoch 1438/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7418 - val_loss: 0.9544\n",
      "Epoch 1439/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7418 - val_loss: 0.9754\n",
      "Epoch 1440/1500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7418 - val_loss: 0.9553\n",
      "Epoch 1441/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7417 - val_loss: 0.9675\n",
      "Epoch 1442/1500\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7416 - val_loss: 0.9706\n",
      "Epoch 1443/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7416 - val_loss: 0.9581\n",
      "Epoch 1444/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7417 - val_loss: 0.9774\n",
      "Epoch 1445/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7419 - val_loss: 0.9501\n",
      "Epoch 1446/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7419 - val_loss: 0.9741\n",
      "Epoch 1447/1500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7418 - val_loss: 0.9624\n",
      "Epoch 1448/1500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7416 - val_loss: 0.9635\n",
      "Epoch 1449/1500\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7416 - val_loss: 0.9747\n",
      "Epoch 1450/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7417 - val_loss: 0.9520\n",
      "Epoch 1451/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7418 - val_loss: 0.9733\n",
      "Epoch 1452/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7419 - val_loss: 0.9577\n",
      "Epoch 1453/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7417 - val_loss: 0.9674\n",
      "Epoch 1454/1500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7417 - val_loss: 0.9717\n",
      "Epoch 1455/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7417 - val_loss: 0.9591\n",
      "Epoch 1456/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7417 - val_loss: 0.9708\n",
      "Epoch 1457/1500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7417 - val_loss: 0.9565\n",
      "Epoch 1458/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7417 - val_loss: 0.9662\n",
      "Epoch 1459/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7417 - val_loss: 0.9697\n",
      "Epoch 1460/1500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7417 - val_loss: 0.9654\n",
      "Epoch 1461/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7417 - val_loss: 0.9698\n",
      "Epoch 1462/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7416 - val_loss: 0.9590\n",
      "Epoch 1463/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7416 - val_loss: 0.9683\n",
      "Epoch 1464/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7417 - val_loss: 0.9607\n",
      "Epoch 1465/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7418 - val_loss: 0.9742\n",
      "Epoch 1466/1500\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7418 - val_loss: 0.9566\n",
      "Epoch 1467/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7419 - val_loss: 0.9796\n",
      "Epoch 1468/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7420 - val_loss: 0.9472\n",
      "Epoch 1469/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7422 - val_loss: 0.9890\n",
      "Epoch 1470/1500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7426 - val_loss: 0.9445\n",
      "Epoch 1471/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7425 - val_loss: 0.9825\n",
      "Epoch 1472/1500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7422 - val_loss: 0.9579\n",
      "Epoch 1473/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7418 - val_loss: 0.9586\n",
      "Epoch 1474/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7418 - val_loss: 0.9807\n",
      "Epoch 1475/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7421 - val_loss: 0.9506\n",
      "Epoch 1476/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7420 - val_loss: 0.9742\n",
      "Epoch 1477/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7419 - val_loss: 0.9601\n",
      "Epoch 1478/1500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7418 - val_loss: 0.9595\n",
      "Epoch 1479/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7418 - val_loss: 0.9736\n",
      "Epoch 1480/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7419 - val_loss: 0.9550\n",
      "Epoch 1481/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7418 - val_loss: 0.9717\n",
      "Epoch 1482/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7417 - val_loss: 0.9582\n",
      "Epoch 1483/1500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7417 - val_loss: 0.9698\n",
      "Epoch 1484/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7418 - val_loss: 0.9655\n",
      "Epoch 1485/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7418 - val_loss: 0.9696\n",
      "Epoch 1486/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7417 - val_loss: 0.9636\n",
      "Epoch 1487/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7416 - val_loss: 0.9696\n",
      "Epoch 1488/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7416 - val_loss: 0.9613\n",
      "Epoch 1489/1500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7416 - val_loss: 0.9733\n",
      "Epoch 1490/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7417 - val_loss: 0.9597\n",
      "Epoch 1491/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7417 - val_loss: 0.9738\n",
      "Epoch 1492/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7417 - val_loss: 0.9590\n",
      "Epoch 1493/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7416 - val_loss: 0.9709\n",
      "Epoch 1494/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7417 - val_loss: 0.9629\n",
      "Epoch 1495/1500\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7417 - val_loss: 0.9677\n",
      "Epoch 1496/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7417 - val_loss: 0.9661\n",
      "Epoch 1497/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7416 - val_loss: 0.9666\n",
      "Epoch 1498/1500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7415 - val_loss: 0.9644\n",
      "Epoch 1499/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7415 - val_loss: 0.9679\n",
      "Epoch 1500/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7416 - val_loss: 0.9639\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.8652\n",
      "0.8651784062385559\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.SimpleRNN(units = 1024, activation = \"relu\", return_sequences = True)(input)\n",
    "    x = layers.SimpleRNN(units = 1024, activation = \"relu\", return_sequences = True)(x)\n",
    "    x = layers.SimpleRNN(units = 512, activation = \"relu\", return_sequences = True)(x)\n",
    "    \n",
    "\n",
    "    # 中間層最後のreturn_sequencesは、Falseにする\n",
    "    # 出力は一つなので、中間層の最後で次元数を落として出力できるようにしている\n",
    "    x = layers.SimpleRNN(units = 512, activation = \"relu\", return_sequences = False)(x)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "model.summary()\n",
    "\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = len(x), epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc964f05e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 405ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdc972da550>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n",
      "0.04625219106674194\n",
      "0.6407108306884766\n",
      "0.3892660140991211\n",
      "0.0666351318359375\n",
      "0.6210851669311523\n",
      "0.03276348114013672\n",
      "0.04367828369140625\n",
      "0.014240264892578125\n",
      "0.019643306732177734\n",
      "0.07885026931762695\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "SINGLE_SE = list()\n",
    "\n",
    "def single_sa(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        c = a - b\n",
    "        output.append(float(abs(c[0])))\n",
    "\n",
    "    return output\n",
    "\n",
    "# 標準化を元の縮尺に戻す関数\n",
    "def decode(x):\n",
    "    return x * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"]\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    SINGLE_SE.append(single_sa(decode(x), decode(y)))\n",
    "    print(SINGLE_SE[-1][-1])\n",
    "    \n",
    "# SINGLE_SE[0]\n",
    "    \n",
    "min_SINGLE_SE = list()\n",
    "max_SINGLE_SE = list()\n",
    "\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    decode_min = min(SINGLE_SE[i])\n",
    "    decode_min_index = SINGLE_SE[i].index(min(SINGLE_SE[i]))\n",
    "    decode_max = max(SINGLE_SE[i])\n",
    "    decode_max_index = SINGLE_SE[i].index(max(SINGLE_SE[i]))\n",
    "    min_SINGLE_SE.append([decode_min, decode_min_index])\n",
    "    max_SINGLE_SE.append([decode_max, decode_max_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 21番目 0.042561%, max : 5番目 13.052%\n",
      "min : 15番目 0.07416%, max : 1番目 57.156%\n",
      "min : 21番目 0.011821%, max : 0番目 23.15%\n",
      "min : 18番目 0.039036%, max : 2番目 48.14%\n",
      "min : 20番目 0.11667%, max : 3番目 48.094%\n",
      "min : 20番目 0.0042572%, max : 1番目 14.874%\n",
      "min : 22番目 0.017521%, max : 0番目 24.007%\n",
      "min : 23番目 0.01424%, max : 2番目 47.377%\n",
      "min : 18番目 0.001091%, max : 2番目 12.261%\n",
      "min : 22番目 0.0058451%, max : 2番目 20.453%\n"
     ]
    }
   ],
   "source": [
    "# 各入力データの1〜24(SPILT_SIZE)の中の最大、最小(上からグラフのソート順になってる)\n",
    "for a ,b in zip(min_SINGLE_SE,max_SINGLE_SE):\n",
    "    print(f\"min : {a[1]}番目 {a[0]:.5}%, max : {b[1]}番目 {b[0]:.5}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "# 各検証データの予測と正解のMSEをとる\n",
    "def mse(x, y):\n",
    "    tmp = 0.0\n",
    "    for a, b in zip(x, y):\n",
    "        tmp += (a - b) ** 2\n",
    "    tmp /= len(x)\n",
    "    return tmp\n",
    "# 各検証データに含まれるNヶ月の各予測と正解の二乗和誤差を算出する\n",
    "def single_se(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        output.append((a - b) ** 2)\n",
    "\n",
    "    return output\n",
    "\n",
    "MSE = []\n",
    "SINGLE_SE = []\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    MSE.append(mse(x, y))\n",
    "    SINGLE_SE.append(single_se(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSEの最小値：[0.04170025]、最大値：[1.3652302]\n",
      "\n",
      "0個目の検証用データにおけるSingle MSEの最小値：[6.9743687e-06]、最大値：[0.6558595]\n",
      "1個目の検証用データにおけるSingle MSEの最小値：[2.1173604e-05]、最大値：[12.577825]\n",
      "2個目の検証用データにおけるSingle MSEの最小値：[5.378397e-07]、最大値：[2.063346]\n",
      "3個目の検証用データにおけるSingle MSEの最小値：[5.866541e-06]、最大値：[8.922792]\n",
      "4個目の検証用データにおけるSingle MSEの最小値：[5.2408068e-05]、最大値：[8.905441]\n",
      "5個目の検証用データにおけるSingle MSEの最小値：[6.975313e-08]、最大値：[0.85185206]\n",
      "6個目の検証用データにおけるSingle MSEの最小値：[1.1819793e-06]、最大値：[2.2190425]\n",
      "7個目の検証用データにおけるSingle MSEの最小値：[7.807123e-07]、最大値：[8.642171]\n",
      "8個目の検証用データにおけるSingle MSEの最小値：[4.584763e-09]、最大値：[0.5788471]\n",
      "9個目の検証用データにおけるSingle MSEの最小値：[1.3152551e-07]、最大値：[1.6105521]\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSEの最小値：{min(MSE)}、最大値：{max(MSE)}\")\n",
    "print()\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    print(f\"{i}個目の検証用データにおけるSingle MSEの最小値：{min(SINGLE_SE[i])}、最大値：{max(SINGLE_SE[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM(多層)sequence=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 3, 3)]            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 3, 1024)           4210688   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 3, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 3, 512)            3147776   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,850,881\n",
      "Trainable params: 17,850,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.0338 - val_loss: 0.8897\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0335 - val_loss: 0.8896\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 1.0332 - val_loss: 0.8895\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0329 - val_loss: 0.8895\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 1s 761ms/step - loss: 1.0327 - val_loss: 0.8894\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 1.0324 - val_loss: 0.8893\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 1.0321 - val_loss: 0.8892\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0318 - val_loss: 0.8890\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 1.0314 - val_loss: 0.8889\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 1.0311 - val_loss: 0.8888\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 1.0306 - val_loss: 0.8886\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 1.0302 - val_loss: 0.8884\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 1.0296 - val_loss: 0.8882\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 1.0291 - val_loss: 0.8879\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 1.0285 - val_loss: 0.8877\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 1.0278 - val_loss: 0.8874\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 1.0270 - val_loss: 0.8871\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 1.0262 - val_loss: 0.8867\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0252 - val_loss: 0.8863\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 1.0242 - val_loss: 0.8859\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 1.0231 - val_loss: 0.8854\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 1.0219 - val_loss: 0.8849\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 1.0205 - val_loss: 0.8843\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 1.0190 - val_loss: 0.8837\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 1s 983ms/step - loss: 1.0174 - val_loss: 0.8830\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 1.0156 - val_loss: 0.8822\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 1.0136 - val_loss: 0.8814\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0115 - val_loss: 0.8806\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 1.0091 - val_loss: 0.8797\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0065 - val_loss: 0.8787\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0037 - val_loss: 0.8777\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0007 - val_loss: 0.8766\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9974 - val_loss: 0.8755\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9937 - val_loss: 0.8743\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.9898 - val_loss: 0.8730\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9856 - val_loss: 0.8718\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9810 - val_loss: 0.8706\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9761 - val_loss: 0.8694\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9708 - val_loss: 0.8682\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9652 - val_loss: 0.8672\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9592 - val_loss: 0.8664\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9529 - val_loss: 0.8659\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9463 - val_loss: 0.8659\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.9396 - val_loss: 0.8664\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.9327 - val_loss: 0.8677\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.9257 - val_loss: 0.8702\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.9189 - val_loss: 0.8740\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.9125 - val_loss: 0.8797\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.9066 - val_loss: 0.8879\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.9016 - val_loss: 0.8991\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.8978 - val_loss: 0.9137\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.8955 - val_loss: 0.9318\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.8948 - val_loss: 0.9520\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.8957 - val_loss: 0.9709\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.8976 - val_loss: 0.9839\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.8989 - val_loss: 0.9887\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.8986 - val_loss: 0.9856\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.8967 - val_loss: 0.9769\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.8938 - val_loss: 0.9651\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.8905 - val_loss: 0.9523\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.8875 - val_loss: 0.9399\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.8850 - val_loss: 0.9287\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.8831 - val_loss: 0.9191\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.8818 - val_loss: 0.9112\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.8809 - val_loss: 0.9046\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8802 - val_loss: 0.8994\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.8796 - val_loss: 0.8954\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8788 - val_loss: 0.8925\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.8779 - val_loss: 0.8909\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.8769 - val_loss: 0.8903\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.8756 - val_loss: 0.8907\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.8743 - val_loss: 0.8921\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.8728 - val_loss: 0.8945\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.8713 - val_loss: 0.8979\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8699 - val_loss: 0.9023\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8687 - val_loss: 0.9070\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.8677 - val_loss: 0.9116\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8668 - val_loss: 0.9161\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8660 - val_loss: 0.9205\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8654 - val_loss: 0.9248\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8648 - val_loss: 0.9285\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8643 - val_loss: 0.9314\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.8639 - val_loss: 0.9331\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.8635 - val_loss: 0.9337\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.8630 - val_loss: 0.9333\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.8625 - val_loss: 0.9324\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8619 - val_loss: 0.9311\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.8613 - val_loss: 0.9295\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8608 - val_loss: 0.9274\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.8603 - val_loss: 0.9249\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8598 - val_loss: 0.9222\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8594 - val_loss: 0.9196\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8589 - val_loss: 0.9176\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8585 - val_loss: 0.9160\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8581 - val_loss: 0.9149\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.8578 - val_loss: 0.9143\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8573 - val_loss: 0.9141\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.8569 - val_loss: 0.9144\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.8564 - val_loss: 0.9151\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8559 - val_loss: 0.9162\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8555 - val_loss: 0.9172\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8550 - val_loss: 0.9181\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8545 - val_loss: 0.9191\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.8540 - val_loss: 0.9202\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.8536 - val_loss: 0.9213\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.8532 - val_loss: 0.9224\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8527 - val_loss: 0.9232\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8523 - val_loss: 0.9237\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8518 - val_loss: 0.9239\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8514 - val_loss: 0.9237\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.8509 - val_loss: 0.9232\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.8504 - val_loss: 0.9224\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.8500 - val_loss: 0.9214\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8495 - val_loss: 0.9205\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.8491 - val_loss: 0.9196\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.8486 - val_loss: 0.9187\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.8482 - val_loss: 0.9181\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.8478 - val_loss: 0.9179\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.8473 - val_loss: 0.9183\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8469 - val_loss: 0.9195\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8465 - val_loss: 0.9211\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8460 - val_loss: 0.9230\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.8456 - val_loss: 0.9248\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8452 - val_loss: 0.9260\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8447 - val_loss: 0.9267\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8443 - val_loss: 0.9269\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8438 - val_loss: 0.9266\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.8434 - val_loss: 0.9260\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.8429 - val_loss: 0.9254\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8425 - val_loss: 0.9251\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8420 - val_loss: 0.9251\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8416 - val_loss: 0.9254\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8411 - val_loss: 0.9258\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8406 - val_loss: 0.9262\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8402 - val_loss: 0.9265\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8397 - val_loss: 0.9266\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8392 - val_loss: 0.9265\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.8387 - val_loss: 0.9263\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8383 - val_loss: 0.9262\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.8378 - val_loss: 0.9261\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.8373 - val_loss: 0.9262\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8368 - val_loss: 0.9263\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.8363 - val_loss: 0.9264\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.8357 - val_loss: 0.9264\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.8352 - val_loss: 0.9264\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.8347 - val_loss: 0.9263\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.8342 - val_loss: 0.9262\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8337 - val_loss: 0.9262\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.8332 - val_loss: 0.9265\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.8328 - val_loss: 0.9267\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.8328 - val_loss: 0.9278\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.8334 - val_loss: 0.9276\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8322 - val_loss: 0.9275\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8310 - val_loss: 0.9284\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8319 - val_loss: 0.9273\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.8303 - val_loss: 0.9272\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8305 - val_loss: 0.9270\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8298 - val_loss: 0.9264\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8293 - val_loss: 0.9258\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8293 - val_loss: 0.9255\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8283 - val_loss: 0.9258\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8287 - val_loss: 0.9257\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8276 - val_loss: 0.9261\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8277 - val_loss: 0.9266\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8271 - val_loss: 0.9269\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8267 - val_loss: 0.9267\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8265 - val_loss: 0.9269\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8258 - val_loss: 0.9272\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8258 - val_loss: 0.9268\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8252 - val_loss: 0.9267\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.8249 - val_loss: 0.9269\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8246 - val_loss: 0.9269\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8240 - val_loss: 0.9269\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8239 - val_loss: 0.9272\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.8234 - val_loss: 0.9271\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8230 - val_loss: 0.9268\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.8228 - val_loss: 0.9270\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8223 - val_loss: 0.9270\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.8219 - val_loss: 0.9268\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8217 - val_loss: 0.9272\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8213 - val_loss: 0.9271\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8208 - val_loss: 0.9269\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8205 - val_loss: 0.9269\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8202 - val_loss: 0.9264\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8198 - val_loss: 0.9260\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.8194 - val_loss: 0.9258\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.8191 - val_loss: 0.9253\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8188 - val_loss: 0.9244\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8185 - val_loss: 0.9250\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8182 - val_loss: 0.9255\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8179 - val_loss: 0.9268\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8176 - val_loss: 0.9268\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8173 - val_loss: 0.9271\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.8170 - val_loss: 0.9265\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8167 - val_loss: 0.9264\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.8165 - val_loss: 0.9257\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.8163 - val_loss: 0.9262\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.8161 - val_loss: 0.9258\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.8157 - val_loss: 0.9264\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.8154 - val_loss: 0.9258\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.8149 - val_loss: 0.9260\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.8145 - val_loss: 0.9254\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8142 - val_loss: 0.9250\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.8139 - val_loss: 0.9249\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8137 - val_loss: 0.9245\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8135 - val_loss: 0.9251\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8135 - val_loss: 0.9240\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8138 - val_loss: 0.9258\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8148 - val_loss: 0.9233\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8149 - val_loss: 0.9255\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8139 - val_loss: 0.9229\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.8121 - val_loss: 0.9223\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8126 - val_loss: 0.9253\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.8136 - val_loss: 0.9218\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8120 - val_loss: 0.9227\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.8113 - val_loss: 0.9257\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.8122 - val_loss: 0.9215\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.8116 - val_loss: 0.9223\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.8106 - val_loss: 0.9240\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8110 - val_loss: 0.9212\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8109 - val_loss: 0.9232\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8102 - val_loss: 0.9230\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8100 - val_loss: 0.9204\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.8102 - val_loss: 0.9241\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8098 - val_loss: 0.9210\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8092 - val_loss: 0.9197\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.8092 - val_loss: 0.9251\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8093 - val_loss: 0.9208\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8089 - val_loss: 0.9233\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8084 - val_loss: 0.9235\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.8083 - val_loss: 0.9197\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8084 - val_loss: 0.9254\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8082 - val_loss: 0.9213\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8078 - val_loss: 0.9221\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.8075 - val_loss: 0.9234\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.8074 - val_loss: 0.9198\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8074 - val_loss: 0.9246\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8072 - val_loss: 0.9189\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.8070 - val_loss: 0.9229\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.8067 - val_loss: 0.9211\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.8064 - val_loss: 0.9210\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8062 - val_loss: 0.9223\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8061 - val_loss: 0.9188\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8060 - val_loss: 0.9247\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8060 - val_loss: 0.9172\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8060 - val_loss: 0.9268\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8062 - val_loss: 0.9148\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8064 - val_loss: 0.9296\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8067 - val_loss: 0.9142\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8063 - val_loss: 0.9260\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.8056 - val_loss: 0.9178\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8047 - val_loss: 0.9194\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.8044 - val_loss: 0.9239\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8046 - val_loss: 0.9140\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8049 - val_loss: 0.9266\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8049 - val_loss: 0.9160\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8043 - val_loss: 0.9218\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8037 - val_loss: 0.9197\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8034 - val_loss: 0.9158\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8035 - val_loss: 0.9251\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.8037 - val_loss: 0.9138\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8037 - val_loss: 0.9245\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8034 - val_loss: 0.9151\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8029 - val_loss: 0.9195\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8026 - val_loss: 0.9190\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.8024 - val_loss: 0.9149\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8024 - val_loss: 0.9236\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.8025 - val_loss: 0.9120\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.8026 - val_loss: 0.9247\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8026 - val_loss: 0.9108\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8024 - val_loss: 0.9242\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.8022 - val_loss: 0.9122\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.8017 - val_loss: 0.9199\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8014 - val_loss: 0.9146\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8011 - val_loss: 0.9165\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8009 - val_loss: 0.9181\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.8007 - val_loss: 0.9128\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.8007 - val_loss: 0.9219\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8008 - val_loss: 0.9082\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8012 - val_loss: 0.9300\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8021 - val_loss: 0.9027\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.8033 - val_loss: 0.9377\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.8046 - val_loss: 0.9037\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.8024 - val_loss: 0.9193\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7999 - val_loss: 0.9198\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7997 - val_loss: 0.9060\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8013 - val_loss: 0.9304\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8017 - val_loss: 0.9072\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7996 - val_loss: 0.9105\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7991 - val_loss: 0.9273\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.8003 - val_loss: 0.9066\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.8001 - val_loss: 0.9188\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.7989 - val_loss: 0.9161\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7985 - val_loss: 0.9073\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7992 - val_loss: 0.9264\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7994 - val_loss: 0.9097\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7984 - val_loss: 0.9115\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7980 - val_loss: 0.9223\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7985 - val_loss: 0.9074\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7985 - val_loss: 0.9197\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7979 - val_loss: 0.9135\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7975 - val_loss: 0.9099\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.7976 - val_loss: 0.9230\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7979 - val_loss: 0.9073\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7976 - val_loss: 0.9181\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.7972 - val_loss: 0.9138\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.7969 - val_loss: 0.9114\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7969 - val_loss: 0.9212\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7970 - val_loss: 0.9066\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7971 - val_loss: 0.9229\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7970 - val_loss: 0.9081\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7967 - val_loss: 0.9194\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.7963 - val_loss: 0.9120\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7961 - val_loss: 0.9153\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7959 - val_loss: 0.9156\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7958 - val_loss: 0.9112\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7957 - val_loss: 0.9206\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7958 - val_loss: 0.9076\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7959 - val_loss: 0.9284\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7965 - val_loss: 0.8988\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7977 - val_loss: 0.9467\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.8004 - val_loss: 0.8937\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.8014 - val_loss: 0.9444\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.8006 - val_loss: 0.9050\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7957 - val_loss: 0.9072\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7954 - val_loss: 0.9393\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7985 - val_loss: 0.8994\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7974 - val_loss: 0.9193\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7948 - val_loss: 0.9240\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7952 - val_loss: 0.9017\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7967 - val_loss: 0.9292\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.7958 - val_loss: 0.9140\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7942 - val_loss: 0.9049\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7952 - val_loss: 0.9312\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7959 - val_loss: 0.9082\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7943 - val_loss: 0.9101\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7941 - val_loss: 0.9292\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.7951 - val_loss: 0.9057\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7946 - val_loss: 0.9158\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7936 - val_loss: 0.9220\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7940 - val_loss: 0.9059\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7944 - val_loss: 0.9236\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7938 - val_loss: 0.9145\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7933 - val_loss: 0.9083\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7936 - val_loss: 0.9258\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7938 - val_loss: 0.9093\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7934 - val_loss: 0.9165\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7930 - val_loss: 0.9199\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7930 - val_loss: 0.9079\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7932 - val_loss: 0.9240\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.7931 - val_loss: 0.9111\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7928 - val_loss: 0.9156\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7925 - val_loss: 0.9200\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7926 - val_loss: 0.9090\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7927 - val_loss: 0.9242\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7927 - val_loss: 0.9093\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7925 - val_loss: 0.9216\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7923 - val_loss: 0.9136\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7920 - val_loss: 0.9156\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7919 - val_loss: 0.9192\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7919 - val_loss: 0.9116\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.7919 - val_loss: 0.9242\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.7920 - val_loss: 0.9070\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7922 - val_loss: 0.9312\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7926 - val_loss: 0.9017\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7932 - val_loss: 0.9429\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7945 - val_loss: 0.8949\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7956 - val_loss: 0.9519\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.7967 - val_loss: 0.8969\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7947 - val_loss: 0.9304\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7923 - val_loss: 0.9167\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7910 - val_loss: 0.9060\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7919 - val_loss: 0.9377\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7933 - val_loss: 0.9010\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7928 - val_loss: 0.9269\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7914 - val_loss: 0.9179\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7907 - val_loss: 0.9074\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7913 - val_loss: 0.9321\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7920 - val_loss: 0.9046\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7917 - val_loss: 0.9243\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7908 - val_loss: 0.9181\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7904 - val_loss: 0.9080\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7908 - val_loss: 0.9292\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7912 - val_loss: 0.9068\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7910 - val_loss: 0.9245\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7905 - val_loss: 0.9151\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.7901 - val_loss: 0.9117\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7901 - val_loss: 0.9263\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7904 - val_loss: 0.9076\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7905 - val_loss: 0.9276\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7904 - val_loss: 0.9091\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7901 - val_loss: 0.9215\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.7898 - val_loss: 0.9168\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7896 - val_loss: 0.9140\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7896 - val_loss: 0.9234\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7897 - val_loss: 0.9091\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7898 - val_loss: 0.9292\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7900 - val_loss: 0.9053\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7903 - val_loss: 0.9358\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.7908 - val_loss: 0.9009\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7912 - val_loss: 0.9435\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7920 - val_loss: 0.8977\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7923 - val_loss: 0.9453\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.7923 - val_loss: 0.9010\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7911 - val_loss: 0.9311\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7898 - val_loss: 0.9134\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7889 - val_loss: 0.9130\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7889 - val_loss: 0.9297\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7895 - val_loss: 0.9036\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7901 - val_loss: 0.9365\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7903 - val_loss: 0.9043\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7898 - val_loss: 0.9277\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7890 - val_loss: 0.9140\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7885 - val_loss: 0.9145\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7884 - val_loss: 0.9261\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7887 - val_loss: 0.9065\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7891 - val_loss: 0.9326\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7893 - val_loss: 0.9052\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.7892 - val_loss: 0.9301\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7889 - val_loss: 0.9089\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7885 - val_loss: 0.9231\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.7881 - val_loss: 0.9158\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7879 - val_loss: 0.9151\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7879 - val_loss: 0.9225\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7879 - val_loss: 0.9096\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.7881 - val_loss: 0.9293\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7884 - val_loss: 0.9046\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.7888 - val_loss: 0.9385\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7895 - val_loss: 0.8985\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7904 - val_loss: 0.9499\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7917 - val_loss: 0.8949\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7920 - val_loss: 0.9499\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7918 - val_loss: 0.9002\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7896 - val_loss: 0.9267\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7878 - val_loss: 0.9202\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7873 - val_loss: 0.9055\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7881 - val_loss: 0.9376\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7892 - val_loss: 0.9015\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.7890 - val_loss: 0.9313\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7881 - val_loss: 0.9130\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7871 - val_loss: 0.9121\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7871 - val_loss: 0.9289\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7877 - val_loss: 0.9040\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7881 - val_loss: 0.9315\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7879 - val_loss: 0.9086\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7872 - val_loss: 0.9187\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7867 - val_loss: 0.9207\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7867 - val_loss: 0.9082\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7871 - val_loss: 0.9294\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7873 - val_loss: 0.9059\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.7873 - val_loss: 0.9273\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7870 - val_loss: 0.9096\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7866 - val_loss: 0.9200\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7863 - val_loss: 0.9173\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7862 - val_loss: 0.9125\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.7863 - val_loss: 0.9237\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7864 - val_loss: 0.9081\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7866 - val_loss: 0.9291\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7868 - val_loss: 0.9044\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7870 - val_loss: 0.9355\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7875 - val_loss: 0.8998\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7881 - val_loss: 0.9445\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7891 - val_loss: 0.8951\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7897 - val_loss: 0.9510\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7905 - val_loss: 0.8950\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7896 - val_loss: 0.9399\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7882 - val_loss: 0.9055\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7863 - val_loss: 0.9164\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7855 - val_loss: 0.9271\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7861 - val_loss: 0.9015\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7871 - val_loss: 0.9379\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7876 - val_loss: 0.9022\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.7869 - val_loss: 0.9263\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7858 - val_loss: 0.9150\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7853 - val_loss: 0.9091\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7855 - val_loss: 0.9292\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7860 - val_loss: 0.9034\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7863 - val_loss: 0.9295\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7860 - val_loss: 0.9071\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7855 - val_loss: 0.9194\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7850 - val_loss: 0.9180\n",
      "Epoch 482/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7849 - val_loss: 0.9093\n",
      "Epoch 483/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7851 - val_loss: 0.9260\n",
      "Epoch 484/1500\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.7854 - val_loss: 0.9045\n",
      "Epoch 485/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7856 - val_loss: 0.9303\n",
      "Epoch 486/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7857 - val_loss: 0.9037\n",
      "Epoch 487/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7857 - val_loss: 0.9301\n",
      "Epoch 488/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7856 - val_loss: 0.9041\n",
      "Epoch 489/1500\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.7854 - val_loss: 0.9283\n",
      "Epoch 490/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7853 - val_loss: 0.9056\n",
      "Epoch 491/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7851 - val_loss: 0.9264\n",
      "Epoch 492/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7849 - val_loss: 0.9067\n",
      "Epoch 493/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7848 - val_loss: 0.9256\n",
      "Epoch 494/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7847 - val_loss: 0.9064\n",
      "Epoch 495/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7847 - val_loss: 0.9282\n",
      "Epoch 496/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7849 - val_loss: 0.9036\n",
      "Epoch 497/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7851 - val_loss: 0.9352\n",
      "Epoch 498/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7858 - val_loss: 0.8963\n",
      "Epoch 499/1500\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.7869 - val_loss: 0.9529\n",
      "Epoch 500/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7892 - val_loss: 0.8885\n",
      "Epoch 501/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7915 - val_loss: 0.9726\n",
      "Epoch 502/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7948 - val_loss: 0.8875\n",
      "Epoch 503/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7923 - val_loss: 0.9461\n",
      "Epoch 504/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7879 - val_loss: 0.9109\n",
      "Epoch 505/1500\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.7839 - val_loss: 0.9012\n",
      "Epoch 506/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7854 - val_loss: 0.9493\n",
      "Epoch 507/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7888 - val_loss: 0.8944\n",
      "Epoch 508/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7871 - val_loss: 0.9223\n",
      "Epoch 509/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7841 - val_loss: 0.9261\n",
      "Epoch 510/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7843 - val_loss: 0.8977\n",
      "Epoch 511/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7863 - val_loss: 0.9354\n",
      "Epoch 512/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7859 - val_loss: 0.9079\n",
      "Epoch 513/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7837 - val_loss: 0.9051\n",
      "Epoch 514/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7842 - val_loss: 0.9359\n",
      "Epoch 515/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7856 - val_loss: 0.9019\n",
      "Epoch 516/1500\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.7845 - val_loss: 0.9140\n",
      "Epoch 517/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7834 - val_loss: 0.9252\n",
      "Epoch 518/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7840 - val_loss: 0.9015\n",
      "Epoch 519/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7846 - val_loss: 0.9244\n",
      "Epoch 520/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7839 - val_loss: 0.9126\n",
      "Epoch 521/1500\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.7831 - val_loss: 0.9056\n",
      "Epoch 522/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7836 - val_loss: 0.9283\n",
      "Epoch 523/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7841 - val_loss: 0.9045\n",
      "Epoch 524/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7835 - val_loss: 0.9156\n",
      "Epoch 525/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7829 - val_loss: 0.9193\n",
      "Epoch 526/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7830 - val_loss: 0.9049\n",
      "Epoch 527/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7834 - val_loss: 0.9245\n",
      "Epoch 528/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7834 - val_loss: 0.9062\n",
      "Epoch 529/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7830 - val_loss: 0.9153\n",
      "Epoch 530/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7826 - val_loss: 0.9180\n",
      "Epoch 531/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7826 - val_loss: 0.9066\n",
      "Epoch 532/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7828 - val_loss: 0.9243\n",
      "Epoch 533/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7830 - val_loss: 0.9047\n",
      "Epoch 534/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7829 - val_loss: 0.9234\n",
      "Epoch 535/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7827 - val_loss: 0.9083\n",
      "Epoch 536/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7824 - val_loss: 0.9175\n",
      "Epoch 537/1500\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.7822 - val_loss: 0.9139\n",
      "Epoch 538/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7821 - val_loss: 0.9121\n",
      "Epoch 539/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7821 - val_loss: 0.9190\n",
      "Epoch 540/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7821 - val_loss: 0.9077\n",
      "Epoch 541/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7822 - val_loss: 0.9264\n",
      "Epoch 542/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7825 - val_loss: 0.9011\n",
      "Epoch 543/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7831 - val_loss: 0.9400\n",
      "Epoch 544/1500\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.7844 - val_loss: 0.8915\n",
      "Epoch 545/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7866 - val_loss: 0.9704\n",
      "Epoch 546/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7915 - val_loss: 0.8827\n",
      "Epoch 547/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7950 - val_loss: 0.9952\n",
      "Epoch 548/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7999 - val_loss: 0.8870\n",
      "Epoch 549/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7901 - val_loss: 0.9210\n",
      "Epoch 550/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7821 - val_loss: 0.9380\n",
      "Epoch 551/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7843 - val_loss: 0.8901\n",
      "Epoch 552/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.7885 - val_loss: 0.9425\n",
      "Epoch 553/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.7856 - val_loss: 0.9128\n",
      "Epoch 554/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7817 - val_loss: 0.8921\n",
      "Epoch 555/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7856 - val_loss: 0.9456\n",
      "Epoch 556/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.7861 - val_loss: 0.9096\n",
      "Epoch 557/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7817 - val_loss: 0.8946\n",
      "Epoch 558/1500\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.7842 - val_loss: 0.9399\n",
      "Epoch 559/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7854 - val_loss: 0.9079\n",
      "Epoch 560/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7817 - val_loss: 0.8980\n",
      "Epoch 561/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7835 - val_loss: 0.9380\n",
      "Epoch 562/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7846 - val_loss: 0.9075\n",
      "Epoch 563/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7815 - val_loss: 0.8977\n",
      "Epoch 564/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7830 - val_loss: 0.9354\n",
      "Epoch 565/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7840 - val_loss: 0.9076\n",
      "Epoch 566/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7813 - val_loss: 0.8990\n",
      "Epoch 567/1500\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.7825 - val_loss: 0.9328\n",
      "Epoch 568/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7835 - val_loss: 0.9057\n",
      "Epoch 569/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7812 - val_loss: 0.9011\n",
      "Epoch 570/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7818 - val_loss: 0.9316\n",
      "Epoch 571/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7830 - val_loss: 0.9031\n",
      "Epoch 572/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7813 - val_loss: 0.9047\n",
      "Epoch 573/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7810 - val_loss: 0.9281\n",
      "Epoch 574/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7823 - val_loss: 0.9003\n",
      "Epoch 575/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7815 - val_loss: 0.9107\n",
      "Epoch 576/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7805 - val_loss: 0.9216\n",
      "Epoch 577/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7812 - val_loss: 0.8998\n",
      "Epoch 578/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7815 - val_loss: 0.9191\n",
      "Epoch 579/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7808 - val_loss: 0.9120\n",
      "Epoch 580/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.7803 - val_loss: 0.9032\n",
      "Epoch 581/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7807 - val_loss: 0.9248\n",
      "Epoch 582/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7810 - val_loss: 0.9039\n",
      "Epoch 583/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7805 - val_loss: 0.9130\n",
      "Epoch 584/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7800 - val_loss: 0.9163\n",
      "Epoch 585/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7801 - val_loss: 0.9038\n",
      "Epoch 586/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7804 - val_loss: 0.9236\n",
      "Epoch 587/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7805 - val_loss: 0.9041\n",
      "Epoch 588/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7802 - val_loss: 0.9171\n",
      "Epoch 589/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7798 - val_loss: 0.9117\n",
      "Epoch 590/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7796 - val_loss: 0.9102\n",
      "Epoch 591/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7796 - val_loss: 0.9194\n",
      "Epoch 592/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7797 - val_loss: 0.9046\n",
      "Epoch 593/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7799 - val_loss: 0.9260\n",
      "Epoch 594/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7801 - val_loss: 0.9008\n",
      "Epoch 595/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7804 - val_loss: 0.9346\n",
      "Epoch 596/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7811 - val_loss: 0.8951\n",
      "Epoch 597/1500\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.7818 - val_loss: 0.9479\n",
      "Epoch 598/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7834 - val_loss: 0.8901\n",
      "Epoch 599/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7843 - val_loss: 0.9612\n",
      "Epoch 600/1500\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.7864 - val_loss: 0.8878\n",
      "Epoch 601/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7853 - val_loss: 0.9486\n",
      "Epoch 602/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7838 - val_loss: 0.8984\n",
      "Epoch 603/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7804 - val_loss: 0.9116\n",
      "Epoch 604/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7790 - val_loss: 0.9291\n",
      "Epoch 605/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7802 - val_loss: 0.8933\n",
      "Epoch 606/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7818 - val_loss: 0.9373\n",
      "Epoch 607/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7816 - val_loss: 0.8999\n",
      "Epoch 608/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7797 - val_loss: 0.9107\n",
      "Epoch 609/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7788 - val_loss: 0.9266\n",
      "Epoch 610/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7797 - val_loss: 0.8962\n",
      "Epoch 611/1500\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.7806 - val_loss: 0.9305\n",
      "Epoch 612/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7803 - val_loss: 0.9029\n",
      "Epoch 613/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.7790 - val_loss: 0.9100\n",
      "Epoch 614/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7785 - val_loss: 0.9238\n",
      "Epoch 615/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7791 - val_loss: 0.8974\n",
      "Epoch 616/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7798 - val_loss: 0.9336\n",
      "Epoch 617/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7802 - val_loss: 0.8976\n",
      "Epoch 618/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7797 - val_loss: 0.9250\n",
      "Epoch 619/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7789 - val_loss: 0.9069\n",
      "Epoch 620/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7782 - val_loss: 0.9107\n",
      "Epoch 621/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7779 - val_loss: 0.9195\n",
      "Epoch 622/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7781 - val_loss: 0.9004\n",
      "Epoch 623/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7787 - val_loss: 0.9353\n",
      "Epoch 624/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7797 - val_loss: 0.8918\n",
      "Epoch 625/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7813 - val_loss: 0.9654\n",
      "Epoch 626/1500\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.7859 - val_loss: 0.8809\n",
      "Epoch 627/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7913 - val_loss: 1.0291\n",
      "Epoch 628/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8062 - val_loss: 0.8824\n",
      "Epoch 629/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7976 - val_loss: 0.9592\n",
      "Epoch 630/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7860 - val_loss: 0.9167\n",
      "Epoch 631/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7782 - val_loss: 0.8820\n",
      "Epoch 632/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7883 - val_loss: 0.9609\n",
      "Epoch 633/1500\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.7876 - val_loss: 0.9144\n",
      "Epoch 634/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7784 - val_loss: 0.8830\n",
      "Epoch 635/1500\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.7878 - val_loss: 0.9431\n",
      "Epoch 636/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7840 - val_loss: 0.9244\n",
      "Epoch 637/1500\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.7799 - val_loss: 0.8848\n",
      "Epoch 638/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7870 - val_loss: 0.9212\n",
      "Epoch 639/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7795 - val_loss: 0.9366\n",
      "Epoch 640/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7825 - val_loss: 0.8899\n",
      "Epoch 641/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7822 - val_loss: 0.9005\n",
      "Epoch 642/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7789 - val_loss: 0.9383\n",
      "Epoch 643/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7827 - val_loss: 0.9038\n",
      "Epoch 644/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7785 - val_loss: 0.8921\n",
      "Epoch 645/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7811 - val_loss: 0.9259\n",
      "Epoch 646/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7801 - val_loss: 0.9182\n",
      "Epoch 647/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7788 - val_loss: 0.8921\n",
      "Epoch 648/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7809 - val_loss: 0.9130\n",
      "Epoch 649/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7781 - val_loss: 0.9248\n",
      "Epoch 650/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7795 - val_loss: 0.8961\n",
      "Epoch 651/1500\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.7791 - val_loss: 0.9049\n",
      "Epoch 652/1500\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.7778 - val_loss: 0.9267\n",
      "Epoch 653/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7792 - val_loss: 0.9024\n",
      "Epoch 654/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7778 - val_loss: 0.9004\n",
      "Epoch 655/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7779 - val_loss: 0.9239\n",
      "Epoch 656/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7786 - val_loss: 0.9063\n",
      "Epoch 657/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7773 - val_loss: 0.8996\n",
      "Epoch 658/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7778 - val_loss: 0.9214\n",
      "Epoch 659/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7780 - val_loss: 0.9066\n",
      "Epoch 660/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7770 - val_loss: 0.9002\n",
      "Epoch 661/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7775 - val_loss: 0.9216\n",
      "Epoch 662/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7777 - val_loss: 0.9051\n",
      "Epoch 663/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7768 - val_loss: 0.9027\n",
      "Epoch 664/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7769 - val_loss: 0.9218\n",
      "Epoch 665/1500\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.7773 - val_loss: 0.9028\n",
      "Epoch 666/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7768 - val_loss: 0.9091\n",
      "Epoch 667/1500\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.7764 - val_loss: 0.9183\n",
      "Epoch 668/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7767 - val_loss: 0.9007\n",
      "Epoch 669/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7768 - val_loss: 0.9188\n",
      "Epoch 670/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7764 - val_loss: 0.9090\n",
      "Epoch 671/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7760 - val_loss: 0.9062\n",
      "Epoch 672/1500\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.7761 - val_loss: 0.9207\n",
      "Epoch 673/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7763 - val_loss: 0.9014\n",
      "Epoch 674/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7764 - val_loss: 0.9245\n",
      "Epoch 675/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7764 - val_loss: 0.9026\n",
      "Epoch 676/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7761 - val_loss: 0.9212\n",
      "Epoch 677/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7759 - val_loss: 0.9047\n",
      "Epoch 678/1500\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.7757 - val_loss: 0.9202\n",
      "Epoch 679/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7756 - val_loss: 0.9045\n",
      "Epoch 680/1500\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.7756 - val_loss: 0.9265\n",
      "Epoch 681/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7759 - val_loss: 0.8968\n",
      "Epoch 682/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7768 - val_loss: 0.9532\n",
      "Epoch 683/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7799 - val_loss: 0.8821\n",
      "Epoch 684/1500\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.7852 - val_loss: 1.0258\n",
      "Epoch 685/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.8008 - val_loss: 0.8784\n",
      "Epoch 686/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8046 - val_loss: 1.0459\n",
      "Epoch 687/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8098 - val_loss: 0.8955\n",
      "Epoch 688/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7783 - val_loss: 0.8759\n",
      "Epoch 689/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7867 - val_loss: 0.9996\n",
      "Epoch 690/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7993 - val_loss: 0.9098\n",
      "Epoch 691/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7761 - val_loss: 0.8807\n",
      "Epoch 692/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7953 - val_loss: 0.9556\n",
      "Epoch 693/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7856 - val_loss: 0.9456\n",
      "Epoch 694/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.7836 - val_loss: 0.8781\n",
      "Epoch 695/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7888 - val_loss: 0.8955\n",
      "Epoch 696/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7779 - val_loss: 0.9601\n",
      "Epoch 697/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7874 - val_loss: 0.9139\n",
      "Epoch 698/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7773 - val_loss: 0.8826\n",
      "Epoch 699/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7863 - val_loss: 0.9063\n",
      "Epoch 700/1500\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.7772 - val_loss: 0.9434\n",
      "Epoch 701/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7839 - val_loss: 0.9035\n",
      "Epoch 702/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7772 - val_loss: 0.8870\n",
      "Epoch 703/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7827 - val_loss: 0.9129\n",
      "Epoch 704/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7774 - val_loss: 0.9329\n",
      "Epoch 705/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7811 - val_loss: 0.8988\n",
      "Epoch 706/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7772 - val_loss: 0.8898\n",
      "Epoch 707/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7801 - val_loss: 0.9169\n",
      "Epoch 708/1500\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.7774 - val_loss: 0.9264\n",
      "Epoch 709/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7790 - val_loss: 0.8970\n",
      "Epoch 710/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7773 - val_loss: 0.8942\n",
      "Epoch 711/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7780 - val_loss: 0.9199\n",
      "Epoch 712/1500\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.7774 - val_loss: 0.9189\n",
      "Epoch 713/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7771 - val_loss: 0.8953\n",
      "Epoch 714/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7774 - val_loss: 0.8998\n",
      "Epoch 715/1500\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.7763 - val_loss: 0.9213\n",
      "Epoch 716/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.7772 - val_loss: 0.9100\n",
      "Epoch 717/1500\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.7758 - val_loss: 0.8957\n",
      "Epoch 718/1500\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.7770 - val_loss: 0.9095\n",
      "Epoch 719/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7756 - val_loss: 0.9183\n",
      "Epoch 720/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7764 - val_loss: 0.8997\n",
      "Epoch 721/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.7757 - val_loss: 0.9005\n",
      "Epoch 722/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7756 - val_loss: 0.9181\n",
      "Epoch 723/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7758 - val_loss: 0.9086\n",
      "Epoch 724/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7751 - val_loss: 0.8969\n",
      "Epoch 725/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7757 - val_loss: 0.9114\n",
      "Epoch 726/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7750 - val_loss: 0.9141\n",
      "Epoch 727/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7750 - val_loss: 0.9002\n",
      "Epoch 728/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7751 - val_loss: 0.9081\n",
      "Epoch 729/1500\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.7745 - val_loss: 0.9157\n",
      "Epoch 730/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7748 - val_loss: 0.9022\n",
      "Epoch 731/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7746 - val_loss: 0.9069\n",
      "Epoch 732/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7743 - val_loss: 0.9166\n",
      "Epoch 733/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7745 - val_loss: 0.9037\n",
      "Epoch 734/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7742 - val_loss: 0.9065\n",
      "Epoch 735/1500\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.7740 - val_loss: 0.9161\n",
      "Epoch 736/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7741 - val_loss: 0.9043\n",
      "Epoch 737/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7739 - val_loss: 0.9112\n",
      "Epoch 738/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7737 - val_loss: 0.9144\n",
      "Epoch 739/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7736 - val_loss: 0.9045\n",
      "Epoch 740/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7737 - val_loss: 0.9169\n",
      "Epoch 741/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7735 - val_loss: 0.9107\n",
      "Epoch 742/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.7733 - val_loss: 0.9092\n",
      "Epoch 743/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7733 - val_loss: 0.9176\n",
      "Epoch 744/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7733 - val_loss: 0.9060\n",
      "Epoch 745/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7732 - val_loss: 0.9177\n",
      "Epoch 746/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7731 - val_loss: 0.9098\n",
      "Epoch 747/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7729 - val_loss: 0.9125\n",
      "Epoch 748/1500\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.7728 - val_loss: 0.9157\n",
      "Epoch 749/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7727 - val_loss: 0.9085\n",
      "Epoch 750/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7727 - val_loss: 0.9217\n",
      "Epoch 751/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7727 - val_loss: 0.9042\n",
      "Epoch 752/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7728 - val_loss: 0.9295\n",
      "Epoch 753/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7732 - val_loss: 0.8971\n",
      "Epoch 754/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7739 - val_loss: 0.9514\n",
      "Epoch 755/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7761 - val_loss: 0.8824\n",
      "Epoch 756/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7802 - val_loss: 1.0171\n",
      "Epoch 757/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7933 - val_loss: 0.8739\n",
      "Epoch 758/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8035 - val_loss: 1.1070\n",
      "Epoch 759/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8275 - val_loss: 0.8854\n",
      "Epoch 760/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7845 - val_loss: 0.8843\n",
      "Epoch 761/1500\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.7767 - val_loss: 1.0005\n",
      "Epoch 762/1500\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.7962 - val_loss: 0.8927\n",
      "Epoch 763/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7749 - val_loss: 0.8800\n",
      "Epoch 764/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7855 - val_loss: 0.9671\n",
      "Epoch 765/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7845 - val_loss: 0.9342\n",
      "Epoch 766/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7773 - val_loss: 0.8743\n",
      "Epoch 767/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7866 - val_loss: 0.9008\n",
      "Epoch 768/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7743 - val_loss: 0.9565\n",
      "Epoch 769/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7837 - val_loss: 0.9042\n",
      "Epoch 770/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7745 - val_loss: 0.8814\n",
      "Epoch 771/1500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7820 - val_loss: 0.9132\n",
      "Epoch 772/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7752 - val_loss: 0.9370\n",
      "Epoch 773/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7798 - val_loss: 0.8947\n",
      "Epoch 774/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7752 - val_loss: 0.8859\n",
      "Epoch 775/1500\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.7785 - val_loss: 0.9189\n",
      "Epoch 776/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7756 - val_loss: 0.9264\n",
      "Epoch 777/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7771 - val_loss: 0.8914\n",
      "Epoch 778/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7755 - val_loss: 0.8906\n",
      "Epoch 779/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7759 - val_loss: 0.9234\n",
      "Epoch 780/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7756 - val_loss: 0.9194\n",
      "Epoch 781/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7750 - val_loss: 0.8899\n",
      "Epoch 782/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7756 - val_loss: 0.8969\n",
      "Epoch 783/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7741 - val_loss: 0.9247\n",
      "Epoch 784/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7754 - val_loss: 0.9109\n",
      "Epoch 785/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7735 - val_loss: 0.8925\n",
      "Epoch 786/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7751 - val_loss: 0.9077\n",
      "Epoch 787/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7732 - val_loss: 0.9210\n",
      "Epoch 788/1500\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.7744 - val_loss: 0.8997\n",
      "Epoch 789/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7733 - val_loss: 0.8981\n",
      "Epoch 790/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7736 - val_loss: 0.9197\n",
      "Epoch 791/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7735 - val_loss: 0.9116\n",
      "Epoch 792/1500\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.7728 - val_loss: 0.8944\n",
      "Epoch 793/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7735 - val_loss: 0.9084\n",
      "Epoch 794/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7725 - val_loss: 0.9189\n",
      "Epoch 795/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7730 - val_loss: 0.9007\n",
      "Epoch 796/1500\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.7726 - val_loss: 0.9026\n",
      "Epoch 797/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7723 - val_loss: 0.9176\n",
      "Epoch 798/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7727 - val_loss: 0.9043\n",
      "Epoch 799/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7720 - val_loss: 0.9011\n",
      "Epoch 800/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7722 - val_loss: 0.9171\n",
      "Epoch 801/1500\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.7721 - val_loss: 0.9083\n",
      "Epoch 802/1500\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.7717 - val_loss: 0.9002\n",
      "Epoch 803/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7719 - val_loss: 0.9166\n",
      "Epoch 804/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7717 - val_loss: 0.9096\n",
      "Epoch 805/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7714 - val_loss: 0.9030\n",
      "Epoch 806/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7715 - val_loss: 0.9171\n",
      "Epoch 807/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7714 - val_loss: 0.9082\n",
      "Epoch 808/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7711 - val_loss: 0.9056\n",
      "Epoch 809/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7711 - val_loss: 0.9182\n",
      "Epoch 810/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7711 - val_loss: 0.9055\n",
      "Epoch 811/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7708 - val_loss: 0.9109\n",
      "Epoch 812/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7706 - val_loss: 0.9160\n",
      "Epoch 813/1500\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.7706 - val_loss: 0.9056\n",
      "Epoch 814/1500\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.7706 - val_loss: 0.9190\n",
      "Epoch 815/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7705 - val_loss: 0.9077\n",
      "Epoch 816/1500\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.7703 - val_loss: 0.9144\n",
      "Epoch 817/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7701 - val_loss: 0.9151\n",
      "Epoch 818/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7699 - val_loss: 0.9100\n",
      "Epoch 819/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7699 - val_loss: 0.9203\n",
      "Epoch 820/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7699 - val_loss: 0.9054\n",
      "Epoch 821/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7700 - val_loss: 0.9296\n",
      "Epoch 822/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7703 - val_loss: 0.8984\n",
      "Epoch 823/1500\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.7710 - val_loss: 0.9533\n",
      "Epoch 824/1500\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.7734 - val_loss: 0.8786\n",
      "Epoch 825/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7795 - val_loss: 1.0555\n",
      "Epoch 826/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.8020 - val_loss: 0.8771\n",
      "Epoch 827/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.8289 - val_loss: 1.2725\n",
      "Epoch 828/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.8950 - val_loss: 0.8954\n",
      "Epoch 829/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7808 - val_loss: 0.8691\n",
      "Epoch 830/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8171 - val_loss: 1.0965\n",
      "Epoch 831/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8367 - val_loss: 0.9901\n",
      "Epoch 832/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7902 - val_loss: 0.8805\n",
      "Epoch 833/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.8257 - val_loss: 0.8790\n",
      "Epoch 834/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7805 - val_loss: 1.0003\n",
      "Epoch 835/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8038 - val_loss: 0.9772\n",
      "Epoch 836/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7945 - val_loss: 0.8824\n",
      "Epoch 837/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7818 - val_loss: 0.8748\n",
      "Epoch 838/1500\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.8015 - val_loss: 0.8964\n",
      "Epoch 839/1500\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.7765 - val_loss: 0.9618\n",
      "Epoch 840/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7936 - val_loss: 0.9460\n",
      "Epoch 841/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7868 - val_loss: 0.8940\n",
      "Epoch 842/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7789 - val_loss: 0.8836\n",
      "Epoch 843/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7916 - val_loss: 0.8897\n",
      "Epoch 844/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7794 - val_loss: 0.9249\n",
      "Epoch 845/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7825 - val_loss: 0.9385\n",
      "Epoch 846/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7866 - val_loss: 0.9082\n",
      "Epoch 847/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7779 - val_loss: 0.8879\n",
      "Epoch 848/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7828 - val_loss: 0.8878\n",
      "Epoch 849/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7826 - val_loss: 0.9038\n",
      "Epoch 850/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7774 - val_loss: 0.9254\n",
      "Epoch 851/1500\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.7823 - val_loss: 0.9183\n",
      "Epoch 852/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7798 - val_loss: 0.8967\n",
      "Epoch 853/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7773 - val_loss: 0.8886\n",
      "Epoch 854/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7810 - val_loss: 0.8939\n",
      "Epoch 855/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7776 - val_loss: 0.9111\n",
      "Epoch 856/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7777 - val_loss: 0.9177\n",
      "Epoch 857/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7793 - val_loss: 0.9035\n",
      "Epoch 858/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7763 - val_loss: 0.8917\n",
      "Epoch 859/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7776 - val_loss: 0.8926\n",
      "Epoch 860/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7776 - val_loss: 0.9051\n",
      "Epoch 861/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7757 - val_loss: 0.9166\n",
      "Epoch 862/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7773 - val_loss: 0.9094\n",
      "Epoch 863/1500\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.7760 - val_loss: 0.8951\n",
      "Epoch 864/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7756 - val_loss: 0.8916\n",
      "Epoch 865/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7764 - val_loss: 0.9001\n",
      "Epoch 866/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7749 - val_loss: 0.9127\n",
      "Epoch 867/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7756 - val_loss: 0.9118\n",
      "Epoch 868/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7752 - val_loss: 0.9000\n",
      "Epoch 869/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7745 - val_loss: 0.8943\n",
      "Epoch 870/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7752 - val_loss: 0.8993\n",
      "Epoch 871/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7742 - val_loss: 0.9088\n",
      "Epoch 872/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7745 - val_loss: 0.9083\n",
      "Epoch 873/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7742 - val_loss: 0.8996\n",
      "Epoch 874/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7738 - val_loss: 0.8968\n",
      "Epoch 875/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7741 - val_loss: 0.9032\n",
      "Epoch 876/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.7734 - val_loss: 0.9102\n",
      "Epoch 877/1500\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.7736 - val_loss: 0.9065\n",
      "Epoch 878/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7732 - val_loss: 0.8988\n",
      "Epoch 879/1500\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.7732 - val_loss: 0.8989\n",
      "Epoch 880/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7731 - val_loss: 0.9068\n",
      "Epoch 881/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7728 - val_loss: 0.9111\n",
      "Epoch 882/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7729 - val_loss: 0.9050\n",
      "Epoch 883/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7725 - val_loss: 0.8994\n",
      "Epoch 884/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7726 - val_loss: 0.9023\n",
      "Epoch 885/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7723 - val_loss: 0.9090\n",
      "Epoch 886/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7723 - val_loss: 0.9081\n",
      "Epoch 887/1500\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.7721 - val_loss: 0.9022\n",
      "Epoch 888/1500\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.7720 - val_loss: 0.9015\n",
      "Epoch 889/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7719 - val_loss: 0.9067\n",
      "Epoch 890/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7718 - val_loss: 0.9084\n",
      "Epoch 891/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7717 - val_loss: 0.9039\n",
      "Epoch 892/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7715 - val_loss: 0.9021\n",
      "Epoch 893/1500\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.7715 - val_loss: 0.9062\n",
      "Epoch 894/1500\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.7713 - val_loss: 0.9088\n",
      "Epoch 895/1500\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.7713 - val_loss: 0.9051\n",
      "Epoch 896/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7711 - val_loss: 0.9028\n",
      "Epoch 897/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7711 - val_loss: 0.9067\n",
      "Epoch 898/1500\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.7709 - val_loss: 0.9095\n",
      "Epoch 899/1500\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.7709 - val_loss: 0.9062\n",
      "Epoch 900/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7707 - val_loss: 0.9038\n",
      "Epoch 901/1500\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.7706 - val_loss: 0.9072\n",
      "Epoch 902/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7705 - val_loss: 0.9099\n",
      "Epoch 903/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7704 - val_loss: 0.9072\n",
      "Epoch 904/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7703 - val_loss: 0.9062\n",
      "Epoch 905/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7702 - val_loss: 0.9091\n",
      "Epoch 906/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7701 - val_loss: 0.9096\n",
      "Epoch 907/1500\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.7700 - val_loss: 0.9066\n",
      "Epoch 908/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7699 - val_loss: 0.9074\n",
      "Epoch 909/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7698 - val_loss: 0.9108\n",
      "Epoch 910/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7697 - val_loss: 0.9100\n",
      "Epoch 911/1500\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.7696 - val_loss: 0.9074\n",
      "Epoch 912/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7695 - val_loss: 0.9090\n",
      "Epoch 913/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7694 - val_loss: 0.9108\n",
      "Epoch 914/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7694 - val_loss: 0.9089\n",
      "Epoch 915/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7693 - val_loss: 0.9086\n",
      "Epoch 916/1500\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.7692 - val_loss: 0.9109\n",
      "Epoch 917/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7691 - val_loss: 0.9103\n",
      "Epoch 918/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7690 - val_loss: 0.9090\n",
      "Epoch 919/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7689 - val_loss: 0.9112\n",
      "Epoch 920/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7688 - val_loss: 0.9120\n",
      "Epoch 921/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7688 - val_loss: 0.9102\n",
      "Epoch 922/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7687 - val_loss: 0.9110\n",
      "Epoch 923/1500\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.7686 - val_loss: 0.9121\n",
      "Epoch 924/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7685 - val_loss: 0.9108\n",
      "Epoch 925/1500\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.7684 - val_loss: 0.9110\n",
      "Epoch 926/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7683 - val_loss: 0.9127\n",
      "Epoch 927/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7683 - val_loss: 0.9113\n",
      "Epoch 928/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7682 - val_loss: 0.9115\n",
      "Epoch 929/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7681 - val_loss: 0.9135\n",
      "Epoch 930/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7680 - val_loss: 0.9121\n",
      "Epoch 931/1500\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.7679 - val_loss: 0.9120\n",
      "Epoch 932/1500\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.7678 - val_loss: 0.9140\n",
      "Epoch 933/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7677 - val_loss: 0.9127\n",
      "Epoch 934/1500\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.7676 - val_loss: 0.9125\n",
      "Epoch 935/1500\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.7675 - val_loss: 0.9143\n",
      "Epoch 936/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7675 - val_loss: 0.9125\n",
      "Epoch 937/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7674 - val_loss: 0.9133\n",
      "Epoch 938/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7673 - val_loss: 0.9147\n",
      "Epoch 939/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7672 - val_loss: 0.9128\n",
      "Epoch 940/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7670 - val_loss: 0.9144\n",
      "Epoch 941/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7669 - val_loss: 0.9148\n",
      "Epoch 942/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7668 - val_loss: 0.9132\n",
      "Epoch 943/1500\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.7667 - val_loss: 0.9164\n",
      "Epoch 944/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7666 - val_loss: 0.9137\n",
      "Epoch 945/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7665 - val_loss: 0.9154\n",
      "Epoch 946/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7664 - val_loss: 0.9160\n",
      "Epoch 947/1500\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.7663 - val_loss: 0.9134\n",
      "Epoch 948/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7662 - val_loss: 0.9201\n",
      "Epoch 949/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7661 - val_loss: 0.9070\n",
      "Epoch 950/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7662 - val_loss: 0.9296\n",
      "Epoch 951/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7665 - val_loss: 0.8946\n",
      "Epoch 952/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7674 - val_loss: 0.9570\n",
      "Epoch 953/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7699 - val_loss: 0.8760\n",
      "Epoch 954/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7750 - val_loss: 1.0328\n",
      "Epoch 955/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7887 - val_loss: 0.8648\n",
      "Epoch 956/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.8064 - val_loss: 1.1941\n",
      "Epoch 957/1500\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.8495 - val_loss: 0.8693\n",
      "Epoch 958/1500\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.8074 - val_loss: 0.9407\n",
      "Epoch 959/1500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.7687 - val_loss: 0.9894\n",
      "Epoch 960/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7808 - val_loss: 0.8630\n",
      "Epoch 961/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7866 - val_loss: 0.9216\n",
      "Epoch 962/1500\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.7676 - val_loss: 0.9800\n",
      "Epoch 963/1500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.7782 - val_loss: 0.8813\n",
      "Epoch 964/1500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.7722 - val_loss: 0.8813\n",
      "Epoch 965/1500\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.7706 - val_loss: 0.9543\n",
      "Epoch 966/1500\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.7750 - val_loss: 0.9150\n",
      "Epoch 967/1500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.7682 - val_loss: 0.8748\n",
      "Epoch 968/1500\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.7750 - val_loss: 0.9121\n",
      "Epoch 969/1500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.7681 - val_loss: 0.9443\n",
      "Epoch 970/1500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.7729 - val_loss: 0.8921\n",
      "Epoch 971/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7687 - val_loss: 0.8813\n",
      "Epoch 972/1500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.7712 - val_loss: 0.9245\n",
      "Epoch 973/1500\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.7694 - val_loss: 0.9276\n",
      "Epoch 974/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.7698 - val_loss: 0.8863\n",
      "Epoch 975/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7697 - val_loss: 0.8910\n",
      "Epoch 976/1500\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.7686 - val_loss: 0.9275\n",
      "Epoch 977/1500\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.7698 - val_loss: 0.9129\n",
      "Epoch 978/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7679 - val_loss: 0.8864\n",
      "Epoch 979/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7696 - val_loss: 0.9031\n",
      "Epoch 980/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7675 - val_loss: 0.9246\n",
      "Epoch 981/1500\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.7691 - val_loss: 0.8995\n",
      "Epoch 982/1500\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.7674 - val_loss: 0.8910\n",
      "Epoch 983/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.7684 - val_loss: 0.9177\n",
      "Epoch 984/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7675 - val_loss: 0.9186\n",
      "Epoch 985/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7675 - val_loss: 0.8931\n",
      "Epoch 986/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7677 - val_loss: 0.9015\n",
      "Epoch 987/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7669 - val_loss: 0.9222\n",
      "Epoch 988/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7676 - val_loss: 0.9048\n",
      "Epoch 989/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7666 - val_loss: 0.8973\n",
      "Epoch 990/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7671 - val_loss: 0.9170\n",
      "Epoch 991/1500\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.7667 - val_loss: 0.9121\n",
      "Epoch 992/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7664 - val_loss: 0.8959\n",
      "Epoch 993/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7668 - val_loss: 0.9109\n",
      "Epoch 994/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.7661 - val_loss: 0.9182\n",
      "Epoch 995/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7663 - val_loss: 0.8999\n",
      "Epoch 996/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7662 - val_loss: 0.9065\n",
      "Epoch 997/1500\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.7658 - val_loss: 0.9180\n",
      "Epoch 998/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7660 - val_loss: 0.9028\n",
      "Epoch 999/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7657 - val_loss: 0.9061\n",
      "Epoch 1000/1500\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.7655 - val_loss: 0.9182\n",
      "Epoch 1001/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7657 - val_loss: 0.9042\n",
      "Epoch 1002/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7654 - val_loss: 0.9063\n",
      "Epoch 1003/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7652 - val_loss: 0.9173\n",
      "Epoch 1004/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7653 - val_loss: 0.9045\n",
      "Epoch 1005/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7651 - val_loss: 0.9082\n",
      "Epoch 1006/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7649 - val_loss: 0.9161\n",
      "Epoch 1007/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7650 - val_loss: 0.9042\n",
      "Epoch 1008/1500\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.7648 - val_loss: 0.9123\n",
      "Epoch 1009/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7646 - val_loss: 0.9142\n",
      "Epoch 1010/1500\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.7646 - val_loss: 0.9050\n",
      "Epoch 1011/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7646 - val_loss: 0.9168\n",
      "Epoch 1012/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7644 - val_loss: 0.9095\n",
      "Epoch 1013/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7642 - val_loss: 0.9098\n",
      "Epoch 1014/1500\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.7641 - val_loss: 0.9172\n",
      "Epoch 1015/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7641 - val_loss: 0.9061\n",
      "Epoch 1016/1500\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.7641 - val_loss: 0.9180\n",
      "Epoch 1017/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7639 - val_loss: 0.9105\n",
      "Epoch 1018/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7638 - val_loss: 0.9133\n",
      "Epoch 1019/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7636 - val_loss: 0.9163\n",
      "Epoch 1020/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7635 - val_loss: 0.9087\n",
      "Epoch 1021/1500\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.7635 - val_loss: 0.9214\n",
      "Epoch 1022/1500\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.7635 - val_loss: 0.9059\n",
      "Epoch 1023/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7635 - val_loss: 0.9277\n",
      "Epoch 1024/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7636 - val_loss: 0.8999\n",
      "Epoch 1025/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7639 - val_loss: 0.9407\n",
      "Epoch 1026/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.7647 - val_loss: 0.8862\n",
      "Epoch 1027/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7667 - val_loss: 0.9867\n",
      "Epoch 1028/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7731 - val_loss: 0.8638\n",
      "Epoch 1029/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7894 - val_loss: 1.2055\n",
      "Epoch 1030/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.8496 - val_loss: 0.9085\n",
      "Epoch 1031/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8976 - val_loss: 1.4443\n",
      "Epoch 1032/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.9621 - val_loss: 0.9223\n",
      "Epoch 1033/1500\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.7658 - val_loss: 0.9156\n",
      "Epoch 1034/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.9140 - val_loss: 1.0902\n",
      "Epoch 1035/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.8229 - val_loss: 1.1764\n",
      "Epoch 1036/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8586 - val_loss: 0.8791\n",
      "Epoch 1037/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7784 - val_loss: 0.8817\n",
      "Epoch 1038/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.8538 - val_loss: 0.8868\n",
      "Epoch 1039/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7722 - val_loss: 1.0383\n",
      "Epoch 1040/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8197 - val_loss: 1.0159\n",
      "Epoch 1041/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.8059 - val_loss: 0.8988\n",
      "Epoch 1042/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7752 - val_loss: 0.8756\n",
      "Epoch 1043/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.8106 - val_loss: 0.8682\n",
      "Epoch 1044/1500\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.7891 - val_loss: 0.9053\n",
      "Epoch 1045/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7790 - val_loss: 0.9606\n",
      "Epoch 1046/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7994 - val_loss: 0.9486\n",
      "Epoch 1047/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7896 - val_loss: 0.9038\n",
      "Epoch 1048/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7762 - val_loss: 0.8879\n",
      "Epoch 1049/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7905 - val_loss: 0.8857\n",
      "Epoch 1050/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7884 - val_loss: 0.8943\n",
      "Epoch 1051/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7765 - val_loss: 0.9199\n",
      "Epoch 1052/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7838 - val_loss: 0.9283\n",
      "Epoch 1053/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7875 - val_loss: 0.9084\n",
      "Epoch 1054/1500\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.7785 - val_loss: 0.8893\n",
      "Epoch 1055/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7780 - val_loss: 0.8853\n",
      "Epoch 1056/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7844 - val_loss: 0.8894\n",
      "Epoch 1057/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7797 - val_loss: 0.9033\n",
      "Epoch 1058/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7761 - val_loss: 0.9187\n",
      "Epoch 1059/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7805 - val_loss: 0.9167\n",
      "Epoch 1060/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7802 - val_loss: 0.9009\n",
      "Epoch 1061/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7757 - val_loss: 0.8896\n",
      "Epoch 1062/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7772 - val_loss: 0.8874\n",
      "Epoch 1063/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7792 - val_loss: 0.8929\n",
      "Epoch 1064/1500\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.7759 - val_loss: 0.9057\n",
      "Epoch 1065/1500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7754 - val_loss: 0.9145\n",
      "Epoch 1066/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7775 - val_loss: 0.9092\n",
      "Epoch 1067/1500\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.7760 - val_loss: 0.8977\n",
      "Epoch 1068/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7744 - val_loss: 0.8916\n",
      "Epoch 1069/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7759 - val_loss: 0.8923\n",
      "Epoch 1070/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7756 - val_loss: 0.8993\n",
      "Epoch 1071/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7739 - val_loss: 0.9088\n",
      "Epoch 1072/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7747 - val_loss: 0.9107\n",
      "Epoch 1073/1500\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.7750 - val_loss: 0.9029\n",
      "Epoch 1074/1500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7736 - val_loss: 0.8947\n",
      "Epoch 1075/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7737 - val_loss: 0.8922\n",
      "Epoch 1076/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7742 - val_loss: 0.8959\n",
      "Epoch 1077/1500\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.7732 - val_loss: 0.9034\n",
      "Epoch 1078/1500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7730 - val_loss: 0.9080\n",
      "Epoch 1079/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7735 - val_loss: 0.9049\n",
      "Epoch 1080/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7728 - val_loss: 0.8981\n",
      "Epoch 1081/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7725 - val_loss: 0.8944\n",
      "Epoch 1082/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7728 - val_loss: 0.8958\n",
      "Epoch 1083/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7723 - val_loss: 0.9009\n",
      "Epoch 1084/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7720 - val_loss: 0.9044\n",
      "Epoch 1085/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7723 - val_loss: 0.9023\n",
      "Epoch 1086/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7719 - val_loss: 0.8977\n",
      "Epoch 1087/1500\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.7716 - val_loss: 0.8956\n",
      "Epoch 1088/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7718 - val_loss: 0.8979\n",
      "Epoch 1089/1500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7714 - val_loss: 0.9026\n",
      "Epoch 1090/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7713 - val_loss: 0.9047\n",
      "Epoch 1091/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7713 - val_loss: 0.9017\n",
      "Epoch 1092/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7710 - val_loss: 0.8973\n",
      "Epoch 1093/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7709 - val_loss: 0.8960\n",
      "Epoch 1094/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7709 - val_loss: 0.8987\n",
      "Epoch 1095/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7706 - val_loss: 0.9029\n",
      "Epoch 1096/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7706 - val_loss: 0.9040\n",
      "Epoch 1097/1500\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.7705 - val_loss: 0.9011\n",
      "Epoch 1098/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7703 - val_loss: 0.8980\n",
      "Epoch 1099/1500\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.7702 - val_loss: 0.8980\n",
      "Epoch 1100/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7701 - val_loss: 0.9009\n",
      "Epoch 1101/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7699 - val_loss: 0.9037\n",
      "Epoch 1102/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7699 - val_loss: 0.9032\n",
      "Epoch 1103/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7697 - val_loss: 0.9006\n",
      "Epoch 1104/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7696 - val_loss: 0.8992\n",
      "Epoch 1105/1500\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.7696 - val_loss: 0.9006\n",
      "Epoch 1106/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7694 - val_loss: 0.9030\n",
      "Epoch 1107/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7693 - val_loss: 0.9036\n",
      "Epoch 1108/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7692 - val_loss: 0.9018\n",
      "Epoch 1109/1500\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.7691 - val_loss: 0.9005\n",
      "Epoch 1110/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7690 - val_loss: 0.9013\n",
      "Epoch 1111/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7689 - val_loss: 0.9034\n",
      "Epoch 1112/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7688 - val_loss: 0.9042\n",
      "Epoch 1113/1500\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.7687 - val_loss: 0.9028\n",
      "Epoch 1114/1500\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.7685 - val_loss: 0.9014\n",
      "Epoch 1115/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7684 - val_loss: 0.9020\n",
      "Epoch 1116/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7683 - val_loss: 0.9041\n",
      "Epoch 1117/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7682 - val_loss: 0.9050\n",
      "Epoch 1118/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7681 - val_loss: 0.9040\n",
      "Epoch 1119/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7680 - val_loss: 0.9029\n",
      "Epoch 1120/1500\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.7679 - val_loss: 0.9034\n",
      "Epoch 1121/1500\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.7678 - val_loss: 0.9051\n",
      "Epoch 1122/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7677 - val_loss: 0.9059\n",
      "Epoch 1123/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7676 - val_loss: 0.9049\n",
      "Epoch 1124/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7675 - val_loss: 0.9041\n",
      "Epoch 1125/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7674 - val_loss: 0.9049\n",
      "Epoch 1126/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7673 - val_loss: 0.9064\n",
      "Epoch 1127/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7672 - val_loss: 0.9067\n",
      "Epoch 1128/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7671 - val_loss: 0.9058\n",
      "Epoch 1129/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7670 - val_loss: 0.9056\n",
      "Epoch 1130/1500\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.7669 - val_loss: 0.9067\n",
      "Epoch 1131/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7668 - val_loss: 0.9076\n",
      "Epoch 1132/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7667 - val_loss: 0.9072\n",
      "Epoch 1133/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7666 - val_loss: 0.9067\n",
      "Epoch 1134/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7665 - val_loss: 0.9076\n",
      "Epoch 1135/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7664 - val_loss: 0.9091\n",
      "Epoch 1136/1500\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.7663 - val_loss: 0.9093\n",
      "Epoch 1137/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7662 - val_loss: 0.9086\n",
      "Epoch 1138/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7661 - val_loss: 0.9090\n",
      "Epoch 1139/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7660 - val_loss: 0.9102\n",
      "Epoch 1140/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7659 - val_loss: 0.9109\n",
      "Epoch 1141/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7659 - val_loss: 0.9106\n",
      "Epoch 1142/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7658 - val_loss: 0.9105\n",
      "Epoch 1143/1500\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.7657 - val_loss: 0.9114\n",
      "Epoch 1144/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7656 - val_loss: 0.9120\n",
      "Epoch 1145/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7655 - val_loss: 0.9115\n",
      "Epoch 1146/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7654 - val_loss: 0.9112\n",
      "Epoch 1147/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7653 - val_loss: 0.9121\n",
      "Epoch 1148/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7652 - val_loss: 0.9129\n",
      "Epoch 1149/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7652 - val_loss: 0.9126\n",
      "Epoch 1150/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7651 - val_loss: 0.9124\n",
      "Epoch 1151/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7650 - val_loss: 0.9130\n",
      "Epoch 1152/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7649 - val_loss: 0.9136\n",
      "Epoch 1153/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7648 - val_loss: 0.9134\n",
      "Epoch 1154/1500\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.7647 - val_loss: 0.9135\n",
      "Epoch 1155/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7647 - val_loss: 0.9144\n",
      "Epoch 1156/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7646 - val_loss: 0.9148\n",
      "Epoch 1157/1500\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.7645 - val_loss: 0.9144\n",
      "Epoch 1158/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7644 - val_loss: 0.9145\n",
      "Epoch 1159/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7643 - val_loss: 0.9149\n",
      "Epoch 1160/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7643 - val_loss: 0.9153\n",
      "Epoch 1161/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7642 - val_loss: 0.9154\n",
      "Epoch 1162/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7641 - val_loss: 0.9158\n",
      "Epoch 1163/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7640 - val_loss: 0.9164\n",
      "Epoch 1164/1500\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.7639 - val_loss: 0.9159\n",
      "Epoch 1165/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7639 - val_loss: 0.9157\n",
      "Epoch 1166/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7638 - val_loss: 0.9164\n",
      "Epoch 1167/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7637 - val_loss: 0.9168\n",
      "Epoch 1168/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7636 - val_loss: 0.9170\n",
      "Epoch 1169/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7636 - val_loss: 0.9174\n",
      "Epoch 1170/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7635 - val_loss: 0.9174\n",
      "Epoch 1171/1500\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.7634 - val_loss: 0.9172\n",
      "Epoch 1172/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7633 - val_loss: 0.9175\n",
      "Epoch 1173/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7633 - val_loss: 0.9178\n",
      "Epoch 1174/1500\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.7632 - val_loss: 0.9178\n",
      "Epoch 1175/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7631 - val_loss: 0.9185\n",
      "Epoch 1176/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7630 - val_loss: 0.9188\n",
      "Epoch 1177/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7630 - val_loss: 0.9187\n",
      "Epoch 1178/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7629 - val_loss: 0.9190\n",
      "Epoch 1179/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7628 - val_loss: 0.9191\n",
      "Epoch 1180/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7627 - val_loss: 0.9193\n",
      "Epoch 1181/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7627 - val_loss: 0.9193\n",
      "Epoch 1182/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7626 - val_loss: 0.9198\n",
      "Epoch 1183/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7625 - val_loss: 0.9199\n",
      "Epoch 1184/1500\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.7625 - val_loss: 0.9201\n",
      "Epoch 1185/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7624 - val_loss: 0.9203\n",
      "Epoch 1186/1500\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.7623 - val_loss: 0.9203\n",
      "Epoch 1187/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7623 - val_loss: 0.9203\n",
      "Epoch 1188/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7622 - val_loss: 0.9205\n",
      "Epoch 1189/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7621 - val_loss: 0.9208\n",
      "Epoch 1190/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7620 - val_loss: 0.9214\n",
      "Epoch 1191/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7620 - val_loss: 0.9212\n",
      "Epoch 1192/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7619 - val_loss: 0.9214\n",
      "Epoch 1193/1500\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.7618 - val_loss: 0.9214\n",
      "Epoch 1194/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7618 - val_loss: 0.9207\n",
      "Epoch 1195/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7617 - val_loss: 0.9218\n",
      "Epoch 1196/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7616 - val_loss: 0.9219\n",
      "Epoch 1197/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7615 - val_loss: 0.9222\n",
      "Epoch 1198/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7615 - val_loss: 0.9221\n",
      "Epoch 1199/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7614 - val_loss: 0.9213\n",
      "Epoch 1200/1500\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.7613 - val_loss: 0.9222\n",
      "Epoch 1201/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7613 - val_loss: 0.9217\n",
      "Epoch 1202/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7612 - val_loss: 0.9228\n",
      "Epoch 1203/1500\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.7611 - val_loss: 0.9227\n",
      "Epoch 1204/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7611 - val_loss: 0.9230\n",
      "Epoch 1205/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7610 - val_loss: 0.9232\n",
      "Epoch 1206/1500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7609 - val_loss: 0.9234\n",
      "Epoch 1207/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7609 - val_loss: 0.9239\n",
      "Epoch 1208/1500\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.7608 - val_loss: 0.9238\n",
      "Epoch 1209/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7607 - val_loss: 0.9247\n",
      "Epoch 1210/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7607 - val_loss: 0.9231\n",
      "Epoch 1211/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7606 - val_loss: 0.9255\n",
      "Epoch 1212/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7606 - val_loss: 0.9217\n",
      "Epoch 1213/1500\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.7605 - val_loss: 0.9285\n",
      "Epoch 1214/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7605 - val_loss: 0.9184\n",
      "Epoch 1215/1500\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.7605 - val_loss: 0.9337\n",
      "Epoch 1216/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7605 - val_loss: 0.9131\n",
      "Epoch 1217/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7606 - val_loss: 0.9399\n",
      "Epoch 1218/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7608 - val_loss: 0.9088\n",
      "Epoch 1219/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7609 - val_loss: 0.9450\n",
      "Epoch 1220/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7610 - val_loss: 0.9064\n",
      "Epoch 1221/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7611 - val_loss: 0.9481\n",
      "Epoch 1222/1500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7611 - val_loss: 0.9062\n",
      "Epoch 1223/1500\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.7611 - val_loss: 0.9495\n",
      "Epoch 1224/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7611 - val_loss: 0.9038\n",
      "Epoch 1225/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7613 - val_loss: 0.9558\n",
      "Epoch 1226/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7617 - val_loss: 0.8973\n",
      "Epoch 1227/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7625 - val_loss: 0.9760\n",
      "Epoch 1228/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7644 - val_loss: 0.8833\n",
      "Epoch 1229/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7673 - val_loss: 1.0199\n",
      "Epoch 1230/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7736 - val_loss: 0.8658\n",
      "Epoch 1231/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7815 - val_loss: 1.0950\n",
      "Epoch 1232/1500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7958 - val_loss: 0.8596\n",
      "Epoch 1233/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7980 - val_loss: 1.0837\n",
      "Epoch 1234/1500\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.7930 - val_loss: 0.8796\n",
      "Epoch 1235/1500\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.7683 - val_loss: 0.9052\n",
      "Epoch 1236/1500\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.7608 - val_loss: 1.0104\n",
      "Epoch 1237/1500\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.7738 - val_loss: 0.8688\n",
      "Epoch 1238/1500\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.7736 - val_loss: 0.9441\n",
      "Epoch 1239/1500\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.7616 - val_loss: 0.9600\n",
      "Epoch 1240/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7639 - val_loss: 0.8741\n",
      "Epoch 1241/1500\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.7696 - val_loss: 0.9490\n",
      "Epoch 1242/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7626 - val_loss: 0.9439\n",
      "Epoch 1243/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7620 - val_loss: 0.8798\n",
      "Epoch 1244/1500\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.7667 - val_loss: 0.9434\n",
      "Epoch 1245/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7619 - val_loss: 0.9426\n",
      "Epoch 1246/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7618 - val_loss: 0.8854\n",
      "Epoch 1247/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7648 - val_loss: 0.9339\n",
      "Epoch 1248/1500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7611 - val_loss: 0.9424\n",
      "Epoch 1249/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7618 - val_loss: 0.8901\n",
      "Epoch 1250/1500\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.7634 - val_loss: 0.9263\n",
      "Epoch 1251/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7605 - val_loss: 0.9416\n",
      "Epoch 1252/1500\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.7617 - val_loss: 0.8948\n",
      "Epoch 1253/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7622 - val_loss: 0.9213\n",
      "Epoch 1254/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7603 - val_loss: 0.9403\n",
      "Epoch 1255/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7614 - val_loss: 0.8992\n",
      "Epoch 1256/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7614 - val_loss: 0.9191\n",
      "Epoch 1257/1500\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.7601 - val_loss: 0.9380\n",
      "Epoch 1258/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7610 - val_loss: 0.9028\n",
      "Epoch 1259/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7609 - val_loss: 0.9195\n",
      "Epoch 1260/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7600 - val_loss: 0.9358\n",
      "Epoch 1261/1500\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.7606 - val_loss: 0.9051\n",
      "Epoch 1262/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7605 - val_loss: 0.9217\n",
      "Epoch 1263/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7598 - val_loss: 0.9330\n",
      "Epoch 1264/1500\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.7602 - val_loss: 0.9069\n",
      "Epoch 1265/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7603 - val_loss: 0.9257\n",
      "Epoch 1266/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7597 - val_loss: 0.9286\n",
      "Epoch 1267/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7597 - val_loss: 0.9086\n",
      "Epoch 1268/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7600 - val_loss: 0.9301\n",
      "Epoch 1269/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7597 - val_loss: 0.9231\n",
      "Epoch 1270/1500\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.7594 - val_loss: 0.9125\n",
      "Epoch 1271/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7596 - val_loss: 0.9340\n",
      "Epoch 1272/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7596 - val_loss: 0.9174\n",
      "Epoch 1273/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7593 - val_loss: 0.9203\n",
      "Epoch 1274/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7592 - val_loss: 0.9327\n",
      "Epoch 1275/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7593 - val_loss: 0.9143\n",
      "Epoch 1276/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7593 - val_loss: 0.9301\n",
      "Epoch 1277/1500\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.7591 - val_loss: 0.9248\n",
      "Epoch 1278/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7589 - val_loss: 0.9189\n",
      "Epoch 1279/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7590 - val_loss: 0.9336\n",
      "Epoch 1280/1500\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.7590 - val_loss: 0.9173\n",
      "Epoch 1281/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7589 - val_loss: 0.9306\n",
      "Epoch 1282/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7588 - val_loss: 0.9252\n",
      "Epoch 1283/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7587 - val_loss: 0.9232\n",
      "Epoch 1284/1500\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.7586 - val_loss: 0.9327\n",
      "Epoch 1285/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7587 - val_loss: 0.9187\n",
      "Epoch 1286/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7587 - val_loss: 0.9352\n",
      "Epoch 1287/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7586 - val_loss: 0.9191\n",
      "Epoch 1288/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7586 - val_loss: 0.9338\n",
      "Epoch 1289/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7585 - val_loss: 0.9219\n",
      "Epoch 1290/1500\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.7584 - val_loss: 0.9315\n",
      "Epoch 1291/1500\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.7583 - val_loss: 0.9243\n",
      "Epoch 1292/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7582 - val_loss: 0.9304\n",
      "Epoch 1293/1500\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.7582 - val_loss: 0.9257\n",
      "Epoch 1294/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7581 - val_loss: 0.9307\n",
      "Epoch 1295/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7581 - val_loss: 0.9258\n",
      "Epoch 1296/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7580 - val_loss: 0.9326\n",
      "Epoch 1297/1500\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.7580 - val_loss: 0.9237\n",
      "Epoch 1298/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7580 - val_loss: 0.9384\n",
      "Epoch 1299/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7581 - val_loss: 0.9160\n",
      "Epoch 1300/1500\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.7584 - val_loss: 0.9569\n",
      "Epoch 1301/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7594 - val_loss: 0.8931\n",
      "Epoch 1302/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7625 - val_loss: 1.0316\n",
      "Epoch 1303/1500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7735 - val_loss: 0.8597\n",
      "Epoch 1304/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.8059 - val_loss: 1.4139\n",
      "Epoch 1305/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.9193 - val_loss: 0.9678\n",
      "Epoch 1306/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 1.0062 - val_loss: 1.6521\n",
      "Epoch 1307/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 1.0391 - val_loss: 0.9724\n",
      "Epoch 1308/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7639 - val_loss: 0.9494\n",
      "Epoch 1309/1500\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.9841 - val_loss: 0.9951\n",
      "Epoch 1310/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7800 - val_loss: 1.3039\n",
      "Epoch 1311/1500\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.9030 - val_loss: 0.9589\n",
      "Epoch 1312/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7705 - val_loss: 0.8726\n",
      "Epoch 1313/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8513 - val_loss: 0.8542\n",
      "Epoch 1314/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.8046 - val_loss: 0.9539\n",
      "Epoch 1315/1500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.7829 - val_loss: 1.0773\n",
      "Epoch 1316/1500\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.8289 - val_loss: 0.9929\n",
      "Epoch 1317/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7881 - val_loss: 0.8896\n",
      "Epoch 1318/1500\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.7793 - val_loss: 0.8732\n",
      "Epoch 1319/1500\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.8103 - val_loss: 0.8668\n",
      "Epoch 1320/1500\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.7838 - val_loss: 0.9037\n",
      "Epoch 1321/1500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.7772 - val_loss: 0.9589\n",
      "Epoch 1322/1500\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.7967 - val_loss: 0.9564\n",
      "Epoch 1323/1500\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.7890 - val_loss: 0.9151\n",
      "Epoch 1324/1500\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.7733 - val_loss: 0.8926\n",
      "Epoch 1325/1500\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.7844 - val_loss: 0.8883\n",
      "Epoch 1326/1500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.7889 - val_loss: 0.8906\n",
      "Epoch 1327/1500\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.7755 - val_loss: 0.9090\n",
      "Epoch 1328/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7763 - val_loss: 0.9267\n",
      "Epoch 1329/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7847 - val_loss: 0.9213\n",
      "Epoch 1330/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7805 - val_loss: 0.9022\n",
      "Epoch 1331/1500\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.7732 - val_loss: 0.8911\n",
      "Epoch 1332/1500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.7774 - val_loss: 0.8902\n",
      "Epoch 1333/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7809 - val_loss: 0.8956\n",
      "Epoch 1334/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7750 - val_loss: 0.9086\n",
      "Epoch 1335/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7733 - val_loss: 0.9203\n",
      "Epoch 1336/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7774 - val_loss: 0.9182\n",
      "Epoch 1337/1500\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.7766 - val_loss: 0.9065\n",
      "Epoch 1338/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7723 - val_loss: 0.8993\n",
      "Epoch 1339/1500\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.7725 - val_loss: 0.8999\n",
      "Epoch 1340/1500\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.7745 - val_loss: 0.9092\n",
      "Epoch 1341/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7725 - val_loss: 0.9276\n",
      "Epoch 1342/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7716 - val_loss: 0.9225\n",
      "Epoch 1343/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7722 - val_loss: 0.8999\n",
      "Epoch 1344/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7716 - val_loss: 0.8829\n",
      "Epoch 1345/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7717 - val_loss: 0.8849\n",
      "Epoch 1346/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7712 - val_loss: 0.9033\n",
      "Epoch 1347/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7701 - val_loss: 0.9273\n",
      "Epoch 1348/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7706 - val_loss: 0.9344\n",
      "Epoch 1349/1500\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.7709 - val_loss: 0.9177\n",
      "Epoch 1350/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7695 - val_loss: 0.8962\n",
      "Epoch 1351/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7695 - val_loss: 0.8859\n",
      "Epoch 1352/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7700 - val_loss: 0.8911\n",
      "Epoch 1353/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7694 - val_loss: 0.9064\n",
      "Epoch 1354/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7689 - val_loss: 0.9189\n",
      "Epoch 1355/1500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7691 - val_loss: 0.9171\n",
      "Epoch 1356/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7689 - val_loss: 0.9064\n",
      "Epoch 1357/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7685 - val_loss: 0.8987\n",
      "Epoch 1358/1500\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.7684 - val_loss: 0.8994\n",
      "Epoch 1359/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7681 - val_loss: 0.9061\n",
      "Epoch 1360/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7681 - val_loss: 0.9105\n",
      "Epoch 1361/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7680 - val_loss: 0.9084\n",
      "Epoch 1362/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7676 - val_loss: 0.9041\n",
      "Epoch 1363/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7676 - val_loss: 0.9034\n",
      "Epoch 1364/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7676 - val_loss: 0.9071\n",
      "Epoch 1365/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7672 - val_loss: 0.9103\n",
      "Epoch 1366/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7671 - val_loss: 0.9085\n",
      "Epoch 1367/1500\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.7671 - val_loss: 0.9038\n",
      "Epoch 1368/1500\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.7668 - val_loss: 0.9024\n",
      "Epoch 1369/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7667 - val_loss: 0.9064\n",
      "Epoch 1370/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7666 - val_loss: 0.9118\n",
      "Epoch 1371/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7665 - val_loss: 0.9122\n",
      "Epoch 1372/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7663 - val_loss: 0.9065\n",
      "Epoch 1373/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7661 - val_loss: 0.9011\n",
      "Epoch 1374/1500\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.7661 - val_loss: 0.9019\n",
      "Epoch 1375/1500\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.7660 - val_loss: 0.9081\n",
      "Epoch 1376/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7658 - val_loss: 0.9134\n",
      "Epoch 1377/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7657 - val_loss: 0.9123\n",
      "Epoch 1378/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7656 - val_loss: 0.9074\n",
      "Epoch 1379/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7654 - val_loss: 0.9047\n",
      "Epoch 1380/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7653 - val_loss: 0.9067\n",
      "Epoch 1381/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7652 - val_loss: 0.9101\n",
      "Epoch 1382/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7651 - val_loss: 0.9108\n",
      "Epoch 1383/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7650 - val_loss: 0.9095\n",
      "Epoch 1384/1500\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.7649 - val_loss: 0.9093\n",
      "Epoch 1385/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7648 - val_loss: 0.9110\n",
      "Epoch 1386/1500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7647 - val_loss: 0.9120\n",
      "Epoch 1387/1500\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.7646 - val_loss: 0.9101\n",
      "Epoch 1388/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7645 - val_loss: 0.9079\n",
      "Epoch 1389/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7643 - val_loss: 0.9088\n",
      "Epoch 1390/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7642 - val_loss: 0.9123\n",
      "Epoch 1391/1500\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.7641 - val_loss: 0.9143\n",
      "Epoch 1392/1500\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7640 - val_loss: 0.9127\n",
      "Epoch 1393/1500\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.7639 - val_loss: 0.9101\n",
      "Epoch 1394/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7638 - val_loss: 0.9103\n",
      "Epoch 1395/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7637 - val_loss: 0.9127\n",
      "Epoch 1396/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7636 - val_loss: 0.9143\n",
      "Epoch 1397/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7635 - val_loss: 0.9134\n",
      "Epoch 1398/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7634 - val_loss: 0.9125\n",
      "Epoch 1399/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7633 - val_loss: 0.9132\n",
      "Epoch 1400/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7632 - val_loss: 0.9144\n",
      "Epoch 1401/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7631 - val_loss: 0.9141\n",
      "Epoch 1402/1500\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.7630 - val_loss: 0.9133\n",
      "Epoch 1403/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7629 - val_loss: 0.9141\n",
      "Epoch 1404/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7628 - val_loss: 0.9157\n",
      "Epoch 1405/1500\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.7627 - val_loss: 0.9160\n",
      "Epoch 1406/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7626 - val_loss: 0.9149\n",
      "Epoch 1407/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7625 - val_loss: 0.9146\n",
      "Epoch 1408/1500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.7624 - val_loss: 0.9158\n",
      "Epoch 1409/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7623 - val_loss: 0.9170\n",
      "Epoch 1410/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7622 - val_loss: 0.9166\n",
      "Epoch 1411/1500\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.7621 - val_loss: 0.9159\n",
      "Epoch 1412/1500\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.7620 - val_loss: 0.9166\n",
      "Epoch 1413/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7619 - val_loss: 0.9175\n",
      "Epoch 1414/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7618 - val_loss: 0.9175\n",
      "Epoch 1415/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7617 - val_loss: 0.9174\n",
      "Epoch 1416/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7616 - val_loss: 0.9181\n",
      "Epoch 1417/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7615 - val_loss: 0.9189\n",
      "Epoch 1418/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7614 - val_loss: 0.9186\n",
      "Epoch 1419/1500\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.7613 - val_loss: 0.9183\n",
      "Epoch 1420/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7613 - val_loss: 0.9189\n",
      "Epoch 1421/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7612 - val_loss: 0.9198\n",
      "Epoch 1422/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7611 - val_loss: 0.9200\n",
      "Epoch 1423/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7610 - val_loss: 0.9197\n",
      "Epoch 1424/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7609 - val_loss: 0.9200\n",
      "Epoch 1425/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7609 - val_loss: 0.9204\n",
      "Epoch 1426/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7608 - val_loss: 0.9205\n",
      "Epoch 1427/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7607 - val_loss: 0.9207\n",
      "Epoch 1428/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.7606 - val_loss: 0.9212\n",
      "Epoch 1429/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7605 - val_loss: 0.9217\n",
      "Epoch 1430/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7605 - val_loss: 0.9219\n",
      "Epoch 1431/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7604 - val_loss: 0.9221\n",
      "Epoch 1432/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7603 - val_loss: 0.9231\n",
      "Epoch 1433/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7602 - val_loss: 0.9235\n",
      "Epoch 1434/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7602 - val_loss: 0.9234\n",
      "Epoch 1435/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7601 - val_loss: 0.9239\n",
      "Epoch 1436/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7600 - val_loss: 0.9244\n",
      "Epoch 1437/1500\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.7600 - val_loss: 0.9242\n",
      "Epoch 1438/1500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7599 - val_loss: 0.9244\n",
      "Epoch 1439/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7598 - val_loss: 0.9252\n",
      "Epoch 1440/1500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.7598 - val_loss: 0.9253\n",
      "Epoch 1441/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7597 - val_loss: 0.9251\n",
      "Epoch 1442/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7596 - val_loss: 0.9256\n",
      "Epoch 1443/1500\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.7596 - val_loss: 0.9259\n",
      "Epoch 1444/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7595 - val_loss: 0.9256\n",
      "Epoch 1445/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7594 - val_loss: 0.9262\n",
      "Epoch 1446/1500\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.7594 - val_loss: 0.9267\n",
      "Epoch 1447/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7593 - val_loss: 0.9265\n",
      "Epoch 1448/1500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7593 - val_loss: 0.9270\n",
      "Epoch 1449/1500\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7592 - val_loss: 0.9274\n",
      "Epoch 1450/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7591 - val_loss: 0.9272\n",
      "Epoch 1451/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7591 - val_loss: 0.9277\n",
      "Epoch 1452/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7590 - val_loss: 0.9284\n",
      "Epoch 1453/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7590 - val_loss: 0.9282\n",
      "Epoch 1454/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7589 - val_loss: 0.9286\n",
      "Epoch 1455/1500\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.7588 - val_loss: 0.9294\n",
      "Epoch 1456/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7588 - val_loss: 0.9291\n",
      "Epoch 1457/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7587 - val_loss: 0.9297\n",
      "Epoch 1458/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7587 - val_loss: 0.9303\n",
      "Epoch 1459/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7586 - val_loss: 0.9300\n",
      "Epoch 1460/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7586 - val_loss: 0.9307\n",
      "Epoch 1461/1500\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.7585 - val_loss: 0.9312\n",
      "Epoch 1462/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7584 - val_loss: 0.9312\n",
      "Epoch 1463/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7584 - val_loss: 0.9322\n",
      "Epoch 1464/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7583 - val_loss: 0.9325\n",
      "Epoch 1465/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7583 - val_loss: 0.9320\n",
      "Epoch 1466/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7582 - val_loss: 0.9334\n",
      "Epoch 1467/1500\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7582 - val_loss: 0.9328\n",
      "Epoch 1468/1500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7581 - val_loss: 0.9335\n",
      "Epoch 1469/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.7581 - val_loss: 0.9343\n",
      "Epoch 1470/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.7580 - val_loss: 0.9337\n",
      "Epoch 1471/1500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.7580 - val_loss: 0.9344\n",
      "Epoch 1472/1500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7579 - val_loss: 0.9344\n",
      "Epoch 1473/1500\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.7579 - val_loss: 0.9343\n",
      "Epoch 1474/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7578 - val_loss: 0.9359\n",
      "Epoch 1475/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7578 - val_loss: 0.9352\n",
      "Epoch 1476/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7577 - val_loss: 0.9360\n",
      "Epoch 1477/1500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.7577 - val_loss: 0.9363\n",
      "Epoch 1478/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.7577 - val_loss: 0.9361\n",
      "Epoch 1479/1500\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.7576 - val_loss: 0.9372\n",
      "Epoch 1480/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7576 - val_loss: 0.9360\n",
      "Epoch 1481/1500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.7575 - val_loss: 0.9378\n",
      "Epoch 1482/1500\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7575 - val_loss: 0.9360\n",
      "Epoch 1483/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7574 - val_loss: 0.9383\n",
      "Epoch 1484/1500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.7574 - val_loss: 0.9358\n",
      "Epoch 1485/1500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7573 - val_loss: 0.9389\n",
      "Epoch 1486/1500\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.7573 - val_loss: 0.9355\n",
      "Epoch 1487/1500\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.7572 - val_loss: 0.9395\n",
      "Epoch 1488/1500\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7572 - val_loss: 0.9347\n",
      "Epoch 1489/1500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7572 - val_loss: 0.9413\n",
      "Epoch 1490/1500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.7571 - val_loss: 0.9332\n",
      "Epoch 1491/1500\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.7571 - val_loss: 0.9440\n",
      "Epoch 1492/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7571 - val_loss: 0.9304\n",
      "Epoch 1493/1500\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7571 - val_loss: 0.9478\n",
      "Epoch 1494/1500\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.7571 - val_loss: 0.9262\n",
      "Epoch 1495/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7572 - val_loss: 0.9533\n",
      "Epoch 1496/1500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.7573 - val_loss: 0.9218\n",
      "Epoch 1497/1500\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.7574 - val_loss: 0.9563\n",
      "Epoch 1498/1500\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.7574 - val_loss: 0.9213\n",
      "Epoch 1499/1500\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7573 - val_loss: 0.9521\n",
      "Epoch 1500/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7571 - val_loss: 0.9279\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.8542\n",
      "0.8542402386665344\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.LSTM(units = 1024, activation = \"relu\", return_sequences = True)(input)\n",
    "    x = layers.LSTM(units = 1024, activation = \"relu\", return_sequences = True)(x)\n",
    "    x = layers.LSTM(units = 512, activation = \"relu\", return_sequences = True)(x)\n",
    "    \n",
    "\n",
    "    # 中間層最後のreturn_sequencesは、Falseにする\n",
    "    # 出力は一つなので、中間層の最後で次元数を落として出力できるようにしている\n",
    "    x = layers.LSTM(units = 512, activation = \"relu\", return_sequences = False)(x)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "model.summary()\n",
    "\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = len(x), epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc974cfe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 574ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdc6666d0a0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5797253251075745,\n",
       " 0.4915603995323181,\n",
       " -0.8667244911193848,\n",
       " -0.5,\n",
       " -0.23478007316589355,\n",
       " 0.6816413998603821,\n",
       " -0.36398664116859436,\n",
       " -0.6307228803634644,\n",
       " 0.10846006870269775,\n",
       " -0.0008369386196136475,\n",
       " 0.002753734588623047,\n",
       " 0.06834695488214493,\n",
       " 0.0017560720443725586,\n",
       " -0.07213879376649857,\n",
       " -0.03258407115936279,\n",
       " -0.06198304891586304,\n",
       " -0.005166113376617432,\n",
       " 0.045560240745544434,\n",
       " 0.07029014825820923,\n",
       " -0.029395341873168945,\n",
       " -0.047061145305633545,\n",
       " 0.08965520560741425,\n",
       " -0.036761268973350525,\n",
       " -0.06668856739997864]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "SINGLE_SE = list()\n",
    "\n",
    "def single_sa(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        c = a - b\n",
    "        output.append(float(c[0]))\n",
    "\n",
    "    return output\n",
    "\n",
    "# 標準化を元の縮尺に戻す関数\n",
    "def decode(x):\n",
    "    return x * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"]\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    SINGLE_SE.append(single_sa(x, y))\n",
    "SINGLE_SE[0]\n",
    "\n",
    "min_SINGLE_SE = list()\n",
    "max_SINGLE_SE = list()\n",
    "\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    decode_min = decode(min(SINGLE_SE[i]))\n",
    "    decode_min_index = SINGLE_SE[i].index(min(SINGLE_SE[i]))\n",
    "    decode_max = decode(max(SINGLE_SE[i]))\n",
    "    decode_max_index = SINGLE_SE[i].index(max(SINGLE_SE[i]))\n",
    "    min_SINGLE_SE.append([decode_min, decode_min_index])\n",
    "    max_SINGLE_SE.append([decode_max, decode_max_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 2番目 -9.8274%, max : 5番目 15.126%\n",
      "min : 1番目 -8.5522%, max : 3番目 16.323%\n",
      "min : 5番目 -3.2361%, max : 0番目 22.145%\n",
      "min : 0番目 -4.5157%, max : 9番目 6.9924%\n",
      "min : 4番目 0.4726%, max : 2番目 20.01%\n",
      "min : 1番目 -20.866%, max : 2番目 14.728%\n",
      "min : 4番目 -21.416%, max : 0番目 30.962%\n",
      "min : 1番目 -40.847%, max : 0番目 20.163%\n",
      "min : 0番目 -15.611%, max : 4番目 9.6603%\n",
      "min : 6番目 -8.3548%, max : 2番目 32.923%\n"
     ]
    }
   ],
   "source": [
    "# 各入力データの1〜24(SPILT_SIZE)の中の最大、最小(上からグラフのソート順になってる)\n",
    "for a ,b in zip(min_SINGLE_SE,max_SINGLE_SE):\n",
    "    print(f\"min : {a[1]}番目 {a[0]:.5}%, max : {b[1]}番目 {b[0]:.5}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 407ms/step\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "# 各検証データの予測と正解のMSEをとる\n",
    "def mse(x, y):\n",
    "    tmp = 0.0\n",
    "    for a, b in zip(x, y):\n",
    "        tmp += (a - b) ** 2\n",
    "    tmp /= len(x)\n",
    "    return tmp\n",
    "# 各検証データに含まれるNヶ月の各予測と正解の二乗和誤差を算出する\n",
    "def single_se(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        output.append((a - b) ** 2)\n",
    "\n",
    "    return output\n",
    "\n",
    "MSE = []\n",
    "SINGLE_SE = []\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    MSE.append(mse(x, y))\n",
    "    SINGLE_SE.append(single_se(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSEの最小値：[0.02401841]、最大値：[0.43760762]\n",
      "\n",
      "0個目の検証用データにおけるSingle MSEの最小値：[7.004663e-07]、最大値：[0.75121135]\n",
      "1個目の検証用データにおけるSingle MSEの最小値：[1.6677279e-05]、最大値：[0.6203133]\n",
      "2個目の検証用データにおけるSingle MSEの最小値：[1.7798055e-06]、最大値：[1.2479926]\n",
      "3個目の検証用データにおけるSingle MSEの最小値：[0.00032992]、最大値：[0.28851172]\n",
      "4個目の検証用データにおけるSingle MSEの最小値：[1.0455449e-05]、最大値：[0.96960247]\n",
      "5個目の検証用データにおけるSingle MSEの最小値：[0.00047711]、最大値：[2.4077647]\n",
      "6個目の検証用データにおけるSingle MSEの最小値：[0.00011431]、最大値：[2.7697968]\n",
      "7個目の検証用データにおけるSingle MSEの最小値：[1.633222e-05]、最大値：[7.792389]\n",
      "8個目の検証用データにおけるSingle MSEの最小値：[4.9529312e-06]、最大値：[1.5021144]\n",
      "9個目の検証用データにおけるSingle MSEの最小値：[2.8256106e-06]、最大値：[3.1895304]\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSEの最小値：{min(MSE)}、最大値：{max(MSE)}\")\n",
    "print()\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    print(f\"{i}個目の検証用データにおけるSingle MSEの最小値：{min(SINGLE_SE[i])}、最大値：{max(SINGLE_SE[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN(1層)ミニバッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 3, 3)]            0         \n",
      "                                                                 \n",
      " simple_rnn_11 (SimpleRNN)   (None, 1024)              1052672   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,053,697\n",
      "Trainable params: 1,053,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 1.0057 - val_loss: 0.8991\n",
      "Epoch 2/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9172 - val_loss: 0.9610\n",
      "Epoch 3/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9060 - val_loss: 1.0079\n",
      "Epoch 4/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8984 - val_loss: 0.9781\n",
      "Epoch 5/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8829 - val_loss: 0.9416\n",
      "Epoch 6/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8711 - val_loss: 0.9189\n",
      "Epoch 7/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8634 - val_loss: 0.9009\n",
      "Epoch 8/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8574 - val_loss: 0.8960\n",
      "Epoch 9/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8516 - val_loss: 0.9043\n",
      "Epoch 10/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8444 - val_loss: 0.9034\n",
      "Epoch 11/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8407 - val_loss: 0.9125\n",
      "Epoch 12/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8366 - val_loss: 0.9083\n",
      "Epoch 13/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8351 - val_loss: 0.9167\n",
      "Epoch 14/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8308 - val_loss: 0.9041\n",
      "Epoch 15/1500\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.8292 - val_loss: 0.8888\n",
      "Epoch 16/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8256 - val_loss: 0.8903\n",
      "Epoch 17/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8251 - val_loss: 0.8941\n",
      "Epoch 18/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8223 - val_loss: 0.9099\n",
      "Epoch 19/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8218 - val_loss: 0.9072\n",
      "Epoch 20/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8203 - val_loss: 0.8940\n",
      "Epoch 21/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8186 - val_loss: 0.8973\n",
      "Epoch 22/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8187 - val_loss: 0.8878\n",
      "Epoch 23/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8165 - val_loss: 0.9008\n",
      "Epoch 24/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8161 - val_loss: 0.8961\n",
      "Epoch 25/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8148 - val_loss: 0.8975\n",
      "Epoch 26/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8149 - val_loss: 0.9143\n",
      "Epoch 27/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8144 - val_loss: 0.9034\n",
      "Epoch 28/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8123 - val_loss: 0.8950\n",
      "Epoch 29/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8126 - val_loss: 0.8894\n",
      "Epoch 30/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8141 - val_loss: 0.8830\n",
      "Epoch 31/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8126 - val_loss: 0.9058\n",
      "Epoch 32/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8127 - val_loss: 0.8964\n",
      "Epoch 33/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8107 - val_loss: 0.9055\n",
      "Epoch 34/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8099 - val_loss: 0.8893\n",
      "Epoch 35/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8089 - val_loss: 0.8951\n",
      "Epoch 36/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8089 - val_loss: 0.9001\n",
      "Epoch 37/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8076 - val_loss: 0.8934\n",
      "Epoch 38/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8075 - val_loss: 0.8875\n",
      "Epoch 39/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8070 - val_loss: 0.8917\n",
      "Epoch 40/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8070 - val_loss: 0.9013\n",
      "Epoch 41/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8090 - val_loss: 0.9183\n",
      "Epoch 42/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8063 - val_loss: 0.9000\n",
      "Epoch 43/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8049 - val_loss: 0.8803\n",
      "Epoch 44/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8058 - val_loss: 0.8772\n",
      "Epoch 45/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8059 - val_loss: 0.8934\n",
      "Epoch 46/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8076 - val_loss: 0.9090\n",
      "Epoch 47/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8044 - val_loss: 0.8864\n",
      "Epoch 48/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8058 - val_loss: 0.8832\n",
      "Epoch 49/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8069 - val_loss: 0.9107\n",
      "Epoch 50/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8033 - val_loss: 0.9010\n",
      "Epoch 51/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8055 - val_loss: 0.8815\n",
      "Epoch 52/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8026 - val_loss: 0.8906\n",
      "Epoch 53/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8025 - val_loss: 0.9015\n",
      "Epoch 54/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8023 - val_loss: 0.9057\n",
      "Epoch 55/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8020 - val_loss: 0.8974\n",
      "Epoch 56/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8063 - val_loss: 0.8692\n",
      "Epoch 57/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8037 - val_loss: 0.9020\n",
      "Epoch 58/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8013 - val_loss: 0.9045\n",
      "Epoch 59/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8004 - val_loss: 0.8887\n",
      "Epoch 60/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8005 - val_loss: 0.8963\n",
      "Epoch 61/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8001 - val_loss: 0.8896\n",
      "Epoch 62/1500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7995 - val_loss: 0.8870\n",
      "Epoch 63/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7994 - val_loss: 0.9036\n",
      "Epoch 64/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7986 - val_loss: 0.9012\n",
      "Epoch 65/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7981 - val_loss: 0.8873\n",
      "Epoch 66/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7994 - val_loss: 0.8872\n",
      "Epoch 67/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8003 - val_loss: 0.9063\n",
      "Epoch 68/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7989 - val_loss: 0.8884\n",
      "Epoch 69/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7996 - val_loss: 0.8737\n",
      "Epoch 70/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7979 - val_loss: 0.8994\n",
      "Epoch 71/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7975 - val_loss: 0.9112\n",
      "Epoch 72/1500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7965 - val_loss: 0.8975\n",
      "Epoch 73/1500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7966 - val_loss: 0.8859\n",
      "Epoch 74/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7974 - val_loss: 0.8805\n",
      "Epoch 75/1500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7951 - val_loss: 0.8956\n",
      "Epoch 76/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7961 - val_loss: 0.8935\n",
      "Epoch 77/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7948 - val_loss: 0.8987\n",
      "Epoch 78/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7955 - val_loss: 0.9068\n",
      "Epoch 79/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7948 - val_loss: 0.8980\n",
      "Epoch 80/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7952 - val_loss: 0.8896\n",
      "Epoch 81/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7938 - val_loss: 0.8807\n",
      "Epoch 82/1500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7959 - val_loss: 0.8760\n",
      "Epoch 83/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7983 - val_loss: 0.9063\n",
      "Epoch 84/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7954 - val_loss: 0.9026\n",
      "Epoch 85/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7970 - val_loss: 0.8717\n",
      "Epoch 86/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7944 - val_loss: 0.8889\n",
      "Epoch 87/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7976 - val_loss: 0.9254\n",
      "Epoch 88/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7941 - val_loss: 0.8878\n",
      "Epoch 89/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7929 - val_loss: 0.8813\n",
      "Epoch 90/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7935 - val_loss: 0.8787\n",
      "Epoch 91/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7919 - val_loss: 0.8947\n",
      "Epoch 92/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7943 - val_loss: 0.9144\n",
      "Epoch 93/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7929 - val_loss: 0.8905\n",
      "Epoch 94/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7936 - val_loss: 0.8774\n",
      "Epoch 95/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7958 - val_loss: 0.8953\n",
      "Epoch 96/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7919 - val_loss: 0.8916\n",
      "Epoch 97/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7922 - val_loss: 0.8969\n",
      "Epoch 98/1500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7937 - val_loss: 0.8877\n",
      "Epoch 99/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7980 - val_loss: 0.9044\n",
      "Epoch 100/1500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7931 - val_loss: 0.8728\n",
      "Epoch 101/1500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7938 - val_loss: 0.8916\n",
      "Epoch 102/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7911 - val_loss: 0.8998\n",
      "Epoch 103/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7899 - val_loss: 0.8870\n",
      "Epoch 104/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7899 - val_loss: 0.8872\n",
      "Epoch 105/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7907 - val_loss: 0.9004\n",
      "Epoch 106/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7916 - val_loss: 0.8900\n",
      "Epoch 107/1500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7899 - val_loss: 0.8854\n",
      "Epoch 108/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7898 - val_loss: 0.8997\n",
      "Epoch 109/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7928 - val_loss: 0.8728\n",
      "Epoch 110/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7888 - val_loss: 0.8874\n",
      "Epoch 111/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7949 - val_loss: 0.9367\n",
      "Epoch 112/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7925 - val_loss: 0.8922\n",
      "Epoch 113/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7890 - val_loss: 0.8735\n",
      "Epoch 114/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7887 - val_loss: 0.8841\n",
      "Epoch 115/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7898 - val_loss: 0.9034\n",
      "Epoch 116/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7876 - val_loss: 0.8946\n",
      "Epoch 117/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7885 - val_loss: 0.8814\n",
      "Epoch 118/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7870 - val_loss: 0.8929\n",
      "Epoch 119/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7910 - val_loss: 0.9238\n",
      "Epoch 120/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7873 - val_loss: 0.8877\n",
      "Epoch 121/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7869 - val_loss: 0.8801\n",
      "Epoch 122/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7881 - val_loss: 0.8872\n",
      "Epoch 123/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7868 - val_loss: 0.9124\n",
      "Epoch 124/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7871 - val_loss: 0.8934\n",
      "Epoch 125/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7852 - val_loss: 0.8827\n",
      "Epoch 126/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7881 - val_loss: 0.8761\n",
      "Epoch 127/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7865 - val_loss: 0.8897\n",
      "Epoch 128/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7879 - val_loss: 0.9214\n",
      "Epoch 129/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7886 - val_loss: 0.8985\n",
      "Epoch 130/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7899 - val_loss: 0.8714\n",
      "Epoch 131/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7864 - val_loss: 0.8913\n",
      "Epoch 132/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7846 - val_loss: 0.9067\n",
      "Epoch 133/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7870 - val_loss: 0.9076\n",
      "Epoch 134/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7833 - val_loss: 0.8831\n",
      "Epoch 135/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7860 - val_loss: 0.8684\n",
      "Epoch 136/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7845 - val_loss: 0.8913\n",
      "Epoch 137/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7841 - val_loss: 0.9061\n",
      "Epoch 138/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7839 - val_loss: 0.9023\n",
      "Epoch 139/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7863 - val_loss: 0.8786\n",
      "Epoch 140/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7850 - val_loss: 0.8944\n",
      "Epoch 141/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7881 - val_loss: 0.8765\n",
      "Epoch 142/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7867 - val_loss: 0.9113\n",
      "Epoch 143/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7869 - val_loss: 0.8788\n",
      "Epoch 144/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7857 - val_loss: 0.9038\n",
      "Epoch 145/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7830 - val_loss: 0.8981\n",
      "Epoch 146/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7845 - val_loss: 0.8754\n",
      "Epoch 147/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7841 - val_loss: 0.8954\n",
      "Epoch 148/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7825 - val_loss: 0.8833\n",
      "Epoch 149/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7842 - val_loss: 0.8984\n",
      "Epoch 150/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7828 - val_loss: 0.8818\n",
      "Epoch 151/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7819 - val_loss: 0.8943\n",
      "Epoch 152/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7826 - val_loss: 0.8970\n",
      "Epoch 153/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7858 - val_loss: 0.9073\n",
      "Epoch 154/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7830 - val_loss: 0.8869\n",
      "Epoch 155/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7812 - val_loss: 0.8698\n",
      "Epoch 156/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7840 - val_loss: 0.8845\n",
      "Epoch 157/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7815 - val_loss: 0.8989\n",
      "Epoch 158/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7831 - val_loss: 0.9101\n",
      "Epoch 159/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7829 - val_loss: 0.8740\n",
      "Epoch 160/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7829 - val_loss: 0.8913\n",
      "Epoch 161/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7813 - val_loss: 0.8887\n",
      "Epoch 162/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7813 - val_loss: 0.8998\n",
      "Epoch 163/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7802 - val_loss: 0.8898\n",
      "Epoch 164/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7814 - val_loss: 0.8898\n",
      "Epoch 165/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7808 - val_loss: 0.8828\n",
      "Epoch 166/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7804 - val_loss: 0.8847\n",
      "Epoch 167/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7801 - val_loss: 0.8932\n",
      "Epoch 168/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7801 - val_loss: 0.8948\n",
      "Epoch 169/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7805 - val_loss: 0.8799\n",
      "Epoch 170/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7808 - val_loss: 0.8883\n",
      "Epoch 171/1500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7799 - val_loss: 0.9113\n",
      "Epoch 172/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7822 - val_loss: 0.9149\n",
      "Epoch 173/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7836 - val_loss: 0.8627\n",
      "Epoch 174/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7836 - val_loss: 0.8783\n",
      "Epoch 175/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7817 - val_loss: 0.9391\n",
      "Epoch 176/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7865 - val_loss: 0.8885\n",
      "Epoch 177/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7843 - val_loss: 0.9055\n",
      "Epoch 178/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7813 - val_loss: 0.8694\n",
      "Epoch 179/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7817 - val_loss: 0.8934\n",
      "Epoch 180/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7818 - val_loss: 0.9172\n",
      "Epoch 181/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7789 - val_loss: 0.8849\n",
      "Epoch 182/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7786 - val_loss: 0.8807\n",
      "Epoch 183/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7794 - val_loss: 0.8830\n",
      "Epoch 184/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7785 - val_loss: 0.8965\n",
      "Epoch 185/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7781 - val_loss: 0.8954\n",
      "Epoch 186/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7790 - val_loss: 0.8869\n",
      "Epoch 187/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7793 - val_loss: 0.8848\n",
      "Epoch 188/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7817 - val_loss: 0.9276\n",
      "Epoch 189/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7807 - val_loss: 0.9018\n",
      "Epoch 190/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7822 - val_loss: 0.8593\n",
      "Epoch 191/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7854 - val_loss: 0.9085\n",
      "Epoch 192/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7796 - val_loss: 0.8946\n",
      "Epoch 193/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7791 - val_loss: 0.8861\n",
      "Epoch 194/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7782 - val_loss: 0.8978\n",
      "Epoch 195/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7782 - val_loss: 0.8875\n",
      "Epoch 196/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7783 - val_loss: 0.8807\n",
      "Epoch 197/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7820 - val_loss: 0.9085\n",
      "Epoch 198/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7780 - val_loss: 0.8930\n",
      "Epoch 199/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7794 - val_loss: 0.8697\n",
      "Epoch 200/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7776 - val_loss: 0.8984\n",
      "Epoch 201/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7779 - val_loss: 0.8966\n",
      "Epoch 202/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7784 - val_loss: 0.9038\n",
      "Epoch 203/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7767 - val_loss: 0.8916\n",
      "Epoch 204/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7788 - val_loss: 0.8749\n",
      "Epoch 205/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7767 - val_loss: 0.9061\n",
      "Epoch 206/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7783 - val_loss: 0.8882\n",
      "Epoch 207/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7786 - val_loss: 0.8981\n",
      "Epoch 208/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7866 - val_loss: 0.9323\n",
      "Epoch 209/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7818 - val_loss: 0.8604\n",
      "Epoch 210/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7844 - val_loss: 0.8669\n",
      "Epoch 211/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7795 - val_loss: 0.9346\n",
      "Epoch 212/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7809 - val_loss: 0.9013\n",
      "Epoch 213/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7793 - val_loss: 0.8745\n",
      "Epoch 214/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7779 - val_loss: 0.8873\n",
      "Epoch 215/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7777 - val_loss: 0.9120\n",
      "Epoch 216/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7812 - val_loss: 0.9058\n",
      "Epoch 217/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7781 - val_loss: 0.8708\n",
      "Epoch 218/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7804 - val_loss: 0.9038\n",
      "Epoch 219/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7766 - val_loss: 0.8856\n",
      "Epoch 220/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7791 - val_loss: 0.8863\n",
      "Epoch 221/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7792 - val_loss: 0.8944\n",
      "Epoch 222/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7763 - val_loss: 0.9139\n",
      "Epoch 223/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7774 - val_loss: 0.8869\n",
      "Epoch 224/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7768 - val_loss: 0.8885\n",
      "Epoch 225/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7782 - val_loss: 0.8761\n",
      "Epoch 226/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7799 - val_loss: 0.9042\n",
      "Epoch 227/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7793 - val_loss: 0.8970\n",
      "Epoch 228/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7766 - val_loss: 0.8696\n",
      "Epoch 229/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7768 - val_loss: 0.9035\n",
      "Epoch 230/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7759 - val_loss: 0.8958\n",
      "Epoch 231/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7774 - val_loss: 0.9104\n",
      "Epoch 232/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7767 - val_loss: 0.8758\n",
      "Epoch 233/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7746 - val_loss: 0.8869\n",
      "Epoch 234/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7791 - val_loss: 0.9208\n",
      "Epoch 235/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7760 - val_loss: 0.8995\n",
      "Epoch 236/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7772 - val_loss: 0.8656\n",
      "Epoch 237/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7759 - val_loss: 0.8849\n",
      "Epoch 238/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7752 - val_loss: 0.9215\n",
      "Epoch 239/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7756 - val_loss: 0.8900\n",
      "Epoch 240/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7749 - val_loss: 0.8755\n",
      "Epoch 241/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7748 - val_loss: 0.8983\n",
      "Epoch 242/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7750 - val_loss: 0.8980\n",
      "Epoch 243/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7758 - val_loss: 0.8740\n",
      "Epoch 244/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7746 - val_loss: 0.9014\n",
      "Epoch 245/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7743 - val_loss: 0.9098\n",
      "Epoch 246/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7736 - val_loss: 0.8860\n",
      "Epoch 247/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7745 - val_loss: 0.8763\n",
      "Epoch 248/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7747 - val_loss: 0.9086\n",
      "Epoch 249/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7732 - val_loss: 0.8975\n",
      "Epoch 250/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7738 - val_loss: 0.8862\n",
      "Epoch 251/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7736 - val_loss: 0.8944\n",
      "Epoch 252/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7724 - val_loss: 0.8876\n",
      "Epoch 253/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7751 - val_loss: 0.9082\n",
      "Epoch 254/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7801 - val_loss: 0.8600\n",
      "Epoch 255/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7801 - val_loss: 0.9249\n",
      "Epoch 256/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7773 - val_loss: 0.9148\n",
      "Epoch 257/1500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7745 - val_loss: 0.8555\n",
      "Epoch 258/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7807 - val_loss: 0.8961\n",
      "Epoch 259/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7749 - val_loss: 0.9327\n",
      "Epoch 260/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7765 - val_loss: 0.8760\n",
      "Epoch 261/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7733 - val_loss: 0.8840\n",
      "Epoch 262/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7724 - val_loss: 0.8986\n",
      "Epoch 263/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7724 - val_loss: 0.8958\n",
      "Epoch 264/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7728 - val_loss: 0.8720\n",
      "Epoch 265/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7762 - val_loss: 0.9032\n",
      "Epoch 266/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7712 - val_loss: 0.8882\n",
      "Epoch 267/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7754 - val_loss: 0.8687\n",
      "Epoch 268/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7780 - val_loss: 0.9249\n",
      "Epoch 269/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7748 - val_loss: 0.8997\n",
      "Epoch 270/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7744 - val_loss: 0.8867\n",
      "Epoch 271/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7754 - val_loss: 0.8893\n",
      "Epoch 272/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7739 - val_loss: 0.9099\n",
      "Epoch 273/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7735 - val_loss: 0.8841\n",
      "Epoch 274/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7753 - val_loss: 0.8706\n",
      "Epoch 275/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7735 - val_loss: 0.9258\n",
      "Epoch 276/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7757 - val_loss: 0.8903\n",
      "Epoch 277/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7742 - val_loss: 0.8669\n",
      "Epoch 278/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7716 - val_loss: 0.9112\n",
      "Epoch 279/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7727 - val_loss: 0.9019\n",
      "Epoch 280/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7732 - val_loss: 0.8744\n",
      "Epoch 281/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7724 - val_loss: 0.8982\n",
      "Epoch 282/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7716 - val_loss: 0.8952\n",
      "Epoch 283/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7709 - val_loss: 0.8790\n",
      "Epoch 284/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7714 - val_loss: 0.8892\n",
      "Epoch 285/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7710 - val_loss: 0.9099\n",
      "Epoch 286/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7702 - val_loss: 0.8889\n",
      "Epoch 287/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7710 - val_loss: 0.8779\n",
      "Epoch 288/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7715 - val_loss: 0.8935\n",
      "Epoch 289/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7715 - val_loss: 0.8883\n",
      "Epoch 290/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7763 - val_loss: 0.9098\n",
      "Epoch 291/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7787 - val_loss: 0.8628\n",
      "Epoch 292/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7718 - val_loss: 0.9228\n",
      "Epoch 293/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7733 - val_loss: 0.9009\n",
      "Epoch 294/1500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7731 - val_loss: 0.8647\n",
      "Epoch 295/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7714 - val_loss: 0.9037\n",
      "Epoch 296/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7704 - val_loss: 0.9063\n",
      "Epoch 297/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7702 - val_loss: 0.8851\n",
      "Epoch 298/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7695 - val_loss: 0.8833\n",
      "Epoch 299/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7698 - val_loss: 0.8865\n",
      "Epoch 300/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7692 - val_loss: 0.9059\n",
      "Epoch 301/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7712 - val_loss: 0.9118\n",
      "Epoch 302/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7685 - val_loss: 0.8685\n",
      "Epoch 303/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7705 - val_loss: 0.8677\n",
      "Epoch 304/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7704 - val_loss: 0.9153\n",
      "Epoch 305/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7700 - val_loss: 0.9042\n",
      "Epoch 306/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7691 - val_loss: 0.8713\n",
      "Epoch 307/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7706 - val_loss: 0.8928\n",
      "Epoch 308/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7754 - val_loss: 0.9361\n",
      "Epoch 309/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7704 - val_loss: 0.8733\n",
      "Epoch 310/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7713 - val_loss: 0.8703\n",
      "Epoch 311/1500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7688 - val_loss: 0.9229\n",
      "Epoch 312/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7750 - val_loss: 0.9179\n",
      "Epoch 313/1500\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7706 - val_loss: 0.8424\n",
      "Epoch 314/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7754 - val_loss: 0.8780\n",
      "Epoch 315/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7727 - val_loss: 0.9429\n",
      "Epoch 316/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7711 - val_loss: 0.8962\n",
      "Epoch 317/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7684 - val_loss: 0.8605\n",
      "Epoch 318/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7693 - val_loss: 0.8940\n",
      "Epoch 319/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7687 - val_loss: 0.9162\n",
      "Epoch 320/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7677 - val_loss: 0.8885\n",
      "Epoch 321/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7678 - val_loss: 0.8802\n",
      "Epoch 322/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7719 - val_loss: 0.8752\n",
      "Epoch 323/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7702 - val_loss: 0.9394\n",
      "Epoch 324/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7709 - val_loss: 0.8879\n",
      "Epoch 325/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7762 - val_loss: 0.8533\n",
      "Epoch 326/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7729 - val_loss: 0.9292\n",
      "Epoch 327/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7711 - val_loss: 0.9020\n",
      "Epoch 328/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7681 - val_loss: 0.8646\n",
      "Epoch 329/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7762 - val_loss: 0.9211\n",
      "Epoch 330/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7710 - val_loss: 0.8786\n",
      "Epoch 331/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7700 - val_loss: 0.9073\n",
      "Epoch 332/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7673 - val_loss: 0.8895\n",
      "Epoch 333/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7692 - val_loss: 0.8734\n",
      "Epoch 334/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7693 - val_loss: 0.9136\n",
      "Epoch 335/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7688 - val_loss: 0.8938\n",
      "Epoch 336/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7675 - val_loss: 0.8666\n",
      "Epoch 337/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7688 - val_loss: 0.9006\n",
      "Epoch 338/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7674 - val_loss: 0.9067\n",
      "Epoch 339/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7678 - val_loss: 0.8979\n",
      "Epoch 340/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7668 - val_loss: 0.8851\n",
      "Epoch 341/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7682 - val_loss: 0.8768\n",
      "Epoch 342/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7674 - val_loss: 0.9044\n",
      "Epoch 343/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7687 - val_loss: 0.8920\n",
      "Epoch 344/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7704 - val_loss: 0.8670\n",
      "Epoch 345/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7668 - val_loss: 0.9225\n",
      "Epoch 346/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7724 - val_loss: 0.9148\n",
      "Epoch 347/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7665 - val_loss: 0.8619\n",
      "Epoch 348/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7712 - val_loss: 0.8782\n",
      "Epoch 349/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7674 - val_loss: 0.9342\n",
      "Epoch 350/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7684 - val_loss: 0.8973\n",
      "Epoch 351/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7720 - val_loss: 0.8567\n",
      "Epoch 352/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7689 - val_loss: 0.9157\n",
      "Epoch 353/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7733 - val_loss: 0.9279\n",
      "Epoch 354/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7702 - val_loss: 0.8531\n",
      "Epoch 355/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7734 - val_loss: 0.8918\n",
      "Epoch 356/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7672 - val_loss: 0.9106\n",
      "Epoch 357/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7678 - val_loss: 0.8990\n",
      "Epoch 358/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7666 - val_loss: 0.8814\n",
      "Epoch 359/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7683 - val_loss: 0.8881\n",
      "Epoch 360/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7663 - val_loss: 0.9166\n",
      "Epoch 361/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7725 - val_loss: 0.9031\n",
      "Epoch 362/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7652 - val_loss: 0.8675\n",
      "Epoch 363/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7737 - val_loss: 0.8580\n",
      "Epoch 364/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7630 - val_loss: 0.9478\n",
      "Epoch 365/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7709 - val_loss: 0.9255\n",
      "Epoch 366/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7646 - val_loss: 0.8647\n",
      "Epoch 367/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7679 - val_loss: 0.8865\n",
      "Epoch 368/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7657 - val_loss: 0.9031\n",
      "Epoch 369/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7655 - val_loss: 0.8887\n",
      "Epoch 370/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7652 - val_loss: 0.8869\n",
      "Epoch 371/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7678 - val_loss: 0.8684\n",
      "Epoch 372/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7698 - val_loss: 0.9369\n",
      "Epoch 373/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7716 - val_loss: 0.8723\n",
      "Epoch 374/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7674 - val_loss: 0.8960\n",
      "Epoch 375/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7652 - val_loss: 0.9188\n",
      "Epoch 376/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7663 - val_loss: 0.8871\n",
      "Epoch 377/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7646 - val_loss: 0.8760\n",
      "Epoch 378/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7672 - val_loss: 0.9101\n",
      "Epoch 379/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7655 - val_loss: 0.8754\n",
      "Epoch 380/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7656 - val_loss: 0.8901\n",
      "Epoch 381/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7657 - val_loss: 0.9099\n",
      "Epoch 382/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7681 - val_loss: 0.9136\n",
      "Epoch 383/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7619 - val_loss: 0.8687\n",
      "Epoch 384/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7711 - val_loss: 0.8812\n",
      "Epoch 385/1500\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7668 - val_loss: 0.9411\n",
      "Epoch 386/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7669 - val_loss: 0.8800\n",
      "Epoch 387/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7649 - val_loss: 0.8817\n",
      "Epoch 388/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7648 - val_loss: 0.9087\n",
      "Epoch 389/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7665 - val_loss: 0.9034\n",
      "Epoch 390/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7727 - val_loss: 0.8559\n",
      "Epoch 391/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7660 - val_loss: 0.9390\n",
      "Epoch 392/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7750 - val_loss: 0.9192\n",
      "Epoch 393/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7699 - val_loss: 0.8465\n",
      "Epoch 394/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7682 - val_loss: 0.9016\n",
      "Epoch 395/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7689 - val_loss: 0.9446\n",
      "Epoch 396/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7655 - val_loss: 0.8744\n",
      "Epoch 397/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7658 - val_loss: 0.8817\n",
      "Epoch 398/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7641 - val_loss: 0.9020\n",
      "Epoch 399/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7678 - val_loss: 0.9304\n",
      "Epoch 400/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7725 - val_loss: 0.8674\n",
      "Epoch 401/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7643 - val_loss: 0.8975\n",
      "Epoch 402/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7697 - val_loss: 0.9523\n",
      "Epoch 403/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7677 - val_loss: 0.8643\n",
      "Epoch 404/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7700 - val_loss: 0.8802\n",
      "Epoch 405/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7733 - val_loss: 0.9436\n",
      "Epoch 406/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7672 - val_loss: 0.8547\n",
      "Epoch 407/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7687 - val_loss: 0.8804\n",
      "Epoch 408/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7685 - val_loss: 0.9660\n",
      "Epoch 409/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7663 - val_loss: 0.8896\n",
      "Epoch 410/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7652 - val_loss: 0.8557\n",
      "Epoch 411/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7647 - val_loss: 0.9073\n",
      "Epoch 412/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7692 - val_loss: 0.9341\n",
      "Epoch 413/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7663 - val_loss: 0.8636\n",
      "Epoch 414/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7660 - val_loss: 0.9044\n",
      "Epoch 415/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7692 - val_loss: 0.9194\n",
      "Epoch 416/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7615 - val_loss: 0.8707\n",
      "Epoch 417/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7667 - val_loss: 0.8779\n",
      "Epoch 418/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7646 - val_loss: 0.9323\n",
      "Epoch 419/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7654 - val_loss: 0.8981\n",
      "Epoch 420/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7631 - val_loss: 0.8631\n",
      "Epoch 421/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7667 - val_loss: 0.9118\n",
      "Epoch 422/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7634 - val_loss: 0.9025\n",
      "Epoch 423/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7624 - val_loss: 0.8918\n",
      "Epoch 424/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7637 - val_loss: 0.8946\n",
      "Epoch 425/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7639 - val_loss: 0.9039\n",
      "Epoch 426/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7644 - val_loss: 0.9215\n",
      "Epoch 427/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7656 - val_loss: 0.8775\n",
      "Epoch 428/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7634 - val_loss: 0.8993\n",
      "Epoch 429/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7661 - val_loss: 0.9209\n",
      "Epoch 430/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7608 - val_loss: 0.8717\n",
      "Epoch 431/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7646 - val_loss: 0.8819\n",
      "Epoch 432/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7629 - val_loss: 0.9115\n",
      "Epoch 433/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7663 - val_loss: 0.8892\n",
      "Epoch 434/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7637 - val_loss: 0.9130\n",
      "Epoch 435/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7684 - val_loss: 0.8873\n",
      "Epoch 436/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7611 - val_loss: 0.9159\n",
      "Epoch 437/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7649 - val_loss: 0.9152\n",
      "Epoch 438/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7622 - val_loss: 0.8805\n",
      "Epoch 439/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7634 - val_loss: 0.8883\n",
      "Epoch 440/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7620 - val_loss: 0.9124\n",
      "Epoch 441/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7620 - val_loss: 0.8965\n",
      "Epoch 442/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7614 - val_loss: 0.9013\n",
      "Epoch 443/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7618 - val_loss: 0.8974\n",
      "Epoch 444/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7622 - val_loss: 0.8972\n",
      "Epoch 445/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7616 - val_loss: 0.8923\n",
      "Epoch 446/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7625 - val_loss: 0.8887\n",
      "Epoch 447/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7641 - val_loss: 0.9022\n",
      "Epoch 448/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7609 - val_loss: 0.8855\n",
      "Epoch 449/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7631 - val_loss: 0.9052\n",
      "Epoch 450/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7605 - val_loss: 0.8840\n",
      "Epoch 451/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7621 - val_loss: 0.8984\n",
      "Epoch 452/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7650 - val_loss: 0.9295\n",
      "Epoch 453/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7658 - val_loss: 0.8710\n",
      "Epoch 454/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7664 - val_loss: 0.9418\n",
      "Epoch 455/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7628 - val_loss: 0.8954\n",
      "Epoch 456/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7607 - val_loss: 0.8737\n",
      "Epoch 457/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7623 - val_loss: 0.8882\n",
      "Epoch 458/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7623 - val_loss: 0.9167\n",
      "Epoch 459/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7612 - val_loss: 0.8843\n",
      "Epoch 460/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7628 - val_loss: 0.8889\n",
      "Epoch 461/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7606 - val_loss: 0.9303\n",
      "Epoch 462/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7672 - val_loss: 0.8806\n",
      "Epoch 463/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7599 - val_loss: 0.9146\n",
      "Epoch 464/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7604 - val_loss: 0.9132\n",
      "Epoch 465/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7620 - val_loss: 0.8801\n",
      "Epoch 466/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7610 - val_loss: 0.9025\n",
      "Epoch 467/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7624 - val_loss: 0.9128\n",
      "Epoch 468/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7602 - val_loss: 0.8866\n",
      "Epoch 469/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7627 - val_loss: 0.8988\n",
      "Epoch 470/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7615 - val_loss: 0.9024\n",
      "Epoch 471/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7616 - val_loss: 0.8924\n",
      "Epoch 472/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7616 - val_loss: 0.8884\n",
      "Epoch 473/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7612 - val_loss: 0.9179\n",
      "Epoch 474/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7609 - val_loss: 0.8973\n",
      "Epoch 475/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7668 - val_loss: 0.8716\n",
      "Epoch 476/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7654 - val_loss: 0.9279\n",
      "Epoch 477/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7626 - val_loss: 0.8751\n",
      "Epoch 478/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7642 - val_loss: 0.8952\n",
      "Epoch 479/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7648 - val_loss: 0.9569\n",
      "Epoch 480/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7610 - val_loss: 0.8764\n",
      "Epoch 481/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7684 - val_loss: 0.8698\n",
      "Epoch 482/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7657 - val_loss: 0.9628\n",
      "Epoch 483/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7654 - val_loss: 0.8844\n",
      "Epoch 484/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7616 - val_loss: 0.8915\n",
      "Epoch 485/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7636 - val_loss: 0.9424\n",
      "Epoch 486/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7595 - val_loss: 0.8705\n",
      "Epoch 487/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7634 - val_loss: 0.8986\n",
      "Epoch 488/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7601 - val_loss: 0.9119\n",
      "Epoch 489/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7614 - val_loss: 0.9047\n",
      "Epoch 490/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7628 - val_loss: 0.8753\n",
      "Epoch 491/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7617 - val_loss: 0.9393\n",
      "Epoch 492/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7628 - val_loss: 0.8902\n",
      "Epoch 493/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7661 - val_loss: 0.8671\n",
      "Epoch 494/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7646 - val_loss: 0.9610\n",
      "Epoch 495/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7623 - val_loss: 0.8936\n",
      "Epoch 496/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7602 - val_loss: 0.8709\n",
      "Epoch 497/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7627 - val_loss: 0.9193\n",
      "Epoch 498/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7615 - val_loss: 0.8865\n",
      "Epoch 499/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7631 - val_loss: 0.8879\n",
      "Epoch 500/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7582 - val_loss: 0.9190\n",
      "Epoch 501/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7605 - val_loss: 0.8934\n",
      "Epoch 502/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7603 - val_loss: 0.8990\n",
      "Epoch 503/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7665 - val_loss: 0.9393\n",
      "Epoch 504/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7651 - val_loss: 0.8505\n",
      "Epoch 505/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7660 - val_loss: 0.9020\n",
      "Epoch 506/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7694 - val_loss: 0.9715\n",
      "Epoch 507/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7626 - val_loss: 0.8630\n",
      "Epoch 508/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7641 - val_loss: 0.8872\n",
      "Epoch 509/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7590 - val_loss: 0.9391\n",
      "Epoch 510/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7611 - val_loss: 0.8892\n",
      "Epoch 511/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7616 - val_loss: 0.9072\n",
      "Epoch 512/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7592 - val_loss: 0.9021\n",
      "Epoch 513/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7616 - val_loss: 0.9123\n",
      "Epoch 514/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7589 - val_loss: 0.8884\n",
      "Epoch 515/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7589 - val_loss: 0.9102\n",
      "Epoch 516/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7590 - val_loss: 0.9070\n",
      "Epoch 517/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7593 - val_loss: 0.8969\n",
      "Epoch 518/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7590 - val_loss: 0.8988\n",
      "Epoch 519/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7590 - val_loss: 0.9015\n",
      "Epoch 520/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7610 - val_loss: 0.8968\n",
      "Epoch 521/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7623 - val_loss: 0.9031\n",
      "Epoch 522/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7623 - val_loss: 0.8994\n",
      "Epoch 523/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7613 - val_loss: 0.8936\n",
      "Epoch 524/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7598 - val_loss: 0.9300\n",
      "Epoch 525/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7644 - val_loss: 0.8789\n",
      "Epoch 526/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7607 - val_loss: 0.9287\n",
      "Epoch 527/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7589 - val_loss: 0.8979\n",
      "Epoch 528/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7589 - val_loss: 0.8958\n",
      "Epoch 529/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7587 - val_loss: 0.9251\n",
      "Epoch 530/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7584 - val_loss: 0.8999\n",
      "Epoch 531/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7609 - val_loss: 0.8787\n",
      "Epoch 532/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7636 - val_loss: 0.9391\n",
      "Epoch 533/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7587 - val_loss: 0.8786\n",
      "Epoch 534/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7687 - val_loss: 0.8837\n",
      "Epoch 535/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7703 - val_loss: 1.0232\n",
      "Epoch 536/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7705 - val_loss: 0.8531\n",
      "Epoch 537/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7802 - val_loss: 0.8673\n",
      "Epoch 538/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7649 - val_loss: 1.0076\n",
      "Epoch 539/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7732 - val_loss: 0.8877\n",
      "Epoch 540/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7704 - val_loss: 0.8554\n",
      "Epoch 541/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7629 - val_loss: 0.9521\n",
      "Epoch 542/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7640 - val_loss: 0.9199\n",
      "Epoch 543/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7594 - val_loss: 0.8854\n",
      "Epoch 544/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7672 - val_loss: 0.8817\n",
      "Epoch 545/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7683 - val_loss: 0.9654\n",
      "Epoch 546/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7622 - val_loss: 0.8845\n",
      "Epoch 547/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7624 - val_loss: 0.8741\n",
      "Epoch 548/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7599 - val_loss: 0.9395\n",
      "Epoch 549/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7612 - val_loss: 0.9152\n",
      "Epoch 550/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7603 - val_loss: 0.8746\n",
      "Epoch 551/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7593 - val_loss: 0.9251\n",
      "Epoch 552/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7618 - val_loss: 0.9209\n",
      "Epoch 553/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7579 - val_loss: 0.8803\n",
      "Epoch 554/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7609 - val_loss: 0.9055\n",
      "Epoch 555/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7735 - val_loss: 0.9557\n",
      "Epoch 556/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7616 - val_loss: 0.8465\n",
      "Epoch 557/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7715 - val_loss: 0.9035\n",
      "Epoch 558/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7612 - val_loss: 0.9662\n",
      "Epoch 559/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7621 - val_loss: 0.8755\n",
      "Epoch 560/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7665 - val_loss: 0.8644\n",
      "Epoch 561/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7648 - val_loss: 0.9780\n",
      "Epoch 562/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7663 - val_loss: 0.8924\n",
      "Epoch 563/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7615 - val_loss: 0.8682\n",
      "Epoch 564/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7603 - val_loss: 0.9188\n",
      "Epoch 565/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7590 - val_loss: 0.9138\n",
      "Epoch 566/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7576 - val_loss: 0.9055\n",
      "Epoch 567/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7586 - val_loss: 0.9180\n",
      "Epoch 568/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7568 - val_loss: 0.8907\n",
      "Epoch 569/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7579 - val_loss: 0.8995\n",
      "Epoch 570/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7601 - val_loss: 0.9406\n",
      "Epoch 571/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7577 - val_loss: 0.8843\n",
      "Epoch 572/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7603 - val_loss: 0.8867\n",
      "Epoch 573/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7621 - val_loss: 0.9442\n",
      "Epoch 574/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7591 - val_loss: 0.8808\n",
      "Epoch 575/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7591 - val_loss: 0.9004\n",
      "Epoch 576/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7581 - val_loss: 0.9549\n",
      "Epoch 577/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7585 - val_loss: 0.8873\n",
      "Epoch 578/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7580 - val_loss: 0.8809\n",
      "Epoch 579/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7570 - val_loss: 0.9190\n",
      "Epoch 580/1500\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7593 - val_loss: 0.9375\n",
      "Epoch 581/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7595 - val_loss: 0.8799\n",
      "Epoch 582/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7590 - val_loss: 0.9075\n",
      "Epoch 583/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7599 - val_loss: 0.9302\n",
      "Epoch 584/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7575 - val_loss: 0.8798\n",
      "Epoch 585/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7585 - val_loss: 0.9029\n",
      "Epoch 586/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7562 - val_loss: 0.9151\n",
      "Epoch 587/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7577 - val_loss: 0.9039\n",
      "Epoch 588/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7573 - val_loss: 0.9127\n",
      "Epoch 589/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7581 - val_loss: 0.9038\n",
      "Epoch 590/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7585 - val_loss: 0.9102\n",
      "Epoch 591/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7592 - val_loss: 0.9019\n",
      "Epoch 592/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7579 - val_loss: 0.8971\n",
      "Epoch 593/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7580 - val_loss: 0.9071\n",
      "Epoch 594/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7592 - val_loss: 0.9025\n",
      "Epoch 595/1500\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7574 - val_loss: 0.9177\n",
      "Epoch 596/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7592 - val_loss: 0.9133\n",
      "Epoch 597/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7611 - val_loss: 0.8770\n",
      "Epoch 598/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7592 - val_loss: 0.9435\n",
      "Epoch 599/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7600 - val_loss: 0.9078\n",
      "Epoch 600/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7587 - val_loss: 0.8882\n",
      "Epoch 601/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7569 - val_loss: 0.9309\n",
      "Epoch 602/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7577 - val_loss: 0.9096\n",
      "Epoch 603/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7578 - val_loss: 0.9006\n",
      "Epoch 604/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7572 - val_loss: 0.9127\n",
      "Epoch 605/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7562 - val_loss: 0.9069\n",
      "Epoch 606/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7556 - val_loss: 0.9086\n",
      "Epoch 607/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7556 - val_loss: 0.9014\n",
      "Epoch 608/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7567 - val_loss: 0.9093\n",
      "Epoch 609/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7566 - val_loss: 0.9060\n",
      "Epoch 610/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7565 - val_loss: 0.9174\n",
      "Epoch 611/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7562 - val_loss: 0.9003\n",
      "Epoch 612/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7557 - val_loss: 0.9076\n",
      "Epoch 613/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7570 - val_loss: 0.9227\n",
      "Epoch 614/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7584 - val_loss: 0.8876\n",
      "Epoch 615/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7557 - val_loss: 0.9262\n",
      "Epoch 616/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7573 - val_loss: 0.9126\n",
      "Epoch 617/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7564 - val_loss: 0.8936\n",
      "Epoch 618/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7557 - val_loss: 0.9230\n",
      "Epoch 619/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7560 - val_loss: 0.9036\n",
      "Epoch 620/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7564 - val_loss: 0.8970\n",
      "Epoch 621/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7584 - val_loss: 0.9189\n",
      "Epoch 622/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7593 - val_loss: 0.8843\n",
      "Epoch 623/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7585 - val_loss: 0.9478\n",
      "Epoch 624/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7612 - val_loss: 0.8838\n",
      "Epoch 625/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7589 - val_loss: 0.9336\n",
      "Epoch 626/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7563 - val_loss: 0.9004\n",
      "Epoch 627/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7553 - val_loss: 0.9069\n",
      "Epoch 628/1500\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7571 - val_loss: 0.9220\n",
      "Epoch 629/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7560 - val_loss: 0.8864\n",
      "Epoch 630/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7558 - val_loss: 0.9252\n",
      "Epoch 631/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7593 - val_loss: 0.9233\n",
      "Epoch 632/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7645 - val_loss: 0.8673\n",
      "Epoch 633/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7548 - val_loss: 0.9809\n",
      "Epoch 634/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7710 - val_loss: 0.9231\n",
      "Epoch 635/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7586 - val_loss: 0.8401\n",
      "Epoch 636/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7738 - val_loss: 0.9812\n",
      "Epoch 637/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7696 - val_loss: 0.9097\n",
      "Epoch 638/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7681 - val_loss: 0.8585\n",
      "Epoch 639/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7622 - val_loss: 0.9865\n",
      "Epoch 640/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7657 - val_loss: 0.8947\n",
      "Epoch 641/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7637 - val_loss: 0.8862\n",
      "Epoch 642/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7565 - val_loss: 0.9593\n",
      "Epoch 643/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7595 - val_loss: 0.9052\n",
      "Epoch 644/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7566 - val_loss: 0.8764\n",
      "Epoch 645/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7579 - val_loss: 0.9384\n",
      "Epoch 646/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7570 - val_loss: 0.9305\n",
      "Epoch 647/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7603 - val_loss: 0.8779\n",
      "Epoch 648/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7570 - val_loss: 0.9520\n",
      "Epoch 649/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7618 - val_loss: 0.8992\n",
      "Epoch 650/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7576 - val_loss: 0.8901\n",
      "Epoch 651/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7593 - val_loss: 0.9473\n",
      "Epoch 652/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7575 - val_loss: 0.8876\n",
      "Epoch 653/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7576 - val_loss: 0.9248\n",
      "Epoch 654/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7563 - val_loss: 0.9161\n",
      "Epoch 655/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7552 - val_loss: 0.9143\n",
      "Epoch 656/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7573 - val_loss: 0.8891\n",
      "Epoch 657/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7570 - val_loss: 0.9373\n",
      "Epoch 658/1500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7560 - val_loss: 0.8989\n",
      "Epoch 659/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7547 - val_loss: 0.9187\n",
      "Epoch 660/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7579 - val_loss: 0.9134\n",
      "Epoch 661/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7571 - val_loss: 0.9397\n",
      "Epoch 662/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7580 - val_loss: 0.8836\n",
      "Epoch 663/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7588 - val_loss: 0.9323\n",
      "Epoch 664/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7576 - val_loss: 0.8921\n",
      "Epoch 665/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7545 - val_loss: 0.9349\n",
      "Epoch 666/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7568 - val_loss: 0.9127\n",
      "Epoch 667/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7558 - val_loss: 0.8943\n",
      "Epoch 668/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7562 - val_loss: 0.9217\n",
      "Epoch 669/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7597 - val_loss: 0.9362\n",
      "Epoch 670/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7603 - val_loss: 0.8724\n",
      "Epoch 671/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7574 - val_loss: 0.9452\n",
      "Epoch 672/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7625 - val_loss: 0.9476\n",
      "Epoch 673/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7585 - val_loss: 0.8628\n",
      "Epoch 674/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7689 - val_loss: 0.9411\n",
      "Epoch 675/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7562 - val_loss: 0.8943\n",
      "Epoch 676/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7567 - val_loss: 0.9023\n",
      "Epoch 677/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7558 - val_loss: 0.9166\n",
      "Epoch 678/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7558 - val_loss: 0.9209\n",
      "Epoch 679/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7551 - val_loss: 0.9113\n",
      "Epoch 680/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7548 - val_loss: 0.9105\n",
      "Epoch 681/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7544 - val_loss: 0.9132\n",
      "Epoch 682/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7550 - val_loss: 0.9285\n",
      "Epoch 683/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7540 - val_loss: 0.9198\n",
      "Epoch 684/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7538 - val_loss: 0.9052\n",
      "Epoch 685/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7565 - val_loss: 0.9162\n",
      "Epoch 686/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7545 - val_loss: 0.9274\n",
      "Epoch 687/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7547 - val_loss: 0.9093\n",
      "Epoch 688/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7554 - val_loss: 0.8913\n",
      "Epoch 689/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7541 - val_loss: 0.9470\n",
      "Epoch 690/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7564 - val_loss: 0.9135\n",
      "Epoch 691/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7539 - val_loss: 0.8892\n",
      "Epoch 692/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7541 - val_loss: 0.9279\n",
      "Epoch 693/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7573 - val_loss: 0.9309\n",
      "Epoch 694/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7573 - val_loss: 0.8834\n",
      "Epoch 695/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7544 - val_loss: 0.9437\n",
      "Epoch 696/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7550 - val_loss: 0.9134\n",
      "Epoch 697/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7531 - val_loss: 0.8950\n",
      "Epoch 698/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7561 - val_loss: 0.9290\n",
      "Epoch 699/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7569 - val_loss: 0.9025\n",
      "Epoch 700/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7528 - val_loss: 0.9467\n",
      "Epoch 701/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7599 - val_loss: 0.9189\n",
      "Epoch 702/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7561 - val_loss: 0.8703\n",
      "Epoch 703/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7582 - val_loss: 0.9391\n",
      "Epoch 704/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7549 - val_loss: 0.9199\n",
      "Epoch 705/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7533 - val_loss: 0.9122\n",
      "Epoch 706/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7552 - val_loss: 0.9182\n",
      "Epoch 707/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7641 - val_loss: 0.9371\n",
      "Epoch 708/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7658 - val_loss: 0.8762\n",
      "Epoch 709/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7530 - val_loss: 0.9504\n",
      "Epoch 710/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7569 - val_loss: 0.9255\n",
      "Epoch 711/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7539 - val_loss: 0.8985\n",
      "Epoch 712/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7596 - val_loss: 0.9194\n",
      "Epoch 713/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7582 - val_loss: 0.9770\n",
      "Epoch 714/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7608 - val_loss: 0.8725\n",
      "Epoch 715/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7583 - val_loss: 0.9198\n",
      "Epoch 716/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7531 - val_loss: 0.9194\n",
      "Epoch 717/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7547 - val_loss: 0.9220\n",
      "Epoch 718/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7547 - val_loss: 0.8869\n",
      "Epoch 719/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7539 - val_loss: 0.9400\n",
      "Epoch 720/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7604 - val_loss: 0.9518\n",
      "Epoch 721/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7588 - val_loss: 0.8640\n",
      "Epoch 722/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7622 - val_loss: 0.9695\n",
      "Epoch 723/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7642 - val_loss: 0.9279\n",
      "Epoch 724/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7599 - val_loss: 0.8671\n",
      "Epoch 725/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7620 - val_loss: 0.9533\n",
      "Epoch 726/1500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7592 - val_loss: 0.9019\n",
      "Epoch 727/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7549 - val_loss: 0.9119\n",
      "Epoch 728/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7559 - val_loss: 0.9328\n",
      "Epoch 729/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7550 - val_loss: 0.8956\n",
      "Epoch 730/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7567 - val_loss: 0.9429\n",
      "Epoch 731/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7542 - val_loss: 0.9126\n",
      "Epoch 732/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7548 - val_loss: 0.8941\n",
      "Epoch 733/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7536 - val_loss: 0.9335\n",
      "Epoch 734/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7543 - val_loss: 0.9276\n",
      "Epoch 735/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7539 - val_loss: 0.9163\n",
      "Epoch 736/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7542 - val_loss: 0.9277\n",
      "Epoch 737/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7547 - val_loss: 0.9266\n",
      "Epoch 738/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7566 - val_loss: 0.8982\n",
      "Epoch 739/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7568 - val_loss: 0.9364\n",
      "Epoch 740/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7527 - val_loss: 0.8944\n",
      "Epoch 741/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7541 - val_loss: 0.9144\n",
      "Epoch 742/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7536 - val_loss: 0.9169\n",
      "Epoch 743/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7530 - val_loss: 0.9098\n",
      "Epoch 744/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7528 - val_loss: 0.9143\n",
      "Epoch 745/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7538 - val_loss: 0.9395\n",
      "Epoch 746/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7539 - val_loss: 0.9060\n",
      "Epoch 747/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7580 - val_loss: 0.9298\n",
      "Epoch 748/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7584 - val_loss: 0.8813\n",
      "Epoch 749/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7552 - val_loss: 0.9591\n",
      "Epoch 750/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7568 - val_loss: 0.9113\n",
      "Epoch 751/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7572 - val_loss: 0.8847\n",
      "Epoch 752/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7551 - val_loss: 0.9658\n",
      "Epoch 753/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7561 - val_loss: 0.8930\n",
      "Epoch 754/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7625 - val_loss: 0.9168\n",
      "Epoch 755/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7533 - val_loss: 0.9714\n",
      "Epoch 756/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7550 - val_loss: 0.9019\n",
      "Epoch 757/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7562 - val_loss: 0.8982\n",
      "Epoch 758/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7528 - val_loss: 0.9473\n",
      "Epoch 759/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7579 - val_loss: 0.9213\n",
      "Epoch 760/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7614 - val_loss: 0.8728\n",
      "Epoch 761/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7522 - val_loss: 0.9808\n",
      "Epoch 762/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7647 - val_loss: 0.9327\n",
      "Epoch 763/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7665 - val_loss: 0.8457\n",
      "Epoch 764/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7598 - val_loss: 0.9560\n",
      "Epoch 765/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7668 - val_loss: 0.9637\n",
      "Epoch 766/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7592 - val_loss: 0.8539\n",
      "Epoch 767/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7625 - val_loss: 0.9177\n",
      "Epoch 768/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7570 - val_loss: 0.9624\n",
      "Epoch 769/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7605 - val_loss: 0.8840\n",
      "Epoch 770/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7565 - val_loss: 0.9134\n",
      "Epoch 771/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7564 - val_loss: 0.9508\n",
      "Epoch 772/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7514 - val_loss: 0.8882\n",
      "Epoch 773/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7561 - val_loss: 0.9000\n",
      "Epoch 774/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7531 - val_loss: 0.9351\n",
      "Epoch 775/1500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7546 - val_loss: 0.9193\n",
      "Epoch 776/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7515 - val_loss: 0.8959\n",
      "Epoch 777/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7560 - val_loss: 0.9226\n",
      "Epoch 778/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7533 - val_loss: 0.9431\n",
      "Epoch 779/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7541 - val_loss: 0.8987\n",
      "Epoch 780/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7564 - val_loss: 0.8914\n",
      "Epoch 781/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7568 - val_loss: 0.9695\n",
      "Epoch 782/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7543 - val_loss: 0.8941\n",
      "Epoch 783/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7567 - val_loss: 0.9065\n",
      "Epoch 784/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7524 - val_loss: 0.9413\n",
      "Epoch 785/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7531 - val_loss: 0.9148\n",
      "Epoch 786/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7527 - val_loss: 0.9200\n",
      "Epoch 787/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7522 - val_loss: 0.9356\n",
      "Epoch 788/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7528 - val_loss: 0.9178\n",
      "Epoch 789/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7546 - val_loss: 0.9112\n",
      "Epoch 790/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7521 - val_loss: 0.9247\n",
      "Epoch 791/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7590 - val_loss: 0.9391\n",
      "Epoch 792/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7515 - val_loss: 0.8829\n",
      "Epoch 793/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7550 - val_loss: 0.9160\n",
      "Epoch 794/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7547 - val_loss: 0.9388\n",
      "Epoch 795/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7524 - val_loss: 0.8944\n",
      "Epoch 796/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7541 - val_loss: 0.9349\n",
      "Epoch 797/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7540 - val_loss: 0.9245\n",
      "Epoch 798/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7571 - val_loss: 0.8966\n",
      "Epoch 799/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7519 - val_loss: 0.9412\n",
      "Epoch 800/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7524 - val_loss: 0.9210\n",
      "Epoch 801/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7536 - val_loss: 0.9128\n",
      "Epoch 802/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7519 - val_loss: 0.9546\n",
      "Epoch 803/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7540 - val_loss: 0.9146\n",
      "Epoch 804/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7529 - val_loss: 0.8962\n",
      "Epoch 805/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7554 - val_loss: 0.9373\n",
      "Epoch 806/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7512 - val_loss: 0.9037\n",
      "Epoch 807/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7528 - val_loss: 0.9090\n",
      "Epoch 808/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7523 - val_loss: 0.9403\n",
      "Epoch 809/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7543 - val_loss: 0.9105\n",
      "Epoch 810/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7523 - val_loss: 0.9293\n",
      "Epoch 811/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7518 - val_loss: 0.9151\n",
      "Epoch 812/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7544 - val_loss: 0.9249\n",
      "Epoch 813/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7579 - val_loss: 0.8973\n",
      "Epoch 814/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7517 - val_loss: 0.9587\n",
      "Epoch 815/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7545 - val_loss: 0.9062\n",
      "Epoch 816/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7551 - val_loss: 0.9010\n",
      "Epoch 817/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7511 - val_loss: 0.9406\n",
      "Epoch 818/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7530 - val_loss: 0.9351\n",
      "Epoch 819/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7528 - val_loss: 0.9090\n",
      "Epoch 820/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7527 - val_loss: 0.9262\n",
      "Epoch 821/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7517 - val_loss: 0.9158\n",
      "Epoch 822/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7528 - val_loss: 0.9302\n",
      "Epoch 823/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7540 - val_loss: 0.9064\n",
      "Epoch 824/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7509 - val_loss: 0.9317\n",
      "Epoch 825/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7518 - val_loss: 0.9296\n",
      "Epoch 826/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7550 - val_loss: 0.9217\n",
      "Epoch 827/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7566 - val_loss: 0.8942\n",
      "Epoch 828/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7530 - val_loss: 0.9678\n",
      "Epoch 829/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7587 - val_loss: 0.8910\n",
      "Epoch 830/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7530 - val_loss: 0.9347\n",
      "Epoch 831/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7541 - val_loss: 0.9295\n",
      "Epoch 832/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7562 - val_loss: 0.9150\n",
      "Epoch 833/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7552 - val_loss: 0.9486\n",
      "Epoch 834/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7513 - val_loss: 0.8909\n",
      "Epoch 835/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7544 - val_loss: 0.9233\n",
      "Epoch 836/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7520 - val_loss: 0.9256\n",
      "Epoch 837/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7518 - val_loss: 0.9203\n",
      "Epoch 838/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7513 - val_loss: 0.9340\n",
      "Epoch 839/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7511 - val_loss: 0.9153\n",
      "Epoch 840/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7536 - val_loss: 0.9089\n",
      "Epoch 841/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7511 - val_loss: 0.9323\n",
      "Epoch 842/1500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7512 - val_loss: 0.9156\n",
      "Epoch 843/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7534 - val_loss: 0.9149\n",
      "Epoch 844/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7563 - val_loss: 0.9633\n",
      "Epoch 845/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7534 - val_loss: 0.8717\n",
      "Epoch 846/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7601 - val_loss: 0.9302\n",
      "Epoch 847/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7541 - val_loss: 0.9695\n",
      "Epoch 848/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7514 - val_loss: 0.8932\n",
      "Epoch 849/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7577 - val_loss: 0.9302\n",
      "Epoch 850/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7536 - val_loss: 0.9220\n",
      "Epoch 851/1500\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7546 - val_loss: 0.9449\n",
      "Epoch 852/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7515 - val_loss: 0.9009\n",
      "Epoch 853/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7552 - val_loss: 0.9528\n",
      "Epoch 854/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7552 - val_loss: 0.9547\n",
      "Epoch 855/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7520 - val_loss: 0.8915\n",
      "Epoch 856/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7544 - val_loss: 0.9509\n",
      "Epoch 857/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7533 - val_loss: 0.9121\n",
      "Epoch 858/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7517 - val_loss: 0.9245\n",
      "Epoch 859/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7530 - val_loss: 0.9448\n",
      "Epoch 860/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7521 - val_loss: 0.9004\n",
      "Epoch 861/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7522 - val_loss: 0.9359\n",
      "Epoch 862/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7555 - val_loss: 0.9380\n",
      "Epoch 863/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7486 - val_loss: 0.8941\n",
      "Epoch 864/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7565 - val_loss: 0.9321\n",
      "Epoch 865/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7526 - val_loss: 0.9619\n",
      "Epoch 866/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7517 - val_loss: 0.9122\n",
      "Epoch 867/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7553 - val_loss: 0.9001\n",
      "Epoch 868/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7550 - val_loss: 0.9969\n",
      "Epoch 869/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7610 - val_loss: 0.8846\n",
      "Epoch 870/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7620 - val_loss: 0.8951\n",
      "Epoch 871/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7559 - val_loss: 1.0001\n",
      "Epoch 872/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7588 - val_loss: 0.8867\n",
      "Epoch 873/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7574 - val_loss: 0.9128\n",
      "Epoch 874/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7563 - val_loss: 0.9638\n",
      "Epoch 875/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7552 - val_loss: 0.8944\n",
      "Epoch 876/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7538 - val_loss: 0.9178\n",
      "Epoch 877/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7568 - val_loss: 0.9491\n",
      "Epoch 878/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7526 - val_loss: 0.8845\n",
      "Epoch 879/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7550 - val_loss: 0.9233\n",
      "Epoch 880/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7531 - val_loss: 0.9531\n",
      "Epoch 881/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7529 - val_loss: 0.8984\n",
      "Epoch 882/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7519 - val_loss: 0.9354\n",
      "Epoch 883/1500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7513 - val_loss: 0.9389\n",
      "Epoch 884/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7509 - val_loss: 0.9182\n",
      "Epoch 885/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7521 - val_loss: 0.9197\n",
      "Epoch 886/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7532 - val_loss: 0.9385\n",
      "Epoch 887/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7510 - val_loss: 0.9043\n",
      "Epoch 888/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7520 - val_loss: 0.9235\n",
      "Epoch 889/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7510 - val_loss: 0.9413\n",
      "Epoch 890/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7510 - val_loss: 0.9079\n",
      "Epoch 891/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7523 - val_loss: 0.9196\n",
      "Epoch 892/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7523 - val_loss: 0.9564\n",
      "Epoch 893/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7528 - val_loss: 0.9050\n",
      "Epoch 894/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7519 - val_loss: 0.9335\n",
      "Epoch 895/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7524 - val_loss: 0.9211\n",
      "Epoch 896/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7513 - val_loss: 0.9362\n",
      "Epoch 897/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7508 - val_loss: 0.9189\n",
      "Epoch 898/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7513 - val_loss: 0.9231\n",
      "Epoch 899/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7518 - val_loss: 0.9443\n",
      "Epoch 900/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7526 - val_loss: 0.9099\n",
      "Epoch 901/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7519 - val_loss: 0.9273\n",
      "Epoch 902/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7525 - val_loss: 0.9281\n",
      "Epoch 903/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7516 - val_loss: 0.9301\n",
      "Epoch 904/1500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7534 - val_loss: 0.9078\n",
      "Epoch 905/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7536 - val_loss: 0.9431\n",
      "Epoch 906/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7517 - val_loss: 0.9051\n",
      "Epoch 907/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7516 - val_loss: 0.9333\n",
      "Epoch 908/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7521 - val_loss: 0.9333\n",
      "Epoch 909/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7560 - val_loss: 0.9002\n",
      "Epoch 910/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7518 - val_loss: 0.9536\n",
      "Epoch 911/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7517 - val_loss: 0.9200\n",
      "Epoch 912/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7547 - val_loss: 0.9183\n",
      "Epoch 913/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7526 - val_loss: 0.9588\n",
      "Epoch 914/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7506 - val_loss: 0.8961\n",
      "Epoch 915/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7519 - val_loss: 0.9278\n",
      "Epoch 916/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7504 - val_loss: 0.9492\n",
      "Epoch 917/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7617 - val_loss: 0.9073\n",
      "Epoch 918/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7550 - val_loss: 0.9611\n",
      "Epoch 919/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7528 - val_loss: 0.8894\n",
      "Epoch 920/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7551 - val_loss: 0.9261\n",
      "Epoch 921/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7509 - val_loss: 0.9308\n",
      "Epoch 922/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7516 - val_loss: 0.9392\n",
      "Epoch 923/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7537 - val_loss: 0.9299\n",
      "Epoch 924/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7594 - val_loss: 0.9075\n",
      "Epoch 925/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7565 - val_loss: 0.9672\n",
      "Epoch 926/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7506 - val_loss: 0.9002\n",
      "Epoch 927/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7581 - val_loss: 0.9004\n",
      "Epoch 928/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7516 - val_loss: 1.0111\n",
      "Epoch 929/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7568 - val_loss: 0.8925\n",
      "Epoch 930/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7544 - val_loss: 0.8845\n",
      "Epoch 931/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7529 - val_loss: 0.9573\n",
      "Epoch 932/1500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7535 - val_loss: 0.9160\n",
      "Epoch 933/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7580 - val_loss: 0.8809\n",
      "Epoch 934/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7525 - val_loss: 0.9690\n",
      "Epoch 935/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7548 - val_loss: 0.9094\n",
      "Epoch 936/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7521 - val_loss: 0.9083\n",
      "Epoch 937/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7511 - val_loss: 0.9461\n",
      "Epoch 938/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7509 - val_loss: 0.9211\n",
      "Epoch 939/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7514 - val_loss: 0.9116\n",
      "Epoch 940/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7509 - val_loss: 0.9230\n",
      "Epoch 941/1500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7500 - val_loss: 0.9307\n",
      "Epoch 942/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7513 - val_loss: 0.9250\n",
      "Epoch 943/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7501 - val_loss: 0.9105\n",
      "Epoch 944/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7503 - val_loss: 0.9267\n",
      "Epoch 945/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7503 - val_loss: 0.9253\n",
      "Epoch 946/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7514 - val_loss: 0.9356\n",
      "Epoch 947/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7518 - val_loss: 0.9134\n",
      "Epoch 948/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7498 - val_loss: 0.9424\n",
      "Epoch 949/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7509 - val_loss: 0.9329\n",
      "Epoch 950/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7504 - val_loss: 0.9087\n",
      "Epoch 951/1500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7504 - val_loss: 0.9285\n",
      "Epoch 952/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7503 - val_loss: 0.9324\n",
      "Epoch 953/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7503 - val_loss: 0.9206\n",
      "Epoch 954/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7528 - val_loss: 0.9328\n",
      "Epoch 955/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7525 - val_loss: 0.9268\n",
      "Epoch 956/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7509 - val_loss: 0.9191\n",
      "Epoch 957/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7505 - val_loss: 0.9385\n",
      "Epoch 958/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7541 - val_loss: 0.9157\n",
      "Epoch 959/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7524 - val_loss: 0.9531\n",
      "Epoch 960/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7520 - val_loss: 0.8979\n",
      "Epoch 961/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7513 - val_loss: 0.9317\n",
      "Epoch 962/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7520 - val_loss: 0.9207\n",
      "Epoch 963/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7543 - val_loss: 0.9434\n",
      "Epoch 964/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7504 - val_loss: 0.8988\n",
      "Epoch 965/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7581 - val_loss: 0.9524\n",
      "Epoch 966/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7514 - val_loss: 0.9004\n",
      "Epoch 967/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7516 - val_loss: 0.9341\n",
      "Epoch 968/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7513 - val_loss: 0.9204\n",
      "Epoch 969/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7503 - val_loss: 0.9181\n",
      "Epoch 970/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7497 - val_loss: 0.9213\n",
      "Epoch 971/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7509 - val_loss: 0.9358\n",
      "Epoch 972/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7513 - val_loss: 0.9103\n",
      "Epoch 973/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7497 - val_loss: 0.9407\n",
      "Epoch 974/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7502 - val_loss: 0.9461\n",
      "Epoch 975/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7497 - val_loss: 0.9177\n",
      "Epoch 976/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7544 - val_loss: 0.9081\n",
      "Epoch 977/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7516 - val_loss: 0.9557\n",
      "Epoch 978/1500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7547 - val_loss: 0.8848\n",
      "Epoch 979/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7532 - val_loss: 0.9455\n",
      "Epoch 980/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7532 - val_loss: 0.9487\n",
      "Epoch 981/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7506 - val_loss: 0.8911\n",
      "Epoch 982/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7531 - val_loss: 0.9509\n",
      "Epoch 983/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7503 - val_loss: 0.9144\n",
      "Epoch 984/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7508 - val_loss: 0.9144\n",
      "Epoch 985/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7500 - val_loss: 0.9426\n",
      "Epoch 986/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7509 - val_loss: 0.9413\n",
      "Epoch 987/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7513 - val_loss: 0.9040\n",
      "Epoch 988/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7519 - val_loss: 0.9389\n",
      "Epoch 989/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7502 - val_loss: 0.9319\n",
      "Epoch 990/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7506 - val_loss: 0.9162\n",
      "Epoch 991/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7500 - val_loss: 0.9325\n",
      "Epoch 992/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7538 - val_loss: 0.9335\n",
      "Epoch 993/1500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7499 - val_loss: 0.9110\n",
      "Epoch 994/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7505 - val_loss: 0.9233\n",
      "Epoch 995/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7498 - val_loss: 0.9356\n",
      "Epoch 996/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7530 - val_loss: 0.9309\n",
      "Epoch 997/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7552 - val_loss: 0.8920\n",
      "Epoch 998/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7518 - val_loss: 0.9741\n",
      "Epoch 999/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7554 - val_loss: 0.9263\n",
      "Epoch 1000/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7497 - val_loss: 0.8819\n",
      "Epoch 1001/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7547 - val_loss: 0.9375\n",
      "Epoch 1002/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7528 - val_loss: 0.9800\n",
      "Epoch 1003/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7521 - val_loss: 0.9107\n",
      "Epoch 1004/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7539 - val_loss: 0.9048\n",
      "Epoch 1005/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7507 - val_loss: 0.9566\n",
      "Epoch 1006/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7523 - val_loss: 0.9037\n",
      "Epoch 1007/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7504 - val_loss: 0.9344\n",
      "Epoch 1008/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7543 - val_loss: 0.9356\n",
      "Epoch 1009/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7496 - val_loss: 0.9013\n",
      "Epoch 1010/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7504 - val_loss: 0.9498\n",
      "Epoch 1011/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7508 - val_loss: 0.9276\n",
      "Epoch 1012/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7562 - val_loss: 0.9216\n",
      "Epoch 1013/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7493 - val_loss: 0.9522\n",
      "Epoch 1014/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7515 - val_loss: 0.9151\n",
      "Epoch 1015/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7499 - val_loss: 0.9297\n",
      "Epoch 1016/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7528 - val_loss: 0.9426\n",
      "Epoch 1017/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7486 - val_loss: 0.9029\n",
      "Epoch 1018/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7511 - val_loss: 0.9275\n",
      "Epoch 1019/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7495 - val_loss: 0.9595\n",
      "Epoch 1020/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7520 - val_loss: 0.9064\n",
      "Epoch 1021/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7546 - val_loss: 0.9530\n",
      "Epoch 1022/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7501 - val_loss: 0.9013\n",
      "Epoch 1023/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7519 - val_loss: 0.9126\n",
      "Epoch 1024/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7495 - val_loss: 0.9468\n",
      "Epoch 1025/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7517 - val_loss: 0.9293\n",
      "Epoch 1026/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7503 - val_loss: 0.9324\n",
      "Epoch 1027/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7535 - val_loss: 0.9126\n",
      "Epoch 1028/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7505 - val_loss: 0.9451\n",
      "Epoch 1029/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7499 - val_loss: 0.9257\n",
      "Epoch 1030/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7538 - val_loss: 0.9009\n",
      "Epoch 1031/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7518 - val_loss: 0.9586\n",
      "Epoch 1032/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7533 - val_loss: 0.9018\n",
      "Epoch 1033/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7527 - val_loss: 0.9507\n",
      "Epoch 1034/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7536 - val_loss: 0.9548\n",
      "Epoch 1035/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7542 - val_loss: 0.8863\n",
      "Epoch 1036/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7516 - val_loss: 0.9607\n",
      "Epoch 1037/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7567 - val_loss: 0.9361\n",
      "Epoch 1038/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7532 - val_loss: 0.8781\n",
      "Epoch 1039/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7512 - val_loss: 0.9545\n",
      "Epoch 1040/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7554 - val_loss: 0.9422\n",
      "Epoch 1041/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7542 - val_loss: 0.8968\n",
      "Epoch 1042/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7519 - val_loss: 0.9543\n",
      "Epoch 1043/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7507 - val_loss: 0.9103\n",
      "Epoch 1044/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7520 - val_loss: 0.9191\n",
      "Epoch 1045/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7498 - val_loss: 0.9483\n",
      "Epoch 1046/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7502 - val_loss: 0.9091\n",
      "Epoch 1047/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7499 - val_loss: 0.9295\n",
      "Epoch 1048/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7492 - val_loss: 0.9385\n",
      "Epoch 1049/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7511 - val_loss: 0.9115\n",
      "Epoch 1050/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7499 - val_loss: 0.9426\n",
      "Epoch 1051/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7504 - val_loss: 0.9386\n",
      "Epoch 1052/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7520 - val_loss: 0.8914\n",
      "Epoch 1053/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7498 - val_loss: 0.9571\n",
      "Epoch 1054/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7524 - val_loss: 0.9465\n",
      "Epoch 1055/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7481 - val_loss: 0.9061\n",
      "Epoch 1056/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7511 - val_loss: 0.9228\n",
      "Epoch 1057/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7504 - val_loss: 0.9424\n",
      "Epoch 1058/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7493 - val_loss: 0.9104\n",
      "Epoch 1059/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7500 - val_loss: 0.9392\n",
      "Epoch 1060/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7509 - val_loss: 0.9298\n",
      "Epoch 1061/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7496 - val_loss: 0.9094\n",
      "Epoch 1062/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7527 - val_loss: 0.9447\n",
      "Epoch 1063/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7517 - val_loss: 0.9008\n",
      "Epoch 1064/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7502 - val_loss: 0.9683\n",
      "Epoch 1065/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7526 - val_loss: 0.9138\n",
      "Epoch 1066/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7501 - val_loss: 0.9345\n",
      "Epoch 1067/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7526 - val_loss: 0.9289\n",
      "Epoch 1068/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7535 - val_loss: 0.9103\n",
      "Epoch 1069/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7501 - val_loss: 0.9363\n",
      "Epoch 1070/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7508 - val_loss: 0.9352\n",
      "Epoch 1071/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7530 - val_loss: 0.9093\n",
      "Epoch 1072/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7516 - val_loss: 0.9541\n",
      "Epoch 1073/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7493 - val_loss: 0.9058\n",
      "Epoch 1074/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7512 - val_loss: 0.9342\n",
      "Epoch 1075/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7513 - val_loss: 0.9290\n",
      "Epoch 1076/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7498 - val_loss: 0.9192\n",
      "Epoch 1077/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7512 - val_loss: 0.9380\n",
      "Epoch 1078/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7496 - val_loss: 0.9093\n",
      "Epoch 1079/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7539 - val_loss: 0.9177\n",
      "Epoch 1080/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7508 - val_loss: 0.9732\n",
      "Epoch 1081/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7508 - val_loss: 0.9027\n",
      "Epoch 1082/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7527 - val_loss: 0.9256\n",
      "Epoch 1083/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7515 - val_loss: 0.9418\n",
      "Epoch 1084/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7534 - val_loss: 0.9028\n",
      "Epoch 1085/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7498 - val_loss: 0.9472\n",
      "Epoch 1086/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7500 - val_loss: 0.9228\n",
      "Epoch 1087/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7513 - val_loss: 0.9196\n",
      "Epoch 1088/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7490 - val_loss: 0.9448\n",
      "Epoch 1089/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7493 - val_loss: 0.9158\n",
      "Epoch 1090/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7497 - val_loss: 0.9244\n",
      "Epoch 1091/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7498 - val_loss: 0.9194\n",
      "Epoch 1092/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7491 - val_loss: 0.9372\n",
      "Epoch 1093/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7496 - val_loss: 0.9145\n",
      "Epoch 1094/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7494 - val_loss: 0.9303\n",
      "Epoch 1095/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7504 - val_loss: 0.9476\n",
      "Epoch 1096/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7511 - val_loss: 0.9040\n",
      "Epoch 1097/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7516 - val_loss: 0.9528\n",
      "Epoch 1098/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7505 - val_loss: 0.9156\n",
      "Epoch 1099/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7511 - val_loss: 0.9352\n",
      "Epoch 1100/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7520 - val_loss: 0.9460\n",
      "Epoch 1101/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7530 - val_loss: 0.9067\n",
      "Epoch 1102/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7529 - val_loss: 0.9528\n",
      "Epoch 1103/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7506 - val_loss: 0.9130\n",
      "Epoch 1104/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7515 - val_loss: 0.9467\n",
      "Epoch 1105/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7497 - val_loss: 0.9202\n",
      "Epoch 1106/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7506 - val_loss: 0.9323\n",
      "Epoch 1107/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7503 - val_loss: 0.9452\n",
      "Epoch 1108/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7503 - val_loss: 0.9192\n",
      "Epoch 1109/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7523 - val_loss: 0.9389\n",
      "Epoch 1110/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7501 - val_loss: 0.9474\n",
      "Epoch 1111/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7496 - val_loss: 0.9218\n",
      "Epoch 1112/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7502 - val_loss: 0.9156\n",
      "Epoch 1113/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7500 - val_loss: 0.9219\n",
      "Epoch 1114/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7520 - val_loss: 0.9540\n",
      "Epoch 1115/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7513 - val_loss: 0.8946\n",
      "Epoch 1116/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7513 - val_loss: 0.9578\n",
      "Epoch 1117/1500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7515 - val_loss: 0.9291\n",
      "Epoch 1118/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7500 - val_loss: 0.9192\n",
      "Epoch 1119/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7504 - val_loss: 0.9433\n",
      "Epoch 1120/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7494 - val_loss: 0.9109\n",
      "Epoch 1121/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7502 - val_loss: 0.9230\n",
      "Epoch 1122/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7556 - val_loss: 0.9587\n",
      "Epoch 1123/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7546 - val_loss: 0.8926\n",
      "Epoch 1124/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7514 - val_loss: 0.9727\n",
      "Epoch 1125/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7537 - val_loss: 0.9146\n",
      "Epoch 1126/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7530 - val_loss: 0.9068\n",
      "Epoch 1127/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7535 - val_loss: 0.9617\n",
      "Epoch 1128/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7548 - val_loss: 0.9000\n",
      "Epoch 1129/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7527 - val_loss: 0.9650\n",
      "Epoch 1130/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7513 - val_loss: 0.9119\n",
      "Epoch 1131/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7543 - val_loss: 0.9145\n",
      "Epoch 1132/1500\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7499 - val_loss: 0.9574\n",
      "Epoch 1133/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7513 - val_loss: 0.9074\n",
      "Epoch 1134/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7511 - val_loss: 0.9417\n",
      "Epoch 1135/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7495 - val_loss: 0.9499\n",
      "Epoch 1136/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7495 - val_loss: 0.9095\n",
      "Epoch 1137/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7502 - val_loss: 0.9251\n",
      "Epoch 1138/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7485 - val_loss: 0.9453\n",
      "Epoch 1139/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7494 - val_loss: 0.9302\n",
      "Epoch 1140/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7490 - val_loss: 0.9179\n",
      "Epoch 1141/1500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7488 - val_loss: 0.9421\n",
      "Epoch 1142/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7519 - val_loss: 0.9303\n",
      "Epoch 1143/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7547 - val_loss: 0.8985\n",
      "Epoch 1144/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7594 - val_loss: 0.9717\n",
      "Epoch 1145/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7505 - val_loss: 0.8861\n",
      "Epoch 1146/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7529 - val_loss: 0.9519\n",
      "Epoch 1147/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7532 - val_loss: 0.9609\n",
      "Epoch 1148/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7511 - val_loss: 0.8921\n",
      "Epoch 1149/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7520 - val_loss: 0.9601\n",
      "Epoch 1150/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7552 - val_loss: 0.9439\n",
      "Epoch 1151/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7571 - val_loss: 0.8897\n",
      "Epoch 1152/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7522 - val_loss: 0.9765\n",
      "Epoch 1153/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7533 - val_loss: 0.9229\n",
      "Epoch 1154/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7497 - val_loss: 0.8901\n",
      "Epoch 1155/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7506 - val_loss: 0.9326\n",
      "Epoch 1156/1500\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7494 - val_loss: 0.9766\n",
      "Epoch 1157/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7523 - val_loss: 0.9025\n",
      "Epoch 1158/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7499 - val_loss: 0.9293\n",
      "Epoch 1159/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7505 - val_loss: 0.9410\n",
      "Epoch 1160/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7485 - val_loss: 0.9101\n",
      "Epoch 1161/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7495 - val_loss: 0.9400\n",
      "Epoch 1162/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7498 - val_loss: 0.9150\n",
      "Epoch 1163/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7492 - val_loss: 0.9242\n",
      "Epoch 1164/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7503 - val_loss: 0.9454\n",
      "Epoch 1165/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7490 - val_loss: 0.9034\n",
      "Epoch 1166/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7504 - val_loss: 0.9543\n",
      "Epoch 1167/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7527 - val_loss: 0.9103\n",
      "Epoch 1168/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7513 - val_loss: 0.9556\n",
      "Epoch 1169/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7516 - val_loss: 0.9126\n",
      "Epoch 1170/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7492 - val_loss: 0.9282\n",
      "Epoch 1171/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7495 - val_loss: 0.9357\n",
      "Epoch 1172/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7488 - val_loss: 0.9342\n",
      "Epoch 1173/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7505 - val_loss: 0.9255\n",
      "Epoch 1174/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7501 - val_loss: 0.9103\n",
      "Epoch 1175/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7526 - val_loss: 0.9495\n",
      "Epoch 1176/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7503 - val_loss: 0.9120\n",
      "Epoch 1177/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7508 - val_loss: 0.9334\n",
      "Epoch 1178/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7509 - val_loss: 0.9162\n",
      "Epoch 1179/1500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7549 - val_loss: 0.9474\n",
      "Epoch 1180/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7499 - val_loss: 0.9040\n",
      "Epoch 1181/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7502 - val_loss: 0.9372\n",
      "Epoch 1182/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7500 - val_loss: 0.9464\n",
      "Epoch 1183/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7494 - val_loss: 0.9134\n",
      "Epoch 1184/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7505 - val_loss: 0.9320\n",
      "Epoch 1185/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7483 - val_loss: 0.9471\n",
      "Epoch 1186/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7489 - val_loss: 0.9261\n",
      "Epoch 1187/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7519 - val_loss: 0.9194\n",
      "Epoch 1188/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7534 - val_loss: 0.9531\n",
      "Epoch 1189/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7541 - val_loss: 0.9170\n",
      "Epoch 1190/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7484 - val_loss: 0.9466\n",
      "Epoch 1191/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7493 - val_loss: 0.9244\n",
      "Epoch 1192/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7498 - val_loss: 0.9416\n",
      "Epoch 1193/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7481 - val_loss: 0.9246\n",
      "Epoch 1194/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7497 - val_loss: 0.9241\n",
      "Epoch 1195/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7484 - val_loss: 0.9496\n",
      "Epoch 1196/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7508 - val_loss: 0.9314\n",
      "Epoch 1197/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7513 - val_loss: 0.9078\n",
      "Epoch 1198/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7570 - val_loss: 0.9801\n",
      "Epoch 1199/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7535 - val_loss: 0.8765\n",
      "Epoch 1200/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7558 - val_loss: 0.9881\n",
      "Epoch 1201/1500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7552 - val_loss: 0.9283\n",
      "Epoch 1202/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7541 - val_loss: 0.8887\n",
      "Epoch 1203/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7521 - val_loss: 0.9648\n",
      "Epoch 1204/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7520 - val_loss: 0.9014\n",
      "Epoch 1205/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7508 - val_loss: 0.9259\n",
      "Epoch 1206/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7493 - val_loss: 0.9341\n",
      "Epoch 1207/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7486 - val_loss: 0.9345\n",
      "Epoch 1208/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7485 - val_loss: 0.9330\n",
      "Epoch 1209/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7484 - val_loss: 0.9260\n",
      "Epoch 1210/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7483 - val_loss: 0.9281\n",
      "Epoch 1211/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7482 - val_loss: 0.9337\n",
      "Epoch 1212/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7486 - val_loss: 0.9375\n",
      "Epoch 1213/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7495 - val_loss: 0.9224\n",
      "Epoch 1214/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7491 - val_loss: 0.9327\n",
      "Epoch 1215/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7505 - val_loss: 0.9146\n",
      "Epoch 1216/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7506 - val_loss: 0.9447\n",
      "Epoch 1217/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7480 - val_loss: 0.9201\n",
      "Epoch 1218/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7497 - val_loss: 0.9252\n",
      "Epoch 1219/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7488 - val_loss: 0.9302\n",
      "Epoch 1220/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7481 - val_loss: 0.9268\n",
      "Epoch 1221/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7482 - val_loss: 0.9282\n",
      "Epoch 1222/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7489 - val_loss: 0.9310\n",
      "Epoch 1223/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7491 - val_loss: 0.9362\n",
      "Epoch 1224/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7479 - val_loss: 0.9185\n",
      "Epoch 1225/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7489 - val_loss: 0.9271\n",
      "Epoch 1226/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7478 - val_loss: 0.9370\n",
      "Epoch 1227/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7483 - val_loss: 0.9281\n",
      "Epoch 1228/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7497 - val_loss: 0.9402\n",
      "Epoch 1229/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7481 - val_loss: 0.9177\n",
      "Epoch 1230/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7488 - val_loss: 0.9367\n",
      "Epoch 1231/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7502 - val_loss: 0.9452\n",
      "Epoch 1232/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7480 - val_loss: 0.8999\n",
      "Epoch 1233/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7498 - val_loss: 0.9349\n",
      "Epoch 1234/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7504 - val_loss: 0.9382\n",
      "Epoch 1235/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7482 - val_loss: 0.9153\n",
      "Epoch 1236/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7490 - val_loss: 0.9322\n",
      "Epoch 1237/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7479 - val_loss: 0.9459\n",
      "Epoch 1238/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7495 - val_loss: 0.9384\n",
      "Epoch 1239/1500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7501 - val_loss: 0.9033\n",
      "Epoch 1240/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7498 - val_loss: 0.9662\n",
      "Epoch 1241/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7496 - val_loss: 0.9135\n",
      "Epoch 1242/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7537 - val_loss: 0.9022\n",
      "Epoch 1243/1500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7525 - val_loss: 0.9779\n",
      "Epoch 1244/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7516 - val_loss: 0.8897\n",
      "Epoch 1245/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7544 - val_loss: 0.9255\n",
      "Epoch 1246/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7461 - val_loss: 0.9924\n",
      "Epoch 1247/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7522 - val_loss: 0.9126\n",
      "Epoch 1248/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7513 - val_loss: 0.9395\n",
      "Epoch 1249/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7493 - val_loss: 0.9310\n",
      "Epoch 1250/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7487 - val_loss: 0.9221\n",
      "Epoch 1251/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7488 - val_loss: 0.9411\n",
      "Epoch 1252/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7483 - val_loss: 0.9254\n",
      "Epoch 1253/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7501 - val_loss: 0.9246\n",
      "Epoch 1254/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7478 - val_loss: 0.9585\n",
      "Epoch 1255/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7492 - val_loss: 0.9265\n",
      "Epoch 1256/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7490 - val_loss: 0.9333\n",
      "Epoch 1257/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7489 - val_loss: 0.9414\n",
      "Epoch 1258/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7488 - val_loss: 0.9343\n",
      "Epoch 1259/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7485 - val_loss: 0.9246\n",
      "Epoch 1260/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7490 - val_loss: 0.9263\n",
      "Epoch 1261/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7490 - val_loss: 0.9417\n",
      "Epoch 1262/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7488 - val_loss: 0.9310\n",
      "Epoch 1263/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7484 - val_loss: 0.9294\n",
      "Epoch 1264/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7479 - val_loss: 0.9436\n",
      "Epoch 1265/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7487 - val_loss: 0.9284\n",
      "Epoch 1266/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7490 - val_loss: 0.9416\n",
      "Epoch 1267/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7487 - val_loss: 0.9360\n",
      "Epoch 1268/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7493 - val_loss: 0.9165\n",
      "Epoch 1269/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7501 - val_loss: 0.9578\n",
      "Epoch 1270/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7477 - val_loss: 0.9152\n",
      "Epoch 1271/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7523 - val_loss: 0.9283\n",
      "Epoch 1272/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7501 - val_loss: 0.9624\n",
      "Epoch 1273/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7480 - val_loss: 0.9028\n",
      "Epoch 1274/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7504 - val_loss: 0.9378\n",
      "Epoch 1275/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7489 - val_loss: 0.9325\n",
      "Epoch 1276/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7490 - val_loss: 0.9310\n",
      "Epoch 1277/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7489 - val_loss: 0.9197\n",
      "Epoch 1278/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7518 - val_loss: 0.9514\n",
      "Epoch 1279/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7475 - val_loss: 0.9156\n",
      "Epoch 1280/1500\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7515 - val_loss: 0.9427\n",
      "Epoch 1281/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7493 - val_loss: 0.9588\n",
      "Epoch 1282/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7519 - val_loss: 0.9067\n",
      "Epoch 1283/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7484 - val_loss: 0.9467\n",
      "Epoch 1284/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7491 - val_loss: 0.9286\n",
      "Epoch 1285/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7480 - val_loss: 0.9124\n",
      "Epoch 1286/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7497 - val_loss: 0.9448\n",
      "Epoch 1287/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7500 - val_loss: 0.9202\n",
      "Epoch 1288/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7484 - val_loss: 0.9432\n",
      "Epoch 1289/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7484 - val_loss: 0.9343\n",
      "Epoch 1290/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7485 - val_loss: 0.9164\n",
      "Epoch 1291/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7489 - val_loss: 0.9429\n",
      "Epoch 1292/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7509 - val_loss: 0.9306\n",
      "Epoch 1293/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7505 - val_loss: 0.9225\n",
      "Epoch 1294/1500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7509 - val_loss: 0.9611\n",
      "Epoch 1295/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7509 - val_loss: 0.9026\n",
      "Epoch 1296/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7506 - val_loss: 0.9378\n",
      "Epoch 1297/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7515 - val_loss: 0.9371\n",
      "Epoch 1298/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7496 - val_loss: 0.9262\n",
      "Epoch 1299/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7487 - val_loss: 0.9375\n",
      "Epoch 1300/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7498 - val_loss: 0.9414\n",
      "Epoch 1301/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7513 - val_loss: 0.9079\n",
      "Epoch 1302/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7488 - val_loss: 0.9506\n",
      "Epoch 1303/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7553 - val_loss: 0.9283\n",
      "Epoch 1304/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7503 - val_loss: 0.9021\n",
      "Epoch 1305/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7531 - val_loss: 0.9628\n",
      "Epoch 1306/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7529 - val_loss: 0.9223\n",
      "Epoch 1307/1500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7536 - val_loss: 0.9589\n",
      "Epoch 1308/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7494 - val_loss: 0.9206\n",
      "Epoch 1309/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7506 - val_loss: 0.9252\n",
      "Epoch 1310/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7499 - val_loss: 0.9400\n",
      "Epoch 1311/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7525 - val_loss: 0.9386\n",
      "Epoch 1312/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7490 - val_loss: 0.8904\n",
      "Epoch 1313/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7533 - val_loss: 0.9468\n",
      "Epoch 1314/1500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7512 - val_loss: 0.9293\n",
      "Epoch 1315/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7497 - val_loss: 0.9338\n",
      "Epoch 1316/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7487 - val_loss: 0.9355\n",
      "Epoch 1317/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7498 - val_loss: 0.9247\n",
      "Epoch 1318/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7505 - val_loss: 0.9643\n",
      "Epoch 1319/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7497 - val_loss: 0.9114\n",
      "Epoch 1320/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7501 - val_loss: 0.9272\n",
      "Epoch 1321/1500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7498 - val_loss: 0.9524\n",
      "Epoch 1322/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7486 - val_loss: 0.9180\n",
      "Epoch 1323/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7488 - val_loss: 0.9212\n",
      "Epoch 1324/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7483 - val_loss: 0.9432\n",
      "Epoch 1325/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7484 - val_loss: 0.9325\n",
      "Epoch 1326/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7495 - val_loss: 0.9179\n",
      "Epoch 1327/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7495 - val_loss: 0.9260\n",
      "Epoch 1328/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7485 - val_loss: 0.9413\n",
      "Epoch 1329/1500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7494 - val_loss: 0.9318\n",
      "Epoch 1330/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7491 - val_loss: 0.9398\n",
      "Epoch 1331/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7500 - val_loss: 0.9205\n",
      "Epoch 1332/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7503 - val_loss: 0.9598\n",
      "Epoch 1333/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7482 - val_loss: 0.9181\n",
      "Epoch 1334/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7490 - val_loss: 0.9279\n",
      "Epoch 1335/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7485 - val_loss: 0.9378\n",
      "Epoch 1336/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7489 - val_loss: 0.9311\n",
      "Epoch 1337/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7483 - val_loss: 0.9439\n",
      "Epoch 1338/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7490 - val_loss: 0.9126\n",
      "Epoch 1339/1500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7477 - val_loss: 0.9515\n",
      "Epoch 1340/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7487 - val_loss: 0.9280\n",
      "Epoch 1341/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7503 - val_loss: 0.9175\n",
      "Epoch 1342/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7487 - val_loss: 0.9542\n",
      "Epoch 1343/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7483 - val_loss: 0.9192\n",
      "Epoch 1344/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7503 - val_loss: 0.9122\n",
      "Epoch 1345/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7493 - val_loss: 0.9659\n",
      "Epoch 1346/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7484 - val_loss: 0.9206\n",
      "Epoch 1347/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7495 - val_loss: 0.9139\n",
      "Epoch 1348/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7477 - val_loss: 0.9703\n",
      "Epoch 1349/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7509 - val_loss: 0.9063\n",
      "Epoch 1350/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7506 - val_loss: 0.9418\n",
      "Epoch 1351/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7485 - val_loss: 0.9415\n",
      "Epoch 1352/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7483 - val_loss: 0.9260\n",
      "Epoch 1353/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7479 - val_loss: 0.9339\n",
      "Epoch 1354/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7477 - val_loss: 0.9275\n",
      "Epoch 1355/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7498 - val_loss: 0.9448\n",
      "Epoch 1356/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7484 - val_loss: 0.9042\n",
      "Epoch 1357/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7489 - val_loss: 0.9463\n",
      "Epoch 1358/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7494 - val_loss: 0.9559\n",
      "Epoch 1359/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7482 - val_loss: 0.8957\n",
      "Epoch 1360/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7546 - val_loss: 0.9445\n",
      "Epoch 1361/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7500 - val_loss: 0.9374\n",
      "Epoch 1362/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7503 - val_loss: 0.9270\n",
      "Epoch 1363/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7516 - val_loss: 0.9259\n",
      "Epoch 1364/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7494 - val_loss: 0.9504\n",
      "Epoch 1365/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7557 - val_loss: 0.9228\n",
      "Epoch 1366/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7501 - val_loss: 0.9377\n",
      "Epoch 1367/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7491 - val_loss: 0.9266\n",
      "Epoch 1368/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7490 - val_loss: 0.9356\n",
      "Epoch 1369/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7483 - val_loss: 0.9494\n",
      "Epoch 1370/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7484 - val_loss: 0.9278\n",
      "Epoch 1371/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7492 - val_loss: 0.9336\n",
      "Epoch 1372/1500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7488 - val_loss: 0.9272\n",
      "Epoch 1373/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7479 - val_loss: 0.9298\n",
      "Epoch 1374/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7488 - val_loss: 0.9404\n",
      "Epoch 1375/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7475 - val_loss: 0.9173\n",
      "Epoch 1376/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7499 - val_loss: 0.9503\n",
      "Epoch 1377/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7483 - val_loss: 0.9180\n",
      "Epoch 1378/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7478 - val_loss: 0.9436\n",
      "Epoch 1379/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7482 - val_loss: 0.9487\n",
      "Epoch 1380/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7484 - val_loss: 0.9295\n",
      "Epoch 1381/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7495 - val_loss: 0.9122\n",
      "Epoch 1382/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7471 - val_loss: 0.9647\n",
      "Epoch 1383/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7518 - val_loss: 0.9147\n",
      "Epoch 1384/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7513 - val_loss: 0.9145\n",
      "Epoch 1385/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7512 - val_loss: 0.9631\n",
      "Epoch 1386/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7512 - val_loss: 0.9087\n",
      "Epoch 1387/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7490 - val_loss: 0.9484\n",
      "Epoch 1388/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7487 - val_loss: 0.9356\n",
      "Epoch 1389/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7491 - val_loss: 0.9360\n",
      "Epoch 1390/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7479 - val_loss: 0.9179\n",
      "Epoch 1391/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7498 - val_loss: 0.9557\n",
      "Epoch 1392/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7489 - val_loss: 0.9162\n",
      "Epoch 1393/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7485 - val_loss: 0.9390\n",
      "Epoch 1394/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7488 - val_loss: 0.9278\n",
      "Epoch 1395/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7476 - val_loss: 0.9177\n",
      "Epoch 1396/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7487 - val_loss: 0.9439\n",
      "Epoch 1397/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7482 - val_loss: 0.9268\n",
      "Epoch 1398/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7474 - val_loss: 0.9332\n",
      "Epoch 1399/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7474 - val_loss: 0.9380\n",
      "Epoch 1400/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7491 - val_loss: 0.9320\n",
      "Epoch 1401/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7491 - val_loss: 0.9075\n",
      "Epoch 1402/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7474 - val_loss: 0.9574\n",
      "Epoch 1403/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7504 - val_loss: 0.9210\n",
      "Epoch 1404/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7513 - val_loss: 0.9064\n",
      "Epoch 1405/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7494 - val_loss: 0.9665\n",
      "Epoch 1406/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7489 - val_loss: 0.9119\n",
      "Epoch 1407/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7486 - val_loss: 0.9318\n",
      "Epoch 1408/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7499 - val_loss: 0.9390\n",
      "Epoch 1409/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7482 - val_loss: 0.9107\n",
      "Epoch 1410/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7479 - val_loss: 0.9469\n",
      "Epoch 1411/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7527 - val_loss: 0.9400\n",
      "Epoch 1412/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7511 - val_loss: 0.9025\n",
      "Epoch 1413/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7485 - val_loss: 0.9883\n",
      "Epoch 1414/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7514 - val_loss: 0.9203\n",
      "Epoch 1415/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7496 - val_loss: 0.9300\n",
      "Epoch 1416/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7491 - val_loss: 0.9380\n",
      "Epoch 1417/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7490 - val_loss: 0.9335\n",
      "Epoch 1418/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7479 - val_loss: 0.9508\n",
      "Epoch 1419/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7487 - val_loss: 0.9180\n",
      "Epoch 1420/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7503 - val_loss: 0.9514\n",
      "Epoch 1421/1500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7486 - val_loss: 0.9056\n",
      "Epoch 1422/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7489 - val_loss: 0.9577\n",
      "Epoch 1423/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7508 - val_loss: 0.9211\n",
      "Epoch 1424/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7517 - val_loss: 0.9499\n",
      "Epoch 1425/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7526 - val_loss: 0.9046\n",
      "Epoch 1426/1500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7496 - val_loss: 0.9873\n",
      "Epoch 1427/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7541 - val_loss: 0.9050\n",
      "Epoch 1428/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7534 - val_loss: 0.8880\n",
      "Epoch 1429/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7492 - val_loss: 0.9810\n",
      "Epoch 1430/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7533 - val_loss: 0.9340\n",
      "Epoch 1431/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7494 - val_loss: 0.9232\n",
      "Epoch 1432/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7482 - val_loss: 0.9326\n",
      "Epoch 1433/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7487 - val_loss: 0.9366\n",
      "Epoch 1434/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7530 - val_loss: 0.9186\n",
      "Epoch 1435/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7495 - val_loss: 0.9695\n",
      "Epoch 1436/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7489 - val_loss: 0.9040\n",
      "Epoch 1437/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7522 - val_loss: 0.9159\n",
      "Epoch 1438/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7511 - val_loss: 0.9683\n",
      "Epoch 1439/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7483 - val_loss: 0.8990\n",
      "Epoch 1440/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7548 - val_loss: 0.9464\n",
      "Epoch 1441/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7528 - val_loss: 0.9507\n",
      "Epoch 1442/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7478 - val_loss: 0.9105\n",
      "Epoch 1443/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7487 - val_loss: 0.9419\n",
      "Epoch 1444/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7506 - val_loss: 0.9422\n",
      "Epoch 1445/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7518 - val_loss: 0.9020\n",
      "Epoch 1446/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7494 - val_loss: 0.9695\n",
      "Epoch 1447/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7498 - val_loss: 0.9246\n",
      "Epoch 1448/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7491 - val_loss: 0.9312\n",
      "Epoch 1449/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7476 - val_loss: 0.9318\n",
      "Epoch 1450/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7478 - val_loss: 0.9305\n",
      "Epoch 1451/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7474 - val_loss: 0.9244\n",
      "Epoch 1452/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7501 - val_loss: 0.9494\n",
      "Epoch 1453/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7487 - val_loss: 0.9085\n",
      "Epoch 1454/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7507 - val_loss: 0.9723\n",
      "Epoch 1455/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7491 - val_loss: 0.9234\n",
      "Epoch 1456/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7503 - val_loss: 0.9194\n",
      "Epoch 1457/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7473 - val_loss: 0.9753\n",
      "Epoch 1458/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7496 - val_loss: 0.9153\n",
      "Epoch 1459/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7506 - val_loss: 0.9082\n",
      "Epoch 1460/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7552 - val_loss: 0.9830\n",
      "Epoch 1461/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7514 - val_loss: 0.9021\n",
      "Epoch 1462/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7488 - val_loss: 0.9431\n",
      "Epoch 1463/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7498 - val_loss: 0.9423\n",
      "Epoch 1464/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7489 - val_loss: 0.9168\n",
      "Epoch 1465/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7507 - val_loss: 0.9669\n",
      "Epoch 1466/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7505 - val_loss: 0.9052\n",
      "Epoch 1467/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7494 - val_loss: 0.9445\n",
      "Epoch 1468/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7498 - val_loss: 0.9371\n",
      "Epoch 1469/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7494 - val_loss: 0.9087\n",
      "Epoch 1470/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7538 - val_loss: 0.9775\n",
      "Epoch 1471/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7491 - val_loss: 0.9067\n",
      "Epoch 1472/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7515 - val_loss: 0.9338\n",
      "Epoch 1473/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7493 - val_loss: 0.9666\n",
      "Epoch 1474/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7487 - val_loss: 0.9036\n",
      "Epoch 1475/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7506 - val_loss: 0.9466\n",
      "Epoch 1476/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7524 - val_loss: 0.9574\n",
      "Epoch 1477/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7473 - val_loss: 0.8917\n",
      "Epoch 1478/1500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7506 - val_loss: 0.9385\n",
      "Epoch 1479/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7515 - val_loss: 0.9462\n",
      "Epoch 1480/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7490 - val_loss: 0.9056\n",
      "Epoch 1481/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7524 - val_loss: 0.9645\n",
      "Epoch 1482/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7512 - val_loss: 0.9042\n",
      "Epoch 1483/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7492 - val_loss: 0.9468\n",
      "Epoch 1484/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7486 - val_loss: 0.9442\n",
      "Epoch 1485/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7480 - val_loss: 0.9276\n",
      "Epoch 1486/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7509 - val_loss: 0.9287\n",
      "Epoch 1487/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7534 - val_loss: 0.9848\n",
      "Epoch 1488/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7504 - val_loss: 0.8884\n",
      "Epoch 1489/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7550 - val_loss: 0.9484\n",
      "Epoch 1490/1500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7519 - val_loss: 0.9613\n",
      "Epoch 1491/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7506 - val_loss: 0.9219\n",
      "Epoch 1492/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7492 - val_loss: 0.9571\n",
      "Epoch 1493/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7505 - val_loss: 0.9263\n",
      "Epoch 1494/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7492 - val_loss: 0.9538\n",
      "Epoch 1495/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7497 - val_loss: 0.9326\n",
      "Epoch 1496/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7488 - val_loss: 0.9225\n",
      "Epoch 1497/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7491 - val_loss: 0.9533\n",
      "Epoch 1498/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7495 - val_loss: 0.9304\n",
      "Epoch 1499/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7480 - val_loss: 0.9291\n",
      "Epoch 1500/1500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7530 - val_loss: 0.9612\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8401\n",
      "0.8401017189025879\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.SimpleRNN(units = 1024, activation = \"relu\", return_sequences = False)(input)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "# ミニバッチ学習 \n",
    "batch_size = len(train_x) // 4\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "\n",
    "# モデル構造の出力\n",
    "model.summary()\n",
    "\n",
    "# val_lossが一番低いモデルを保存している\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "# 学習データ、テストデータ、バッチサイズ、エポック、保存ポイントの設定\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = batch_size, epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 156ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdc67459280>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM(1層)ミニバッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 3, 3)]            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 1024)              4210688   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,211,713\n",
      "Trainable params: 4,211,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 1.0385 - val_loss: 0.8855\n",
      "Epoch 2/1500\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 1.0209 - val_loss: 0.8798\n",
      "Epoch 3/1500\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 1.0038 - val_loss: 0.8760\n",
      "Epoch 4/1500\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.9885 - val_loss: 0.8732\n",
      "Epoch 5/1500\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.9765 - val_loss: 0.8714\n",
      "Epoch 6/1500\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.9646 - val_loss: 0.8704\n",
      "Epoch 7/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.9562 - val_loss: 0.8706\n",
      "Epoch 8/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.9446 - val_loss: 0.8718\n",
      "Epoch 9/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.9390 - val_loss: 0.8740\n",
      "Epoch 10/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9304 - val_loss: 0.8776\n",
      "Epoch 11/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.9234 - val_loss: 0.8821\n",
      "Epoch 12/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9189 - val_loss: 0.8883\n",
      "Epoch 13/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.9137 - val_loss: 0.8951\n",
      "Epoch 14/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9097 - val_loss: 0.9029\n",
      "Epoch 15/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.9055 - val_loss: 0.9099\n",
      "Epoch 16/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.9033 - val_loss: 0.9177\n",
      "Epoch 17/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9011 - val_loss: 0.9247\n",
      "Epoch 18/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8991 - val_loss: 0.9295\n",
      "Epoch 19/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.8978 - val_loss: 0.9329\n",
      "Epoch 20/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8968 - val_loss: 0.9362\n",
      "Epoch 21/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8957 - val_loss: 0.9386\n",
      "Epoch 22/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8946 - val_loss: 0.9396\n",
      "Epoch 23/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8934 - val_loss: 0.9401\n",
      "Epoch 24/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8919 - val_loss: 0.9358\n",
      "Epoch 25/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8905 - val_loss: 0.9345\n",
      "Epoch 26/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8891 - val_loss: 0.9322\n",
      "Epoch 27/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.8880 - val_loss: 0.9295\n",
      "Epoch 28/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8873 - val_loss: 0.9256\n",
      "Epoch 29/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8855 - val_loss: 0.9245\n",
      "Epoch 30/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.8844 - val_loss: 0.9243\n",
      "Epoch 31/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8833 - val_loss: 0.9261\n",
      "Epoch 32/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8820 - val_loss: 0.9245\n",
      "Epoch 33/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8806 - val_loss: 0.9245\n",
      "Epoch 34/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8796 - val_loss: 0.9228\n",
      "Epoch 35/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8787 - val_loss: 0.9238\n",
      "Epoch 36/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8777 - val_loss: 0.9254\n",
      "Epoch 37/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.8761 - val_loss: 0.9242\n",
      "Epoch 38/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8750 - val_loss: 0.9233\n",
      "Epoch 39/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8740 - val_loss: 0.9205\n",
      "Epoch 40/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8728 - val_loss: 0.9185\n",
      "Epoch 41/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8718 - val_loss: 0.9188\n",
      "Epoch 42/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.8706 - val_loss: 0.9181\n",
      "Epoch 43/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8695 - val_loss: 0.9175\n",
      "Epoch 44/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8683 - val_loss: 0.9161\n",
      "Epoch 45/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8675 - val_loss: 0.9163\n",
      "Epoch 46/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8662 - val_loss: 0.9150\n",
      "Epoch 47/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.8651 - val_loss: 0.9141\n",
      "Epoch 48/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8646 - val_loss: 0.9139\n",
      "Epoch 49/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8632 - val_loss: 0.9133\n",
      "Epoch 50/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.8625 - val_loss: 0.9125\n",
      "Epoch 51/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8617 - val_loss: 0.9151\n",
      "Epoch 52/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8605 - val_loss: 0.9150\n",
      "Epoch 53/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8596 - val_loss: 0.9106\n",
      "Epoch 54/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.8583 - val_loss: 0.9097\n",
      "Epoch 55/1500\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.8576 - val_loss: 0.9101\n",
      "Epoch 56/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8567 - val_loss: 0.9081\n",
      "Epoch 57/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8560 - val_loss: 0.9071\n",
      "Epoch 58/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8553 - val_loss: 0.9093\n",
      "Epoch 59/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8542 - val_loss: 0.9077\n",
      "Epoch 60/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8533 - val_loss: 0.9076\n",
      "Epoch 61/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8524 - val_loss: 0.9072\n",
      "Epoch 62/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8522 - val_loss: 0.9095\n",
      "Epoch 63/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8510 - val_loss: 0.9063\n",
      "Epoch 64/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8504 - val_loss: 0.9068\n",
      "Epoch 65/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8498 - val_loss: 0.9062\n",
      "Epoch 66/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8491 - val_loss: 0.9079\n",
      "Epoch 67/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8482 - val_loss: 0.9069\n",
      "Epoch 68/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8474 - val_loss: 0.9066\n",
      "Epoch 69/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8475 - val_loss: 0.9048\n",
      "Epoch 70/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8463 - val_loss: 0.9045\n",
      "Epoch 71/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8459 - val_loss: 0.9072\n",
      "Epoch 72/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8452 - val_loss: 0.9048\n",
      "Epoch 73/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8443 - val_loss: 0.9049\n",
      "Epoch 74/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8443 - val_loss: 0.9014\n",
      "Epoch 75/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.8442 - val_loss: 0.9044\n",
      "Epoch 76/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8435 - val_loss: 0.9057\n",
      "Epoch 77/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.8419 - val_loss: 0.9044\n",
      "Epoch 78/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8418 - val_loss: 0.9046\n",
      "Epoch 79/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8411 - val_loss: 0.9054\n",
      "Epoch 80/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8404 - val_loss: 0.9048\n",
      "Epoch 81/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8405 - val_loss: 0.9046\n",
      "Epoch 82/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8401 - val_loss: 0.9072\n",
      "Epoch 83/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8393 - val_loss: 0.9065\n",
      "Epoch 84/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8387 - val_loss: 0.9040\n",
      "Epoch 85/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8380 - val_loss: 0.9030\n",
      "Epoch 86/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.8375 - val_loss: 0.9044\n",
      "Epoch 87/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8368 - val_loss: 0.9027\n",
      "Epoch 88/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.8366 - val_loss: 0.9032\n",
      "Epoch 89/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8360 - val_loss: 0.9042\n",
      "Epoch 90/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8353 - val_loss: 0.9033\n",
      "Epoch 91/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8349 - val_loss: 0.9009\n",
      "Epoch 92/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8343 - val_loss: 0.9006\n",
      "Epoch 93/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8343 - val_loss: 0.8994\n",
      "Epoch 94/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8336 - val_loss: 0.9010\n",
      "Epoch 95/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.8333 - val_loss: 0.9053\n",
      "Epoch 96/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8331 - val_loss: 0.9093\n",
      "Epoch 97/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8325 - val_loss: 0.9099\n",
      "Epoch 98/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8322 - val_loss: 0.9049\n",
      "Epoch 99/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8314 - val_loss: 0.9032\n",
      "Epoch 100/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8314 - val_loss: 0.9024\n",
      "Epoch 101/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8307 - val_loss: 0.9023\n",
      "Epoch 102/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8303 - val_loss: 0.9036\n",
      "Epoch 103/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8306 - val_loss: 0.9044\n",
      "Epoch 104/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8301 - val_loss: 0.9016\n",
      "Epoch 105/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8299 - val_loss: 0.8995\n",
      "Epoch 106/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8291 - val_loss: 0.9022\n",
      "Epoch 107/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8287 - val_loss: 0.9029\n",
      "Epoch 108/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.8288 - val_loss: 0.9055\n",
      "Epoch 109/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8294 - val_loss: 0.9074\n",
      "Epoch 110/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8277 - val_loss: 0.9054\n",
      "Epoch 111/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8277 - val_loss: 0.9061\n",
      "Epoch 112/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8271 - val_loss: 0.9032\n",
      "Epoch 113/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8269 - val_loss: 0.9037\n",
      "Epoch 114/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8268 - val_loss: 0.9019\n",
      "Epoch 115/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8268 - val_loss: 0.8987\n",
      "Epoch 116/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8271 - val_loss: 0.9042\n",
      "Epoch 117/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8263 - val_loss: 0.9050\n",
      "Epoch 118/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8259 - val_loss: 0.9028\n",
      "Epoch 119/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8258 - val_loss: 0.9007\n",
      "Epoch 120/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8258 - val_loss: 0.9002\n",
      "Epoch 121/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8251 - val_loss: 0.9013\n",
      "Epoch 122/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8254 - val_loss: 0.9059\n",
      "Epoch 123/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8250 - val_loss: 0.9062\n",
      "Epoch 124/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8247 - val_loss: 0.9041\n",
      "Epoch 125/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8251 - val_loss: 0.9025\n",
      "Epoch 126/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8238 - val_loss: 0.9034\n",
      "Epoch 127/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8246 - val_loss: 0.9026\n",
      "Epoch 128/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8237 - val_loss: 0.9026\n",
      "Epoch 129/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8245 - val_loss: 0.9013\n",
      "Epoch 130/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8241 - val_loss: 0.9010\n",
      "Epoch 131/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8235 - val_loss: 0.9028\n",
      "Epoch 132/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8237 - val_loss: 0.9055\n",
      "Epoch 133/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8242 - val_loss: 0.9081\n",
      "Epoch 134/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8229 - val_loss: 0.9055\n",
      "Epoch 135/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8232 - val_loss: 0.9029\n",
      "Epoch 136/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.8224 - val_loss: 0.9028\n",
      "Epoch 137/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8227 - val_loss: 0.9023\n",
      "Epoch 138/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8227 - val_loss: 0.9048\n",
      "Epoch 139/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8226 - val_loss: 0.9071\n",
      "Epoch 140/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8222 - val_loss: 0.9071\n",
      "Epoch 141/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8231 - val_loss: 0.9018\n",
      "Epoch 142/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8224 - val_loss: 0.9036\n",
      "Epoch 143/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8222 - val_loss: 0.9034\n",
      "Epoch 144/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8217 - val_loss: 0.9049\n",
      "Epoch 145/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.8221 - val_loss: 0.8999\n",
      "Epoch 146/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8221 - val_loss: 0.9037\n",
      "Epoch 147/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8218 - val_loss: 0.8993\n",
      "Epoch 148/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8209 - val_loss: 0.8994\n",
      "Epoch 149/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8213 - val_loss: 0.9001\n",
      "Epoch 150/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8208 - val_loss: 0.8994\n",
      "Epoch 151/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8207 - val_loss: 0.9005\n",
      "Epoch 152/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8210 - val_loss: 0.9009\n",
      "Epoch 153/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8208 - val_loss: 0.9061\n",
      "Epoch 154/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8202 - val_loss: 0.9062\n",
      "Epoch 155/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8201 - val_loss: 0.9067\n",
      "Epoch 156/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8210 - val_loss: 0.9096\n",
      "Epoch 157/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8201 - val_loss: 0.9028\n",
      "Epoch 158/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8202 - val_loss: 0.9003\n",
      "Epoch 159/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8201 - val_loss: 0.8988\n",
      "Epoch 160/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8201 - val_loss: 0.8971\n",
      "Epoch 161/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8205 - val_loss: 0.9010\n",
      "Epoch 162/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8197 - val_loss: 0.9013\n",
      "Epoch 163/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8200 - val_loss: 0.8995\n",
      "Epoch 164/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8202 - val_loss: 0.9005\n",
      "Epoch 165/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8207 - val_loss: 0.9060\n",
      "Epoch 166/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8193 - val_loss: 0.9074\n",
      "Epoch 167/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8192 - val_loss: 0.9034\n",
      "Epoch 168/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8190 - val_loss: 0.9010\n",
      "Epoch 169/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8191 - val_loss: 0.8998\n",
      "Epoch 170/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8190 - val_loss: 0.8968\n",
      "Epoch 171/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8188 - val_loss: 0.8980\n",
      "Epoch 172/1500\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.8188 - val_loss: 0.9030\n",
      "Epoch 173/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.8186 - val_loss: 0.9040\n",
      "Epoch 174/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.8184 - val_loss: 0.9060\n",
      "Epoch 175/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.8183 - val_loss: 0.9049\n",
      "Epoch 176/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.8187 - val_loss: 0.9004\n",
      "Epoch 177/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.8183 - val_loss: 0.9017\n",
      "Epoch 178/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.8180 - val_loss: 0.9009\n",
      "Epoch 179/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8188 - val_loss: 0.9005\n",
      "Epoch 180/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8181 - val_loss: 0.9001\n",
      "Epoch 181/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8182 - val_loss: 0.9023\n",
      "Epoch 182/1500\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.8178 - val_loss: 0.9035\n",
      "Epoch 183/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8183 - val_loss: 0.9032\n",
      "Epoch 184/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.8177 - val_loss: 0.8991\n",
      "Epoch 185/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.8177 - val_loss: 0.9012\n",
      "Epoch 186/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8176 - val_loss: 0.9035\n",
      "Epoch 187/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8173 - val_loss: 0.9033\n",
      "Epoch 188/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8173 - val_loss: 0.9006\n",
      "Epoch 189/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8168 - val_loss: 0.9006\n",
      "Epoch 190/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8170 - val_loss: 0.9022\n",
      "Epoch 191/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8173 - val_loss: 0.8983\n",
      "Epoch 192/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8173 - val_loss: 0.8963\n",
      "Epoch 193/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8169 - val_loss: 0.8968\n",
      "Epoch 194/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8167 - val_loss: 0.9013\n",
      "Epoch 195/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8167 - val_loss: 0.9032\n",
      "Epoch 196/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8171 - val_loss: 0.9053\n",
      "Epoch 197/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.8167 - val_loss: 0.9020\n",
      "Epoch 198/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8172 - val_loss: 0.8987\n",
      "Epoch 199/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8160 - val_loss: 0.8985\n",
      "Epoch 200/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8172 - val_loss: 0.8992\n",
      "Epoch 201/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8164 - val_loss: 0.8997\n",
      "Epoch 202/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8180 - val_loss: 0.9053\n",
      "Epoch 203/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8165 - val_loss: 0.9042\n",
      "Epoch 204/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8163 - val_loss: 0.8982\n",
      "Epoch 205/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8164 - val_loss: 0.9007\n",
      "Epoch 206/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8156 - val_loss: 0.9002\n",
      "Epoch 207/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8153 - val_loss: 0.8974\n",
      "Epoch 208/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8164 - val_loss: 0.8971\n",
      "Epoch 209/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8153 - val_loss: 0.8974\n",
      "Epoch 210/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8156 - val_loss: 0.9032\n",
      "Epoch 211/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8151 - val_loss: 0.9041\n",
      "Epoch 212/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8156 - val_loss: 0.8987\n",
      "Epoch 213/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8151 - val_loss: 0.8998\n",
      "Epoch 214/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8152 - val_loss: 0.8964\n",
      "Epoch 215/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.8157 - val_loss: 0.8969\n",
      "Epoch 216/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8155 - val_loss: 0.8984\n",
      "Epoch 217/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8155 - val_loss: 0.9005\n",
      "Epoch 218/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8152 - val_loss: 0.9060\n",
      "Epoch 219/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8158 - val_loss: 0.9033\n",
      "Epoch 220/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8146 - val_loss: 0.9019\n",
      "Epoch 221/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8151 - val_loss: 0.8985\n",
      "Epoch 222/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8150 - val_loss: 0.8996\n",
      "Epoch 223/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8144 - val_loss: 0.9009\n",
      "Epoch 224/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8144 - val_loss: 0.9012\n",
      "Epoch 225/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8147 - val_loss: 0.8961\n",
      "Epoch 226/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8141 - val_loss: 0.8981\n",
      "Epoch 227/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8144 - val_loss: 0.9018\n",
      "Epoch 228/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8135 - val_loss: 0.8984\n",
      "Epoch 229/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.8142 - val_loss: 0.8961\n",
      "Epoch 230/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8136 - val_loss: 0.8969\n",
      "Epoch 231/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.8147 - val_loss: 0.9034\n",
      "Epoch 232/1500\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.8141 - val_loss: 0.8963\n",
      "Epoch 233/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8135 - val_loss: 0.8987\n",
      "Epoch 234/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.8140 - val_loss: 0.8971\n",
      "Epoch 235/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.8133 - val_loss: 0.8975\n",
      "Epoch 236/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.8131 - val_loss: 0.8977\n",
      "Epoch 237/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8142 - val_loss: 0.8980\n",
      "Epoch 238/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8132 - val_loss: 0.8958\n",
      "Epoch 239/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8137 - val_loss: 0.9017\n",
      "Epoch 240/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.8131 - val_loss: 0.9019\n",
      "Epoch 241/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8128 - val_loss: 0.8999\n",
      "Epoch 242/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8130 - val_loss: 0.8945\n",
      "Epoch 243/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8126 - val_loss: 0.8955\n",
      "Epoch 244/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.8127 - val_loss: 0.8985\n",
      "Epoch 245/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8126 - val_loss: 0.8976\n",
      "Epoch 246/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8132 - val_loss: 0.8989\n",
      "Epoch 247/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8129 - val_loss: 0.8971\n",
      "Epoch 248/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.8133 - val_loss: 0.8998\n",
      "Epoch 249/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8120 - val_loss: 0.8970\n",
      "Epoch 250/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8133 - val_loss: 0.9025\n",
      "Epoch 251/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8120 - val_loss: 0.9025\n",
      "Epoch 252/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8118 - val_loss: 0.8989\n",
      "Epoch 253/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8122 - val_loss: 0.8934\n",
      "Epoch 254/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.8126 - val_loss: 0.8912\n",
      "Epoch 255/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.8124 - val_loss: 0.8973\n",
      "Epoch 256/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8119 - val_loss: 0.8944\n",
      "Epoch 257/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8115 - val_loss: 0.8985\n",
      "Epoch 258/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8114 - val_loss: 0.9004\n",
      "Epoch 259/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.8118 - val_loss: 0.8954\n",
      "Epoch 260/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8119 - val_loss: 0.8942\n",
      "Epoch 261/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8119 - val_loss: 0.9030\n",
      "Epoch 262/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8117 - val_loss: 0.9019\n",
      "Epoch 263/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.8113 - val_loss: 0.9029\n",
      "Epoch 264/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8113 - val_loss: 0.8987\n",
      "Epoch 265/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8125 - val_loss: 0.8889\n",
      "Epoch 266/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8118 - val_loss: 0.8863\n",
      "Epoch 267/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8110 - val_loss: 0.8937\n",
      "Epoch 268/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8119 - val_loss: 0.9006\n",
      "Epoch 269/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8107 - val_loss: 0.9024\n",
      "Epoch 270/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8112 - val_loss: 0.9029\n",
      "Epoch 271/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8109 - val_loss: 0.8966\n",
      "Epoch 272/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8105 - val_loss: 0.8930\n",
      "Epoch 273/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8106 - val_loss: 0.8929\n",
      "Epoch 274/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8102 - val_loss: 0.8971\n",
      "Epoch 275/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8107 - val_loss: 0.8973\n",
      "Epoch 276/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8106 - val_loss: 0.8967\n",
      "Epoch 277/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8101 - val_loss: 0.8995\n",
      "Epoch 278/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8106 - val_loss: 0.8992\n",
      "Epoch 279/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8103 - val_loss: 0.8966\n",
      "Epoch 280/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8103 - val_loss: 0.8930\n",
      "Epoch 281/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8099 - val_loss: 0.8973\n",
      "Epoch 282/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8103 - val_loss: 0.8945\n",
      "Epoch 283/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8102 - val_loss: 0.9022\n",
      "Epoch 284/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8100 - val_loss: 0.9005\n",
      "Epoch 285/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8099 - val_loss: 0.9007\n",
      "Epoch 286/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8094 - val_loss: 0.8970\n",
      "Epoch 287/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8096 - val_loss: 0.8974\n",
      "Epoch 288/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8094 - val_loss: 0.8913\n",
      "Epoch 289/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.8098 - val_loss: 0.8897\n",
      "Epoch 290/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8105 - val_loss: 0.8981\n",
      "Epoch 291/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8092 - val_loss: 0.8978\n",
      "Epoch 292/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8093 - val_loss: 0.8946\n",
      "Epoch 293/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8095 - val_loss: 0.8903\n",
      "Epoch 294/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8107 - val_loss: 0.8982\n",
      "Epoch 295/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8097 - val_loss: 0.8970\n",
      "Epoch 296/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8100 - val_loss: 0.8924\n",
      "Epoch 297/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8088 - val_loss: 0.8959\n",
      "Epoch 298/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8096 - val_loss: 0.8992\n",
      "Epoch 299/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8087 - val_loss: 0.8955\n",
      "Epoch 300/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8082 - val_loss: 0.8948\n",
      "Epoch 301/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8084 - val_loss: 0.8939\n",
      "Epoch 302/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8099 - val_loss: 0.8896\n",
      "Epoch 303/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8094 - val_loss: 0.9001\n",
      "Epoch 304/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8091 - val_loss: 0.8987\n",
      "Epoch 305/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8080 - val_loss: 0.8979\n",
      "Epoch 306/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8081 - val_loss: 0.8933\n",
      "Epoch 307/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8092 - val_loss: 0.8995\n",
      "Epoch 308/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8081 - val_loss: 0.8988\n",
      "Epoch 309/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8080 - val_loss: 0.8913\n",
      "Epoch 310/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8078 - val_loss: 0.8906\n",
      "Epoch 311/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8082 - val_loss: 0.8892\n",
      "Epoch 312/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8081 - val_loss: 0.8914\n",
      "Epoch 313/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8080 - val_loss: 0.8930\n",
      "Epoch 314/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8074 - val_loss: 0.8988\n",
      "Epoch 315/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8086 - val_loss: 0.9038\n",
      "Epoch 316/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8076 - val_loss: 0.9021\n",
      "Epoch 317/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8080 - val_loss: 0.8917\n",
      "Epoch 318/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8074 - val_loss: 0.8934\n",
      "Epoch 319/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8075 - val_loss: 0.8943\n",
      "Epoch 320/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8071 - val_loss: 0.8930\n",
      "Epoch 321/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8074 - val_loss: 0.8954\n",
      "Epoch 322/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8082 - val_loss: 0.8872\n",
      "Epoch 323/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8076 - val_loss: 0.8864\n",
      "Epoch 324/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8074 - val_loss: 0.8963\n",
      "Epoch 325/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8075 - val_loss: 0.9003\n",
      "Epoch 326/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8077 - val_loss: 0.9028\n",
      "Epoch 327/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8071 - val_loss: 0.8964\n",
      "Epoch 328/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8067 - val_loss: 0.8927\n",
      "Epoch 329/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8063 - val_loss: 0.8905\n",
      "Epoch 330/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8066 - val_loss: 0.8957\n",
      "Epoch 331/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8069 - val_loss: 0.8963\n",
      "Epoch 332/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8064 - val_loss: 0.8934\n",
      "Epoch 333/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8066 - val_loss: 0.8922\n",
      "Epoch 334/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8066 - val_loss: 0.8879\n",
      "Epoch 335/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8059 - val_loss: 0.8921\n",
      "Epoch 336/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8061 - val_loss: 0.8976\n",
      "Epoch 337/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8060 - val_loss: 0.8976\n",
      "Epoch 338/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8064 - val_loss: 0.8981\n",
      "Epoch 339/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.8064 - val_loss: 0.8889\n",
      "Epoch 340/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8063 - val_loss: 0.8871\n",
      "Epoch 341/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8066 - val_loss: 0.8975\n",
      "Epoch 342/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8055 - val_loss: 0.8985\n",
      "Epoch 343/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8060 - val_loss: 0.8909\n",
      "Epoch 344/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8061 - val_loss: 0.8878\n",
      "Epoch 345/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8067 - val_loss: 0.9005\n",
      "Epoch 346/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8054 - val_loss: 0.9001\n",
      "Epoch 347/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8053 - val_loss: 0.8932\n",
      "Epoch 348/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8063 - val_loss: 0.8854\n",
      "Epoch 349/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8050 - val_loss: 0.8897\n",
      "Epoch 350/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8054 - val_loss: 0.8896\n",
      "Epoch 351/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8050 - val_loss: 0.8955\n",
      "Epoch 352/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8052 - val_loss: 0.8998\n",
      "Epoch 353/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8050 - val_loss: 0.8970\n",
      "Epoch 354/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8059 - val_loss: 0.8986\n",
      "Epoch 355/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.8051 - val_loss: 0.8893\n",
      "Epoch 356/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8056 - val_loss: 0.8912\n",
      "Epoch 357/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8050 - val_loss: 0.8910\n",
      "Epoch 358/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8047 - val_loss: 0.8929\n",
      "Epoch 359/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8044 - val_loss: 0.8938\n",
      "Epoch 360/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8048 - val_loss: 0.8958\n",
      "Epoch 361/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8056 - val_loss: 0.8887\n",
      "Epoch 362/1500\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8053 - val_loss: 0.8848\n",
      "Epoch 363/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8040 - val_loss: 0.8908\n",
      "Epoch 364/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8043 - val_loss: 0.8952\n",
      "Epoch 365/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8043 - val_loss: 0.8993\n",
      "Epoch 366/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8042 - val_loss: 0.8968\n",
      "Epoch 367/1500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8044 - val_loss: 0.8927\n",
      "Epoch 368/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8041 - val_loss: 0.8915\n",
      "Epoch 369/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.8042 - val_loss: 0.8927\n",
      "Epoch 370/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8047 - val_loss: 0.8976\n",
      "Epoch 371/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8034 - val_loss: 0.8949\n",
      "Epoch 372/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8047 - val_loss: 0.8854\n",
      "Epoch 373/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8041 - val_loss: 0.8913\n",
      "Epoch 374/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8038 - val_loss: 0.8927\n",
      "Epoch 375/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8040 - val_loss: 0.8978\n",
      "Epoch 376/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8045 - val_loss: 0.9007\n",
      "Epoch 377/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8039 - val_loss: 0.8887\n",
      "Epoch 378/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8031 - val_loss: 0.8870\n",
      "Epoch 379/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8032 - val_loss: 0.8860\n",
      "Epoch 380/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8033 - val_loss: 0.8858\n",
      "Epoch 381/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8033 - val_loss: 0.8926\n",
      "Epoch 382/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8032 - val_loss: 0.8965\n",
      "Epoch 383/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.8030 - val_loss: 0.8970\n",
      "Epoch 384/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8033 - val_loss: 0.8943\n",
      "Epoch 385/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8027 - val_loss: 0.8902\n",
      "Epoch 386/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8032 - val_loss: 0.8903\n",
      "Epoch 387/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.8029 - val_loss: 0.8953\n",
      "Epoch 388/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8030 - val_loss: 0.8920\n",
      "Epoch 389/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8026 - val_loss: 0.8904\n",
      "Epoch 390/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8029 - val_loss: 0.8933\n",
      "Epoch 391/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8025 - val_loss: 0.8901\n",
      "Epoch 392/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8024 - val_loss: 0.8898\n",
      "Epoch 393/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8025 - val_loss: 0.8926\n",
      "Epoch 394/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8024 - val_loss: 0.8955\n",
      "Epoch 395/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8029 - val_loss: 0.8889\n",
      "Epoch 396/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.8024 - val_loss: 0.8915\n",
      "Epoch 397/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.8022 - val_loss: 0.8894\n",
      "Epoch 398/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.8027 - val_loss: 0.8956\n",
      "Epoch 399/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8028 - val_loss: 0.8878\n",
      "Epoch 400/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8028 - val_loss: 0.8849\n",
      "Epoch 401/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8019 - val_loss: 0.8928\n",
      "Epoch 402/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.8015 - val_loss: 0.8982\n",
      "Epoch 403/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8023 - val_loss: 0.8975\n",
      "Epoch 404/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8019 - val_loss: 0.8967\n",
      "Epoch 405/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8021 - val_loss: 0.8912\n",
      "Epoch 406/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8021 - val_loss: 0.8867\n",
      "Epoch 407/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8020 - val_loss: 0.8927\n",
      "Epoch 408/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8015 - val_loss: 0.8936\n",
      "Epoch 409/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8018 - val_loss: 0.8977\n",
      "Epoch 410/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8014 - val_loss: 0.8901\n",
      "Epoch 411/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8026 - val_loss: 0.8823\n",
      "Epoch 412/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8011 - val_loss: 0.8869\n",
      "Epoch 413/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8007 - val_loss: 0.8921\n",
      "Epoch 414/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8010 - val_loss: 0.8949\n",
      "Epoch 415/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8009 - val_loss: 0.9004\n",
      "Epoch 416/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8013 - val_loss: 0.9026\n",
      "Epoch 417/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8008 - val_loss: 0.8910\n",
      "Epoch 418/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8011 - val_loss: 0.8828\n",
      "Epoch 419/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8019 - val_loss: 0.8936\n",
      "Epoch 420/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8008 - val_loss: 0.8925\n",
      "Epoch 421/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8005 - val_loss: 0.8884\n",
      "Epoch 422/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8004 - val_loss: 0.8894\n",
      "Epoch 423/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8010 - val_loss: 0.8874\n",
      "Epoch 424/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8010 - val_loss: 0.8917\n",
      "Epoch 425/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8002 - val_loss: 0.8924\n",
      "Epoch 426/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8007 - val_loss: 0.8898\n",
      "Epoch 427/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8002 - val_loss: 0.8945\n",
      "Epoch 428/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8002 - val_loss: 0.8952\n",
      "Epoch 429/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7997 - val_loss: 0.8928\n",
      "Epoch 430/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8003 - val_loss: 0.8890\n",
      "Epoch 431/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.8006 - val_loss: 0.8850\n",
      "Epoch 432/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8004 - val_loss: 0.8890\n",
      "Epoch 433/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7997 - val_loss: 0.8971\n",
      "Epoch 434/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8009 - val_loss: 0.9050\n",
      "Epoch 435/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7999 - val_loss: 0.8970\n",
      "Epoch 436/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7994 - val_loss: 0.8884\n",
      "Epoch 437/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8009 - val_loss: 0.8785\n",
      "Epoch 438/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8008 - val_loss: 0.8779\n",
      "Epoch 439/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7990 - val_loss: 0.8925\n",
      "Epoch 440/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7993 - val_loss: 0.8988\n",
      "Epoch 441/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7996 - val_loss: 0.9010\n",
      "Epoch 442/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8001 - val_loss: 0.8933\n",
      "Epoch 443/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7997 - val_loss: 0.8886\n",
      "Epoch 444/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.8004 - val_loss: 0.8989\n",
      "Epoch 445/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8001 - val_loss: 0.8871\n",
      "Epoch 446/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7991 - val_loss: 0.8857\n",
      "Epoch 447/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7995 - val_loss: 0.8915\n",
      "Epoch 448/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8003 - val_loss: 0.8824\n",
      "Epoch 449/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7994 - val_loss: 0.8951\n",
      "Epoch 450/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7998 - val_loss: 0.8912\n",
      "Epoch 451/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7987 - val_loss: 0.8947\n",
      "Epoch 452/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7986 - val_loss: 0.8937\n",
      "Epoch 453/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7992 - val_loss: 0.8897\n",
      "Epoch 454/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7987 - val_loss: 0.8926\n",
      "Epoch 455/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.8008 - val_loss: 0.8819\n",
      "Epoch 456/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7988 - val_loss: 0.8846\n",
      "Epoch 457/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7982 - val_loss: 0.8928\n",
      "Epoch 458/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7982 - val_loss: 0.8986\n",
      "Epoch 459/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7994 - val_loss: 0.9038\n",
      "Epoch 460/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7986 - val_loss: 0.8941\n",
      "Epoch 461/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7985 - val_loss: 0.8847\n",
      "Epoch 462/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7989 - val_loss: 0.8877\n",
      "Epoch 463/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7981 - val_loss: 0.8881\n",
      "Epoch 464/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7980 - val_loss: 0.8900\n",
      "Epoch 465/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7990 - val_loss: 0.9018\n",
      "Epoch 466/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7981 - val_loss: 0.8942\n",
      "Epoch 467/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7981 - val_loss: 0.8867\n",
      "Epoch 468/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7981 - val_loss: 0.8888\n",
      "Epoch 469/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7991 - val_loss: 0.8818\n",
      "Epoch 470/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7986 - val_loss: 0.8873\n",
      "Epoch 471/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7976 - val_loss: 0.8944\n",
      "Epoch 472/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7998 - val_loss: 0.9064\n",
      "Epoch 473/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7983 - val_loss: 0.8980\n",
      "Epoch 474/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7970 - val_loss: 0.8893\n",
      "Epoch 475/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7983 - val_loss: 0.8850\n",
      "Epoch 476/1500\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7979 - val_loss: 0.8806\n",
      "Epoch 477/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7981 - val_loss: 0.8907\n",
      "Epoch 478/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7981 - val_loss: 0.8920\n",
      "Epoch 479/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7991 - val_loss: 0.8995\n",
      "Epoch 480/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7976 - val_loss: 0.8907\n",
      "Epoch 481/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7970 - val_loss: 0.8868\n",
      "Epoch 482/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7970 - val_loss: 0.8850\n",
      "Epoch 483/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7972 - val_loss: 0.8864\n",
      "Epoch 484/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7975 - val_loss: 0.8898\n",
      "Epoch 485/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7978 - val_loss: 0.8953\n",
      "Epoch 486/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7986 - val_loss: 0.9018\n",
      "Epoch 487/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7968 - val_loss: 0.8930\n",
      "Epoch 488/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7980 - val_loss: 0.8799\n",
      "Epoch 489/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7974 - val_loss: 0.8868\n",
      "Epoch 490/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7974 - val_loss: 0.8880\n",
      "Epoch 491/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7971 - val_loss: 0.8841\n",
      "Epoch 492/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7962 - val_loss: 0.8891\n",
      "Epoch 493/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7965 - val_loss: 0.8945\n",
      "Epoch 494/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7978 - val_loss: 0.8857\n",
      "Epoch 495/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7962 - val_loss: 0.8904\n",
      "Epoch 496/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7970 - val_loss: 0.8893\n",
      "Epoch 497/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7961 - val_loss: 0.8974\n",
      "Epoch 498/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7964 - val_loss: 0.8994\n",
      "Epoch 499/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7970 - val_loss: 0.8961\n",
      "Epoch 500/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7970 - val_loss: 0.8809\n",
      "Epoch 501/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7965 - val_loss: 0.8812\n",
      "Epoch 502/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7963 - val_loss: 0.8946\n",
      "Epoch 503/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7966 - val_loss: 0.8912\n",
      "Epoch 504/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7967 - val_loss: 0.8991\n",
      "Epoch 505/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7968 - val_loss: 0.8941\n",
      "Epoch 506/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7960 - val_loss: 0.8852\n",
      "Epoch 507/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7959 - val_loss: 0.8832\n",
      "Epoch 508/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7972 - val_loss: 0.8949\n",
      "Epoch 509/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7963 - val_loss: 0.8976\n",
      "Epoch 510/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7952 - val_loss: 0.8925\n",
      "Epoch 511/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7963 - val_loss: 0.8791\n",
      "Epoch 512/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7958 - val_loss: 0.8847\n",
      "Epoch 513/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7958 - val_loss: 0.8890\n",
      "Epoch 514/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7954 - val_loss: 0.8937\n",
      "Epoch 515/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7960 - val_loss: 0.8878\n",
      "Epoch 516/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7962 - val_loss: 0.8924\n",
      "Epoch 517/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7956 - val_loss: 0.8864\n",
      "Epoch 518/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7951 - val_loss: 0.8900\n",
      "Epoch 519/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7949 - val_loss: 0.8896\n",
      "Epoch 520/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7950 - val_loss: 0.8873\n",
      "Epoch 521/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7952 - val_loss: 0.8869\n",
      "Epoch 522/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7957 - val_loss: 0.8984\n",
      "Epoch 523/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7968 - val_loss: 0.8837\n",
      "Epoch 524/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7958 - val_loss: 0.8966\n",
      "Epoch 525/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7959 - val_loss: 0.9019\n",
      "Epoch 526/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7946 - val_loss: 0.8911\n",
      "Epoch 527/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7945 - val_loss: 0.8838\n",
      "Epoch 528/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7953 - val_loss: 0.8795\n",
      "Epoch 529/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7949 - val_loss: 0.8815\n",
      "Epoch 530/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7947 - val_loss: 0.8899\n",
      "Epoch 531/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7949 - val_loss: 0.9035\n",
      "Epoch 532/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7967 - val_loss: 0.9024\n",
      "Epoch 533/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7960 - val_loss: 0.8840\n",
      "Epoch 534/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7959 - val_loss: 0.8752\n",
      "Epoch 535/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7977 - val_loss: 0.8983\n",
      "Epoch 536/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7947 - val_loss: 0.8981\n",
      "Epoch 537/1500\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.7937 - val_loss: 0.8905\n",
      "Epoch 538/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7942 - val_loss: 0.8825\n",
      "Epoch 539/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7947 - val_loss: 0.8842\n",
      "Epoch 540/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7941 - val_loss: 0.8869\n",
      "Epoch 541/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7942 - val_loss: 0.8882\n",
      "Epoch 542/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7939 - val_loss: 0.8859\n",
      "Epoch 543/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7955 - val_loss: 0.8834\n",
      "Epoch 544/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7941 - val_loss: 0.8978\n",
      "Epoch 545/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7940 - val_loss: 0.8931\n",
      "Epoch 546/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7938 - val_loss: 0.8877\n",
      "Epoch 547/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7963 - val_loss: 0.9021\n",
      "Epoch 548/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7942 - val_loss: 0.8894\n",
      "Epoch 549/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7936 - val_loss: 0.8861\n",
      "Epoch 550/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7943 - val_loss: 0.8854\n",
      "Epoch 551/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7943 - val_loss: 0.8957\n",
      "Epoch 552/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7935 - val_loss: 0.8877\n",
      "Epoch 553/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7939 - val_loss: 0.8857\n",
      "Epoch 554/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7948 - val_loss: 0.8987\n",
      "Epoch 555/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7938 - val_loss: 0.8967\n",
      "Epoch 556/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7949 - val_loss: 0.8778\n",
      "Epoch 557/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7950 - val_loss: 0.8763\n",
      "Epoch 558/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7932 - val_loss: 0.8872\n",
      "Epoch 559/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7942 - val_loss: 0.9034\n",
      "Epoch 560/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7961 - val_loss: 0.9075\n",
      "Epoch 561/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7935 - val_loss: 0.8956\n",
      "Epoch 562/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7937 - val_loss: 0.8819\n",
      "Epoch 563/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7935 - val_loss: 0.8767\n",
      "Epoch 564/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7945 - val_loss: 0.8889\n",
      "Epoch 565/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7929 - val_loss: 0.8898\n",
      "Epoch 566/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7934 - val_loss: 0.8899\n",
      "Epoch 567/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7933 - val_loss: 0.8897\n",
      "Epoch 568/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7934 - val_loss: 0.8965\n",
      "Epoch 569/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7959 - val_loss: 0.9096\n",
      "Epoch 570/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7927 - val_loss: 0.8892\n",
      "Epoch 571/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7925 - val_loss: 0.8859\n",
      "Epoch 572/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7937 - val_loss: 0.8744\n",
      "Epoch 573/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7930 - val_loss: 0.8810\n",
      "Epoch 574/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7922 - val_loss: 0.8919\n",
      "Epoch 575/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7930 - val_loss: 0.8961\n",
      "Epoch 576/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7928 - val_loss: 0.8952\n",
      "Epoch 577/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7941 - val_loss: 0.8850\n",
      "Epoch 578/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7921 - val_loss: 0.8881\n",
      "Epoch 579/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7921 - val_loss: 0.8948\n",
      "Epoch 580/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7922 - val_loss: 0.8984\n",
      "Epoch 581/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7922 - val_loss: 0.8941\n",
      "Epoch 582/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7918 - val_loss: 0.8881\n",
      "Epoch 583/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7933 - val_loss: 0.8884\n",
      "Epoch 584/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7927 - val_loss: 0.8845\n",
      "Epoch 585/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7922 - val_loss: 0.8911\n",
      "Epoch 586/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7925 - val_loss: 0.8974\n",
      "Epoch 587/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7919 - val_loss: 0.8901\n",
      "Epoch 588/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7916 - val_loss: 0.8855\n",
      "Epoch 589/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7927 - val_loss: 0.8843\n",
      "Epoch 590/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7919 - val_loss: 0.8929\n",
      "Epoch 591/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7919 - val_loss: 0.9034\n",
      "Epoch 592/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7928 - val_loss: 0.8949\n",
      "Epoch 593/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7922 - val_loss: 0.8880\n",
      "Epoch 594/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7919 - val_loss: 0.8897\n",
      "Epoch 595/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7920 - val_loss: 0.8941\n",
      "Epoch 596/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7920 - val_loss: 0.8877\n",
      "Epoch 597/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7914 - val_loss: 0.8916\n",
      "Epoch 598/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7917 - val_loss: 0.8935\n",
      "Epoch 599/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7921 - val_loss: 0.8834\n",
      "Epoch 600/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7919 - val_loss: 0.8823\n",
      "Epoch 601/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7918 - val_loss: 0.8980\n",
      "Epoch 602/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7917 - val_loss: 0.9017\n",
      "Epoch 603/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7911 - val_loss: 0.8980\n",
      "Epoch 604/1500\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.7914 - val_loss: 0.8817\n",
      "Epoch 605/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7944 - val_loss: 0.8706\n",
      "Epoch 606/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7938 - val_loss: 0.8999\n",
      "Epoch 607/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7919 - val_loss: 0.8955\n",
      "Epoch 608/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7926 - val_loss: 0.9065\n",
      "Epoch 609/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7915 - val_loss: 0.8879\n",
      "Epoch 610/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7909 - val_loss: 0.8859\n",
      "Epoch 611/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7913 - val_loss: 0.8794\n",
      "Epoch 612/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7922 - val_loss: 0.8969\n",
      "Epoch 613/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7916 - val_loss: 0.8963\n",
      "Epoch 614/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7905 - val_loss: 0.8882\n",
      "Epoch 615/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7921 - val_loss: 0.8839\n",
      "Epoch 616/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7909 - val_loss: 0.8848\n",
      "Epoch 617/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7938 - val_loss: 0.9066\n",
      "Epoch 618/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7919 - val_loss: 0.8996\n",
      "Epoch 619/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7903 - val_loss: 0.8893\n",
      "Epoch 620/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7913 - val_loss: 0.8835\n",
      "Epoch 621/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7912 - val_loss: 0.8797\n",
      "Epoch 622/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7906 - val_loss: 0.8818\n",
      "Epoch 623/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7905 - val_loss: 0.8926\n",
      "Epoch 624/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7912 - val_loss: 0.8957\n",
      "Epoch 625/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7918 - val_loss: 0.9026\n",
      "Epoch 626/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7906 - val_loss: 0.8948\n",
      "Epoch 627/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7910 - val_loss: 0.8801\n",
      "Epoch 628/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7917 - val_loss: 0.8866\n",
      "Epoch 629/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7901 - val_loss: 0.8859\n",
      "Epoch 630/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7910 - val_loss: 0.8925\n",
      "Epoch 631/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7908 - val_loss: 0.8859\n",
      "Epoch 632/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7905 - val_loss: 0.8945\n",
      "Epoch 633/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7917 - val_loss: 0.9058\n",
      "Epoch 634/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7902 - val_loss: 0.8925\n",
      "Epoch 635/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7901 - val_loss: 0.8773\n",
      "Epoch 636/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7920 - val_loss: 0.8896\n",
      "Epoch 637/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7899 - val_loss: 0.8883\n",
      "Epoch 638/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7900 - val_loss: 0.8858\n",
      "Epoch 639/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7917 - val_loss: 0.9004\n",
      "Epoch 640/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7920 - val_loss: 0.9034\n",
      "Epoch 641/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7919 - val_loss: 0.8746\n",
      "Epoch 642/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7908 - val_loss: 0.8779\n",
      "Epoch 643/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7896 - val_loss: 0.8873\n",
      "Epoch 644/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7895 - val_loss: 0.8981\n",
      "Epoch 645/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7904 - val_loss: 0.9086\n",
      "Epoch 646/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7907 - val_loss: 0.8956\n",
      "Epoch 647/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7911 - val_loss: 0.8782\n",
      "Epoch 648/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7907 - val_loss: 0.8911\n",
      "Epoch 649/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7898 - val_loss: 0.8880\n",
      "Epoch 650/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7904 - val_loss: 0.9018\n",
      "Epoch 651/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7897 - val_loss: 0.8976\n",
      "Epoch 652/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7898 - val_loss: 0.8810\n",
      "Epoch 653/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7901 - val_loss: 0.8884\n",
      "Epoch 654/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7892 - val_loss: 0.8871\n",
      "Epoch 655/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7890 - val_loss: 0.8883\n",
      "Epoch 656/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7890 - val_loss: 0.8966\n",
      "Epoch 657/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7901 - val_loss: 0.8902\n",
      "Epoch 658/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7895 - val_loss: 0.8986\n",
      "Epoch 659/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7902 - val_loss: 0.8901\n",
      "Epoch 660/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7893 - val_loss: 0.8876\n",
      "Epoch 661/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7916 - val_loss: 0.8792\n",
      "Epoch 662/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7892 - val_loss: 0.8867\n",
      "Epoch 663/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7892 - val_loss: 0.8948\n",
      "Epoch 664/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7893 - val_loss: 0.8962\n",
      "Epoch 665/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7893 - val_loss: 0.9013\n",
      "Epoch 666/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7891 - val_loss: 0.8908\n",
      "Epoch 667/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7890 - val_loss: 0.8861\n",
      "Epoch 668/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7893 - val_loss: 0.8811\n",
      "Epoch 669/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7892 - val_loss: 0.8928\n",
      "Epoch 670/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7888 - val_loss: 0.8892\n",
      "Epoch 671/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7885 - val_loss: 0.8963\n",
      "Epoch 672/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7885 - val_loss: 0.8918\n",
      "Epoch 673/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7885 - val_loss: 0.8906\n",
      "Epoch 674/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7889 - val_loss: 0.8827\n",
      "Epoch 675/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7882 - val_loss: 0.8855\n",
      "Epoch 676/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7882 - val_loss: 0.8938\n",
      "Epoch 677/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7883 - val_loss: 0.8969\n",
      "Epoch 678/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7887 - val_loss: 0.9006\n",
      "Epoch 679/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7879 - val_loss: 0.8929\n",
      "Epoch 680/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7877 - val_loss: 0.8890\n",
      "Epoch 681/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7886 - val_loss: 0.8853\n",
      "Epoch 682/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7888 - val_loss: 0.8882\n",
      "Epoch 683/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7883 - val_loss: 0.8958\n",
      "Epoch 684/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7883 - val_loss: 0.8942\n",
      "Epoch 685/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7888 - val_loss: 0.8909\n",
      "Epoch 686/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7878 - val_loss: 0.8833\n",
      "Epoch 687/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7892 - val_loss: 0.8818\n",
      "Epoch 688/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7878 - val_loss: 0.8920\n",
      "Epoch 689/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7875 - val_loss: 0.9024\n",
      "Epoch 690/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7888 - val_loss: 0.9009\n",
      "Epoch 691/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7886 - val_loss: 0.8981\n",
      "Epoch 692/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7878 - val_loss: 0.8820\n",
      "Epoch 693/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7911 - val_loss: 0.8773\n",
      "Epoch 694/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7896 - val_loss: 0.8997\n",
      "Epoch 695/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7884 - val_loss: 0.8943\n",
      "Epoch 696/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7882 - val_loss: 0.8844\n",
      "Epoch 697/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7876 - val_loss: 0.8928\n",
      "Epoch 698/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7897 - val_loss: 0.8818\n",
      "Epoch 699/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7885 - val_loss: 0.9023\n",
      "Epoch 700/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7874 - val_loss: 0.8950\n",
      "Epoch 701/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7872 - val_loss: 0.8906\n",
      "Epoch 702/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7899 - val_loss: 0.8765\n",
      "Epoch 703/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7876 - val_loss: 0.8921\n",
      "Epoch 704/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7909 - val_loss: 0.9164\n",
      "Epoch 705/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7887 - val_loss: 0.8900\n",
      "Epoch 706/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7888 - val_loss: 0.8732\n",
      "Epoch 707/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7884 - val_loss: 0.8836\n",
      "Epoch 708/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7872 - val_loss: 0.8920\n",
      "Epoch 709/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7867 - val_loss: 0.9037\n",
      "Epoch 710/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7877 - val_loss: 0.9128\n",
      "Epoch 711/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7877 - val_loss: 0.9001\n",
      "Epoch 712/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7863 - val_loss: 0.8869\n",
      "Epoch 713/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7869 - val_loss: 0.8815\n",
      "Epoch 714/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7878 - val_loss: 0.8739\n",
      "Epoch 715/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7875 - val_loss: 0.8828\n",
      "Epoch 716/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7866 - val_loss: 0.8987\n",
      "Epoch 717/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7929 - val_loss: 0.9237\n",
      "Epoch 718/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7872 - val_loss: 0.8952\n",
      "Epoch 719/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7876 - val_loss: 0.8724\n",
      "Epoch 720/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7891 - val_loss: 0.8722\n",
      "Epoch 721/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7876 - val_loss: 0.8849\n",
      "Epoch 722/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7863 - val_loss: 0.9010\n",
      "Epoch 723/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7901 - val_loss: 0.9167\n",
      "Epoch 724/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7880 - val_loss: 0.8875\n",
      "Epoch 725/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7872 - val_loss: 0.8840\n",
      "Epoch 726/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7869 - val_loss: 0.8888\n",
      "Epoch 727/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7871 - val_loss: 0.8956\n",
      "Epoch 728/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7873 - val_loss: 0.8864\n",
      "Epoch 729/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7863 - val_loss: 0.8885\n",
      "Epoch 730/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7873 - val_loss: 0.8955\n",
      "Epoch 731/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7894 - val_loss: 0.8812\n",
      "Epoch 732/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7869 - val_loss: 0.8938\n",
      "Epoch 733/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7866 - val_loss: 0.9089\n",
      "Epoch 734/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7876 - val_loss: 0.9018\n",
      "Epoch 735/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7855 - val_loss: 0.8887\n",
      "Epoch 736/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7867 - val_loss: 0.8820\n",
      "Epoch 737/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7865 - val_loss: 0.8880\n",
      "Epoch 738/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7864 - val_loss: 0.8857\n",
      "Epoch 739/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7862 - val_loss: 0.8946\n",
      "Epoch 740/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7862 - val_loss: 0.8956\n",
      "Epoch 741/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7884 - val_loss: 0.9043\n",
      "Epoch 742/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7891 - val_loss: 0.8798\n",
      "Epoch 743/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7869 - val_loss: 0.8790\n",
      "Epoch 744/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7875 - val_loss: 0.8991\n",
      "Epoch 745/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7867 - val_loss: 0.8964\n",
      "Epoch 746/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7860 - val_loss: 0.8982\n",
      "Epoch 747/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7868 - val_loss: 0.8902\n",
      "Epoch 748/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7865 - val_loss: 0.8977\n",
      "Epoch 749/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7861 - val_loss: 0.8872\n",
      "Epoch 750/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7865 - val_loss: 0.8891\n",
      "Epoch 751/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7895 - val_loss: 0.8768\n",
      "Epoch 752/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7853 - val_loss: 0.8910\n",
      "Epoch 753/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7866 - val_loss: 0.9078\n",
      "Epoch 754/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7871 - val_loss: 0.8976\n",
      "Epoch 755/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7857 - val_loss: 0.8848\n",
      "Epoch 756/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7862 - val_loss: 0.8831\n",
      "Epoch 757/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7856 - val_loss: 0.8880\n",
      "Epoch 758/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7859 - val_loss: 0.8973\n",
      "Epoch 759/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7857 - val_loss: 0.8880\n",
      "Epoch 760/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7871 - val_loss: 0.8906\n",
      "Epoch 761/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7856 - val_loss: 0.8942\n",
      "Epoch 762/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7862 - val_loss: 0.9005\n",
      "Epoch 763/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7850 - val_loss: 0.8865\n",
      "Epoch 764/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7859 - val_loss: 0.8822\n",
      "Epoch 765/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7863 - val_loss: 0.8845\n",
      "Epoch 766/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7852 - val_loss: 0.9015\n",
      "Epoch 767/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7859 - val_loss: 0.8993\n",
      "Epoch 768/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7857 - val_loss: 0.8981\n",
      "Epoch 769/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7854 - val_loss: 0.8843\n",
      "Epoch 770/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7850 - val_loss: 0.8844\n",
      "Epoch 771/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7852 - val_loss: 0.8817\n",
      "Epoch 772/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7868 - val_loss: 0.9049\n",
      "Epoch 773/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7873 - val_loss: 0.9017\n",
      "Epoch 774/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7850 - val_loss: 0.8817\n",
      "Epoch 775/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7867 - val_loss: 0.8811\n",
      "Epoch 776/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7864 - val_loss: 0.8853\n",
      "Epoch 777/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7848 - val_loss: 0.8986\n",
      "Epoch 778/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7849 - val_loss: 0.9033\n",
      "Epoch 779/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7880 - val_loss: 0.9118\n",
      "Epoch 780/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7840 - val_loss: 0.8883\n",
      "Epoch 781/1500\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.7863 - val_loss: 0.8665\n",
      "Epoch 782/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7857 - val_loss: 0.8799\n",
      "Epoch 783/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7859 - val_loss: 0.9086\n",
      "Epoch 784/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7865 - val_loss: 0.9037\n",
      "Epoch 785/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7849 - val_loss: 0.8860\n",
      "Epoch 786/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7861 - val_loss: 0.8741\n",
      "Epoch 787/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7850 - val_loss: 0.8825\n",
      "Epoch 788/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7849 - val_loss: 0.9012\n",
      "Epoch 789/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7851 - val_loss: 0.9131\n",
      "Epoch 790/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7854 - val_loss: 0.9016\n",
      "Epoch 791/1500\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7863 - val_loss: 0.8750\n",
      "Epoch 792/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7862 - val_loss: 0.8813\n",
      "Epoch 793/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7843 - val_loss: 0.8880\n",
      "Epoch 794/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7847 - val_loss: 0.8939\n",
      "Epoch 795/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7865 - val_loss: 0.9159\n",
      "Epoch 796/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7872 - val_loss: 0.8844\n",
      "Epoch 797/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7880 - val_loss: 0.8976\n",
      "Epoch 798/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7866 - val_loss: 0.8789\n",
      "Epoch 799/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7868 - val_loss: 0.8939\n",
      "Epoch 800/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7841 - val_loss: 0.8939\n",
      "Epoch 801/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7867 - val_loss: 0.8813\n",
      "Epoch 802/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7850 - val_loss: 0.8950\n",
      "Epoch 803/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7846 - val_loss: 0.9036\n",
      "Epoch 804/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7847 - val_loss: 0.8951\n",
      "Epoch 805/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7856 - val_loss: 0.8717\n",
      "Epoch 806/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7852 - val_loss: 0.8765\n",
      "Epoch 807/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7863 - val_loss: 0.9080\n",
      "Epoch 808/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7852 - val_loss: 0.8992\n",
      "Epoch 809/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7845 - val_loss: 0.8862\n",
      "Epoch 810/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7841 - val_loss: 0.8934\n",
      "Epoch 811/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7847 - val_loss: 0.8991\n",
      "Epoch 812/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7867 - val_loss: 0.8801\n",
      "Epoch 813/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7847 - val_loss: 0.8922\n",
      "Epoch 814/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7839 - val_loss: 0.8903\n",
      "Epoch 815/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7854 - val_loss: 0.8839\n",
      "Epoch 816/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7831 - val_loss: 0.9002\n",
      "Epoch 817/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7848 - val_loss: 0.9092\n",
      "Epoch 818/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7836 - val_loss: 0.8889\n",
      "Epoch 819/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7835 - val_loss: 0.8843\n",
      "Epoch 820/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7834 - val_loss: 0.8832\n",
      "Epoch 821/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7832 - val_loss: 0.8906\n",
      "Epoch 822/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7866 - val_loss: 0.9122\n",
      "Epoch 823/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7841 - val_loss: 0.8892\n",
      "Epoch 824/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7871 - val_loss: 0.8687\n",
      "Epoch 825/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7844 - val_loss: 0.8946\n",
      "Epoch 826/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7842 - val_loss: 0.9007\n",
      "Epoch 827/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7832 - val_loss: 0.8952\n",
      "Epoch 828/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7837 - val_loss: 0.8844\n",
      "Epoch 829/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7842 - val_loss: 0.8800\n",
      "Epoch 830/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7827 - val_loss: 0.8983\n",
      "Epoch 831/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7836 - val_loss: 0.8977\n",
      "Epoch 832/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7827 - val_loss: 0.8944\n",
      "Epoch 833/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7841 - val_loss: 0.8925\n",
      "Epoch 834/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7847 - val_loss: 0.8928\n",
      "Epoch 835/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7854 - val_loss: 0.8980\n",
      "Epoch 836/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7843 - val_loss: 0.8811\n",
      "Epoch 837/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7846 - val_loss: 0.8875\n",
      "Epoch 838/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7835 - val_loss: 0.8888\n",
      "Epoch 839/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7835 - val_loss: 0.8912\n",
      "Epoch 840/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7835 - val_loss: 0.8857\n",
      "Epoch 841/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7828 - val_loss: 0.8852\n",
      "Epoch 842/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7824 - val_loss: 0.8939\n",
      "Epoch 843/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7836 - val_loss: 0.8915\n",
      "Epoch 844/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7823 - val_loss: 0.8979\n",
      "Epoch 845/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7841 - val_loss: 0.8858\n",
      "Epoch 846/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7822 - val_loss: 0.8935\n",
      "Epoch 847/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7827 - val_loss: 0.8989\n",
      "Epoch 848/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7857 - val_loss: 0.8774\n",
      "Epoch 849/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7832 - val_loss: 0.8898\n",
      "Epoch 850/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7889 - val_loss: 0.9176\n",
      "Epoch 851/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7858 - val_loss: 0.8807\n",
      "Epoch 852/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7844 - val_loss: 0.8814\n",
      "Epoch 853/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7836 - val_loss: 0.8860\n",
      "Epoch 854/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7829 - val_loss: 0.8927\n",
      "Epoch 855/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7832 - val_loss: 0.8974\n",
      "Epoch 856/1500\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.7827 - val_loss: 0.8932\n",
      "Epoch 857/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7837 - val_loss: 0.8775\n",
      "Epoch 858/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7826 - val_loss: 0.8866\n",
      "Epoch 859/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7826 - val_loss: 0.8985\n",
      "Epoch 860/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7818 - val_loss: 0.8966\n",
      "Epoch 861/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7824 - val_loss: 0.8945\n",
      "Epoch 862/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7828 - val_loss: 0.8892\n",
      "Epoch 863/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7829 - val_loss: 0.8815\n",
      "Epoch 864/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7827 - val_loss: 0.8850\n",
      "Epoch 865/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7820 - val_loss: 0.8960\n",
      "Epoch 866/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7828 - val_loss: 0.9062\n",
      "Epoch 867/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7850 - val_loss: 0.8823\n",
      "Epoch 868/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7827 - val_loss: 0.8917\n",
      "Epoch 869/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7832 - val_loss: 0.8952\n",
      "Epoch 870/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7827 - val_loss: 0.8942\n",
      "Epoch 871/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7824 - val_loss: 0.8911\n",
      "Epoch 872/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7829 - val_loss: 0.8830\n",
      "Epoch 873/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7827 - val_loss: 0.8869\n",
      "Epoch 874/1500\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.7819 - val_loss: 0.8951\n",
      "Epoch 875/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7826 - val_loss: 0.8899\n",
      "Epoch 876/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7824 - val_loss: 0.8955\n",
      "Epoch 877/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7828 - val_loss: 0.8888\n",
      "Epoch 878/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7838 - val_loss: 0.8836\n",
      "Epoch 879/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7825 - val_loss: 0.8968\n",
      "Epoch 880/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7852 - val_loss: 0.9096\n",
      "Epoch 881/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7834 - val_loss: 0.8895\n",
      "Epoch 882/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7841 - val_loss: 0.8818\n",
      "Epoch 883/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7833 - val_loss: 0.8931\n",
      "Epoch 884/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7837 - val_loss: 0.8832\n",
      "Epoch 885/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7824 - val_loss: 0.8957\n",
      "Epoch 886/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7826 - val_loss: 0.8968\n",
      "Epoch 887/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7815 - val_loss: 0.8932\n",
      "Epoch 888/1500\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.7816 - val_loss: 0.8877\n",
      "Epoch 889/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7835 - val_loss: 0.8791\n",
      "Epoch 890/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7832 - val_loss: 0.9007\n",
      "Epoch 891/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7824 - val_loss: 0.8942\n",
      "Epoch 892/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7813 - val_loss: 0.8899\n",
      "Epoch 893/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7818 - val_loss: 0.8864\n",
      "Epoch 894/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7813 - val_loss: 0.8980\n",
      "Epoch 895/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7822 - val_loss: 0.9033\n",
      "Epoch 896/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7817 - val_loss: 0.8825\n",
      "Epoch 897/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7821 - val_loss: 0.8904\n",
      "Epoch 898/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7813 - val_loss: 0.8861\n",
      "Epoch 899/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7813 - val_loss: 0.8839\n",
      "Epoch 900/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7809 - val_loss: 0.8936\n",
      "Epoch 901/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7821 - val_loss: 0.8929\n",
      "Epoch 902/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7819 - val_loss: 0.8925\n",
      "Epoch 903/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7824 - val_loss: 0.8915\n",
      "Epoch 904/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7824 - val_loss: 0.8879\n",
      "Epoch 905/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7819 - val_loss: 0.8880\n",
      "Epoch 906/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7827 - val_loss: 0.9094\n",
      "Epoch 907/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7816 - val_loss: 0.8964\n",
      "Epoch 908/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7814 - val_loss: 0.8786\n",
      "Epoch 909/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7820 - val_loss: 0.8849\n",
      "Epoch 910/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7838 - val_loss: 0.9072\n",
      "Epoch 911/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7826 - val_loss: 0.8899\n",
      "Epoch 912/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7813 - val_loss: 0.8707\n",
      "Epoch 913/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7817 - val_loss: 0.8843\n",
      "Epoch 914/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7820 - val_loss: 0.9022\n",
      "Epoch 915/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7827 - val_loss: 0.8926\n",
      "Epoch 916/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7811 - val_loss: 0.8889\n",
      "Epoch 917/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7820 - val_loss: 0.8982\n",
      "Epoch 918/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7811 - val_loss: 0.8839\n",
      "Epoch 919/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7817 - val_loss: 0.8873\n",
      "Epoch 920/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7814 - val_loss: 0.8961\n",
      "Epoch 921/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7806 - val_loss: 0.8979\n",
      "Epoch 922/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7818 - val_loss: 0.8804\n",
      "Epoch 923/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7810 - val_loss: 0.8859\n",
      "Epoch 924/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7809 - val_loss: 0.8957\n",
      "Epoch 925/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7830 - val_loss: 0.9213\n",
      "Epoch 926/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7831 - val_loss: 0.8963\n",
      "Epoch 927/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7820 - val_loss: 0.8728\n",
      "Epoch 928/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7818 - val_loss: 0.8863\n",
      "Epoch 929/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7823 - val_loss: 0.8847\n",
      "Epoch 930/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7821 - val_loss: 0.9110\n",
      "Epoch 931/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7812 - val_loss: 0.9125\n",
      "Epoch 932/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7818 - val_loss: 0.8802\n",
      "Epoch 933/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7862 - val_loss: 0.8710\n",
      "Epoch 934/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7807 - val_loss: 0.8897\n",
      "Epoch 935/1500\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7834 - val_loss: 0.9225\n",
      "Epoch 936/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7815 - val_loss: 0.9044\n",
      "Epoch 937/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7826 - val_loss: 0.8683\n",
      "Epoch 938/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7834 - val_loss: 0.8781\n",
      "Epoch 939/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7799 - val_loss: 0.8943\n",
      "Epoch 940/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7828 - val_loss: 0.9189\n",
      "Epoch 941/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7810 - val_loss: 0.8988\n",
      "Epoch 942/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7807 - val_loss: 0.8688\n",
      "Epoch 943/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7814 - val_loss: 0.8709\n",
      "Epoch 944/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7806 - val_loss: 0.9056\n",
      "Epoch 945/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7812 - val_loss: 0.9050\n",
      "Epoch 946/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7821 - val_loss: 0.9072\n",
      "Epoch 947/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7793 - val_loss: 0.8815\n",
      "Epoch 948/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7805 - val_loss: 0.8719\n",
      "Epoch 949/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7846 - val_loss: 0.8995\n",
      "Epoch 950/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7802 - val_loss: 0.8888\n",
      "Epoch 951/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7802 - val_loss: 0.8932\n",
      "Epoch 952/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7811 - val_loss: 0.8978\n",
      "Epoch 953/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7800 - val_loss: 0.8783\n",
      "Epoch 954/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7815 - val_loss: 0.8787\n",
      "Epoch 955/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7809 - val_loss: 0.9039\n",
      "Epoch 956/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7806 - val_loss: 0.9008\n",
      "Epoch 957/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7800 - val_loss: 0.8907\n",
      "Epoch 958/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7794 - val_loss: 0.8789\n",
      "Epoch 959/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7811 - val_loss: 0.8749\n",
      "Epoch 960/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7807 - val_loss: 0.8920\n",
      "Epoch 961/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7823 - val_loss: 0.9212\n",
      "Epoch 962/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7815 - val_loss: 0.9038\n",
      "Epoch 963/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7797 - val_loss: 0.8768\n",
      "Epoch 964/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7802 - val_loss: 0.8689\n",
      "Epoch 965/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7797 - val_loss: 0.8915\n",
      "Epoch 966/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7805 - val_loss: 0.9099\n",
      "Epoch 967/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7806 - val_loss: 0.8879\n",
      "Epoch 968/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7814 - val_loss: 0.8732\n",
      "Epoch 969/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7796 - val_loss: 0.8951\n",
      "Epoch 970/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7797 - val_loss: 0.9117\n",
      "Epoch 971/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7820 - val_loss: 0.8989\n",
      "Epoch 972/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7797 - val_loss: 0.8710\n",
      "Epoch 973/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7808 - val_loss: 0.8738\n",
      "Epoch 974/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7807 - val_loss: 0.9027\n",
      "Epoch 975/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7801 - val_loss: 0.9101\n",
      "Epoch 976/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7794 - val_loss: 0.8945\n",
      "Epoch 977/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7804 - val_loss: 0.8772\n",
      "Epoch 978/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7799 - val_loss: 0.8866\n",
      "Epoch 979/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7793 - val_loss: 0.8959\n",
      "Epoch 980/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7794 - val_loss: 0.8995\n",
      "Epoch 981/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7791 - val_loss: 0.8919\n",
      "Epoch 982/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7792 - val_loss: 0.8833\n",
      "Epoch 983/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7790 - val_loss: 0.8936\n",
      "Epoch 984/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7787 - val_loss: 0.8964\n",
      "Epoch 985/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7800 - val_loss: 0.8835\n",
      "Epoch 986/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7795 - val_loss: 0.8826\n",
      "Epoch 987/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7794 - val_loss: 0.8950\n",
      "Epoch 988/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7798 - val_loss: 0.9010\n",
      "Epoch 989/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7792 - val_loss: 0.8972\n",
      "Epoch 990/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7789 - val_loss: 0.8842\n",
      "Epoch 991/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7792 - val_loss: 0.8887\n",
      "Epoch 992/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7826 - val_loss: 0.8753\n",
      "Epoch 993/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7793 - val_loss: 0.9081\n",
      "Epoch 994/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7811 - val_loss: 0.9200\n",
      "Epoch 995/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7813 - val_loss: 0.8792\n",
      "Epoch 996/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7792 - val_loss: 0.8810\n",
      "Epoch 997/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7809 - val_loss: 0.9024\n",
      "Epoch 998/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7815 - val_loss: 0.8820\n",
      "Epoch 999/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7792 - val_loss: 0.8952\n",
      "Epoch 1000/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7786 - val_loss: 0.8941\n",
      "Epoch 1001/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7795 - val_loss: 0.8838\n",
      "Epoch 1002/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7812 - val_loss: 0.8912\n",
      "Epoch 1003/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7829 - val_loss: 0.9177\n",
      "Epoch 1004/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7847 - val_loss: 0.8713\n",
      "Epoch 1005/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7796 - val_loss: 0.8809\n",
      "Epoch 1006/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7799 - val_loss: 0.9018\n",
      "Epoch 1007/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7789 - val_loss: 0.9015\n",
      "Epoch 1008/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7801 - val_loss: 0.8986\n",
      "Epoch 1009/1500\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.7798 - val_loss: 0.8664\n",
      "Epoch 1010/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7808 - val_loss: 0.8802\n",
      "Epoch 1011/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7777 - val_loss: 0.8992\n",
      "Epoch 1012/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7786 - val_loss: 0.9128\n",
      "Epoch 1013/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7787 - val_loss: 0.8944\n",
      "Epoch 1014/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7793 - val_loss: 0.8874\n",
      "Epoch 1015/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7806 - val_loss: 0.8684\n",
      "Epoch 1016/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7833 - val_loss: 0.9115\n",
      "Epoch 1017/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7802 - val_loss: 0.8947\n",
      "Epoch 1018/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7793 - val_loss: 0.9005\n",
      "Epoch 1019/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7785 - val_loss: 0.8928\n",
      "Epoch 1020/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7788 - val_loss: 0.8800\n",
      "Epoch 1021/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7785 - val_loss: 0.8951\n",
      "Epoch 1022/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7808 - val_loss: 0.8770\n",
      "Epoch 1023/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7776 - val_loss: 0.8940\n",
      "Epoch 1024/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7799 - val_loss: 0.9157\n",
      "Epoch 1025/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7798 - val_loss: 0.8885\n",
      "Epoch 1026/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7816 - val_loss: 0.8724\n",
      "Epoch 1027/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7841 - val_loss: 0.9036\n",
      "Epoch 1028/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7811 - val_loss: 0.8949\n",
      "Epoch 1029/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7788 - val_loss: 0.8897\n",
      "Epoch 1030/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7801 - val_loss: 0.8933\n",
      "Epoch 1031/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7788 - val_loss: 0.8933\n",
      "Epoch 1032/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7828 - val_loss: 0.8757\n",
      "Epoch 1033/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7798 - val_loss: 0.9044\n",
      "Epoch 1034/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7805 - val_loss: 0.9074\n",
      "Epoch 1035/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7793 - val_loss: 0.8821\n",
      "Epoch 1036/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7780 - val_loss: 0.8799\n",
      "Epoch 1037/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7780 - val_loss: 0.8846\n",
      "Epoch 1038/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7790 - val_loss: 0.9032\n",
      "Epoch 1039/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7781 - val_loss: 0.8851\n",
      "Epoch 1040/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7799 - val_loss: 0.8763\n",
      "Epoch 1041/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7773 - val_loss: 0.8958\n",
      "Epoch 1042/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7780 - val_loss: 0.9015\n",
      "Epoch 1043/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7777 - val_loss: 0.8931\n",
      "Epoch 1044/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7800 - val_loss: 0.8767\n",
      "Epoch 1045/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7776 - val_loss: 0.9012\n",
      "Epoch 1046/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7780 - val_loss: 0.8907\n",
      "Epoch 1047/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7770 - val_loss: 0.8891\n",
      "Epoch 1048/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7793 - val_loss: 0.9007\n",
      "Epoch 1049/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7774 - val_loss: 0.8804\n",
      "Epoch 1050/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7786 - val_loss: 0.8750\n",
      "Epoch 1051/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7777 - val_loss: 0.8917\n",
      "Epoch 1052/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7776 - val_loss: 0.9077\n",
      "Epoch 1053/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7798 - val_loss: 0.8836\n",
      "Epoch 1054/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7777 - val_loss: 0.8859\n",
      "Epoch 1055/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7770 - val_loss: 0.8963\n",
      "Epoch 1056/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7773 - val_loss: 0.8999\n",
      "Epoch 1057/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7774 - val_loss: 0.8955\n",
      "Epoch 1058/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7782 - val_loss: 0.8782\n",
      "Epoch 1059/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7768 - val_loss: 0.8894\n",
      "Epoch 1060/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7791 - val_loss: 0.8828\n",
      "Epoch 1061/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7785 - val_loss: 0.9130\n",
      "Epoch 1062/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7788 - val_loss: 0.8944\n",
      "Epoch 1063/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7777 - val_loss: 0.8806\n",
      "Epoch 1064/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7768 - val_loss: 0.8827\n",
      "Epoch 1065/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7797 - val_loss: 0.9077\n",
      "Epoch 1066/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7764 - val_loss: 0.8900\n",
      "Epoch 1067/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7771 - val_loss: 0.8773\n",
      "Epoch 1068/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7797 - val_loss: 0.8789\n",
      "Epoch 1069/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7797 - val_loss: 0.9149\n",
      "Epoch 1070/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7781 - val_loss: 0.8970\n",
      "Epoch 1071/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7768 - val_loss: 0.8788\n",
      "Epoch 1072/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7772 - val_loss: 0.8874\n",
      "Epoch 1073/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7780 - val_loss: 0.8970\n",
      "Epoch 1074/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7774 - val_loss: 0.8944\n",
      "Epoch 1075/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7758 - val_loss: 0.8802\n",
      "Epoch 1076/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7772 - val_loss: 0.8773\n",
      "Epoch 1077/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7768 - val_loss: 0.8883\n",
      "Epoch 1078/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7760 - val_loss: 0.8979\n",
      "Epoch 1079/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7768 - val_loss: 0.8992\n",
      "Epoch 1080/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7770 - val_loss: 0.8985\n",
      "Epoch 1081/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7786 - val_loss: 0.8754\n",
      "Epoch 1082/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7764 - val_loss: 0.8852\n",
      "Epoch 1083/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7764 - val_loss: 0.9104\n",
      "Epoch 1084/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7772 - val_loss: 0.8971\n",
      "Epoch 1085/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7778 - val_loss: 0.8770\n",
      "Epoch 1086/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7797 - val_loss: 0.8966\n",
      "Epoch 1087/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7817 - val_loss: 0.8745\n",
      "Epoch 1088/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7766 - val_loss: 0.8955\n",
      "Epoch 1089/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7781 - val_loss: 0.9095\n",
      "Epoch 1090/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7777 - val_loss: 0.8787\n",
      "Epoch 1091/1500\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.7850 - val_loss: 0.8641\n",
      "Epoch 1092/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7763 - val_loss: 0.9122\n",
      "Epoch 1093/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7797 - val_loss: 0.9183\n",
      "Epoch 1094/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7795 - val_loss: 0.9128\n",
      "Epoch 1095/1500\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.7822 - val_loss: 0.8627\n",
      "Epoch 1096/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7790 - val_loss: 0.8812\n",
      "Epoch 1097/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7772 - val_loss: 0.9113\n",
      "Epoch 1098/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7781 - val_loss: 0.9010\n",
      "Epoch 1099/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7768 - val_loss: 0.8842\n",
      "Epoch 1100/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7766 - val_loss: 0.8769\n",
      "Epoch 1101/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7769 - val_loss: 0.8876\n",
      "Epoch 1102/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7806 - val_loss: 0.9130\n",
      "Epoch 1103/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7805 - val_loss: 0.8684\n",
      "Epoch 1104/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7788 - val_loss: 0.8752\n",
      "Epoch 1105/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7780 - val_loss: 0.9189\n",
      "Epoch 1106/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7784 - val_loss: 0.9159\n",
      "Epoch 1107/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7764 - val_loss: 0.8818\n",
      "Epoch 1108/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7759 - val_loss: 0.8720\n",
      "Epoch 1109/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7787 - val_loss: 0.8725\n",
      "Epoch 1110/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7801 - val_loss: 0.9001\n",
      "Epoch 1111/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7781 - val_loss: 0.8849\n",
      "Epoch 1112/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7769 - val_loss: 0.8895\n",
      "Epoch 1113/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7776 - val_loss: 0.8949\n",
      "Epoch 1114/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7764 - val_loss: 0.8831\n",
      "Epoch 1115/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7778 - val_loss: 0.8926\n",
      "Epoch 1116/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7770 - val_loss: 0.8949\n",
      "Epoch 1117/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7779 - val_loss: 0.8757\n",
      "Epoch 1118/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7770 - val_loss: 0.8862\n",
      "Epoch 1119/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7770 - val_loss: 0.8964\n",
      "Epoch 1120/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7764 - val_loss: 0.8900\n",
      "Epoch 1121/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7769 - val_loss: 0.8883\n",
      "Epoch 1122/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7797 - val_loss: 0.8957\n",
      "Epoch 1123/1500\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.7763 - val_loss: 0.8883\n",
      "Epoch 1124/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7765 - val_loss: 0.8757\n",
      "Epoch 1125/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7776 - val_loss: 0.8955\n",
      "Epoch 1126/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7755 - val_loss: 0.8873\n",
      "Epoch 1127/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7761 - val_loss: 0.8931\n",
      "Epoch 1128/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7761 - val_loss: 0.8831\n",
      "Epoch 1129/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7755 - val_loss: 0.8890\n",
      "Epoch 1130/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7763 - val_loss: 0.8867\n",
      "Epoch 1131/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7753 - val_loss: 0.8913\n",
      "Epoch 1132/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7755 - val_loss: 0.8906\n",
      "Epoch 1133/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7759 - val_loss: 0.8957\n",
      "Epoch 1134/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7776 - val_loss: 0.8749\n",
      "Epoch 1135/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7768 - val_loss: 0.8772\n",
      "Epoch 1136/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7757 - val_loss: 0.9090\n",
      "Epoch 1137/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7763 - val_loss: 0.8980\n",
      "Epoch 1138/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7762 - val_loss: 0.8868\n",
      "Epoch 1139/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7766 - val_loss: 0.8777\n",
      "Epoch 1140/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7761 - val_loss: 0.8835\n",
      "Epoch 1141/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7786 - val_loss: 0.9145\n",
      "Epoch 1142/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7778 - val_loss: 0.8852\n",
      "Epoch 1143/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7750 - val_loss: 0.8822\n",
      "Epoch 1144/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7777 - val_loss: 0.8885\n",
      "Epoch 1145/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7764 - val_loss: 0.8863\n",
      "Epoch 1146/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7753 - val_loss: 0.8893\n",
      "Epoch 1147/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7754 - val_loss: 0.8888\n",
      "Epoch 1148/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7749 - val_loss: 0.8890\n",
      "Epoch 1149/1500\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7790 - val_loss: 0.9007\n",
      "Epoch 1150/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7754 - val_loss: 0.8756\n",
      "Epoch 1151/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7773 - val_loss: 0.8752\n",
      "Epoch 1152/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7763 - val_loss: 0.9001\n",
      "Epoch 1153/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7764 - val_loss: 0.9021\n",
      "Epoch 1154/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7747 - val_loss: 0.8881\n",
      "Epoch 1155/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7751 - val_loss: 0.8815\n",
      "Epoch 1156/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7763 - val_loss: 0.8810\n",
      "Epoch 1157/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7778 - val_loss: 0.8953\n",
      "Epoch 1158/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7746 - val_loss: 0.8948\n",
      "Epoch 1159/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7794 - val_loss: 0.8725\n",
      "Epoch 1160/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7746 - val_loss: 0.8984\n",
      "Epoch 1161/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7767 - val_loss: 0.9091\n",
      "Epoch 1162/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7758 - val_loss: 0.8833\n",
      "Epoch 1163/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7768 - val_loss: 0.8878\n",
      "Epoch 1164/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7745 - val_loss: 0.8924\n",
      "Epoch 1165/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7754 - val_loss: 0.8924\n",
      "Epoch 1166/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7743 - val_loss: 0.8815\n",
      "Epoch 1167/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7753 - val_loss: 0.8810\n",
      "Epoch 1168/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7748 - val_loss: 0.8854\n",
      "Epoch 1169/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7749 - val_loss: 0.8892\n",
      "Epoch 1170/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7758 - val_loss: 0.9024\n",
      "Epoch 1171/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7754 - val_loss: 0.8910\n",
      "Epoch 1172/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7790 - val_loss: 0.8627\n",
      "Epoch 1173/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7769 - val_loss: 0.9014\n",
      "Epoch 1174/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7756 - val_loss: 0.9003\n",
      "Epoch 1175/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7748 - val_loss: 0.8887\n",
      "Epoch 1176/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7749 - val_loss: 0.8906\n",
      "Epoch 1177/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7759 - val_loss: 0.8800\n",
      "Epoch 1178/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7748 - val_loss: 0.8920\n",
      "Epoch 1179/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7767 - val_loss: 0.8948\n",
      "Epoch 1180/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7742 - val_loss: 0.8846\n",
      "Epoch 1181/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7761 - val_loss: 0.8730\n",
      "Epoch 1182/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7754 - val_loss: 0.8891\n",
      "Epoch 1183/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7750 - val_loss: 0.8925\n",
      "Epoch 1184/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7752 - val_loss: 0.8970\n",
      "Epoch 1185/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7779 - val_loss: 0.8734\n",
      "Epoch 1186/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7756 - val_loss: 0.8985\n",
      "Epoch 1187/1500\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7741 - val_loss: 0.9004\n",
      "Epoch 1188/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7759 - val_loss: 0.8710\n",
      "Epoch 1189/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7751 - val_loss: 0.8915\n",
      "Epoch 1190/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7739 - val_loss: 0.8942\n",
      "Epoch 1191/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7762 - val_loss: 0.8737\n",
      "Epoch 1192/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7753 - val_loss: 0.8978\n",
      "Epoch 1193/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7736 - val_loss: 0.8910\n",
      "Epoch 1194/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7754 - val_loss: 0.8806\n",
      "Epoch 1195/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7736 - val_loss: 0.8909\n",
      "Epoch 1196/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7745 - val_loss: 0.9057\n",
      "Epoch 1197/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7742 - val_loss: 0.8828\n",
      "Epoch 1198/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7752 - val_loss: 0.8785\n",
      "Epoch 1199/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7757 - val_loss: 0.9012\n",
      "Epoch 1200/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7764 - val_loss: 0.8738\n",
      "Epoch 1201/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7751 - val_loss: 0.8901\n",
      "Epoch 1202/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7752 - val_loss: 0.8947\n",
      "Epoch 1203/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7758 - val_loss: 0.8979\n",
      "Epoch 1204/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7739 - val_loss: 0.8867\n",
      "Epoch 1205/1500\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.7754 - val_loss: 0.8623\n",
      "Epoch 1206/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7754 - val_loss: 0.8895\n",
      "Epoch 1207/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7759 - val_loss: 0.9126\n",
      "Epoch 1208/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7754 - val_loss: 0.8799\n",
      "Epoch 1209/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7747 - val_loss: 0.8840\n",
      "Epoch 1210/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7749 - val_loss: 0.8798\n",
      "Epoch 1211/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7743 - val_loss: 0.8999\n",
      "Epoch 1212/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7777 - val_loss: 0.9026\n",
      "Epoch 1213/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7748 - val_loss: 0.8700\n",
      "Epoch 1214/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7749 - val_loss: 0.8733\n",
      "Epoch 1215/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7728 - val_loss: 0.8912\n",
      "Epoch 1216/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7766 - val_loss: 0.9173\n",
      "Epoch 1217/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7736 - val_loss: 0.8862\n",
      "Epoch 1218/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7754 - val_loss: 0.8598\n",
      "Epoch 1219/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7773 - val_loss: 0.8881\n",
      "Epoch 1220/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7735 - val_loss: 0.8974\n",
      "Epoch 1221/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7756 - val_loss: 0.8936\n",
      "Epoch 1222/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7753 - val_loss: 0.8966\n",
      "Epoch 1223/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7761 - val_loss: 0.8747\n",
      "Epoch 1224/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7755 - val_loss: 0.8837\n",
      "Epoch 1225/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7777 - val_loss: 0.8916\n",
      "Epoch 1226/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7738 - val_loss: 0.8723\n",
      "Epoch 1227/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7738 - val_loss: 0.8776\n",
      "Epoch 1228/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7745 - val_loss: 0.9047\n",
      "Epoch 1229/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7731 - val_loss: 0.8909\n",
      "Epoch 1230/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7743 - val_loss: 0.8707\n",
      "Epoch 1231/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7758 - val_loss: 0.8960\n",
      "Epoch 1232/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7748 - val_loss: 0.8966\n",
      "Epoch 1233/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7734 - val_loss: 0.8725\n",
      "Epoch 1234/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7740 - val_loss: 0.8744\n",
      "Epoch 1235/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7737 - val_loss: 0.8943\n",
      "Epoch 1236/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7737 - val_loss: 0.8969\n",
      "Epoch 1237/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7751 - val_loss: 0.9035\n",
      "Epoch 1238/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7774 - val_loss: 0.8680\n",
      "Epoch 1239/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7737 - val_loss: 0.8795\n",
      "Epoch 1240/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7744 - val_loss: 0.9133\n",
      "Epoch 1241/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7745 - val_loss: 0.8930\n",
      "Epoch 1242/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7727 - val_loss: 0.8846\n",
      "Epoch 1243/1500\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.7767 - val_loss: 0.8616\n",
      "Epoch 1244/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7740 - val_loss: 0.8875\n",
      "Epoch 1245/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7782 - val_loss: 0.9373\n",
      "Epoch 1246/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7805 - val_loss: 0.8915\n",
      "Epoch 1247/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7763 - val_loss: 0.8661\n",
      "Epoch 1248/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7742 - val_loss: 0.8909\n",
      "Epoch 1249/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7736 - val_loss: 0.9111\n",
      "Epoch 1250/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7729 - val_loss: 0.8897\n",
      "Epoch 1251/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7729 - val_loss: 0.8792\n",
      "Epoch 1252/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7783 - val_loss: 0.8662\n",
      "Epoch 1253/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7734 - val_loss: 0.9066\n",
      "Epoch 1254/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7815 - val_loss: 0.9378\n",
      "Epoch 1255/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7821 - val_loss: 0.8657\n",
      "Epoch 1256/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7752 - val_loss: 0.8721\n",
      "Epoch 1257/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7739 - val_loss: 0.8881\n",
      "Epoch 1258/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7733 - val_loss: 0.9083\n",
      "Epoch 1259/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7729 - val_loss: 0.8928\n",
      "Epoch 1260/1500\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.7777 - val_loss: 0.8575\n",
      "Epoch 1261/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7781 - val_loss: 0.9155\n",
      "Epoch 1262/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7756 - val_loss: 0.9150\n",
      "Epoch 1263/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7709 - val_loss: 0.8720\n",
      "Epoch 1264/1500\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.7755 - val_loss: 0.8537\n",
      "Epoch 1265/1500\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.7746 - val_loss: 0.8898\n",
      "Epoch 1266/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7723 - val_loss: 0.9137\n",
      "Epoch 1267/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7748 - val_loss: 0.8902\n",
      "Epoch 1268/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7725 - val_loss: 0.8827\n",
      "Epoch 1269/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7744 - val_loss: 0.8909\n",
      "Epoch 1270/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7734 - val_loss: 0.8764\n",
      "Epoch 1271/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7750 - val_loss: 0.8719\n",
      "Epoch 1272/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7727 - val_loss: 0.9020\n",
      "Epoch 1273/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7740 - val_loss: 0.9062\n",
      "Epoch 1274/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7741 - val_loss: 0.8796\n",
      "Epoch 1275/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7731 - val_loss: 0.8767\n",
      "Epoch 1276/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7728 - val_loss: 0.8885\n",
      "Epoch 1277/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7734 - val_loss: 0.8885\n",
      "Epoch 1278/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7730 - val_loss: 0.8869\n",
      "Epoch 1279/1500\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7735 - val_loss: 0.8950\n",
      "Epoch 1280/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7718 - val_loss: 0.8824\n",
      "Epoch 1281/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7735 - val_loss: 0.8784\n",
      "Epoch 1282/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7724 - val_loss: 0.8828\n",
      "Epoch 1283/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7742 - val_loss: 0.8857\n",
      "Epoch 1284/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7722 - val_loss: 0.8940\n",
      "Epoch 1285/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7752 - val_loss: 0.9149\n",
      "Epoch 1286/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7715 - val_loss: 0.8844\n",
      "Epoch 1287/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7749 - val_loss: 0.8622\n",
      "Epoch 1288/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7744 - val_loss: 0.8955\n",
      "Epoch 1289/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7732 - val_loss: 0.9097\n",
      "Epoch 1290/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7739 - val_loss: 0.8760\n",
      "Epoch 1291/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7738 - val_loss: 0.8654\n",
      "Epoch 1292/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7726 - val_loss: 0.8911\n",
      "Epoch 1293/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7729 - val_loss: 0.8946\n",
      "Epoch 1294/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7732 - val_loss: 0.8788\n",
      "Epoch 1295/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7727 - val_loss: 0.8940\n",
      "Epoch 1296/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7736 - val_loss: 0.8825\n",
      "Epoch 1297/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7718 - val_loss: 0.8820\n",
      "Epoch 1298/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7721 - val_loss: 0.8906\n",
      "Epoch 1299/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7744 - val_loss: 0.9091\n",
      "Epoch 1300/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7749 - val_loss: 0.8739\n",
      "Epoch 1301/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7766 - val_loss: 0.8969\n",
      "Epoch 1302/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7729 - val_loss: 0.8867\n",
      "Epoch 1303/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7725 - val_loss: 0.8905\n",
      "Epoch 1304/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7713 - val_loss: 0.8884\n",
      "Epoch 1305/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7730 - val_loss: 0.8745\n",
      "Epoch 1306/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7731 - val_loss: 0.8949\n",
      "Epoch 1307/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7730 - val_loss: 0.8822\n",
      "Epoch 1308/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7721 - val_loss: 0.8851\n",
      "Epoch 1309/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7722 - val_loss: 0.8957\n",
      "Epoch 1310/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7709 - val_loss: 0.8885\n",
      "Epoch 1311/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7750 - val_loss: 0.8669\n",
      "Epoch 1312/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7734 - val_loss: 0.8985\n",
      "Epoch 1313/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7731 - val_loss: 0.8985\n",
      "Epoch 1314/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7723 - val_loss: 0.8910\n",
      "Epoch 1315/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7734 - val_loss: 0.8699\n",
      "Epoch 1316/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7740 - val_loss: 0.8983\n",
      "Epoch 1317/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7734 - val_loss: 0.8870\n",
      "Epoch 1318/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7720 - val_loss: 0.8943\n",
      "Epoch 1319/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7729 - val_loss: 0.8700\n",
      "Epoch 1320/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7727 - val_loss: 0.8932\n",
      "Epoch 1321/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7733 - val_loss: 0.9031\n",
      "Epoch 1322/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7726 - val_loss: 0.8718\n",
      "Epoch 1323/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7717 - val_loss: 0.8746\n",
      "Epoch 1324/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7726 - val_loss: 0.8872\n",
      "Epoch 1325/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7710 - val_loss: 0.9050\n",
      "Epoch 1326/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7722 - val_loss: 0.8921\n",
      "Epoch 1327/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7711 - val_loss: 0.8883\n",
      "Epoch 1328/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7705 - val_loss: 0.8764\n",
      "Epoch 1329/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7710 - val_loss: 0.8822\n",
      "Epoch 1330/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7732 - val_loss: 0.8815\n",
      "Epoch 1331/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7718 - val_loss: 0.9037\n",
      "Epoch 1332/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7719 - val_loss: 0.8811\n",
      "Epoch 1333/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7707 - val_loss: 0.8853\n",
      "Epoch 1334/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7706 - val_loss: 0.8868\n",
      "Epoch 1335/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7727 - val_loss: 0.9010\n",
      "Epoch 1336/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7704 - val_loss: 0.8810\n",
      "Epoch 1337/1500\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.7732 - val_loss: 0.8766\n",
      "Epoch 1338/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7720 - val_loss: 0.9026\n",
      "Epoch 1339/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7728 - val_loss: 0.8721\n",
      "Epoch 1340/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7720 - val_loss: 0.8885\n",
      "Epoch 1341/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7730 - val_loss: 0.8863\n",
      "Epoch 1342/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7710 - val_loss: 0.8888\n",
      "Epoch 1343/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7710 - val_loss: 0.8920\n",
      "Epoch 1344/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7715 - val_loss: 0.8824\n",
      "Epoch 1345/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7706 - val_loss: 0.8872\n",
      "Epoch 1346/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7735 - val_loss: 0.8957\n",
      "Epoch 1347/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7720 - val_loss: 0.8758\n",
      "Epoch 1348/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7712 - val_loss: 0.8957\n",
      "Epoch 1349/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7725 - val_loss: 0.9018\n",
      "Epoch 1350/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7714 - val_loss: 0.8668\n",
      "Epoch 1351/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7710 - val_loss: 0.8754\n",
      "Epoch 1352/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7694 - val_loss: 0.8956\n",
      "Epoch 1353/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7709 - val_loss: 0.8976\n",
      "Epoch 1354/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7714 - val_loss: 0.8880\n",
      "Epoch 1355/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7715 - val_loss: 0.8750\n",
      "Epoch 1356/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7704 - val_loss: 0.8764\n",
      "Epoch 1357/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7749 - val_loss: 0.8847\n",
      "Epoch 1358/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7733 - val_loss: 0.8983\n",
      "Epoch 1359/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7719 - val_loss: 0.8831\n",
      "Epoch 1360/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7709 - val_loss: 0.8799\n",
      "Epoch 1361/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7713 - val_loss: 0.8779\n",
      "Epoch 1362/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7715 - val_loss: 0.8900\n",
      "Epoch 1363/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7711 - val_loss: 0.9064\n",
      "Epoch 1364/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7757 - val_loss: 0.8690\n",
      "Epoch 1365/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7717 - val_loss: 0.8860\n",
      "Epoch 1366/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7741 - val_loss: 0.9237\n",
      "Epoch 1367/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7752 - val_loss: 0.8740\n",
      "Epoch 1368/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7747 - val_loss: 0.8680\n",
      "Epoch 1369/1500\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7707 - val_loss: 0.8992\n",
      "Epoch 1370/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7741 - val_loss: 0.9335\n",
      "Epoch 1371/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7735 - val_loss: 0.8851\n",
      "Epoch 1372/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7770 - val_loss: 0.8481\n",
      "Epoch 1373/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7730 - val_loss: 0.8949\n",
      "Epoch 1374/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7772 - val_loss: 0.9395\n",
      "Epoch 1375/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7723 - val_loss: 0.8717\n",
      "Epoch 1376/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7725 - val_loss: 0.8548\n",
      "Epoch 1377/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7727 - val_loss: 0.8971\n",
      "Epoch 1378/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7708 - val_loss: 0.9023\n",
      "Epoch 1379/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7698 - val_loss: 0.8797\n",
      "Epoch 1380/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7708 - val_loss: 0.8714\n",
      "Epoch 1381/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7732 - val_loss: 0.9087\n",
      "Epoch 1382/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7703 - val_loss: 0.8862\n",
      "Epoch 1383/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7722 - val_loss: 0.8624\n",
      "Epoch 1384/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7727 - val_loss: 0.8957\n",
      "Epoch 1385/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7710 - val_loss: 0.8874\n",
      "Epoch 1386/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7699 - val_loss: 0.8867\n",
      "Epoch 1387/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7716 - val_loss: 0.8916\n",
      "Epoch 1388/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7711 - val_loss: 0.8771\n",
      "Epoch 1389/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7719 - val_loss: 0.8816\n",
      "Epoch 1390/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7706 - val_loss: 0.9035\n",
      "Epoch 1391/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7706 - val_loss: 0.8875\n",
      "Epoch 1392/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7699 - val_loss: 0.8883\n",
      "Epoch 1393/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7707 - val_loss: 0.8724\n",
      "Epoch 1394/1500\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.7699 - val_loss: 0.8989\n",
      "Epoch 1395/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7717 - val_loss: 0.8790\n",
      "Epoch 1396/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7725 - val_loss: 0.8963\n",
      "Epoch 1397/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7694 - val_loss: 0.8758\n",
      "Epoch 1398/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7715 - val_loss: 0.8780\n",
      "Epoch 1399/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7704 - val_loss: 0.8891\n",
      "Epoch 1400/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7720 - val_loss: 0.8972\n",
      "Epoch 1401/1500\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.7710 - val_loss: 0.8743\n",
      "Epoch 1402/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7706 - val_loss: 0.8860\n",
      "Epoch 1403/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7697 - val_loss: 0.8976\n",
      "Epoch 1404/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7701 - val_loss: 0.8814\n",
      "Epoch 1405/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7697 - val_loss: 0.8836\n",
      "Epoch 1406/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7698 - val_loss: 0.8834\n",
      "Epoch 1407/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7703 - val_loss: 0.8993\n",
      "Epoch 1408/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7704 - val_loss: 0.8801\n",
      "Epoch 1409/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7684 - val_loss: 0.8876\n",
      "Epoch 1410/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7701 - val_loss: 0.8909\n",
      "Epoch 1411/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7697 - val_loss: 0.8837\n",
      "Epoch 1412/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7685 - val_loss: 0.8891\n",
      "Epoch 1413/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7693 - val_loss: 0.8807\n",
      "Epoch 1414/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7698 - val_loss: 0.8959\n",
      "Epoch 1415/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7694 - val_loss: 0.8847\n",
      "Epoch 1416/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7689 - val_loss: 0.8837\n",
      "Epoch 1417/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7699 - val_loss: 0.8804\n",
      "Epoch 1418/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7693 - val_loss: 0.8848\n",
      "Epoch 1419/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7708 - val_loss: 0.8995\n",
      "Epoch 1420/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7705 - val_loss: 0.8718\n",
      "Epoch 1421/1500\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7695 - val_loss: 0.8771\n",
      "Epoch 1422/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7701 - val_loss: 0.9081\n",
      "Epoch 1423/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7726 - val_loss: 0.8787\n",
      "Epoch 1424/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7749 - val_loss: 0.9064\n",
      "Epoch 1425/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7689 - val_loss: 0.8779\n",
      "Epoch 1426/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7712 - val_loss: 0.8640\n",
      "Epoch 1427/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7695 - val_loss: 0.8911\n",
      "Epoch 1428/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7705 - val_loss: 0.8905\n",
      "Epoch 1429/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7717 - val_loss: 0.9074\n",
      "Epoch 1430/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7696 - val_loss: 0.8798\n",
      "Epoch 1431/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7684 - val_loss: 0.8774\n",
      "Epoch 1432/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7701 - val_loss: 0.8913\n",
      "Epoch 1433/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7700 - val_loss: 0.8968\n",
      "Epoch 1434/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7683 - val_loss: 0.8841\n",
      "Epoch 1435/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7680 - val_loss: 0.8770\n",
      "Epoch 1436/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7685 - val_loss: 0.8805\n",
      "Epoch 1437/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7686 - val_loss: 0.9018\n",
      "Epoch 1438/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7690 - val_loss: 0.8916\n",
      "Epoch 1439/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7701 - val_loss: 0.8789\n",
      "Epoch 1440/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7682 - val_loss: 0.8801\n",
      "Epoch 1441/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7690 - val_loss: 0.8944\n",
      "Epoch 1442/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7698 - val_loss: 0.8772\n",
      "Epoch 1443/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7697 - val_loss: 0.8985\n",
      "Epoch 1444/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7711 - val_loss: 0.8952\n",
      "Epoch 1445/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7680 - val_loss: 0.8550\n",
      "Epoch 1446/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7718 - val_loss: 0.8707\n",
      "Epoch 1447/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7691 - val_loss: 0.9201\n",
      "Epoch 1448/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7710 - val_loss: 0.8907\n",
      "Epoch 1449/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7683 - val_loss: 0.8736\n",
      "Epoch 1450/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7727 - val_loss: 0.8643\n",
      "Epoch 1451/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7679 - val_loss: 0.9029\n",
      "Epoch 1452/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7700 - val_loss: 0.9110\n",
      "Epoch 1453/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7678 - val_loss: 0.8810\n",
      "Epoch 1454/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7694 - val_loss: 0.8652\n",
      "Epoch 1455/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7684 - val_loss: 0.8993\n",
      "Epoch 1456/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7730 - val_loss: 0.9173\n",
      "Epoch 1457/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7730 - val_loss: 0.8540\n",
      "Epoch 1458/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7689 - val_loss: 0.8809\n",
      "Epoch 1459/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7686 - val_loss: 0.9099\n",
      "Epoch 1460/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7700 - val_loss: 0.8833\n",
      "Epoch 1461/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7676 - val_loss: 0.8792\n",
      "Epoch 1462/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7684 - val_loss: 0.8819\n",
      "Epoch 1463/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7705 - val_loss: 0.8786\n",
      "Epoch 1464/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7681 - val_loss: 0.8989\n",
      "Epoch 1465/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7687 - val_loss: 0.8877\n",
      "Epoch 1466/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7692 - val_loss: 0.8790\n",
      "Epoch 1467/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7693 - val_loss: 0.8960\n",
      "Epoch 1468/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7686 - val_loss: 0.8765\n",
      "Epoch 1469/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7695 - val_loss: 0.8773\n",
      "Epoch 1470/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7674 - val_loss: 0.8919\n",
      "Epoch 1471/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7697 - val_loss: 0.9038\n",
      "Epoch 1472/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7682 - val_loss: 0.8772\n",
      "Epoch 1473/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7681 - val_loss: 0.8718\n",
      "Epoch 1474/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7714 - val_loss: 0.8993\n",
      "Epoch 1475/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7697 - val_loss: 0.8725\n",
      "Epoch 1476/1500\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7704 - val_loss: 0.8748\n",
      "Epoch 1477/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7712 - val_loss: 0.8907\n",
      "Epoch 1478/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7697 - val_loss: 0.8967\n",
      "Epoch 1479/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7705 - val_loss: 0.9090\n",
      "Epoch 1480/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7686 - val_loss: 0.8737\n",
      "Epoch 1481/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7681 - val_loss: 0.8667\n",
      "Epoch 1482/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7698 - val_loss: 0.8927\n",
      "Epoch 1483/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7683 - val_loss: 0.8848\n",
      "Epoch 1484/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7680 - val_loss: 0.8847\n",
      "Epoch 1485/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7690 - val_loss: 0.8925\n",
      "Epoch 1486/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7681 - val_loss: 0.8877\n",
      "Epoch 1487/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7674 - val_loss: 0.8766\n",
      "Epoch 1488/1500\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.7693 - val_loss: 0.8870\n",
      "Epoch 1489/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7681 - val_loss: 0.8993\n",
      "Epoch 1490/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7691 - val_loss: 0.8961\n",
      "Epoch 1491/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7684 - val_loss: 0.8641\n",
      "Epoch 1492/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7682 - val_loss: 0.8918\n",
      "Epoch 1493/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7674 - val_loss: 0.8956\n",
      "Epoch 1494/1500\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7712 - val_loss: 0.8711\n",
      "Epoch 1495/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7666 - val_loss: 0.8922\n",
      "Epoch 1496/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7675 - val_loss: 0.8949\n",
      "Epoch 1497/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7671 - val_loss: 0.8912\n",
      "Epoch 1498/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7682 - val_loss: 0.8967\n",
      "Epoch 1499/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7728 - val_loss: 0.8541\n",
      "Epoch 1500/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7679 - val_loss: 0.8999\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8481\n",
      "0.8481228947639465\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.LSTM(units = 1024, activation = \"relu\", return_sequences = False)(input)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "# ミニバッチ学習 \n",
    "batch_size = len(train_x) // 4\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "\n",
    "# モデル構造の出力\n",
    "model.summary()\n",
    "\n",
    "# val_lossが一番低いモデルを保存している\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "# 学習データ、テストデータ、バッチサイズ、エポック、保存ポイントの設定\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = batch_size, epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 454ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdc66e38df0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN(多層)ミニバッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 3, 3)]            0         \n",
      "                                                                 \n",
      " simple_rnn_22 (SimpleRNN)   (None, 3, 1024)           1052672   \n",
      "                                                                 \n",
      " simple_rnn_23 (SimpleRNN)   (None, 3, 1024)           2098176   \n",
      "                                                                 \n",
      " simple_rnn_24 (SimpleRNN)   (None, 3, 512)            786944    \n",
      "                                                                 \n",
      " simple_rnn_25 (SimpleRNN)   (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,463,105\n",
      "Trainable params: 4,463,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "4/4 [==============================] - 3s 307ms/step - loss: 0.9617 - val_loss: 0.9524\n",
      "Epoch 2/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.9119 - val_loss: 0.9923\n",
      "Epoch 3/1500\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8699 - val_loss: 0.8669\n",
      "Epoch 4/1500\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.8601 - val_loss: 0.8636\n",
      "Epoch 5/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8460 - val_loss: 0.9108\n",
      "Epoch 6/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8390 - val_loss: 0.9546\n",
      "Epoch 7/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8369 - val_loss: 0.9462\n",
      "Epoch 8/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8206 - val_loss: 0.8889\n",
      "Epoch 9/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8237 - val_loss: 0.8759\n",
      "Epoch 10/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8175 - val_loss: 0.8904\n",
      "Epoch 11/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8142 - val_loss: 0.9097\n",
      "Epoch 12/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8103 - val_loss: 0.9166\n",
      "Epoch 13/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8113 - val_loss: 0.9199\n",
      "Epoch 14/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8049 - val_loss: 0.8956\n",
      "Epoch 15/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8048 - val_loss: 0.8744\n",
      "Epoch 16/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8031 - val_loss: 0.8868\n",
      "Epoch 17/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8066 - val_loss: 0.9338\n",
      "Epoch 18/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8005 - val_loss: 0.8925\n",
      "Epoch 19/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7995 - val_loss: 0.8706\n",
      "Epoch 20/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7986 - val_loss: 0.8920\n",
      "Epoch 21/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7958 - val_loss: 0.9148\n",
      "Epoch 22/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7961 - val_loss: 0.9119\n",
      "Epoch 23/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7951 - val_loss: 0.8881\n",
      "Epoch 24/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7920 - val_loss: 0.8972\n",
      "Epoch 25/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7913 - val_loss: 0.9039\n",
      "Epoch 26/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7896 - val_loss: 0.8787\n",
      "Epoch 27/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7902 - val_loss: 0.8878\n",
      "Epoch 28/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7907 - val_loss: 0.8764\n",
      "Epoch 29/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7900 - val_loss: 0.9033\n",
      "Epoch 30/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7894 - val_loss: 0.9186\n",
      "Epoch 31/1500\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.7960 - val_loss: 0.8616\n",
      "Epoch 32/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7913 - val_loss: 0.9022\n",
      "Epoch 33/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7873 - val_loss: 0.8931\n",
      "Epoch 34/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7891 - val_loss: 0.9156\n",
      "Epoch 35/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7900 - val_loss: 0.8769\n",
      "Epoch 36/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7887 - val_loss: 0.8772\n",
      "Epoch 37/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7923 - val_loss: 0.9056\n",
      "Epoch 38/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7873 - val_loss: 0.8874\n",
      "Epoch 39/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7832 - val_loss: 0.8886\n",
      "Epoch 40/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7859 - val_loss: 0.9010\n",
      "Epoch 41/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7861 - val_loss: 0.8918\n",
      "Epoch 42/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7871 - val_loss: 0.8859\n",
      "Epoch 43/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7891 - val_loss: 0.8860\n",
      "Epoch 44/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7858 - val_loss: 0.9260\n",
      "Epoch 45/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7832 - val_loss: 0.8762\n",
      "Epoch 46/1500\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.7886 - val_loss: 0.8549\n",
      "Epoch 47/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7824 - val_loss: 0.9275\n",
      "Epoch 48/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7865 - val_loss: 0.9141\n",
      "Epoch 49/1500\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.7858 - val_loss: 0.8496\n",
      "Epoch 50/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7840 - val_loss: 0.8932\n",
      "Epoch 51/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7839 - val_loss: 0.9266\n",
      "Epoch 52/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7898 - val_loss: 0.8643\n",
      "Epoch 53/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7815 - val_loss: 0.9019\n",
      "Epoch 54/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7825 - val_loss: 0.9151\n",
      "Epoch 55/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7790 - val_loss: 0.8807\n",
      "Epoch 56/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7798 - val_loss: 0.8781\n",
      "Epoch 57/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7818 - val_loss: 0.8747\n",
      "Epoch 58/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7806 - val_loss: 0.9394\n",
      "Epoch 59/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7802 - val_loss: 0.8801\n",
      "Epoch 60/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7825 - val_loss: 0.8718\n",
      "Epoch 61/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7779 - val_loss: 0.9032\n",
      "Epoch 62/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7788 - val_loss: 0.8927\n",
      "Epoch 63/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7791 - val_loss: 0.8804\n",
      "Epoch 64/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7767 - val_loss: 0.9012\n",
      "Epoch 65/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7804 - val_loss: 0.9204\n",
      "Epoch 66/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7823 - val_loss: 0.8705\n",
      "Epoch 67/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7805 - val_loss: 0.9030\n",
      "Epoch 68/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7836 - val_loss: 0.9343\n",
      "Epoch 69/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7813 - val_loss: 0.8783\n",
      "Epoch 70/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7858 - val_loss: 0.8706\n",
      "Epoch 71/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7819 - val_loss: 0.9268\n",
      "Epoch 72/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7811 - val_loss: 0.9026\n",
      "Epoch 73/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7785 - val_loss: 0.8732\n",
      "Epoch 74/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7779 - val_loss: 0.9158\n",
      "Epoch 75/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7780 - val_loss: 0.8797\n",
      "Epoch 76/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7752 - val_loss: 0.8988\n",
      "Epoch 77/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7749 - val_loss: 0.9083\n",
      "Epoch 78/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7756 - val_loss: 0.8853\n",
      "Epoch 79/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7768 - val_loss: 0.8926\n",
      "Epoch 80/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7739 - val_loss: 0.8919\n",
      "Epoch 81/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7729 - val_loss: 0.8838\n",
      "Epoch 82/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7743 - val_loss: 0.8890\n",
      "Epoch 83/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7729 - val_loss: 0.9249\n",
      "Epoch 84/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7758 - val_loss: 0.8710\n",
      "Epoch 85/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7802 - val_loss: 0.9106\n",
      "Epoch 86/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7738 - val_loss: 0.8647\n",
      "Epoch 87/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7757 - val_loss: 0.9135\n",
      "Epoch 88/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7728 - val_loss: 0.8908\n",
      "Epoch 89/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7723 - val_loss: 0.9011\n",
      "Epoch 90/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7712 - val_loss: 0.8772\n",
      "Epoch 91/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7738 - val_loss: 0.9158\n",
      "Epoch 92/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7756 - val_loss: 0.8676\n",
      "Epoch 93/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7702 - val_loss: 0.9557\n",
      "Epoch 94/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7747 - val_loss: 0.9020\n",
      "Epoch 95/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7735 - val_loss: 0.8828\n",
      "Epoch 96/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7735 - val_loss: 0.9431\n",
      "Epoch 97/1500\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.7835 - val_loss: 0.8382\n",
      "Epoch 98/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7789 - val_loss: 0.9495\n",
      "Epoch 99/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7760 - val_loss: 0.8876\n",
      "Epoch 100/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7732 - val_loss: 0.8903\n",
      "Epoch 101/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7730 - val_loss: 0.9414\n",
      "Epoch 102/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7700 - val_loss: 0.8712\n",
      "Epoch 103/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7759 - val_loss: 0.8981\n",
      "Epoch 104/1500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7772 - val_loss: 0.9536\n",
      "Epoch 105/1500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7779 - val_loss: 0.8585\n",
      "Epoch 106/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7780 - val_loss: 0.9676\n",
      "Epoch 107/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7756 - val_loss: 0.8887\n",
      "Epoch 108/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7801 - val_loss: 0.8646\n",
      "Epoch 109/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7670 - val_loss: 0.9560\n",
      "Epoch 110/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7769 - val_loss: 0.8877\n",
      "Epoch 111/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7736 - val_loss: 0.8833\n",
      "Epoch 112/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7716 - val_loss: 0.9185\n",
      "Epoch 113/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7695 - val_loss: 0.9015\n",
      "Epoch 114/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7713 - val_loss: 0.9187\n",
      "Epoch 115/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7672 - val_loss: 0.9025\n",
      "Epoch 116/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7681 - val_loss: 0.8866\n",
      "Epoch 117/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7680 - val_loss: 0.9143\n",
      "Epoch 118/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7685 - val_loss: 0.8925\n",
      "Epoch 119/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7695 - val_loss: 0.9211\n",
      "Epoch 120/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7761 - val_loss: 0.9206\n",
      "Epoch 121/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7729 - val_loss: 0.8677\n",
      "Epoch 122/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7696 - val_loss: 0.9596\n",
      "Epoch 123/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7705 - val_loss: 0.8706\n",
      "Epoch 124/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7690 - val_loss: 0.9376\n",
      "Epoch 125/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7682 - val_loss: 0.8830\n",
      "Epoch 126/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7831 - val_loss: 0.9141\n",
      "Epoch 127/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7921 - val_loss: 0.9835\n",
      "Epoch 128/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7792 - val_loss: 0.8473\n",
      "Epoch 129/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7794 - val_loss: 0.9078\n",
      "Epoch 130/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7705 - val_loss: 0.9097\n",
      "Epoch 131/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7715 - val_loss: 0.9227\n",
      "Epoch 132/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7708 - val_loss: 0.8715\n",
      "Epoch 133/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7713 - val_loss: 0.8902\n",
      "Epoch 134/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7724 - val_loss: 0.9483\n",
      "Epoch 135/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7690 - val_loss: 0.8781\n",
      "Epoch 136/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7756 - val_loss: 0.8834\n",
      "Epoch 137/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7708 - val_loss: 0.9796\n",
      "Epoch 138/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7750 - val_loss: 0.8778\n",
      "Epoch 139/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7695 - val_loss: 0.9086\n",
      "Epoch 140/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7753 - val_loss: 0.9366\n",
      "Epoch 141/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7665 - val_loss: 0.8709\n",
      "Epoch 142/1500\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.7727 - val_loss: 0.8956\n",
      "Epoch 143/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7651 - val_loss: 0.9535\n",
      "Epoch 144/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7686 - val_loss: 0.8958\n",
      "Epoch 145/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7659 - val_loss: 0.9027\n",
      "Epoch 146/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7675 - val_loss: 0.8905\n",
      "Epoch 147/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7652 - val_loss: 0.9336\n",
      "Epoch 148/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7658 - val_loss: 0.9375\n",
      "Epoch 149/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7649 - val_loss: 0.8953\n",
      "Epoch 150/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7662 - val_loss: 0.9315\n",
      "Epoch 151/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7648 - val_loss: 0.9004\n",
      "Epoch 152/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7649 - val_loss: 0.9271\n",
      "Epoch 153/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7695 - val_loss: 0.8980\n",
      "Epoch 154/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7733 - val_loss: 0.9293\n",
      "Epoch 155/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7693 - val_loss: 0.9057\n",
      "Epoch 156/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7767 - val_loss: 0.9470\n",
      "Epoch 157/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7607 - val_loss: 0.8649\n",
      "Epoch 158/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7748 - val_loss: 0.9459\n",
      "Epoch 159/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7801 - val_loss: 0.9209\n",
      "Epoch 160/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7725 - val_loss: 0.8398\n",
      "Epoch 161/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7750 - val_loss: 0.9623\n",
      "Epoch 162/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7788 - val_loss: 0.9489\n",
      "Epoch 163/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7654 - val_loss: 0.8744\n",
      "Epoch 164/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7709 - val_loss: 0.8903\n",
      "Epoch 165/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7679 - val_loss: 0.9332\n",
      "Epoch 166/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7660 - val_loss: 0.8849\n",
      "Epoch 167/1500\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7746 - val_loss: 0.9477\n",
      "Epoch 168/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7634 - val_loss: 0.8790\n",
      "Epoch 169/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7647 - val_loss: 0.9174\n",
      "Epoch 170/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7623 - val_loss: 0.9233\n",
      "Epoch 171/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7657 - val_loss: 0.9061\n",
      "Epoch 172/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7640 - val_loss: 0.9356\n",
      "Epoch 173/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7659 - val_loss: 0.9305\n",
      "Epoch 174/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7631 - val_loss: 0.9073\n",
      "Epoch 175/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7625 - val_loss: 0.8940\n",
      "Epoch 176/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7587 - val_loss: 0.9967\n",
      "Epoch 177/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7698 - val_loss: 0.8627\n",
      "Epoch 178/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7819 - val_loss: 0.9531\n",
      "Epoch 179/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7707 - val_loss: 0.9440\n",
      "Epoch 180/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7717 - val_loss: 0.8608\n",
      "Epoch 181/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7705 - val_loss: 0.9419\n",
      "Epoch 182/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7787 - val_loss: 0.9686\n",
      "Epoch 183/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7688 - val_loss: 0.8581\n",
      "Epoch 184/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7780 - val_loss: 0.9232\n",
      "Epoch 185/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7660 - val_loss: 0.9122\n",
      "Epoch 186/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7656 - val_loss: 0.9270\n",
      "Epoch 187/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7628 - val_loss: 0.9059\n",
      "Epoch 188/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7667 - val_loss: 0.8913\n",
      "Epoch 189/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7624 - val_loss: 0.9326\n",
      "Epoch 190/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7647 - val_loss: 0.8884\n",
      "Epoch 191/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7657 - val_loss: 0.9327\n",
      "Epoch 192/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7665 - val_loss: 0.9267\n",
      "Epoch 193/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7646 - val_loss: 0.8814\n",
      "Epoch 194/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7637 - val_loss: 0.9615\n",
      "Epoch 195/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7608 - val_loss: 0.8991\n",
      "Epoch 196/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7622 - val_loss: 0.9359\n",
      "Epoch 197/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7629 - val_loss: 0.9199\n",
      "Epoch 198/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7748 - val_loss: 0.8931\n",
      "Epoch 199/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7747 - val_loss: 1.0104\n",
      "Epoch 200/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7792 - val_loss: 0.8523\n",
      "Epoch 201/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7718 - val_loss: 0.9125\n",
      "Epoch 202/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7659 - val_loss: 0.9835\n",
      "Epoch 203/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7687 - val_loss: 0.8972\n",
      "Epoch 204/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7641 - val_loss: 0.8931\n",
      "Epoch 205/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7634 - val_loss: 0.8957\n",
      "Epoch 206/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7655 - val_loss: 0.9359\n",
      "Epoch 207/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7727 - val_loss: 0.8646\n",
      "Epoch 208/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7717 - val_loss: 0.9917\n",
      "Epoch 209/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7697 - val_loss: 0.8718\n",
      "Epoch 210/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7694 - val_loss: 0.8996\n",
      "Epoch 211/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7731 - val_loss: 0.9700\n",
      "Epoch 212/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7608 - val_loss: 0.8846\n",
      "Epoch 213/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7663 - val_loss: 0.9325\n",
      "Epoch 214/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7676 - val_loss: 0.9160\n",
      "Epoch 215/1500\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.7741 - val_loss: 0.8783\n",
      "Epoch 216/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7613 - val_loss: 0.9686\n",
      "Epoch 217/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7634 - val_loss: 0.8995\n",
      "Epoch 218/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7637 - val_loss: 0.9081\n",
      "Epoch 219/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7731 - val_loss: 0.9633\n",
      "Epoch 220/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7644 - val_loss: 0.8691\n",
      "Epoch 221/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7668 - val_loss: 0.9645\n",
      "Epoch 222/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7671 - val_loss: 0.9145\n",
      "Epoch 223/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7637 - val_loss: 0.8999\n",
      "Epoch 224/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7590 - val_loss: 0.9410\n",
      "Epoch 225/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7577 - val_loss: 0.8949\n",
      "Epoch 226/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7598 - val_loss: 0.9584\n",
      "Epoch 227/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7615 - val_loss: 0.9183\n",
      "Epoch 228/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7557 - val_loss: 0.9453\n",
      "Epoch 229/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7567 - val_loss: 0.9048\n",
      "Epoch 230/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7634 - val_loss: 0.9237\n",
      "Epoch 231/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7579 - val_loss: 0.9506\n",
      "Epoch 232/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7603 - val_loss: 0.9044\n",
      "Epoch 233/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7566 - val_loss: 0.9428\n",
      "Epoch 234/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7553 - val_loss: 0.8906\n",
      "Epoch 235/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7630 - val_loss: 0.9594\n",
      "Epoch 236/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7707 - val_loss: 0.9606\n",
      "Epoch 237/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7549 - val_loss: 0.8674\n",
      "Epoch 238/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7629 - val_loss: 0.9551\n",
      "Epoch 239/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7761 - val_loss: 0.9541\n",
      "Epoch 240/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7847 - val_loss: 0.8710\n",
      "Epoch 241/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7715 - val_loss: 1.0179\n",
      "Epoch 242/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7743 - val_loss: 0.8963\n",
      "Epoch 243/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7663 - val_loss: 0.8896\n",
      "Epoch 244/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7629 - val_loss: 0.9283\n",
      "Epoch 245/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7607 - val_loss: 0.9241\n",
      "Epoch 246/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7604 - val_loss: 0.9100\n",
      "Epoch 247/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7595 - val_loss: 0.9279\n",
      "Epoch 248/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7678 - val_loss: 0.9298\n",
      "Epoch 249/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7588 - val_loss: 0.8839\n",
      "Epoch 250/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7593 - val_loss: 0.9687\n",
      "Epoch 251/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7583 - val_loss: 0.9174\n",
      "Epoch 252/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7555 - val_loss: 0.9293\n",
      "Epoch 253/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7553 - val_loss: 0.9151\n",
      "Epoch 254/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7550 - val_loss: 0.9344\n",
      "Epoch 255/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7582 - val_loss: 0.9254\n",
      "Epoch 256/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7538 - val_loss: 0.9175\n",
      "Epoch 257/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7555 - val_loss: 0.9699\n",
      "Epoch 258/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7618 - val_loss: 0.9075\n",
      "Epoch 259/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7668 - val_loss: 0.9803\n",
      "Epoch 260/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7539 - val_loss: 0.8857\n",
      "Epoch 261/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7623 - val_loss: 0.9694\n",
      "Epoch 262/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7593 - val_loss: 0.9412\n",
      "Epoch 263/1500\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7599 - val_loss: 0.9138\n",
      "Epoch 264/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7595 - val_loss: 0.9591\n",
      "Epoch 265/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7559 - val_loss: 0.9153\n",
      "Epoch 266/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7544 - val_loss: 0.9371\n",
      "Epoch 267/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7563 - val_loss: 0.9382\n",
      "Epoch 268/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7580 - val_loss: 0.9216\n",
      "Epoch 269/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7548 - val_loss: 0.9240\n",
      "Epoch 270/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7539 - val_loss: 0.9315\n",
      "Epoch 271/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7533 - val_loss: 0.9393\n",
      "Epoch 272/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7573 - val_loss: 0.9462\n",
      "Epoch 273/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7660 - val_loss: 0.9208\n",
      "Epoch 274/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7770 - val_loss: 0.8775\n",
      "Epoch 275/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7546 - val_loss: 0.9955\n",
      "Epoch 276/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7640 - val_loss: 0.9076\n",
      "Epoch 277/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7629 - val_loss: 0.8949\n",
      "Epoch 278/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7617 - val_loss: 0.9533\n",
      "Epoch 279/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7572 - val_loss: 0.9067\n",
      "Epoch 280/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7579 - val_loss: 0.9142\n",
      "Epoch 281/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7578 - val_loss: 0.9310\n",
      "Epoch 282/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7550 - val_loss: 0.9317\n",
      "Epoch 283/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7593 - val_loss: 0.9271\n",
      "Epoch 284/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7642 - val_loss: 0.9459\n",
      "Epoch 285/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7598 - val_loss: 0.9252\n",
      "Epoch 286/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7538 - val_loss: 0.9201\n",
      "Epoch 287/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7546 - val_loss: 0.9424\n",
      "Epoch 288/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7519 - val_loss: 0.9197\n",
      "Epoch 289/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7539 - val_loss: 0.9411\n",
      "Epoch 290/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7520 - val_loss: 0.9267\n",
      "Epoch 291/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7556 - val_loss: 0.9583\n",
      "Epoch 292/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7533 - val_loss: 0.9396\n",
      "Epoch 293/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7545 - val_loss: 0.9264\n",
      "Epoch 294/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7676 - val_loss: 0.9256\n",
      "Epoch 295/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7529 - val_loss: 0.8970\n",
      "Epoch 296/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7567 - val_loss: 0.9789\n",
      "Epoch 297/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7593 - val_loss: 0.9071\n",
      "Epoch 298/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7550 - val_loss: 0.9479\n",
      "Epoch 299/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7521 - val_loss: 0.9179\n",
      "Epoch 300/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7525 - val_loss: 0.9345\n",
      "Epoch 301/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7542 - val_loss: 0.9222\n",
      "Epoch 302/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7518 - val_loss: 0.9519\n",
      "Epoch 303/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7556 - val_loss: 0.9307\n",
      "Epoch 304/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7615 - val_loss: 0.9311\n",
      "Epoch 305/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7744 - val_loss: 0.9749\n",
      "Epoch 306/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7562 - val_loss: 0.8769\n",
      "Epoch 307/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7586 - val_loss: 0.9363\n",
      "Epoch 308/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7649 - val_loss: 0.9661\n",
      "Epoch 309/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7546 - val_loss: 0.8920\n",
      "Epoch 310/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7604 - val_loss: 0.9711\n",
      "Epoch 311/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7526 - val_loss: 0.9090\n",
      "Epoch 312/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7551 - val_loss: 0.9278\n",
      "Epoch 313/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7538 - val_loss: 0.9419\n",
      "Epoch 314/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7507 - val_loss: 0.9127\n",
      "Epoch 315/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7520 - val_loss: 0.9544\n",
      "Epoch 316/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7516 - val_loss: 0.9213\n",
      "Epoch 317/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7611 - val_loss: 0.9487\n",
      "Epoch 318/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7601 - val_loss: 0.9821\n",
      "Epoch 319/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7584 - val_loss: 0.8848\n",
      "Epoch 320/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7572 - val_loss: 0.9655\n",
      "Epoch 321/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7550 - val_loss: 0.9493\n",
      "Epoch 322/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7527 - val_loss: 0.9300\n",
      "Epoch 323/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7519 - val_loss: 0.9304\n",
      "Epoch 324/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7516 - val_loss: 0.9362\n",
      "Epoch 325/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7499 - val_loss: 0.9326\n",
      "Epoch 326/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7491 - val_loss: 0.9431\n",
      "Epoch 327/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7507 - val_loss: 0.9569\n",
      "Epoch 328/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7503 - val_loss: 0.9193\n",
      "Epoch 329/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7512 - val_loss: 0.9818\n",
      "Epoch 330/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7600 - val_loss: 0.9077\n",
      "Epoch 331/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7609 - val_loss: 0.9146\n",
      "Epoch 332/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7586 - val_loss: 0.9891\n",
      "Epoch 333/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7660 - val_loss: 0.8914\n",
      "Epoch 334/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7539 - val_loss: 0.9622\n",
      "Epoch 335/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7624 - val_loss: 0.9324\n",
      "Epoch 336/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7519 - val_loss: 0.8952\n",
      "Epoch 337/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7581 - val_loss: 0.9533\n",
      "Epoch 338/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7511 - val_loss: 0.9253\n",
      "Epoch 339/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7542 - val_loss: 0.9493\n",
      "Epoch 340/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7528 - val_loss: 0.9313\n",
      "Epoch 341/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7501 - val_loss: 0.9565\n",
      "Epoch 342/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7513 - val_loss: 0.9237\n",
      "Epoch 343/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7502 - val_loss: 0.9470\n",
      "Epoch 344/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7505 - val_loss: 0.9335\n",
      "Epoch 345/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7493 - val_loss: 0.9278\n",
      "Epoch 346/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7517 - val_loss: 0.9554\n",
      "Epoch 347/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7535 - val_loss: 0.9427\n",
      "Epoch 348/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7480 - val_loss: 0.9645\n",
      "Epoch 349/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7519 - val_loss: 0.9295\n",
      "Epoch 350/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7536 - val_loss: 0.9480\n",
      "Epoch 351/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7524 - val_loss: 0.9249\n",
      "Epoch 352/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7473 - val_loss: 0.9868\n",
      "Epoch 353/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7526 - val_loss: 0.9206\n",
      "Epoch 354/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7494 - val_loss: 0.9535\n",
      "Epoch 355/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7522 - val_loss: 0.9327\n",
      "Epoch 356/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7507 - val_loss: 0.9238\n",
      "Epoch 357/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7495 - val_loss: 0.9617\n",
      "Epoch 358/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7521 - val_loss: 0.9279\n",
      "Epoch 359/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7545 - val_loss: 0.9605\n",
      "Epoch 360/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7483 - val_loss: 0.9207\n",
      "Epoch 361/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7491 - val_loss: 0.9456\n",
      "Epoch 362/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7483 - val_loss: 0.9548\n",
      "Epoch 363/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7486 - val_loss: 0.9373\n",
      "Epoch 364/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7475 - val_loss: 0.9571\n",
      "Epoch 365/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7484 - val_loss: 0.9320\n",
      "Epoch 366/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7491 - val_loss: 0.9549\n",
      "Epoch 367/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7496 - val_loss: 0.9346\n",
      "Epoch 368/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7525 - val_loss: 0.9594\n",
      "Epoch 369/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7496 - val_loss: 0.9536\n",
      "Epoch 370/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7484 - val_loss: 0.9420\n",
      "Epoch 371/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7482 - val_loss: 0.9450\n",
      "Epoch 372/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7475 - val_loss: 0.9409\n",
      "Epoch 373/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7470 - val_loss: 0.9677\n",
      "Epoch 374/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7490 - val_loss: 0.9225\n",
      "Epoch 375/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7524 - val_loss: 0.9394\n",
      "Epoch 376/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7519 - val_loss: 0.9513\n",
      "Epoch 377/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7469 - val_loss: 0.9290\n",
      "Epoch 378/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7512 - val_loss: 0.9947\n",
      "Epoch 379/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7545 - val_loss: 0.9080\n",
      "Epoch 380/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7521 - val_loss: 0.9419\n",
      "Epoch 381/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7542 - val_loss: 0.9470\n",
      "Epoch 382/1500\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7484 - val_loss: 0.9102\n",
      "Epoch 383/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7524 - val_loss: 0.9750\n",
      "Epoch 384/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7499 - val_loss: 0.9225\n",
      "Epoch 385/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7491 - val_loss: 0.9284\n",
      "Epoch 386/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7479 - val_loss: 0.9547\n",
      "Epoch 387/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7468 - val_loss: 0.9274\n",
      "Epoch 388/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7500 - val_loss: 0.9428\n",
      "Epoch 389/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7470 - val_loss: 0.9391\n",
      "Epoch 390/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7467 - val_loss: 0.9499\n",
      "Epoch 391/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7487 - val_loss: 0.9221\n",
      "Epoch 392/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7516 - val_loss: 0.9647\n",
      "Epoch 393/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7533 - val_loss: 0.9481\n",
      "Epoch 394/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7496 - val_loss: 0.9485\n",
      "Epoch 395/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7473 - val_loss: 0.9572\n",
      "Epoch 396/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7481 - val_loss: 0.9379\n",
      "Epoch 397/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7501 - val_loss: 0.9521\n",
      "Epoch 398/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7508 - val_loss: 0.9350\n",
      "Epoch 399/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7563 - val_loss: 0.9432\n",
      "Epoch 400/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7565 - val_loss: 0.9856\n",
      "Epoch 401/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7638 - val_loss: 0.8746\n",
      "Epoch 402/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7593 - val_loss: 1.0131\n",
      "Epoch 403/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7716 - val_loss: 0.9537\n",
      "Epoch 404/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7624 - val_loss: 0.8711\n",
      "Epoch 405/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7614 - val_loss: 0.9572\n",
      "Epoch 406/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7519 - val_loss: 0.9536\n",
      "Epoch 407/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7512 - val_loss: 0.9475\n",
      "Epoch 408/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7517 - val_loss: 0.9568\n",
      "Epoch 409/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7501 - val_loss: 0.9295\n",
      "Epoch 410/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7520 - val_loss: 0.9430\n",
      "Epoch 411/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7547 - val_loss: 0.9326\n",
      "Epoch 412/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7541 - val_loss: 0.9367\n",
      "Epoch 413/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7508 - val_loss: 0.9614\n",
      "Epoch 414/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7513 - val_loss: 0.9313\n",
      "Epoch 415/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7520 - val_loss: 0.9507\n",
      "Epoch 416/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7513 - val_loss: 0.9319\n",
      "Epoch 417/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7523 - val_loss: 0.9759\n",
      "Epoch 418/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7563 - val_loss: 0.9471\n",
      "Epoch 419/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7605 - val_loss: 0.9254\n",
      "Epoch 420/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7612 - val_loss: 0.9472\n",
      "Epoch 421/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7622 - val_loss: 0.9211\n",
      "Epoch 422/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7579 - val_loss: 0.9889\n",
      "Epoch 423/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7547 - val_loss: 0.9225\n",
      "Epoch 424/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7534 - val_loss: 0.9376\n",
      "Epoch 425/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7510 - val_loss: 0.9537\n",
      "Epoch 426/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7533 - val_loss: 0.9455\n",
      "Epoch 427/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7521 - val_loss: 0.9746\n",
      "Epoch 428/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7485 - val_loss: 0.9345\n",
      "Epoch 429/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7488 - val_loss: 0.9566\n",
      "Epoch 430/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7533 - val_loss: 0.9535\n",
      "Epoch 431/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7537 - val_loss: 0.9599\n",
      "Epoch 432/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7521 - val_loss: 0.9383\n",
      "Epoch 433/1500\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7480 - val_loss: 0.9645\n",
      "Epoch 434/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7482 - val_loss: 0.9318\n",
      "Epoch 435/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7486 - val_loss: 0.9606\n",
      "Epoch 436/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7482 - val_loss: 0.9469\n",
      "Epoch 437/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7473 - val_loss: 0.9469\n",
      "Epoch 438/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7466 - val_loss: 0.9486\n",
      "Epoch 439/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7462 - val_loss: 0.9583\n",
      "Epoch 440/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7472 - val_loss: 0.9395\n",
      "Epoch 441/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7480 - val_loss: 0.9307\n",
      "Epoch 442/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7584 - val_loss: 0.9847\n",
      "Epoch 443/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7479 - val_loss: 0.9017\n",
      "Epoch 444/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7526 - val_loss: 0.9579\n",
      "Epoch 445/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7482 - val_loss: 0.9664\n",
      "Epoch 446/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7469 - val_loss: 0.9451\n",
      "Epoch 447/1500\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.7476 - val_loss: 0.9450\n",
      "Epoch 448/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7468 - val_loss: 0.9349\n",
      "Epoch 449/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7465 - val_loss: 0.9654\n",
      "Epoch 450/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7474 - val_loss: 0.9590\n",
      "Epoch 451/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7458 - val_loss: 0.9383\n",
      "Epoch 452/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7460 - val_loss: 0.9725\n",
      "Epoch 453/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7496 - val_loss: 0.9236\n",
      "Epoch 454/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7489 - val_loss: 0.9743\n",
      "Epoch 455/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7483 - val_loss: 0.9362\n",
      "Epoch 456/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7498 - val_loss: 0.9591\n",
      "Epoch 457/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7506 - val_loss: 0.9594\n",
      "Epoch 458/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7490 - val_loss: 0.9211\n",
      "Epoch 459/1500\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.7479 - val_loss: 0.9989\n",
      "Epoch 460/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7502 - val_loss: 0.9055\n",
      "Epoch 461/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7551 - val_loss: 0.9654\n",
      "Epoch 462/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7562 - val_loss: 0.9603\n",
      "Epoch 463/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7509 - val_loss: 0.9192\n",
      "Epoch 464/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7534 - val_loss: 0.9924\n",
      "Epoch 465/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7483 - val_loss: 0.9401\n",
      "Epoch 466/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7484 - val_loss: 0.9705\n",
      "Epoch 467/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7483 - val_loss: 0.9392\n",
      "Epoch 468/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7471 - val_loss: 0.9587\n",
      "Epoch 469/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7458 - val_loss: 0.9585\n",
      "Epoch 470/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7457 - val_loss: 0.9437\n",
      "Epoch 471/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7473 - val_loss: 0.9426\n",
      "Epoch 472/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7474 - val_loss: 0.9555\n",
      "Epoch 473/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7465 - val_loss: 0.9347\n",
      "Epoch 474/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7459 - val_loss: 0.9682\n",
      "Epoch 475/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7476 - val_loss: 0.9589\n",
      "Epoch 476/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7490 - val_loss: 0.9544\n",
      "Epoch 477/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7467 - val_loss: 0.9339\n",
      "Epoch 478/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7465 - val_loss: 0.9643\n",
      "Epoch 479/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7455 - val_loss: 0.9400\n",
      "Epoch 480/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7454 - val_loss: 0.9711\n",
      "Epoch 481/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7463 - val_loss: 0.9386\n",
      "Epoch 482/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7457 - val_loss: 0.9413\n",
      "Epoch 483/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7460 - val_loss: 0.9545\n",
      "Epoch 484/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7467 - val_loss: 0.9345\n",
      "Epoch 485/1500\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7475 - val_loss: 0.9835\n",
      "Epoch 486/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7469 - val_loss: 0.9207\n",
      "Epoch 487/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7497 - val_loss: 1.0284\n",
      "Epoch 488/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7522 - val_loss: 0.9114\n",
      "Epoch 489/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7503 - val_loss: 0.9580\n",
      "Epoch 490/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7484 - val_loss: 0.9543\n",
      "Epoch 491/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7503 - val_loss: 0.9587\n",
      "Epoch 492/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7486 - val_loss: 0.9485\n",
      "Epoch 493/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7467 - val_loss: 0.9303\n",
      "Epoch 494/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7458 - val_loss: 0.9639\n",
      "Epoch 495/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7486 - val_loss: 0.9552\n",
      "Epoch 496/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7491 - val_loss: 0.9443\n",
      "Epoch 497/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7471 - val_loss: 0.9423\n",
      "Epoch 498/1500\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.7456 - val_loss: 0.9590\n",
      "Epoch 499/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7461 - val_loss: 0.9554\n",
      "Epoch 500/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7457 - val_loss: 0.9476\n",
      "Epoch 501/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7448 - val_loss: 0.9584\n",
      "Epoch 502/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7447 - val_loss: 0.9403\n",
      "Epoch 503/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7459 - val_loss: 0.9526\n",
      "Epoch 504/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7445 - val_loss: 0.9458\n",
      "Epoch 505/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7449 - val_loss: 0.9687\n",
      "Epoch 506/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7457 - val_loss: 0.9438\n",
      "Epoch 507/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7464 - val_loss: 0.9659\n",
      "Epoch 508/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7460 - val_loss: 0.9329\n",
      "Epoch 509/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7442 - val_loss: 0.9685\n",
      "Epoch 510/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7456 - val_loss: 0.9487\n",
      "Epoch 511/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7439 - val_loss: 0.9687\n",
      "Epoch 512/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7460 - val_loss: 0.9233\n",
      "Epoch 513/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7531 - val_loss: 0.9996\n",
      "Epoch 514/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7611 - val_loss: 0.9385\n",
      "Epoch 515/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7577 - val_loss: 0.8993\n",
      "Epoch 516/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7478 - val_loss: 0.9902\n",
      "Epoch 517/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7495 - val_loss: 0.9586\n",
      "Epoch 518/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7519 - val_loss: 0.9908\n",
      "Epoch 519/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7485 - val_loss: 0.9393\n",
      "Epoch 520/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7464 - val_loss: 0.9398\n",
      "Epoch 521/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7470 - val_loss: 0.9503\n",
      "Epoch 522/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7457 - val_loss: 0.9617\n",
      "Epoch 523/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7454 - val_loss: 0.9333\n",
      "Epoch 524/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7450 - val_loss: 0.9499\n",
      "Epoch 525/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7460 - val_loss: 0.9432\n",
      "Epoch 526/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7452 - val_loss: 0.9427\n",
      "Epoch 527/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7442 - val_loss: 0.9642\n",
      "Epoch 528/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7457 - val_loss: 0.9418\n",
      "Epoch 529/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7444 - val_loss: 0.9534\n",
      "Epoch 530/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7442 - val_loss: 0.9520\n",
      "Epoch 531/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7456 - val_loss: 0.9601\n",
      "Epoch 532/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7453 - val_loss: 0.9412\n",
      "Epoch 533/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7448 - val_loss: 0.9369\n",
      "Epoch 534/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7450 - val_loss: 0.9640\n",
      "Epoch 535/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7449 - val_loss: 0.9502\n",
      "Epoch 536/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7448 - val_loss: 0.9472\n",
      "Epoch 537/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7449 - val_loss: 0.9609\n",
      "Epoch 538/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7449 - val_loss: 0.9518\n",
      "Epoch 539/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7447 - val_loss: 0.9527\n",
      "Epoch 540/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7488 - val_loss: 0.9598\n",
      "Epoch 541/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7487 - val_loss: 0.9719\n",
      "Epoch 542/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7475 - val_loss: 0.9248\n",
      "Epoch 543/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7458 - val_loss: 0.9978\n",
      "Epoch 544/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7498 - val_loss: 0.9376\n",
      "Epoch 545/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7553 - val_loss: 0.9293\n",
      "Epoch 546/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7485 - val_loss: 1.0679\n",
      "Epoch 547/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7648 - val_loss: 0.8830\n",
      "Epoch 548/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7740 - val_loss: 0.9603\n",
      "Epoch 549/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7610 - val_loss: 0.9803\n",
      "Epoch 550/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7600 - val_loss: 0.9023\n",
      "Epoch 551/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7574 - val_loss: 0.9293\n",
      "Epoch 552/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7500 - val_loss: 0.9720\n",
      "Epoch 553/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7479 - val_loss: 0.9428\n",
      "Epoch 554/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7505 - val_loss: 1.0039\n",
      "Epoch 555/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7573 - val_loss: 0.9501\n",
      "Epoch 556/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7546 - val_loss: 0.9050\n",
      "Epoch 557/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7491 - val_loss: 0.9988\n",
      "Epoch 558/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7532 - val_loss: 0.9160\n",
      "Epoch 559/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7545 - val_loss: 0.9825\n",
      "Epoch 560/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7584 - val_loss: 0.9471\n",
      "Epoch 561/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7539 - val_loss: 0.8887\n",
      "Epoch 562/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7549 - val_loss: 0.9956\n",
      "Epoch 563/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7533 - val_loss: 0.9501\n",
      "Epoch 564/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7501 - val_loss: 0.9770\n",
      "Epoch 565/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7488 - val_loss: 0.9662\n",
      "Epoch 566/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7515 - val_loss: 0.9255\n",
      "Epoch 567/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7552 - val_loss: 1.0058\n",
      "Epoch 568/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7500 - val_loss: 0.9325\n",
      "Epoch 569/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7507 - val_loss: 0.9669\n",
      "Epoch 570/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7491 - val_loss: 0.9830\n",
      "Epoch 571/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7512 - val_loss: 0.9626\n",
      "Epoch 572/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7500 - val_loss: 0.9825\n",
      "Epoch 573/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7500 - val_loss: 0.9337\n",
      "Epoch 574/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7458 - val_loss: 0.9956\n",
      "Epoch 575/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7468 - val_loss: 0.9525\n",
      "Epoch 576/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7446 - val_loss: 0.9625\n",
      "Epoch 577/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7454 - val_loss: 0.9710\n",
      "Epoch 578/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7450 - val_loss: 0.9647\n",
      "Epoch 579/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7454 - val_loss: 0.9573\n",
      "Epoch 580/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7448 - val_loss: 0.9788\n",
      "Epoch 581/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7446 - val_loss: 0.9451\n",
      "Epoch 582/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7456 - val_loss: 0.9620\n",
      "Epoch 583/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7456 - val_loss: 0.9737\n",
      "Epoch 584/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7448 - val_loss: 0.9547\n",
      "Epoch 585/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7440 - val_loss: 0.9677\n",
      "Epoch 586/1500\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7445 - val_loss: 0.9617\n",
      "Epoch 587/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7434 - val_loss: 0.9662\n",
      "Epoch 588/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7437 - val_loss: 0.9642\n",
      "Epoch 589/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7433 - val_loss: 0.9527\n",
      "Epoch 590/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7440 - val_loss: 0.9778\n",
      "Epoch 591/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7476 - val_loss: 0.9600\n",
      "Epoch 592/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7566 - val_loss: 0.9157\n",
      "Epoch 593/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7477 - val_loss: 1.0542\n",
      "Epoch 594/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7672 - val_loss: 0.9113\n",
      "Epoch 595/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7651 - val_loss: 0.8938\n",
      "Epoch 596/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7666 - val_loss: 1.0728\n",
      "Epoch 597/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7567 - val_loss: 0.9062\n",
      "Epoch 598/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7739 - val_loss: 0.8859\n",
      "Epoch 599/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7661 - val_loss: 1.0079\n",
      "Epoch 600/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7623 - val_loss: 0.9492\n",
      "Epoch 601/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7604 - val_loss: 0.9305\n",
      "Epoch 602/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7560 - val_loss: 1.1095\n",
      "Epoch 603/1500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7753 - val_loss: 0.9120\n",
      "Epoch 604/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7589 - val_loss: 0.8715\n",
      "Epoch 605/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7662 - val_loss: 0.9073\n",
      "Epoch 606/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7548 - val_loss: 0.9987\n",
      "Epoch 607/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7571 - val_loss: 0.9401\n",
      "Epoch 608/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7509 - val_loss: 0.9415\n",
      "Epoch 609/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7531 - val_loss: 0.9771\n",
      "Epoch 610/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7483 - val_loss: 0.9175\n",
      "Epoch 611/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7501 - val_loss: 1.0008\n",
      "Epoch 612/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7581 - val_loss: 0.9364\n",
      "Epoch 613/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7507 - val_loss: 0.9069\n",
      "Epoch 614/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7516 - val_loss: 0.9903\n",
      "Epoch 615/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7498 - val_loss: 0.9566\n",
      "Epoch 616/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7467 - val_loss: 0.9458\n",
      "Epoch 617/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7466 - val_loss: 0.9660\n",
      "Epoch 618/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7473 - val_loss: 0.9491\n",
      "Epoch 619/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7463 - val_loss: 0.9716\n",
      "Epoch 620/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7461 - val_loss: 0.9407\n",
      "Epoch 621/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7454 - val_loss: 0.9598\n",
      "Epoch 622/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7448 - val_loss: 0.9324\n",
      "Epoch 623/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7471 - val_loss: 0.9672\n",
      "Epoch 624/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7453 - val_loss: 0.9517\n",
      "Epoch 625/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7446 - val_loss: 0.9629\n",
      "Epoch 626/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7449 - val_loss: 0.9415\n",
      "Epoch 627/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7448 - val_loss: 0.9554\n",
      "Epoch 628/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7473 - val_loss: 0.9536\n",
      "Epoch 629/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7474 - val_loss: 0.9454\n",
      "Epoch 630/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7462 - val_loss: 0.9690\n",
      "Epoch 631/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7439 - val_loss: 0.9393\n",
      "Epoch 632/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7444 - val_loss: 0.9601\n",
      "Epoch 633/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7446 - val_loss: 0.9606\n",
      "Epoch 634/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7477 - val_loss: 0.9514\n",
      "Epoch 635/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7459 - val_loss: 1.0065\n",
      "Epoch 636/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7466 - val_loss: 0.9152\n",
      "Epoch 637/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7481 - val_loss: 0.9324\n",
      "Epoch 638/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7454 - val_loss: 0.9839\n",
      "Epoch 639/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7447 - val_loss: 0.9584\n",
      "Epoch 640/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7458 - val_loss: 0.9857\n",
      "Epoch 641/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7445 - val_loss: 0.9539\n",
      "Epoch 642/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7441 - val_loss: 0.9501\n",
      "Epoch 643/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7451 - val_loss: 0.9630\n",
      "Epoch 644/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7457 - val_loss: 0.9485\n",
      "Epoch 645/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7433 - val_loss: 0.9697\n",
      "Epoch 646/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7444 - val_loss: 0.9396\n",
      "Epoch 647/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7447 - val_loss: 0.9689\n",
      "Epoch 648/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7445 - val_loss: 0.9666\n",
      "Epoch 649/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7435 - val_loss: 0.9438\n",
      "Epoch 650/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7442 - val_loss: 0.9605\n",
      "Epoch 651/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7435 - val_loss: 0.9407\n",
      "Epoch 652/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7452 - val_loss: 0.9636\n",
      "Epoch 653/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7435 - val_loss: 0.9546\n",
      "Epoch 654/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7435 - val_loss: 0.9663\n",
      "Epoch 655/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7436 - val_loss: 0.9441\n",
      "Epoch 656/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7438 - val_loss: 0.9503\n",
      "Epoch 657/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7439 - val_loss: 0.9663\n",
      "Epoch 658/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7467 - val_loss: 0.9618\n",
      "Epoch 659/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7498 - val_loss: 0.9533\n",
      "Epoch 660/1500\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.7473 - val_loss: 0.9222\n",
      "Epoch 661/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7450 - val_loss: 0.9990\n",
      "Epoch 662/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7483 - val_loss: 0.9540\n",
      "Epoch 663/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7527 - val_loss: 0.9762\n",
      "Epoch 664/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7572 - val_loss: 1.0088\n",
      "Epoch 665/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7515 - val_loss: 0.8857\n",
      "Epoch 666/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7620 - val_loss: 0.9150\n",
      "Epoch 667/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7500 - val_loss: 0.9902\n",
      "Epoch 668/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7482 - val_loss: 0.9697\n",
      "Epoch 669/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7475 - val_loss: 0.9728\n",
      "Epoch 670/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7477 - val_loss: 0.9379\n",
      "Epoch 671/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7471 - val_loss: 0.9584\n",
      "Epoch 672/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7452 - val_loss: 0.9413\n",
      "Epoch 673/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7445 - val_loss: 0.9624\n",
      "Epoch 674/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7446 - val_loss: 0.9566\n",
      "Epoch 675/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7442 - val_loss: 0.9435\n",
      "Epoch 676/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7448 - val_loss: 0.9589\n",
      "Epoch 677/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7452 - val_loss: 0.9476\n",
      "Epoch 678/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7440 - val_loss: 0.9656\n",
      "Epoch 679/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7434 - val_loss: 0.9494\n",
      "Epoch 680/1500\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.7434 - val_loss: 0.9620\n",
      "Epoch 681/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7433 - val_loss: 0.9570\n",
      "Epoch 682/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7432 - val_loss: 0.9430\n",
      "Epoch 683/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7438 - val_loss: 0.9797\n",
      "Epoch 684/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7450 - val_loss: 0.9409\n",
      "Epoch 685/1500\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.7443 - val_loss: 0.9671\n",
      "Epoch 686/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7428 - val_loss: 0.9501\n",
      "Epoch 687/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7429 - val_loss: 0.9595\n",
      "Epoch 688/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7430 - val_loss: 0.9585\n",
      "Epoch 689/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7429 - val_loss: 0.9592\n",
      "Epoch 690/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7430 - val_loss: 0.9632\n",
      "Epoch 691/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7431 - val_loss: 0.9442\n",
      "Epoch 692/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7429 - val_loss: 0.9717\n",
      "Epoch 693/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7432 - val_loss: 0.9531\n",
      "Epoch 694/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7428 - val_loss: 0.9566\n",
      "Epoch 695/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7426 - val_loss: 0.9744\n",
      "Epoch 696/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7429 - val_loss: 0.9427\n",
      "Epoch 697/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7430 - val_loss: 0.9695\n",
      "Epoch 698/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7445 - val_loss: 0.9595\n",
      "Epoch 699/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7439 - val_loss: 0.9502\n",
      "Epoch 700/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7436 - val_loss: 0.9775\n",
      "Epoch 701/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7429 - val_loss: 0.9374\n",
      "Epoch 702/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7436 - val_loss: 0.9654\n",
      "Epoch 703/1500\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.7427 - val_loss: 0.9564\n",
      "Epoch 704/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7425 - val_loss: 0.9659\n",
      "Epoch 705/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7428 - val_loss: 0.9609\n",
      "Epoch 706/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7429 - val_loss: 0.9663\n",
      "Epoch 707/1500\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7426 - val_loss: 0.9513\n",
      "Epoch 708/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7430 - val_loss: 0.9730\n",
      "Epoch 709/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7429 - val_loss: 0.9689\n",
      "Epoch 710/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7427 - val_loss: 0.9444\n",
      "Epoch 711/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7433 - val_loss: 0.9693\n",
      "Epoch 712/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7424 - val_loss: 0.9498\n",
      "Epoch 713/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7422 - val_loss: 0.9924\n",
      "Epoch 714/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7432 - val_loss: 0.9526\n",
      "Epoch 715/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7425 - val_loss: 0.9643\n",
      "Epoch 716/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7422 - val_loss: 0.9620\n",
      "Epoch 717/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7423 - val_loss: 0.9662\n",
      "Epoch 718/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7422 - val_loss: 0.9604\n",
      "Epoch 719/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7422 - val_loss: 0.9580\n",
      "Epoch 720/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7429 - val_loss: 0.9635\n",
      "Epoch 721/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7433 - val_loss: 0.9808\n",
      "Epoch 722/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7443 - val_loss: 0.9625\n",
      "Epoch 723/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7466 - val_loss: 0.9596\n",
      "Epoch 724/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7528 - val_loss: 0.9605\n",
      "Epoch 725/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7473 - val_loss: 0.9001\n",
      "Epoch 726/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7554 - val_loss: 1.0956\n",
      "Epoch 727/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7610 - val_loss: 0.9498\n",
      "Epoch 728/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7590 - val_loss: 0.9236\n",
      "Epoch 729/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7497 - val_loss: 1.0547\n",
      "Epoch 730/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7579 - val_loss: 0.9640\n",
      "Epoch 731/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7508 - val_loss: 0.9017\n",
      "Epoch 732/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7543 - val_loss: 1.0131\n",
      "Epoch 733/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7602 - val_loss: 0.9477\n",
      "Epoch 734/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7534 - val_loss: 0.9147\n",
      "Epoch 735/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7503 - val_loss: 1.0325\n",
      "Epoch 736/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7491 - val_loss: 1.0092\n",
      "Epoch 737/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7476 - val_loss: 0.9624\n",
      "Epoch 738/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7452 - val_loss: 1.0072\n",
      "Epoch 739/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7488 - val_loss: 0.9562\n",
      "Epoch 740/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7473 - val_loss: 0.9377\n",
      "Epoch 741/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7450 - val_loss: 1.0192\n",
      "Epoch 742/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7488 - val_loss: 0.9758\n",
      "Epoch 743/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7646 - val_loss: 0.9468\n",
      "Epoch 744/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7617 - val_loss: 1.0707\n",
      "Epoch 745/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7667 - val_loss: 0.9390\n",
      "Epoch 746/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7691 - val_loss: 0.8882\n",
      "Epoch 747/1500\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7610 - val_loss: 0.9470\n",
      "Epoch 748/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7569 - val_loss: 0.9995\n",
      "Epoch 749/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7573 - val_loss: 0.9323\n",
      "Epoch 750/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7579 - val_loss: 0.9454\n",
      "Epoch 751/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7538 - val_loss: 1.0069\n",
      "Epoch 752/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7520 - val_loss: 0.9659\n",
      "Epoch 753/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7547 - val_loss: 0.9854\n",
      "Epoch 754/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7527 - val_loss: 1.0536\n",
      "Epoch 755/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7557 - val_loss: 0.9481\n",
      "Epoch 756/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7511 - val_loss: 1.0060\n",
      "Epoch 757/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7517 - val_loss: 0.9993\n",
      "Epoch 758/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7499 - val_loss: 0.9977\n",
      "Epoch 759/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7514 - val_loss: 0.9710\n",
      "Epoch 760/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7500 - val_loss: 0.9678\n",
      "Epoch 761/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7483 - val_loss: 1.0352\n",
      "Epoch 762/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7497 - val_loss: 0.9702\n",
      "Epoch 763/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7483 - val_loss: 1.0179\n",
      "Epoch 764/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7488 - val_loss: 1.0213\n",
      "Epoch 765/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7471 - val_loss: 0.9839\n",
      "Epoch 766/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7492 - val_loss: 0.9927\n",
      "Epoch 767/1500\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.7461 - val_loss: 1.0190\n",
      "Epoch 768/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7465 - val_loss: 0.9642\n",
      "Epoch 769/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7473 - val_loss: 0.9728\n",
      "Epoch 770/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7580 - val_loss: 1.0034\n",
      "Epoch 771/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7488 - val_loss: 0.9262\n",
      "Epoch 772/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7576 - val_loss: 1.0483\n",
      "Epoch 773/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7504 - val_loss: 0.9267\n",
      "Epoch 774/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7505 - val_loss: 1.0108\n",
      "Epoch 775/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7536 - val_loss: 0.9753\n",
      "Epoch 776/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7536 - val_loss: 0.9188\n",
      "Epoch 777/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7495 - val_loss: 1.0043\n",
      "Epoch 778/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7495 - val_loss: 1.0059\n",
      "Epoch 779/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7455 - val_loss: 0.9558\n",
      "Epoch 780/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7475 - val_loss: 1.0472\n",
      "Epoch 781/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7515 - val_loss: 0.9457\n",
      "Epoch 782/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7529 - val_loss: 0.9648\n",
      "Epoch 783/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7544 - val_loss: 1.0162\n",
      "Epoch 784/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7451 - val_loss: 0.9547\n",
      "Epoch 785/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7481 - val_loss: 1.0370\n",
      "Epoch 786/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7541 - val_loss: 0.9656\n",
      "Epoch 787/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7572 - val_loss: 1.0148\n",
      "Epoch 788/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7528 - val_loss: 0.8921\n",
      "Epoch 789/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7607 - val_loss: 0.9599\n",
      "Epoch 790/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7521 - val_loss: 1.0549\n",
      "Epoch 791/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7505 - val_loss: 0.9452\n",
      "Epoch 792/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7541 - val_loss: 0.9929\n",
      "Epoch 793/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7476 - val_loss: 1.0539\n",
      "Epoch 794/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7465 - val_loss: 0.9509\n",
      "Epoch 795/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7480 - val_loss: 0.9725\n",
      "Epoch 796/1500\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7456 - val_loss: 1.0154\n",
      "Epoch 797/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7468 - val_loss: 0.9778\n",
      "Epoch 798/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7469 - val_loss: 0.9887\n",
      "Epoch 799/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7447 - val_loss: 0.9950\n",
      "Epoch 800/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7442 - val_loss: 0.9829\n",
      "Epoch 801/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7437 - val_loss: 1.0107\n",
      "Epoch 802/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7446 - val_loss: 0.9669\n",
      "Epoch 803/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7450 - val_loss: 0.9927\n",
      "Epoch 804/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7435 - val_loss: 0.9838\n",
      "Epoch 805/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7433 - val_loss: 0.9864\n",
      "Epoch 806/1500\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.7433 - val_loss: 0.9908\n",
      "Epoch 807/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7430 - val_loss: 0.9887\n",
      "Epoch 808/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7431 - val_loss: 0.9755\n",
      "Epoch 809/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7428 - val_loss: 0.9739\n",
      "Epoch 810/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7427 - val_loss: 0.9962\n",
      "Epoch 811/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7430 - val_loss: 0.9872\n",
      "Epoch 812/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7428 - val_loss: 0.9690\n",
      "Epoch 813/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7429 - val_loss: 0.9902\n",
      "Epoch 814/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7425 - val_loss: 0.9847\n",
      "Epoch 815/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7429 - val_loss: 0.9936\n",
      "Epoch 816/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7425 - val_loss: 0.9778\n",
      "Epoch 817/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7425 - val_loss: 0.9790\n",
      "Epoch 818/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7424 - val_loss: 0.9853\n",
      "Epoch 819/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7425 - val_loss: 0.9921\n",
      "Epoch 820/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7424 - val_loss: 0.9732\n",
      "Epoch 821/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7422 - val_loss: 0.9905\n",
      "Epoch 822/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7422 - val_loss: 0.9780\n",
      "Epoch 823/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7424 - val_loss: 0.9884\n",
      "Epoch 824/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7422 - val_loss: 0.9744\n",
      "Epoch 825/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7425 - val_loss: 0.9935\n",
      "Epoch 826/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7420 - val_loss: 0.9763\n",
      "Epoch 827/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7422 - val_loss: 0.9815\n",
      "Epoch 828/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7420 - val_loss: 0.9857\n",
      "Epoch 829/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7420 - val_loss: 0.9841\n",
      "Epoch 830/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7421 - val_loss: 0.9842\n",
      "Epoch 831/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7421 - val_loss: 0.9817\n",
      "Epoch 832/1500\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.7423 - val_loss: 0.9939\n",
      "Epoch 833/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7420 - val_loss: 0.9753\n",
      "Epoch 834/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7421 - val_loss: 1.0042\n",
      "Epoch 835/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7434 - val_loss: 0.9652\n",
      "Epoch 836/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7438 - val_loss: 0.9895\n",
      "Epoch 837/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7438 - val_loss: 0.9951\n",
      "Epoch 838/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7442 - val_loss: 0.9760\n",
      "Epoch 839/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7436 - val_loss: 0.9972\n",
      "Epoch 840/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7432 - val_loss: 0.9715\n",
      "Epoch 841/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7422 - val_loss: 1.0193\n",
      "Epoch 842/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7427 - val_loss: 0.9722\n",
      "Epoch 843/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7436 - val_loss: 0.9671\n",
      "Epoch 844/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7428 - val_loss: 1.0066\n",
      "Epoch 845/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7432 - val_loss: 0.9892\n",
      "Epoch 846/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7426 - val_loss: 1.0014\n",
      "Epoch 847/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7436 - val_loss: 0.9775\n",
      "Epoch 848/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7434 - val_loss: 0.9860\n",
      "Epoch 849/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7436 - val_loss: 1.0041\n",
      "Epoch 850/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7431 - val_loss: 0.9690\n",
      "Epoch 851/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7436 - val_loss: 1.0022\n",
      "Epoch 852/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7440 - val_loss: 0.9857\n",
      "Epoch 853/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7441 - val_loss: 0.9851\n",
      "Epoch 854/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7456 - val_loss: 1.0136\n",
      "Epoch 855/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7481 - val_loss: 0.9725\n",
      "Epoch 856/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7508 - val_loss: 1.0072\n",
      "Epoch 857/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7543 - val_loss: 1.0482\n",
      "Epoch 858/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7550 - val_loss: 0.9498\n",
      "Epoch 859/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7528 - val_loss: 1.0808\n",
      "Epoch 860/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7534 - val_loss: 0.9506\n",
      "Epoch 861/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7580 - val_loss: 0.9287\n",
      "Epoch 862/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7631 - val_loss: 1.0588\n",
      "Epoch 863/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7540 - val_loss: 0.9923\n",
      "Epoch 864/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7509 - val_loss: 1.0000\n",
      "Epoch 865/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7494 - val_loss: 1.0590\n",
      "Epoch 866/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7492 - val_loss: 0.9881\n",
      "Epoch 867/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7475 - val_loss: 0.9656\n",
      "Epoch 868/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7459 - val_loss: 1.0455\n",
      "Epoch 869/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7447 - val_loss: 1.0209\n",
      "Epoch 870/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7448 - val_loss: 0.9917\n",
      "Epoch 871/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7436 - val_loss: 1.0042\n",
      "Epoch 872/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7445 - val_loss: 0.9895\n",
      "Epoch 873/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7435 - val_loss: 0.9778\n",
      "Epoch 874/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7433 - val_loss: 1.0278\n",
      "Epoch 875/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7435 - val_loss: 0.9977\n",
      "Epoch 876/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7437 - val_loss: 0.9994\n",
      "Epoch 877/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7430 - val_loss: 0.9987\n",
      "Epoch 878/1500\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.7434 - val_loss: 0.9823\n",
      "Epoch 879/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7425 - val_loss: 1.0339\n",
      "Epoch 880/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7437 - val_loss: 0.9845\n",
      "Epoch 881/1500\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.7465 - val_loss: 1.0318\n",
      "Epoch 882/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7561 - val_loss: 0.9344\n",
      "Epoch 883/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7648 - val_loss: 1.0920\n",
      "Epoch 884/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7478 - val_loss: 0.9402\n",
      "Epoch 885/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7588 - val_loss: 0.9162\n",
      "Epoch 886/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7491 - val_loss: 1.0352\n",
      "Epoch 887/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7510 - val_loss: 1.0034\n",
      "Epoch 888/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7445 - val_loss: 0.9898\n",
      "Epoch 889/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7441 - val_loss: 1.0140\n",
      "Epoch 890/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7442 - val_loss: 1.0021\n",
      "Epoch 891/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7442 - val_loss: 1.0075\n",
      "Epoch 892/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7428 - val_loss: 1.0073\n",
      "Epoch 893/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7436 - val_loss: 1.0142\n",
      "Epoch 894/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7434 - val_loss: 0.9951\n",
      "Epoch 895/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7435 - val_loss: 0.9936\n",
      "Epoch 896/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7423 - val_loss: 1.0188\n",
      "Epoch 897/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7425 - val_loss: 0.9997\n",
      "Epoch 898/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7422 - val_loss: 1.0052\n",
      "Epoch 899/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7422 - val_loss: 1.0047\n",
      "Epoch 900/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7420 - val_loss: 1.0060\n",
      "Epoch 901/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7421 - val_loss: 1.0012\n",
      "Epoch 902/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7420 - val_loss: 1.0012\n",
      "Epoch 903/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7419 - val_loss: 1.0008\n",
      "Epoch 904/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7418 - val_loss: 1.0015\n",
      "Epoch 905/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7418 - val_loss: 1.0082\n",
      "Epoch 906/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7418 - val_loss: 0.9955\n",
      "Epoch 907/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7420 - val_loss: 1.0095\n",
      "Epoch 908/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7422 - val_loss: 1.0036\n",
      "Epoch 909/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7422 - val_loss: 0.9891\n",
      "Epoch 910/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7420 - val_loss: 1.0304\n",
      "Epoch 911/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7423 - val_loss: 0.9739\n",
      "Epoch 912/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7433 - val_loss: 1.0449\n",
      "Epoch 913/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7453 - val_loss: 0.9733\n",
      "Epoch 914/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7440 - val_loss: 0.9883\n",
      "Epoch 915/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7439 - val_loss: 1.0495\n",
      "Epoch 916/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7426 - val_loss: 0.9950\n",
      "Epoch 917/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7429 - val_loss: 1.0093\n",
      "Epoch 918/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7427 - val_loss: 1.0141\n",
      "Epoch 919/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7421 - val_loss: 0.9924\n",
      "Epoch 920/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7427 - val_loss: 1.0228\n",
      "Epoch 921/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7424 - val_loss: 0.9973\n",
      "Epoch 922/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7427 - val_loss: 0.9969\n",
      "Epoch 923/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7420 - val_loss: 1.0291\n",
      "Epoch 924/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7418 - val_loss: 0.9946\n",
      "Epoch 925/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7420 - val_loss: 1.0176\n",
      "Epoch 926/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7419 - val_loss: 1.0092\n",
      "Epoch 927/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 0.9977\n",
      "Epoch 928/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7417 - val_loss: 1.0148\n",
      "Epoch 929/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7418 - val_loss: 1.0053\n",
      "Epoch 930/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7417 - val_loss: 1.0011\n",
      "Epoch 931/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7416 - val_loss: 1.0207\n",
      "Epoch 932/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7417 - val_loss: 1.0043\n",
      "Epoch 933/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 0.9999\n",
      "Epoch 934/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0224\n",
      "Epoch 935/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7418 - val_loss: 0.9975\n",
      "Epoch 936/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7417 - val_loss: 1.0040\n",
      "Epoch 937/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0199\n",
      "Epoch 938/1500\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.7416 - val_loss: 1.0075\n",
      "Epoch 939/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 0.9953\n",
      "Epoch 940/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0198\n",
      "Epoch 941/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7418 - val_loss: 1.0088\n",
      "Epoch 942/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 0.9915\n",
      "Epoch 943/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0165\n",
      "Epoch 944/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7418 - val_loss: 1.0113\n",
      "Epoch 945/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7417 - val_loss: 0.9987\n",
      "Epoch 946/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0160\n",
      "Epoch 947/1500\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7416 - val_loss: 1.0060\n",
      "Epoch 948/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0060\n",
      "Epoch 949/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0094\n",
      "Epoch 950/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0080\n",
      "Epoch 951/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0071\n",
      "Epoch 952/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0072\n",
      "Epoch 953/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 954/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7415 - val_loss: 1.0072\n",
      "Epoch 955/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0088\n",
      "Epoch 956/1500\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.7415 - val_loss: 1.0064\n",
      "Epoch 957/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0053\n",
      "Epoch 958/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0078\n",
      "Epoch 959/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7415 - val_loss: 1.0062\n",
      "Epoch 960/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0071\n",
      "Epoch 961/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0075\n",
      "Epoch 962/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0087\n",
      "Epoch 963/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 964/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 965/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7415 - val_loss: 1.0072\n",
      "Epoch 966/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0062\n",
      "Epoch 967/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 968/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0072\n",
      "Epoch 969/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0051\n",
      "Epoch 970/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0079\n",
      "Epoch 971/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0061\n",
      "Epoch 972/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0054\n",
      "Epoch 973/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0080\n",
      "Epoch 974/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0058\n",
      "Epoch 975/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0058\n",
      "Epoch 976/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 977/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0073\n",
      "Epoch 978/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0061\n",
      "Epoch 979/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 980/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0071\n",
      "Epoch 981/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0061\n",
      "Epoch 982/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 983/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 984/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0080\n",
      "Epoch 985/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 986/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 987/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0070\n",
      "Epoch 988/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7415 - val_loss: 1.0052\n",
      "Epoch 989/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0082\n",
      "Epoch 990/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 991/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0048\n",
      "Epoch 992/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0078\n",
      "Epoch 993/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0058\n",
      "Epoch 994/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0056\n",
      "Epoch 995/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0067\n",
      "Epoch 996/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0055\n",
      "Epoch 997/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7415 - val_loss: 1.0072\n",
      "Epoch 998/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 999/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7415 - val_loss: 1.0052\n",
      "Epoch 1000/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0071\n",
      "Epoch 1001/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1002/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1003/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0065\n",
      "Epoch 1004/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0061\n",
      "Epoch 1005/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7415 - val_loss: 1.0067\n",
      "Epoch 1006/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7415 - val_loss: 1.0058\n",
      "Epoch 1007/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0057\n",
      "Epoch 1008/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7415 - val_loss: 1.0071\n",
      "Epoch 1009/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7415 - val_loss: 1.0054\n",
      "Epoch 1010/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 1011/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 1012/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0072\n",
      "Epoch 1013/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7415 - val_loss: 1.0046\n",
      "Epoch 1014/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0055\n",
      "Epoch 1015/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0076\n",
      "Epoch 1016/1500\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7415 - val_loss: 1.0052\n",
      "Epoch 1017/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1018/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0062\n",
      "Epoch 1019/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1020/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0065\n",
      "Epoch 1021/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 1022/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0061\n",
      "Epoch 1023/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0069\n",
      "Epoch 1024/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0052\n",
      "Epoch 1025/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0064\n",
      "Epoch 1026/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0070\n",
      "Epoch 1027/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7415 - val_loss: 1.0054\n",
      "Epoch 1028/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 1029/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0071\n",
      "Epoch 1030/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0055\n",
      "Epoch 1031/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1032/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 1033/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0064\n",
      "Epoch 1034/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0064\n",
      "Epoch 1035/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0055\n",
      "Epoch 1036/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0070\n",
      "Epoch 1037/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7415 - val_loss: 1.0057\n",
      "Epoch 1038/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0055\n",
      "Epoch 1039/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0074\n",
      "Epoch 1040/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0051\n",
      "Epoch 1041/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0072\n",
      "Epoch 1042/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 1043/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1044/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7415 - val_loss: 1.0067\n",
      "Epoch 1045/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0057\n",
      "Epoch 1046/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0067\n",
      "Epoch 1047/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 1048/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7415 - val_loss: 1.0054\n",
      "Epoch 1049/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0065\n",
      "Epoch 1050/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0068\n",
      "Epoch 1051/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0055\n",
      "Epoch 1052/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0070\n",
      "Epoch 1053/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 1054/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0065\n",
      "Epoch 1055/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0062\n",
      "Epoch 1056/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0065\n",
      "Epoch 1057/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0061\n",
      "Epoch 1058/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 1059/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 1060/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 1061/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0064\n",
      "Epoch 1062/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 1063/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0062\n",
      "Epoch 1064/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0062\n",
      "Epoch 1065/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1066/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1067/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 1068/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7415 - val_loss: 1.0064\n",
      "Epoch 1069/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7415 - val_loss: 1.0053\n",
      "Epoch 1070/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 1071/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0072\n",
      "Epoch 1072/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0051\n",
      "Epoch 1073/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0067\n",
      "Epoch 1074/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7415 - val_loss: 1.0058\n",
      "Epoch 1075/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0069\n",
      "Epoch 1076/1500\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.7415 - val_loss: 1.0050\n",
      "Epoch 1077/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 1078/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0075\n",
      "Epoch 1079/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7415 - val_loss: 1.0054\n",
      "Epoch 1080/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0067\n",
      "Epoch 1081/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0067\n",
      "Epoch 1082/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 1083/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 1084/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0058\n",
      "Epoch 1085/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0070\n",
      "Epoch 1086/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0054\n",
      "Epoch 1087/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0064\n",
      "Epoch 1088/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0065\n",
      "Epoch 1089/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7415 - val_loss: 1.0056\n",
      "Epoch 1090/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0061\n",
      "Epoch 1091/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0059\n",
      "Epoch 1092/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0071\n",
      "Epoch 1093/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 1094/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1095/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0071\n",
      "Epoch 1096/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0052\n",
      "Epoch 1097/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 1098/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7415 - val_loss: 1.0063\n",
      "Epoch 1099/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7415 - val_loss: 1.0045\n",
      "Epoch 1100/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0080\n",
      "Epoch 1101/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0037\n",
      "Epoch 1102/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0094\n",
      "Epoch 1103/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7415 - val_loss: 1.0032\n",
      "Epoch 1104/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0074\n",
      "Epoch 1105/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0079\n",
      "Epoch 1106/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7415 - val_loss: 1.0062\n",
      "Epoch 1107/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0078\n",
      "Epoch 1108/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7415 - val_loss: 1.0015\n",
      "Epoch 1109/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0165\n",
      "Epoch 1110/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 0.9977\n",
      "Epoch 1111/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 1.0154\n",
      "Epoch 1112/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7419 - val_loss: 1.0093\n",
      "Epoch 1113/1500\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7418 - val_loss: 1.0028\n",
      "Epoch 1114/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 1.0166\n",
      "Epoch 1115/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0080\n",
      "Epoch 1116/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0121\n",
      "Epoch 1117/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7416 - val_loss: 1.0087\n",
      "Epoch 1118/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7416 - val_loss: 1.0028\n",
      "Epoch 1119/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7416 - val_loss: 1.0118\n",
      "Epoch 1120/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7416 - val_loss: 1.0068\n",
      "Epoch 1121/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7416 - val_loss: 1.0070\n",
      "Epoch 1122/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7416 - val_loss: 1.0092\n",
      "Epoch 1123/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7416 - val_loss: 1.0073\n",
      "Epoch 1124/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0064\n",
      "Epoch 1125/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0071\n",
      "Epoch 1126/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0092\n",
      "Epoch 1127/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 1.0075\n",
      "Epoch 1128/1500\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.7417 - val_loss: 1.0133\n",
      "Epoch 1129/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7417 - val_loss: 1.0072\n",
      "Epoch 1130/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7418 - val_loss: 1.0055\n",
      "Epoch 1131/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7419 - val_loss: 1.0106\n",
      "Epoch 1132/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7419 - val_loss: 1.0098\n",
      "Epoch 1133/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7418 - val_loss: 1.0014\n",
      "Epoch 1134/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7419 - val_loss: 1.0053\n",
      "Epoch 1135/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7419 - val_loss: 1.0058\n",
      "Epoch 1136/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7418 - val_loss: 1.0140\n",
      "Epoch 1137/1500\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7419 - val_loss: 1.0122\n",
      "Epoch 1138/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7418 - val_loss: 1.0065\n",
      "Epoch 1139/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7417 - val_loss: 1.0040\n",
      "Epoch 1140/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 1.0062\n",
      "Epoch 1141/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0158\n",
      "Epoch 1142/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7417 - val_loss: 1.0091\n",
      "Epoch 1143/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 1.0073\n",
      "Epoch 1144/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7419 - val_loss: 1.0087\n",
      "Epoch 1145/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7420 - val_loss: 1.0133\n",
      "Epoch 1146/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7421 - val_loss: 0.9962\n",
      "Epoch 1147/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7422 - val_loss: 1.0094\n",
      "Epoch 1148/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7419 - val_loss: 1.0116\n",
      "Epoch 1149/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7421 - val_loss: 1.0066\n",
      "Epoch 1150/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7423 - val_loss: 1.0110\n",
      "Epoch 1151/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7423 - val_loss: 0.9998\n",
      "Epoch 1152/1500\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.7425 - val_loss: 1.0120\n",
      "Epoch 1153/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7422 - val_loss: 1.0128\n",
      "Epoch 1154/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7422 - val_loss: 0.9975\n",
      "Epoch 1155/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7421 - val_loss: 1.0110\n",
      "Epoch 1156/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7420 - val_loss: 0.9997\n",
      "Epoch 1157/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7420 - val_loss: 1.0156\n",
      "Epoch 1158/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7420 - val_loss: 1.0013\n",
      "Epoch 1159/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7420 - val_loss: 1.0095\n",
      "Epoch 1160/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7419 - val_loss: 1.0116\n",
      "Epoch 1161/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7420 - val_loss: 1.0051\n",
      "Epoch 1162/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7419 - val_loss: 1.0055\n",
      "Epoch 1163/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7419 - val_loss: 1.0061\n",
      "Epoch 1164/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7418 - val_loss: 1.0043\n",
      "Epoch 1165/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7419 - val_loss: 1.0061\n",
      "Epoch 1166/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7420 - val_loss: 1.0026\n",
      "Epoch 1167/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7420 - val_loss: 1.0099\n",
      "Epoch 1168/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7418 - val_loss: 1.0069\n",
      "Epoch 1169/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7418 - val_loss: 1.0028\n",
      "Epoch 1170/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7417 - val_loss: 1.0067\n",
      "Epoch 1171/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7416 - val_loss: 1.0057\n",
      "Epoch 1172/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7416 - val_loss: 1.0077\n",
      "Epoch 1173/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0055\n",
      "Epoch 1174/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7416 - val_loss: 1.0050\n",
      "Epoch 1175/1500\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.7416 - val_loss: 1.0066\n",
      "Epoch 1176/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0027\n",
      "Epoch 1177/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0062\n",
      "Epoch 1178/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7416 - val_loss: 1.0047\n",
      "Epoch 1179/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7417 - val_loss: 1.0045\n",
      "Epoch 1180/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0083\n",
      "Epoch 1181/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0044\n",
      "Epoch 1182/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7416 - val_loss: 1.0056\n",
      "Epoch 1183/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7416 - val_loss: 1.0075\n",
      "Epoch 1184/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7416 - val_loss: 1.0040\n",
      "Epoch 1185/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7416 - val_loss: 1.0085\n",
      "Epoch 1186/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7416 - val_loss: 1.0062\n",
      "Epoch 1187/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0069\n",
      "Epoch 1188/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0073\n",
      "Epoch 1189/1500\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7416 - val_loss: 1.0073\n",
      "Epoch 1190/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0065\n",
      "Epoch 1191/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0037\n",
      "Epoch 1192/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7416 - val_loss: 1.0078\n",
      "Epoch 1193/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7416 - val_loss: 1.0052\n",
      "Epoch 1194/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0045\n",
      "Epoch 1195/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0074\n",
      "Epoch 1196/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7416 - val_loss: 1.0048\n",
      "Epoch 1197/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0058\n",
      "Epoch 1198/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0078\n",
      "Epoch 1199/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7416 - val_loss: 1.0027\n",
      "Epoch 1200/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0074\n",
      "Epoch 1201/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0044\n",
      "Epoch 1202/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0071\n",
      "Epoch 1203/1500\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7415 - val_loss: 1.0076\n",
      "Epoch 1204/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0034\n",
      "Epoch 1205/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7416 - val_loss: 1.0082\n",
      "Epoch 1206/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0041\n",
      "Epoch 1207/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0044\n",
      "Epoch 1208/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0090\n",
      "Epoch 1209/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0038\n",
      "Epoch 1210/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0078\n",
      "Epoch 1211/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0060\n",
      "Epoch 1212/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0049\n",
      "Epoch 1213/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7415 - val_loss: 1.0078\n",
      "Epoch 1214/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0065\n",
      "Epoch 1215/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0030\n",
      "Epoch 1216/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1217/1500\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7415 - val_loss: 1.0074\n",
      "Epoch 1218/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0043\n",
      "Epoch 1219/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0098\n",
      "Epoch 1220/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0005\n",
      "Epoch 1221/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7416 - val_loss: 1.0147\n",
      "Epoch 1222/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7417 - val_loss: 0.9953\n",
      "Epoch 1223/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7419 - val_loss: 1.0358\n",
      "Epoch 1224/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7425 - val_loss: 0.9700\n",
      "Epoch 1225/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7443 - val_loss: 1.0865\n",
      "Epoch 1226/1500\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.7542 - val_loss: 0.9294\n",
      "Epoch 1227/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7498 - val_loss: 1.1088\n",
      "Epoch 1228/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7512 - val_loss: 0.9577\n",
      "Epoch 1229/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7499 - val_loss: 1.0127\n",
      "Epoch 1230/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7575 - val_loss: 0.9249\n",
      "Epoch 1231/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7781 - val_loss: 0.8901\n",
      "Epoch 1232/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7633 - val_loss: 0.9950\n",
      "Epoch 1233/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7672 - val_loss: 0.9080\n",
      "Epoch 1234/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7537 - val_loss: 0.9851\n",
      "Epoch 1235/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7545 - val_loss: 0.9210\n",
      "Epoch 1236/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7612 - val_loss: 1.1030\n",
      "Epoch 1237/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7601 - val_loss: 0.8912\n",
      "Epoch 1238/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7702 - val_loss: 0.9551\n",
      "Epoch 1239/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7600 - val_loss: 0.9737\n",
      "Epoch 1240/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7547 - val_loss: 0.9207\n",
      "Epoch 1241/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7558 - val_loss: 0.9646\n",
      "Epoch 1242/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7505 - val_loss: 0.9926\n",
      "Epoch 1243/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7581 - val_loss: 0.9547\n",
      "Epoch 1244/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7522 - val_loss: 1.0130\n",
      "Epoch 1245/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7529 - val_loss: 0.9026\n",
      "Epoch 1246/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7589 - val_loss: 1.0208\n",
      "Epoch 1247/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7696 - val_loss: 0.9435\n",
      "Epoch 1248/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7710 - val_loss: 0.9067\n",
      "Epoch 1249/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7561 - val_loss: 1.0196\n",
      "Epoch 1250/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7563 - val_loss: 0.9381\n",
      "Epoch 1251/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7520 - val_loss: 1.0058\n",
      "Epoch 1252/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7492 - val_loss: 0.9845\n",
      "Epoch 1253/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7468 - val_loss: 1.0048\n",
      "Epoch 1254/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7490 - val_loss: 0.9665\n",
      "Epoch 1255/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7510 - val_loss: 0.9737\n",
      "Epoch 1256/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7513 - val_loss: 1.0103\n",
      "Epoch 1257/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7498 - val_loss: 0.9337\n",
      "Epoch 1258/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7502 - val_loss: 1.0518\n",
      "Epoch 1259/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7569 - val_loss: 0.9760\n",
      "Epoch 1260/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7487 - val_loss: 0.9394\n",
      "Epoch 1261/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7484 - val_loss: 1.0146\n",
      "Epoch 1262/1500\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.7473 - val_loss: 0.9983\n",
      "Epoch 1263/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7470 - val_loss: 1.0088\n",
      "Epoch 1264/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7456 - val_loss: 0.9449\n",
      "Epoch 1265/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7474 - val_loss: 0.9961\n",
      "Epoch 1266/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7463 - val_loss: 0.9892\n",
      "Epoch 1267/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7437 - val_loss: 0.9912\n",
      "Epoch 1268/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7444 - val_loss: 0.9830\n",
      "Epoch 1269/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7435 - val_loss: 1.0103\n",
      "Epoch 1270/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7451 - val_loss: 0.9630\n",
      "Epoch 1271/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7454 - val_loss: 1.0057\n",
      "Epoch 1272/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7490 - val_loss: 0.9627\n",
      "Epoch 1273/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7507 - val_loss: 0.9749\n",
      "Epoch 1274/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7456 - val_loss: 1.0224\n",
      "Epoch 1275/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7472 - val_loss: 0.9609\n",
      "Epoch 1276/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7451 - val_loss: 1.0196\n",
      "Epoch 1277/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7449 - val_loss: 0.9846\n",
      "Epoch 1278/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7436 - val_loss: 1.0025\n",
      "Epoch 1279/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7438 - val_loss: 0.9826\n",
      "Epoch 1280/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7433 - val_loss: 1.0142\n",
      "Epoch 1281/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7441 - val_loss: 0.9651\n",
      "Epoch 1282/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7457 - val_loss: 1.0229\n",
      "Epoch 1283/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7501 - val_loss: 0.9765\n",
      "Epoch 1284/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7537 - val_loss: 0.9745\n",
      "Epoch 1285/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7449 - val_loss: 1.0392\n",
      "Epoch 1286/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7485 - val_loss: 0.9493\n",
      "Epoch 1287/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7506 - val_loss: 1.0137\n",
      "Epoch 1288/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7472 - val_loss: 1.0580\n",
      "Epoch 1289/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7470 - val_loss: 0.9705\n",
      "Epoch 1290/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7541 - val_loss: 0.9552\n",
      "Epoch 1291/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7499 - val_loss: 1.1666\n",
      "Epoch 1292/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7611 - val_loss: 0.9119\n",
      "Epoch 1293/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7611 - val_loss: 0.9118\n",
      "Epoch 1294/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7559 - val_loss: 1.0050\n",
      "Epoch 1295/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7507 - val_loss: 0.9833\n",
      "Epoch 1296/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7486 - val_loss: 0.9929\n",
      "Epoch 1297/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7458 - val_loss: 1.0174\n",
      "Epoch 1298/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7449 - val_loss: 0.9393\n",
      "Epoch 1299/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7488 - val_loss: 1.0122\n",
      "Epoch 1300/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7530 - val_loss: 1.0055\n",
      "Epoch 1301/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7471 - val_loss: 0.9489\n",
      "Epoch 1302/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7464 - val_loss: 1.0266\n",
      "Epoch 1303/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7458 - val_loss: 1.0051\n",
      "Epoch 1304/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7436 - val_loss: 0.9943\n",
      "Epoch 1305/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7438 - val_loss: 1.0163\n",
      "Epoch 1306/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7447 - val_loss: 0.9855\n",
      "Epoch 1307/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7425 - val_loss: 1.0102\n",
      "Epoch 1308/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7432 - val_loss: 0.9783\n",
      "Epoch 1309/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7431 - val_loss: 1.0048\n",
      "Epoch 1310/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7425 - val_loss: 0.9931\n",
      "Epoch 1311/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7424 - val_loss: 1.0061\n",
      "Epoch 1312/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7428 - val_loss: 1.0092\n",
      "Epoch 1313/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7422 - val_loss: 0.9978\n",
      "Epoch 1314/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7418 - val_loss: 1.0113\n",
      "Epoch 1315/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7420 - val_loss: 1.0007\n",
      "Epoch 1316/1500\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.7418 - val_loss: 0.9993\n",
      "Epoch 1317/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7418 - val_loss: 1.0026\n",
      "Epoch 1318/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7419 - val_loss: 1.0026\n",
      "Epoch 1319/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7418 - val_loss: 1.0029\n",
      "Epoch 1320/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7417 - val_loss: 1.0026\n",
      "Epoch 1321/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7417 - val_loss: 0.9986\n",
      "Epoch 1322/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7417 - val_loss: 1.0078\n",
      "Epoch 1323/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7418 - val_loss: 0.9922\n",
      "Epoch 1324/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7418 - val_loss: 1.0099\n",
      "Epoch 1325/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7421 - val_loss: 0.9964\n",
      "Epoch 1326/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7423 - val_loss: 1.0000\n",
      "Epoch 1327/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7420 - val_loss: 1.0137\n",
      "Epoch 1328/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7418 - val_loss: 0.9981\n",
      "Epoch 1329/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7417 - val_loss: 1.0089\n",
      "Epoch 1330/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7420 - val_loss: 1.0041\n",
      "Epoch 1331/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7420 - val_loss: 1.0052\n",
      "Epoch 1332/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7428 - val_loss: 0.9975\n",
      "Epoch 1333/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7419 - val_loss: 0.9800\n",
      "Epoch 1334/1500\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7423 - val_loss: 1.0224\n",
      "Epoch 1335/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7429 - val_loss: 1.0239\n",
      "Epoch 1336/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7422 - val_loss: 0.9755\n",
      "Epoch 1337/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7426 - val_loss: 1.0111\n",
      "Epoch 1338/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7445 - val_loss: 1.0006\n",
      "Epoch 1339/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7439 - val_loss: 0.9950\n",
      "Epoch 1340/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7431 - val_loss: 1.0283\n",
      "Epoch 1341/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7422 - val_loss: 0.9942\n",
      "Epoch 1342/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7424 - val_loss: 1.0158\n",
      "Epoch 1343/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7431 - val_loss: 1.0171\n",
      "Epoch 1344/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7426 - val_loss: 0.9913\n",
      "Epoch 1345/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7419 - val_loss: 1.0472\n",
      "Epoch 1346/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7434 - val_loss: 0.9805\n",
      "Epoch 1347/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7430 - val_loss: 0.9940\n",
      "Epoch 1348/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7422 - val_loss: 1.0299\n",
      "Epoch 1349/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7422 - val_loss: 1.0047\n",
      "Epoch 1350/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7425 - val_loss: 1.0182\n",
      "Epoch 1351/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7419 - val_loss: 1.0084\n",
      "Epoch 1352/1500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.7422 - val_loss: 0.9978\n",
      "Epoch 1353/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7419 - val_loss: 1.0054\n",
      "Epoch 1354/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 1.0198\n",
      "Epoch 1355/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7418 - val_loss: 1.0061\n",
      "Epoch 1356/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7417 - val_loss: 1.0002\n",
      "Epoch 1357/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0100\n",
      "Epoch 1358/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0056\n",
      "Epoch 1359/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7417 - val_loss: 1.0137\n",
      "Epoch 1360/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7418 - val_loss: 1.0087\n",
      "Epoch 1361/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7417 - val_loss: 0.9954\n",
      "Epoch 1362/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0132\n",
      "Epoch 1363/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7416 - val_loss: 1.0102\n",
      "Epoch 1364/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0079\n",
      "Epoch 1365/1500\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.7416 - val_loss: 1.0114\n",
      "Epoch 1366/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7416 - val_loss: 1.0028\n",
      "Epoch 1367/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7416 - val_loss: 1.0163\n",
      "Epoch 1368/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7416 - val_loss: 1.0133\n",
      "Epoch 1369/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0053\n",
      "Epoch 1370/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0127\n",
      "Epoch 1371/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0074\n",
      "Epoch 1372/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7416 - val_loss: 1.0076\n",
      "Epoch 1373/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7416 - val_loss: 1.0139\n",
      "Epoch 1374/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7416 - val_loss: 1.0031\n",
      "Epoch 1375/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0111\n",
      "Epoch 1376/1500\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7416 - val_loss: 1.0132\n",
      "Epoch 1377/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7417 - val_loss: 1.0021\n",
      "Epoch 1378/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7416 - val_loss: 1.0183\n",
      "Epoch 1379/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7416 - val_loss: 1.0109\n",
      "Epoch 1380/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0046\n",
      "Epoch 1381/1500\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7415 - val_loss: 1.0166\n",
      "Epoch 1382/1500\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.7416 - val_loss: 1.0104\n",
      "Epoch 1383/1500\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7416 - val_loss: 1.0053\n",
      "Epoch 1384/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0144\n",
      "Epoch 1385/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7415 - val_loss: 1.0094\n",
      "Epoch 1386/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7416 - val_loss: 1.0089\n",
      "Epoch 1387/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0143\n",
      "Epoch 1388/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7416 - val_loss: 1.0037\n",
      "Epoch 1389/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7416 - val_loss: 1.0109\n",
      "Epoch 1390/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7415 - val_loss: 1.0144\n",
      "Epoch 1391/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0066\n",
      "Epoch 1392/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1393/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7415 - val_loss: 1.0120\n",
      "Epoch 1394/1500\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.7415 - val_loss: 1.0089\n",
      "Epoch 1395/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7415 - val_loss: 1.0100\n",
      "Epoch 1396/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1397/1500\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1398/1500\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1399/1500\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1400/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7415 - val_loss: 1.0099\n",
      "Epoch 1401/1500\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.7415 - val_loss: 1.0089\n",
      "Epoch 1402/1500\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.7415 - val_loss: 1.0085\n",
      "Epoch 1403/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0097\n",
      "Epoch 1404/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7415 - val_loss: 1.0102\n",
      "Epoch 1405/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1406/1500\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1407/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7415 - val_loss: 1.0088\n",
      "Epoch 1408/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0105\n",
      "Epoch 1409/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1410/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7415 - val_loss: 1.0088\n",
      "Epoch 1411/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0093\n",
      "Epoch 1412/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0094\n",
      "Epoch 1413/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1414/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7415 - val_loss: 1.0094\n",
      "Epoch 1415/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0090\n",
      "Epoch 1416/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0094\n",
      "Epoch 1417/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1418/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7415 - val_loss: 1.0098\n",
      "Epoch 1419/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0089\n",
      "Epoch 1420/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0085\n",
      "Epoch 1421/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0103\n",
      "Epoch 1422/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0089\n",
      "Epoch 1423/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1424/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1425/1500\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.7415 - val_loss: 1.0093\n",
      "Epoch 1426/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1427/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1428/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7415 - val_loss: 1.0088\n",
      "Epoch 1429/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0102\n",
      "Epoch 1430/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7415 - val_loss: 1.0089\n",
      "Epoch 1431/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1432/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1433/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0090\n",
      "Epoch 1434/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7415 - val_loss: 1.0094\n",
      "Epoch 1435/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1436/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7415 - val_loss: 1.0088\n",
      "Epoch 1437/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1438/1500\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1439/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1440/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7415 - val_loss: 1.0090\n",
      "Epoch 1441/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1442/1500\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1443/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1444/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1445/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0093\n",
      "Epoch 1446/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0083\n",
      "Epoch 1447/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0100\n",
      "Epoch 1448/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1449/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0088\n",
      "Epoch 1450/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7415 - val_loss: 1.0099\n",
      "Epoch 1451/1500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7415 - val_loss: 1.0090\n",
      "Epoch 1452/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1453/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1454/1500\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1455/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1456/1500\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1457/1500\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1458/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1459/1500\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1460/1500\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7415 - val_loss: 1.0093\n",
      "Epoch 1461/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7415 - val_loss: 1.0097\n",
      "Epoch 1462/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0087\n",
      "Epoch 1463/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1464/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0099\n",
      "Epoch 1465/1500\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.7415 - val_loss: 1.0086\n",
      "Epoch 1466/1500\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1467/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1468/1500\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.7415 - val_loss: 1.0089\n",
      "Epoch 1469/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1470/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0090\n",
      "Epoch 1471/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0096\n",
      "Epoch 1472/1500\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7415 - val_loss: 1.0094\n",
      "Epoch 1473/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0084\n",
      "Epoch 1474/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1475/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1476/1500\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.7415 - val_loss: 1.0086\n",
      "Epoch 1477/1500\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7415 - val_loss: 1.0095\n",
      "Epoch 1478/1500\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1479/1500\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1480/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0097\n",
      "Epoch 1481/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0088\n",
      "Epoch 1482/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1483/1500\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.7415 - val_loss: 1.0093\n",
      "Epoch 1484/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0093\n",
      "Epoch 1485/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1486/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1487/1500\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.7415 - val_loss: 1.0094\n",
      "Epoch 1488/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7415 - val_loss: 1.0093\n",
      "Epoch 1489/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1490/1500\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7415 - val_loss: 1.0093\n",
      "Epoch 1491/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1492/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0094\n",
      "Epoch 1493/1500\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1494/1500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7415 - val_loss: 1.0093\n",
      "Epoch 1495/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1496/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0091\n",
      "Epoch 1497/1500\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1498/1500\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1499/1500\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "Epoch 1500/1500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7415 - val_loss: 1.0092\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.8382\n",
      "0.8382275700569153\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.SimpleRNN(units = 1024, activation = \"relu\", return_sequences = True)(input)\n",
    "    x = layers.SimpleRNN(units = 1024, activation = \"relu\", return_sequences = True)(x)\n",
    "    x = layers.SimpleRNN(units = 512, activation = \"relu\", return_sequences = True)(x)\n",
    "\n",
    "    # 中間層最後のreturn_sequencesは、Falseにする\n",
    "    # 出力は一つなので、中間層の最後で次元数を落として出力できるようにしている\n",
    "    x = layers.SimpleRNN(units = 512, activation = \"relu\", return_sequences = False)(x)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "# ミニバッチ学習 \n",
    "batch_size = len(train_x) // 4\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "\n",
    "# モデル構造の出力\n",
    "model.summary()\n",
    "\n",
    "# val_lossが一番低いモデルを保存している\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "# 学習データ、テストデータ、バッチサイズ、エポック、保存ポイントの設定\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = batch_size, epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM(多層)ミニバッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ミニバッチ学習を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 24, 3)]           0         \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 24, 1024)          4210688   \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 24, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 24, 512)           3147776   \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 24, 512)           2099200   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 24, 1)             513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,850,881\n",
      "Trainable params: 17,850,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "5/5 [==============================] - 9s 1s/step - loss: 0.8211 - val_loss: 0.9726\n",
      "Epoch 2/1500\n",
      "5/5 [==============================] - 5s 963ms/step - loss: 0.8085 - val_loss: 0.9569\n",
      "Epoch 3/1500\n",
      "5/5 [==============================] - 5s 959ms/step - loss: 0.7915 - val_loss: 0.9365\n",
      "Epoch 4/1500\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.7786 - val_loss: 0.9356\n",
      "Epoch 5/1500\n",
      "5/5 [==============================] - 4s 929ms/step - loss: 0.7735 - val_loss: 0.9237\n",
      "Epoch 6/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7688 - val_loss: 0.9195\n",
      "Epoch 7/1500\n",
      "5/5 [==============================] - 5s 966ms/step - loss: 0.7634 - val_loss: 0.9127\n",
      "Epoch 8/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7610 - val_loss: 0.9083\n",
      "Epoch 9/1500\n",
      "5/5 [==============================] - 5s 935ms/step - loss: 0.7575 - val_loss: 0.9059\n",
      "Epoch 10/1500\n",
      "5/5 [==============================] - 5s 958ms/step - loss: 0.7544 - val_loss: 0.9050\n",
      "Epoch 11/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7541 - val_loss: 0.9017\n",
      "Epoch 12/1500\n",
      "5/5 [==============================] - 5s 927ms/step - loss: 0.7549 - val_loss: 0.9012\n",
      "Epoch 13/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.7508 - val_loss: 0.9014\n",
      "Epoch 14/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7481 - val_loss: 0.8968\n",
      "Epoch 15/1500\n",
      "5/5 [==============================] - 5s 979ms/step - loss: 0.7465 - val_loss: 0.8957\n",
      "Epoch 16/1500\n",
      "5/5 [==============================] - 5s 984ms/step - loss: 0.7440 - val_loss: 0.8937\n",
      "Epoch 17/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7424 - val_loss: 0.8927\n",
      "Epoch 18/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7405 - val_loss: 0.8921\n",
      "Epoch 19/1500\n",
      "5/5 [==============================] - 5s 958ms/step - loss: 0.7390 - val_loss: 0.8906\n",
      "Epoch 20/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.7380 - val_loss: 0.8959\n",
      "Epoch 21/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.7380 - val_loss: 0.8927\n",
      "Epoch 22/1500\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.7365 - val_loss: 0.8950\n",
      "Epoch 23/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7353 - val_loss: 0.8889\n",
      "Epoch 24/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7329 - val_loss: 0.8874\n",
      "Epoch 25/1500\n",
      "5/5 [==============================] - 4s 850ms/step - loss: 0.7324 - val_loss: 0.8887\n",
      "Epoch 26/1500\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.7308 - val_loss: 0.8868\n",
      "Epoch 27/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7284 - val_loss: 0.8826\n",
      "Epoch 28/1500\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 0.7258 - val_loss: 0.8828\n",
      "Epoch 29/1500\n",
      "5/5 [==============================] - 4s 903ms/step - loss: 0.7249 - val_loss: 0.8820\n",
      "Epoch 30/1500\n",
      "5/5 [==============================] - 5s 947ms/step - loss: 0.7226 - val_loss: 0.8767\n",
      "Epoch 31/1500\n",
      "5/5 [==============================] - 5s 947ms/step - loss: 0.7200 - val_loss: 0.8760\n",
      "Epoch 32/1500\n",
      "5/5 [==============================] - 4s 752ms/step - loss: 0.7155 - val_loss: 0.8814\n",
      "Epoch 33/1500\n",
      "5/5 [==============================] - 4s 920ms/step - loss: 0.7185 - val_loss: 0.8742\n",
      "Epoch 34/1500\n",
      "5/5 [==============================] - 5s 989ms/step - loss: 0.7167 - val_loss: 0.8696\n",
      "Epoch 35/1500\n",
      "5/5 [==============================] - 5s 976ms/step - loss: 0.7064 - val_loss: 0.8649\n",
      "Epoch 36/1500\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.7002 - val_loss: 0.8587\n",
      "Epoch 37/1500\n",
      "5/5 [==============================] - 4s 736ms/step - loss: 0.6925 - val_loss: 0.8657\n",
      "Epoch 38/1500\n",
      "5/5 [==============================] - 4s 759ms/step - loss: 0.6883 - val_loss: 0.8784\n",
      "Epoch 39/1500\n",
      "5/5 [==============================] - 5s 993ms/step - loss: 0.6889 - val_loss: 0.8585\n",
      "Epoch 40/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.6859 - val_loss: 0.8591\n",
      "Epoch 41/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.6922 - val_loss: 0.8673\n",
      "Epoch 42/1500\n",
      "5/5 [==============================] - 5s 964ms/step - loss: 0.6834 - val_loss: 0.8497\n",
      "Epoch 43/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6764 - val_loss: 0.8481\n",
      "Epoch 44/1500\n",
      "5/5 [==============================] - 4s 875ms/step - loss: 0.6724 - val_loss: 0.8473\n",
      "Epoch 45/1500\n",
      "5/5 [==============================] - 4s 735ms/step - loss: 0.6707 - val_loss: 0.8515\n",
      "Epoch 46/1500\n",
      "5/5 [==============================] - 4s 745ms/step - loss: 0.6669 - val_loss: 0.8499\n",
      "Epoch 47/1500\n",
      "5/5 [==============================] - 4s 807ms/step - loss: 0.6694 - val_loss: 0.8511\n",
      "Epoch 48/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6683 - val_loss: 0.8463\n",
      "Epoch 49/1500\n",
      "5/5 [==============================] - 4s 760ms/step - loss: 0.6651 - val_loss: 0.8479\n",
      "Epoch 50/1500\n",
      "5/5 [==============================] - 4s 743ms/step - loss: 0.6632 - val_loss: 0.8481\n",
      "Epoch 51/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6604 - val_loss: 0.8387\n",
      "Epoch 52/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.6588 - val_loss: 0.8454\n",
      "Epoch 53/1500\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.6612 - val_loss: 0.8459\n",
      "Epoch 54/1500\n",
      "5/5 [==============================] - 5s 975ms/step - loss: 0.6571 - val_loss: 0.8341\n",
      "Epoch 55/1500\n",
      "5/5 [==============================] - 4s 913ms/step - loss: 0.6552 - val_loss: 0.8333\n",
      "Epoch 56/1500\n",
      "5/5 [==============================] - 5s 932ms/step - loss: 0.6526 - val_loss: 0.8405\n",
      "Epoch 57/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.6511 - val_loss: 0.8362\n",
      "Epoch 58/1500\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.6507 - val_loss: 0.8298\n",
      "Epoch 59/1500\n",
      "5/5 [==============================] - 4s 763ms/step - loss: 0.6469 - val_loss: 0.8316\n",
      "Epoch 60/1500\n",
      "5/5 [==============================] - 5s 949ms/step - loss: 0.6450 - val_loss: 0.8275\n",
      "Epoch 61/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.6415 - val_loss: 0.8344\n",
      "Epoch 62/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6494 - val_loss: 0.8269\n",
      "Epoch 63/1500\n",
      "5/5 [==============================] - 4s 876ms/step - loss: 0.6492 - val_loss: 0.8208\n",
      "Epoch 64/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6390 - val_loss: 0.8173\n",
      "Epoch 65/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6371 - val_loss: 0.8169\n",
      "Epoch 66/1500\n",
      "5/5 [==============================] - 4s 922ms/step - loss: 0.6381 - val_loss: 0.8126\n",
      "Epoch 67/1500\n",
      "5/5 [==============================] - 4s 715ms/step - loss: 0.6352 - val_loss: 0.8155\n",
      "Epoch 68/1500\n",
      "5/5 [==============================] - 4s 757ms/step - loss: 0.6362 - val_loss: 0.8182\n",
      "Epoch 69/1500\n",
      "5/5 [==============================] - 4s 892ms/step - loss: 0.6344 - val_loss: 0.8144\n",
      "Epoch 70/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6325 - val_loss: 0.8080\n",
      "Epoch 71/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6284 - val_loss: 0.8046\n",
      "Epoch 72/1500\n",
      "5/5 [==============================] - 4s 886ms/step - loss: 0.6345 - val_loss: 0.8038\n",
      "Epoch 73/1500\n",
      "5/5 [==============================] - 4s 722ms/step - loss: 0.6248 - val_loss: 0.8048\n",
      "Epoch 74/1500\n",
      "5/5 [==============================] - 4s 736ms/step - loss: 0.6212 - val_loss: 0.8090\n",
      "Epoch 75/1500\n",
      "5/5 [==============================] - 5s 955ms/step - loss: 0.6294 - val_loss: 0.7991\n",
      "Epoch 76/1500\n",
      "5/5 [==============================] - 5s 976ms/step - loss: 0.6199 - val_loss: 0.7889\n",
      "Epoch 77/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6160 - val_loss: 0.7862\n",
      "Epoch 78/1500\n",
      "5/5 [==============================] - 4s 690ms/step - loss: 0.6128 - val_loss: 0.8294\n",
      "Epoch 79/1500\n",
      "5/5 [==============================] - 4s 747ms/step - loss: 0.6437 - val_loss: 0.7975\n",
      "Epoch 80/1500\n",
      "5/5 [==============================] - 4s 899ms/step - loss: 0.6245 - val_loss: 0.7831\n",
      "Epoch 81/1500\n",
      "5/5 [==============================] - 4s 879ms/step - loss: 0.6182 - val_loss: 0.7723\n",
      "Epoch 82/1500\n",
      "5/5 [==============================] - 4s 750ms/step - loss: 0.6050 - val_loss: 0.7906\n",
      "Epoch 83/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.6137 - val_loss: 0.7669\n",
      "Epoch 84/1500\n",
      "5/5 [==============================] - 4s 884ms/step - loss: 0.6142 - val_loss: 0.7539\n",
      "Epoch 85/1500\n",
      "5/5 [==============================] - 4s 898ms/step - loss: 0.5948 - val_loss: 0.7349\n",
      "Epoch 86/1500\n",
      "5/5 [==============================] - 4s 732ms/step - loss: 0.5821 - val_loss: 0.7545\n",
      "Epoch 87/1500\n",
      "5/5 [==============================] - 4s 849ms/step - loss: 0.5725 - val_loss: 0.7086\n",
      "Epoch 88/1500\n",
      "5/5 [==============================] - 4s 864ms/step - loss: 0.5709 - val_loss: 0.6916\n",
      "Epoch 89/1500\n",
      "5/5 [==============================] - 4s 741ms/step - loss: 0.5629 - val_loss: 0.7140\n",
      "Epoch 90/1500\n",
      "5/5 [==============================] - 4s 765ms/step - loss: 0.5723 - val_loss: 0.7035\n",
      "Epoch 91/1500\n",
      "5/5 [==============================] - 4s 773ms/step - loss: 0.5919 - val_loss: 0.7396\n",
      "Epoch 92/1500\n",
      "5/5 [==============================] - 4s 769ms/step - loss: 0.6152 - val_loss: 0.7445\n",
      "Epoch 93/1500\n",
      "5/5 [==============================] - 5s 937ms/step - loss: 0.5889 - val_loss: 0.6867\n",
      "Epoch 94/1500\n",
      "5/5 [==============================] - 4s 761ms/step - loss: 0.5812 - val_loss: 0.7367\n",
      "Epoch 95/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.5876 - val_loss: 0.6642\n",
      "Epoch 96/1500\n",
      "5/5 [==============================] - 4s 751ms/step - loss: 0.5580 - val_loss: 0.6849\n",
      "Epoch 97/1500\n",
      "5/5 [==============================] - 4s 880ms/step - loss: 0.5520 - val_loss: 0.6221\n",
      "Epoch 98/1500\n",
      "5/5 [==============================] - 4s 895ms/step - loss: 0.5243 - val_loss: 0.6055\n",
      "Epoch 99/1500\n",
      "5/5 [==============================] - 4s 853ms/step - loss: 0.5156 - val_loss: 0.6007\n",
      "Epoch 100/1500\n",
      "5/5 [==============================] - 4s 872ms/step - loss: 0.5060 - val_loss: 0.6001\n",
      "Epoch 101/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.5004 - val_loss: 0.5753\n",
      "Epoch 102/1500\n",
      "5/5 [==============================] - 4s 740ms/step - loss: 0.4937 - val_loss: 0.7117\n",
      "Epoch 103/1500\n",
      "5/5 [==============================] - 4s 761ms/step - loss: 0.5384 - val_loss: 0.5884\n",
      "Epoch 104/1500\n",
      "5/5 [==============================] - 4s 772ms/step - loss: 0.5054 - val_loss: 0.5817\n",
      "Epoch 105/1500\n",
      "5/5 [==============================] - 5s 954ms/step - loss: 0.5103 - val_loss: 0.5720\n",
      "Epoch 106/1500\n",
      "5/5 [==============================] - 4s 748ms/step - loss: 0.4914 - val_loss: 0.5797\n",
      "Epoch 107/1500\n",
      "5/5 [==============================] - 4s 883ms/step - loss: 0.4969 - val_loss: 0.5501\n",
      "Epoch 108/1500\n",
      "5/5 [==============================] - 4s 749ms/step - loss: 0.4899 - val_loss: 0.5720\n",
      "Epoch 109/1500\n",
      "5/5 [==============================] - 4s 869ms/step - loss: 0.4865 - val_loss: 0.5311\n",
      "Epoch 110/1500\n",
      "5/5 [==============================] - 4s 887ms/step - loss: 0.4843 - val_loss: 0.5309\n",
      "Epoch 111/1500\n",
      "5/5 [==============================] - 4s 738ms/step - loss: 0.4961 - val_loss: 0.5642\n",
      "Epoch 112/1500\n",
      "5/5 [==============================] - 4s 750ms/step - loss: 0.5001 - val_loss: 0.5515\n",
      "Epoch 113/1500\n",
      "5/5 [==============================] - 4s 757ms/step - loss: 0.4992 - val_loss: 0.5538\n",
      "Epoch 114/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.5323 - val_loss: 0.5861\n",
      "Epoch 115/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.5011 - val_loss: 0.6023\n",
      "Epoch 116/1500\n",
      "5/5 [==============================] - 5s 928ms/step - loss: 0.4724 - val_loss: 0.5245\n",
      "Epoch 117/1500\n",
      "5/5 [==============================] - 4s 925ms/step - loss: 0.4574 - val_loss: 0.5111\n",
      "Epoch 118/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.4345 - val_loss: 0.5068\n",
      "Epoch 119/1500\n",
      "5/5 [==============================] - 4s 889ms/step - loss: 0.4315 - val_loss: 0.4980\n",
      "Epoch 120/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.4186 - val_loss: 0.4778\n",
      "Epoch 121/1500\n",
      "5/5 [==============================] - 4s 743ms/step - loss: 0.4053 - val_loss: 0.4793\n",
      "Epoch 122/1500\n",
      "5/5 [==============================] - 4s 907ms/step - loss: 0.3995 - val_loss: 0.4632\n",
      "Epoch 123/1500\n",
      "5/5 [==============================] - 4s 866ms/step - loss: 0.3962 - val_loss: 0.4503\n",
      "Epoch 124/1500\n",
      "5/5 [==============================] - 4s 866ms/step - loss: 0.3825 - val_loss: 0.4469\n",
      "Epoch 125/1500\n",
      "5/5 [==============================] - 4s 753ms/step - loss: 0.3920 - val_loss: 0.4661\n",
      "Epoch 126/1500\n",
      "5/5 [==============================] - 4s 754ms/step - loss: 0.3973 - val_loss: 0.4631\n",
      "Epoch 127/1500\n",
      "5/5 [==============================] - 5s 956ms/step - loss: 0.3915 - val_loss: 0.4437\n",
      "Epoch 128/1500\n",
      "5/5 [==============================] - 4s 771ms/step - loss: 0.3939 - val_loss: 0.4520\n",
      "Epoch 129/1500\n",
      "5/5 [==============================] - 4s 762ms/step - loss: 0.3912 - val_loss: 0.4601\n",
      "Epoch 130/1500\n",
      "5/5 [==============================] - 4s 878ms/step - loss: 0.3841 - val_loss: 0.4421\n",
      "Epoch 131/1500\n",
      "5/5 [==============================] - 4s 753ms/step - loss: 0.4095 - val_loss: 0.5074\n",
      "Epoch 132/1500\n",
      "5/5 [==============================] - 4s 768ms/step - loss: 0.4253 - val_loss: 0.4480\n",
      "Epoch 133/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.3931 - val_loss: 0.4500\n",
      "Epoch 134/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.3916 - val_loss: 0.4426\n",
      "Epoch 135/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.3942 - val_loss: 0.4500\n",
      "Epoch 136/1500\n",
      "5/5 [==============================] - 4s 766ms/step - loss: 0.3930 - val_loss: 0.4477\n",
      "Epoch 137/1500\n",
      "5/5 [==============================] - 4s 898ms/step - loss: 0.3814 - val_loss: 0.4042\n",
      "Epoch 138/1500\n",
      "5/5 [==============================] - 4s 776ms/step - loss: 0.3650 - val_loss: 0.4071\n",
      "Epoch 139/1500\n",
      "5/5 [==============================] - 4s 896ms/step - loss: 0.3642 - val_loss: 0.3845\n",
      "Epoch 140/1500\n",
      "5/5 [==============================] - 4s 744ms/step - loss: 0.3603 - val_loss: 0.3870\n",
      "Epoch 141/1500\n",
      "5/5 [==============================] - 4s 755ms/step - loss: 0.3552 - val_loss: 0.4014\n",
      "Epoch 142/1500\n",
      "5/5 [==============================] - 5s 951ms/step - loss: 0.3594 - val_loss: 0.3830\n",
      "Epoch 143/1500\n",
      "5/5 [==============================] - 4s 773ms/step - loss: 0.3486 - val_loss: 0.3906\n",
      "Epoch 144/1500\n",
      "5/5 [==============================] - 4s 922ms/step - loss: 0.3437 - val_loss: 0.3817\n",
      "Epoch 145/1500\n",
      "5/5 [==============================] - 4s 750ms/step - loss: 0.3806 - val_loss: 0.3921\n",
      "Epoch 146/1500\n",
      "5/5 [==============================] - 4s 746ms/step - loss: 0.3513 - val_loss: 0.4086\n",
      "Epoch 147/1500\n",
      "5/5 [==============================] - 4s 774ms/step - loss: 0.3637 - val_loss: 0.4147\n",
      "Epoch 148/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.3736 - val_loss: 0.4161\n",
      "Epoch 149/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.3739 - val_loss: 0.4077\n",
      "Epoch 150/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.3810 - val_loss: 0.4246\n",
      "Epoch 151/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3667 - val_loss: 0.3882\n",
      "Epoch 152/1500\n",
      "5/5 [==============================] - 5s 948ms/step - loss: 0.3491 - val_loss: 0.3634\n",
      "Epoch 153/1500\n",
      "5/5 [==============================] - 5s 951ms/step - loss: 0.3327 - val_loss: 0.3488\n",
      "Epoch 154/1500\n",
      "5/5 [==============================] - 5s 926ms/step - loss: 0.3245 - val_loss: 0.3472\n",
      "Epoch 155/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.3256 - val_loss: 0.3665\n",
      "Epoch 156/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.3446 - val_loss: 0.3525\n",
      "Epoch 157/1500\n",
      "5/5 [==============================] - 4s 849ms/step - loss: 0.3377 - val_loss: 0.3708\n",
      "Epoch 158/1500\n",
      "5/5 [==============================] - 5s 989ms/step - loss: 0.3413 - val_loss: 0.3325\n",
      "Epoch 159/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.3234 - val_loss: 0.3333\n",
      "Epoch 160/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3208 - val_loss: 0.3298\n",
      "Epoch 161/1500\n",
      "5/5 [==============================] - 4s 785ms/step - loss: 0.3055 - val_loss: 0.3675\n",
      "Epoch 162/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.3656 - val_loss: 0.3736\n",
      "Epoch 163/1500\n",
      "5/5 [==============================] - 4s 860ms/step - loss: 0.3499 - val_loss: 0.3501\n",
      "Epoch 164/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.3344 - val_loss: 0.3382\n",
      "Epoch 165/1500\n",
      "5/5 [==============================] - 4s 852ms/step - loss: 0.3313 - val_loss: 0.3361\n",
      "Epoch 166/1500\n",
      "5/5 [==============================] - 5s 967ms/step - loss: 0.3210 - val_loss: 0.3195\n",
      "Epoch 167/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3067 - val_loss: 0.3136\n",
      "Epoch 168/1500\n",
      "5/5 [==============================] - 5s 960ms/step - loss: 0.2987 - val_loss: 0.3071\n",
      "Epoch 169/1500\n",
      "5/5 [==============================] - 5s 928ms/step - loss: 0.2958 - val_loss: 0.2999\n",
      "Epoch 170/1500\n",
      "5/5 [==============================] - 5s 925ms/step - loss: 0.2866 - val_loss: 0.2948\n",
      "Epoch 171/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.2826 - val_loss: 0.3207\n",
      "Epoch 172/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.2927 - val_loss: 0.3230\n",
      "Epoch 173/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.3157 - val_loss: 0.3408\n",
      "Epoch 174/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.3067 - val_loss: 0.3287\n",
      "Epoch 175/1500\n",
      "5/5 [==============================] - 4s 864ms/step - loss: 0.3069 - val_loss: 0.3092\n",
      "Epoch 176/1500\n",
      "5/5 [==============================] - 4s 850ms/step - loss: 0.2967 - val_loss: 0.3077\n",
      "Epoch 177/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.2845 - val_loss: 0.3211\n",
      "Epoch 178/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.2878 - val_loss: 0.3061\n",
      "Epoch 179/1500\n",
      "5/5 [==============================] - 5s 923ms/step - loss: 0.2799 - val_loss: 0.2908\n",
      "Epoch 180/1500\n",
      "5/5 [==============================] - 5s 950ms/step - loss: 0.2859 - val_loss: 0.2867\n",
      "Epoch 181/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.2822 - val_loss: 0.2988\n",
      "Epoch 182/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.2880 - val_loss: 0.2890\n",
      "Epoch 183/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.2794 - val_loss: 0.3223\n",
      "Epoch 184/1500\n",
      "5/5 [==============================] - 4s 855ms/step - loss: 0.2920 - val_loss: 0.3102\n",
      "Epoch 185/1500\n",
      "5/5 [==============================] - 4s 883ms/step - loss: 0.2832 - val_loss: 0.2941\n",
      "Epoch 186/1500\n",
      "5/5 [==============================] - 4s 864ms/step - loss: 0.2773 - val_loss: 0.2890\n",
      "Epoch 187/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.2705 - val_loss: 0.2909\n",
      "Epoch 188/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.2709 - val_loss: 0.3111\n",
      "Epoch 189/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.3542 - val_loss: 0.3173\n",
      "Epoch 190/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.3168 - val_loss: 0.3135\n",
      "Epoch 191/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.3141 - val_loss: 0.3087\n",
      "Epoch 192/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.3046 - val_loss: 0.3034\n",
      "Epoch 193/1500\n",
      "5/5 [==============================] - 4s 846ms/step - loss: 0.2986 - val_loss: 0.3201\n",
      "Epoch 194/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.2993 - val_loss: 0.2996\n",
      "Epoch 195/1500\n",
      "5/5 [==============================] - 5s 983ms/step - loss: 0.2969 - val_loss: 0.2807\n",
      "Epoch 196/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.2904 - val_loss: 0.2860\n",
      "Epoch 197/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.2765 - val_loss: 0.2817\n",
      "Epoch 198/1500\n",
      "5/5 [==============================] - 5s 946ms/step - loss: 0.2672 - val_loss: 0.2750\n",
      "Epoch 199/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.2622 - val_loss: 0.2827\n",
      "Epoch 200/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.2588 - val_loss: 0.2764\n",
      "Epoch 201/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.2564 - val_loss: 0.3359\n",
      "Epoch 202/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.3231 - val_loss: 0.3020\n",
      "Epoch 203/1500\n",
      "5/5 [==============================] - 4s 865ms/step - loss: 0.2951 - val_loss: 0.3272\n",
      "Epoch 204/1500\n",
      "5/5 [==============================] - 4s 858ms/step - loss: 0.2887 - val_loss: 0.3155\n",
      "Epoch 205/1500\n",
      "5/5 [==============================] - 4s 871ms/step - loss: 0.2886 - val_loss: 0.2867\n",
      "Epoch 206/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2760 - val_loss: 0.2727\n",
      "Epoch 207/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.2637 - val_loss: 0.2763\n",
      "Epoch 208/1500\n",
      "5/5 [==============================] - 5s 950ms/step - loss: 0.2590 - val_loss: 0.2669\n",
      "Epoch 209/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2535 - val_loss: 0.2653\n",
      "Epoch 210/1500\n",
      "5/5 [==============================] - 4s 852ms/step - loss: 0.2505 - val_loss: 0.2733\n",
      "Epoch 211/1500\n",
      "5/5 [==============================] - 5s 953ms/step - loss: 0.2483 - val_loss: 0.2632\n",
      "Epoch 212/1500\n",
      "5/5 [==============================] - 4s 899ms/step - loss: 0.2447 - val_loss: 0.2569\n",
      "Epoch 213/1500\n",
      "5/5 [==============================] - 4s 752ms/step - loss: 0.2452 - val_loss: 0.2602\n",
      "Epoch 214/1500\n",
      "5/5 [==============================] - 4s 776ms/step - loss: 0.2450 - val_loss: 0.2609\n",
      "Epoch 215/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.2485 - val_loss: 0.2607\n",
      "Epoch 216/1500\n",
      "5/5 [==============================] - 4s 901ms/step - loss: 0.2463 - val_loss: 0.2522\n",
      "Epoch 217/1500\n",
      "5/5 [==============================] - 5s 931ms/step - loss: 0.2405 - val_loss: 0.2522\n",
      "Epoch 218/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.2419 - val_loss: 0.2586\n",
      "Epoch 219/1500\n",
      "5/5 [==============================] - 5s 991ms/step - loss: 0.2402 - val_loss: 0.2470\n",
      "Epoch 220/1500\n",
      "5/5 [==============================] - 4s 869ms/step - loss: 0.2370 - val_loss: 0.2435\n",
      "Epoch 221/1500\n",
      "5/5 [==============================] - 4s 862ms/step - loss: 0.2320 - val_loss: 0.2419\n",
      "Epoch 222/1500\n",
      "5/5 [==============================] - 4s 858ms/step - loss: 0.2345 - val_loss: 0.2392\n",
      "Epoch 223/1500\n",
      "5/5 [==============================] - 5s 941ms/step - loss: 0.2333 - val_loss: 0.2339\n",
      "Epoch 224/1500\n",
      "5/5 [==============================] - 4s 755ms/step - loss: 0.2321 - val_loss: 0.2463\n",
      "Epoch 225/1500\n",
      "5/5 [==============================] - 5s 945ms/step - loss: 0.2395 - val_loss: 0.2420\n",
      "Epoch 226/1500\n",
      "5/5 [==============================] - 4s 867ms/step - loss: 0.2388 - val_loss: 0.2509\n",
      "Epoch 227/1500\n",
      "5/5 [==============================] - 4s 863ms/step - loss: 0.2393 - val_loss: 0.2645\n",
      "Epoch 228/1500\n",
      "5/5 [==============================] - 4s 867ms/step - loss: 0.2454 - val_loss: 0.2477\n",
      "Epoch 229/1500\n",
      "5/5 [==============================] - 4s 879ms/step - loss: 0.2420 - val_loss: 0.2377\n",
      "Epoch 230/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.2323 - val_loss: 0.2368\n",
      "Epoch 231/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.2326 - val_loss: 0.2407\n",
      "Epoch 232/1500\n",
      "5/5 [==============================] - 5s 949ms/step - loss: 0.2293 - val_loss: 0.2316\n",
      "Epoch 233/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.2296 - val_loss: 0.2744\n",
      "Epoch 234/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.2911 - val_loss: 0.3032\n",
      "Epoch 235/1500\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.3777 - val_loss: 0.3559\n",
      "Epoch 236/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.3138 - val_loss: 0.3247\n",
      "Epoch 237/1500\n",
      "5/5 [==============================] - 4s 865ms/step - loss: 0.3038 - val_loss: 0.3219\n",
      "Epoch 238/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.2943 - val_loss: 0.3032\n",
      "Epoch 239/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.2793 - val_loss: 0.2905\n",
      "Epoch 240/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.2681 - val_loss: 0.2727\n",
      "Epoch 241/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.2566 - val_loss: 0.2707\n",
      "Epoch 242/1500\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.2519 - val_loss: 0.2668\n",
      "Epoch 243/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.2444 - val_loss: 0.2702\n",
      "Epoch 244/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.2468 - val_loss: 0.2879\n",
      "Epoch 245/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.2571 - val_loss: 0.2621\n",
      "Epoch 246/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.2399 - val_loss: 0.2660\n",
      "Epoch 247/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.2410 - val_loss: 0.2634\n",
      "Epoch 248/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.2432 - val_loss: 0.2493\n",
      "Epoch 249/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.2410 - val_loss: 0.2574\n",
      "Epoch 250/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.2305 - val_loss: 0.2547\n",
      "Epoch 251/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.2250 - val_loss: 0.2486\n",
      "Epoch 252/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.2218 - val_loss: 0.2421\n",
      "Epoch 253/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.2228 - val_loss: 0.2432\n",
      "Epoch 254/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.2213 - val_loss: 0.2366\n",
      "Epoch 255/1500\n",
      "5/5 [==============================] - 5s 935ms/step - loss: 0.2215 - val_loss: 0.2245\n",
      "Epoch 256/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.2179 - val_loss: 0.2274\n",
      "Epoch 257/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.2163 - val_loss: 0.2267\n",
      "Epoch 258/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.2138 - val_loss: 0.2400\n",
      "Epoch 259/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.2721 - val_loss: 0.2875\n",
      "Epoch 260/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.2872 - val_loss: 0.2587\n",
      "Epoch 261/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.2668 - val_loss: 0.2611\n",
      "Epoch 262/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.2560 - val_loss: 0.2589\n",
      "Epoch 263/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.2450 - val_loss: 0.2428\n",
      "Epoch 264/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.2378 - val_loss: 0.2396\n",
      "Epoch 265/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.2303 - val_loss: 0.2376\n",
      "Epoch 266/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.2248 - val_loss: 0.2338\n",
      "Epoch 267/1500\n",
      "5/5 [==============================] - 4s 778ms/step - loss: 0.2215 - val_loss: 0.2455\n",
      "Epoch 268/1500\n",
      "5/5 [==============================] - 4s 780ms/step - loss: 0.2377 - val_loss: 0.2690\n",
      "Epoch 269/1500\n",
      "5/5 [==============================] - 4s 784ms/step - loss: 0.2353 - val_loss: 0.2524\n",
      "Epoch 270/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.2323 - val_loss: 0.2346\n",
      "Epoch 271/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.2308 - val_loss: 0.2246\n",
      "Epoch 272/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.2355 - val_loss: 0.2326\n",
      "Epoch 273/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.2298 - val_loss: 0.2516\n",
      "Epoch 274/1500\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 0.2326 - val_loss: 0.2471\n",
      "Epoch 275/1500\n",
      "5/5 [==============================] - 4s 778ms/step - loss: 0.2312 - val_loss: 0.2254\n",
      "Epoch 276/1500\n",
      "5/5 [==============================] - 4s 763ms/step - loss: 0.2208 - val_loss: 0.2343\n",
      "Epoch 277/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.2192 - val_loss: 0.2487\n",
      "Epoch 278/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.2224 - val_loss: 0.2251\n",
      "Epoch 279/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.2155 - val_loss: 0.2374\n",
      "Epoch 280/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.2177 - val_loss: 0.2291\n",
      "Epoch 281/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.2134 - val_loss: 0.2326\n",
      "Epoch 282/1500\n",
      "5/5 [==============================] - 5s 932ms/step - loss: 0.2144 - val_loss: 0.2220\n",
      "Epoch 283/1500\n",
      "5/5 [==============================] - 4s 768ms/step - loss: 0.2117 - val_loss: 0.2522\n",
      "Epoch 284/1500\n",
      "5/5 [==============================] - 4s 769ms/step - loss: 0.2386 - val_loss: 0.2575\n",
      "Epoch 285/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.2162 - val_loss: 0.2732\n",
      "Epoch 286/1500\n",
      "5/5 [==============================] - 5s 930ms/step - loss: 0.2747 - val_loss: 0.2991\n",
      "Epoch 287/1500\n",
      "5/5 [==============================] - 4s 855ms/step - loss: 0.2580 - val_loss: 0.2538\n",
      "Epoch 288/1500\n",
      "5/5 [==============================] - 4s 860ms/step - loss: 0.2488 - val_loss: 0.2569\n",
      "Epoch 289/1500\n",
      "5/5 [==============================] - 4s 892ms/step - loss: 0.2405 - val_loss: 0.2739\n",
      "Epoch 290/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.2308 - val_loss: 0.2421\n",
      "Epoch 291/1500\n",
      "5/5 [==============================] - 4s 885ms/step - loss: 0.2269 - val_loss: 0.2352\n",
      "Epoch 292/1500\n",
      "5/5 [==============================] - 4s 865ms/step - loss: 0.2154 - val_loss: 0.2462\n",
      "Epoch 293/1500\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.2144 - val_loss: 0.2288\n",
      "Epoch 294/1500\n",
      "5/5 [==============================] - 4s 878ms/step - loss: 0.2084 - val_loss: 0.2254\n",
      "Epoch 295/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.2066 - val_loss: 0.2383\n",
      "Epoch 296/1500\n",
      "5/5 [==============================] - 4s 849ms/step - loss: 0.2061 - val_loss: 0.2293\n",
      "Epoch 297/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.2063 - val_loss: 0.2446\n",
      "Epoch 298/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.2281 - val_loss: 0.2520\n",
      "Epoch 299/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.2147 - val_loss: 0.2487\n",
      "Epoch 300/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.2235 - val_loss: 0.2445\n",
      "Epoch 301/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.2202 - val_loss: 0.2585\n",
      "Epoch 302/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.2150 - val_loss: 0.2402\n",
      "Epoch 303/1500\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 0.2166 - val_loss: 0.2816\n",
      "Epoch 304/1500\n",
      "5/5 [==============================] - 4s 786ms/step - loss: 0.2353 - val_loss: 0.2588\n",
      "Epoch 305/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.2212 - val_loss: 0.2387\n",
      "Epoch 306/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.2158 - val_loss: 0.2357\n",
      "Epoch 307/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.2130 - val_loss: 0.2321\n",
      "Epoch 308/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.2064 - val_loss: 0.2392\n",
      "Epoch 309/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.2079 - val_loss: 0.2339\n",
      "Epoch 310/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.2032 - val_loss: 0.2301\n",
      "Epoch 311/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.2026 - val_loss: 0.2283\n",
      "Epoch 312/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.2685 - val_loss: 0.2778\n",
      "Epoch 313/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.2609 - val_loss: 0.2516\n",
      "Epoch 314/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.2392 - val_loss: 0.2463\n",
      "Epoch 315/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.2266 - val_loss: 0.2432\n",
      "Epoch 316/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.2171 - val_loss: 0.2403\n",
      "Epoch 317/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.2139 - val_loss: 0.2771\n",
      "Epoch 318/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.2239 - val_loss: 0.2621\n",
      "Epoch 319/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.2182 - val_loss: 0.2547\n",
      "Epoch 320/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.2276 - val_loss: 0.2510\n",
      "Epoch 321/1500\n",
      "5/5 [==============================] - 4s 783ms/step - loss: 0.2106 - val_loss: 0.2523\n",
      "Epoch 322/1500\n",
      "5/5 [==============================] - 4s 778ms/step - loss: 0.2152 - val_loss: 0.2371\n",
      "Epoch 323/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.2115 - val_loss: 0.2547\n",
      "Epoch 324/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.2157 - val_loss: 0.2380\n",
      "Epoch 325/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.2093 - val_loss: 0.2360\n",
      "Epoch 326/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.2013 - val_loss: 0.2456\n",
      "Epoch 327/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.2127 - val_loss: 0.2504\n",
      "Epoch 328/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.2060 - val_loss: 0.2314\n",
      "Epoch 329/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1982 - val_loss: 0.2246\n",
      "Epoch 330/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.2001 - val_loss: 0.2369\n",
      "Epoch 331/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1987 - val_loss: 0.2597\n",
      "Epoch 332/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.2277 - val_loss: 0.2554\n",
      "Epoch 333/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.2233 - val_loss: 0.2284\n",
      "Epoch 334/1500\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 0.2127 - val_loss: 0.2873\n",
      "Epoch 335/1500\n",
      "5/5 [==============================] - 4s 781ms/step - loss: 0.2220 - val_loss: 0.2502\n",
      "Epoch 336/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.2085 - val_loss: 0.2448\n",
      "Epoch 337/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.2028 - val_loss: 0.2673\n",
      "Epoch 338/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.2109 - val_loss: 0.2347\n",
      "Epoch 339/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.2018 - val_loss: 0.2243\n",
      "Epoch 340/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.2008 - val_loss: 0.2364\n",
      "Epoch 341/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.2003 - val_loss: 0.2338\n",
      "Epoch 342/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1998 - val_loss: 0.2488\n",
      "Epoch 343/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1980 - val_loss: 0.2293\n",
      "Epoch 344/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1925 - val_loss: 0.2289\n",
      "Epoch 345/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1907 - val_loss: 0.2395\n",
      "Epoch 346/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.1892 - val_loss: 0.2336\n",
      "Epoch 347/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1882 - val_loss: 0.2303\n",
      "Epoch 348/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1873 - val_loss: 0.2398\n",
      "Epoch 349/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1985 - val_loss: 0.2527\n",
      "Epoch 350/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.2008 - val_loss: 0.2652\n",
      "Epoch 351/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1924 - val_loss: 0.2604\n",
      "Epoch 352/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1922 - val_loss: 0.2488\n",
      "Epoch 353/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1919 - val_loss: 0.2522\n",
      "Epoch 354/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1883 - val_loss: 0.2485\n",
      "Epoch 355/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1878 - val_loss: 0.2363\n",
      "Epoch 356/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.1849 - val_loss: 0.2387\n",
      "Epoch 357/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1855 - val_loss: 0.2989\n",
      "Epoch 358/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.2536 - val_loss: 0.3075\n",
      "Epoch 359/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.2514 - val_loss: 0.2403\n",
      "Epoch 360/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.2278 - val_loss: 0.2553\n",
      "Epoch 361/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.2236 - val_loss: 0.2466\n",
      "Epoch 362/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.2899 - val_loss: 0.2837\n",
      "Epoch 363/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.2518 - val_loss: 0.2762\n",
      "Epoch 364/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.2366 - val_loss: 0.2529\n",
      "Epoch 365/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2244 - val_loss: 0.2435\n",
      "Epoch 366/1500\n",
      "5/5 [==============================] - 5s 972ms/step - loss: 0.2145 - val_loss: 0.2654\n",
      "Epoch 367/1500\n",
      "5/5 [==============================] - 5s 925ms/step - loss: 0.2185 - val_loss: 0.2721\n",
      "Epoch 368/1500\n",
      "5/5 [==============================] - 4s 878ms/step - loss: 0.2117 - val_loss: 0.2590\n",
      "Epoch 369/1500\n",
      "5/5 [==============================] - 4s 863ms/step - loss: 0.2098 - val_loss: 0.2701\n",
      "Epoch 370/1500\n",
      "5/5 [==============================] - 4s 879ms/step - loss: 0.2058 - val_loss: 0.2331\n",
      "Epoch 371/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.2028 - val_loss: 0.2334\n",
      "Epoch 372/1500\n",
      "5/5 [==============================] - 4s 849ms/step - loss: 0.2043 - val_loss: 0.2458\n",
      "Epoch 373/1500\n",
      "5/5 [==============================] - 4s 874ms/step - loss: 0.2015 - val_loss: 0.2556\n",
      "Epoch 374/1500\n",
      "5/5 [==============================] - 4s 861ms/step - loss: 0.1952 - val_loss: 0.2510\n",
      "Epoch 375/1500\n",
      "5/5 [==============================] - 4s 875ms/step - loss: 0.1920 - val_loss: 0.2329\n",
      "Epoch 376/1500\n",
      "5/5 [==============================] - 5s 897ms/step - loss: 0.1885 - val_loss: 0.2353\n",
      "Epoch 377/1500\n",
      "5/5 [==============================] - 5s 924ms/step - loss: 0.1859 - val_loss: 0.2357\n",
      "Epoch 378/1500\n",
      "5/5 [==============================] - 4s 865ms/step - loss: 0.1870 - val_loss: 0.2356\n",
      "Epoch 379/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1881 - val_loss: 0.2300\n",
      "Epoch 380/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1864 - val_loss: 0.2305\n",
      "Epoch 381/1500\n",
      "5/5 [==============================] - 4s 859ms/step - loss: 0.1842 - val_loss: 0.2291\n",
      "Epoch 382/1500\n",
      "5/5 [==============================] - 4s 884ms/step - loss: 0.1833 - val_loss: 0.2262\n",
      "Epoch 383/1500\n",
      "5/5 [==============================] - 4s 874ms/step - loss: 0.1849 - val_loss: 0.2338\n",
      "Epoch 384/1500\n",
      "5/5 [==============================] - 4s 861ms/step - loss: 0.1838 - val_loss: 0.2402\n",
      "Epoch 385/1500\n",
      "5/5 [==============================] - 4s 874ms/step - loss: 0.1850 - val_loss: 0.2377\n",
      "Epoch 386/1500\n",
      "5/5 [==============================] - 4s 866ms/step - loss: 0.1820 - val_loss: 0.2415\n",
      "Epoch 387/1500\n",
      "5/5 [==============================] - 4s 871ms/step - loss: 0.1800 - val_loss: 0.2383\n",
      "Epoch 388/1500\n",
      "5/5 [==============================] - 4s 869ms/step - loss: 0.1814 - val_loss: 0.2420\n",
      "Epoch 389/1500\n",
      "5/5 [==============================] - 4s 880ms/step - loss: 0.1796 - val_loss: 0.2265\n",
      "Epoch 390/1500\n",
      "5/5 [==============================] - 4s 868ms/step - loss: 0.1771 - val_loss: 0.3406\n",
      "Epoch 391/1500\n",
      "5/5 [==============================] - 4s 866ms/step - loss: 0.3256 - val_loss: 0.3533\n",
      "Epoch 392/1500\n",
      "5/5 [==============================] - 4s 880ms/step - loss: 0.2604 - val_loss: 0.2878\n",
      "Epoch 393/1500\n",
      "5/5 [==============================] - 4s 885ms/step - loss: 0.2455 - val_loss: 0.2940\n",
      "Epoch 394/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.2467 - val_loss: 0.2917\n",
      "Epoch 395/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.2365 - val_loss: 0.2813\n",
      "Epoch 396/1500\n",
      "5/5 [==============================] - 4s 864ms/step - loss: 0.2212 - val_loss: 0.2785\n",
      "Epoch 397/1500\n",
      "5/5 [==============================] - 4s 892ms/step - loss: 0.2125 - val_loss: 0.2784\n",
      "Epoch 398/1500\n",
      "5/5 [==============================] - 5s 904ms/step - loss: 0.2068 - val_loss: 0.2653\n",
      "Epoch 399/1500\n",
      "5/5 [==============================] - 5s 904ms/step - loss: 0.2006 - val_loss: 0.2579\n",
      "Epoch 400/1500\n",
      "5/5 [==============================] - 4s 862ms/step - loss: 0.1946 - val_loss: 0.2535\n",
      "Epoch 401/1500\n",
      "5/5 [==============================] - 4s 891ms/step - loss: 0.1973 - val_loss: 0.2740\n",
      "Epoch 402/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.2034 - val_loss: 0.2727\n",
      "Epoch 403/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.2006 - val_loss: 0.2608\n",
      "Epoch 404/1500\n",
      "5/5 [==============================] - 4s 870ms/step - loss: 0.2017 - val_loss: 0.2596\n",
      "Epoch 405/1500\n",
      "5/5 [==============================] - 5s 895ms/step - loss: 0.2025 - val_loss: 0.2420\n",
      "Epoch 406/1500\n",
      "5/5 [==============================] - 5s 902ms/step - loss: 0.1958 - val_loss: 0.2633\n",
      "Epoch 407/1500\n",
      "5/5 [==============================] - 5s 908ms/step - loss: 0.1903 - val_loss: 0.2429\n",
      "Epoch 408/1500\n",
      "5/5 [==============================] - 4s 876ms/step - loss: 0.1872 - val_loss: 0.2399\n",
      "Epoch 409/1500\n",
      "5/5 [==============================] - 4s 868ms/step - loss: 0.1866 - val_loss: 0.2445\n",
      "Epoch 410/1500\n",
      "5/5 [==============================] - 4s 865ms/step - loss: 0.1851 - val_loss: 0.2472\n",
      "Epoch 411/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.1826 - val_loss: 0.2376\n",
      "Epoch 412/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.1810 - val_loss: 0.2489\n",
      "Epoch 413/1500\n",
      "5/5 [==============================] - 5s 982ms/step - loss: 0.1809 - val_loss: 0.2453\n",
      "Epoch 414/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.1864 - val_loss: 0.2420\n",
      "Epoch 415/1500\n",
      "5/5 [==============================] - 5s 900ms/step - loss: 0.1920 - val_loss: 0.2376\n",
      "Epoch 416/1500\n",
      "5/5 [==============================] - 5s 933ms/step - loss: 0.1818 - val_loss: 0.2512\n",
      "Epoch 417/1500\n",
      "5/5 [==============================] - 5s 941ms/step - loss: 0.1826 - val_loss: 0.2465\n",
      "Epoch 418/1500\n",
      "5/5 [==============================] - 5s 908ms/step - loss: 0.1797 - val_loss: 0.2575\n",
      "Epoch 419/1500\n",
      "5/5 [==============================] - 5s 935ms/step - loss: 0.1874 - val_loss: 0.2844\n",
      "Epoch 420/1500\n",
      "5/5 [==============================] - 5s 985ms/step - loss: 0.1987 - val_loss: 0.2663\n",
      "Epoch 421/1500\n",
      "5/5 [==============================] - 5s 996ms/step - loss: 0.1890 - val_loss: 0.2496\n",
      "Epoch 422/1500\n",
      "5/5 [==============================] - 5s 948ms/step - loss: 0.1835 - val_loss: 0.2435\n",
      "Epoch 423/1500\n",
      "5/5 [==============================] - 5s 879ms/step - loss: 0.1803 - val_loss: 0.2426\n",
      "Epoch 424/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1812 - val_loss: 0.2471\n",
      "Epoch 425/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1809 - val_loss: 0.2491\n",
      "Epoch 426/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.1795 - val_loss: 0.2543\n",
      "Epoch 427/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1837 - val_loss: 0.2469\n",
      "Epoch 428/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1815 - val_loss: 0.2434\n",
      "Epoch 429/1500\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.1761 - val_loss: 0.2385\n",
      "Epoch 430/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1762 - val_loss: 0.2414\n",
      "Epoch 431/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1730 - val_loss: 0.2434\n",
      "Epoch 432/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1925 - val_loss: 0.2458\n",
      "Epoch 433/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1845 - val_loss: 0.2489\n",
      "Epoch 434/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1810 - val_loss: 0.2397\n",
      "Epoch 435/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1788 - val_loss: 0.2431\n",
      "Epoch 436/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.1765 - val_loss: 0.2350\n",
      "Epoch 437/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1749 - val_loss: 0.2415\n",
      "Epoch 438/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1730 - val_loss: 0.2363\n",
      "Epoch 439/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1752 - val_loss: 0.2400\n",
      "Epoch 440/1500\n",
      "5/5 [==============================] - 4s 811ms/step - loss: 0.1756 - val_loss: 0.2472\n",
      "Epoch 441/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1772 - val_loss: 0.2450\n",
      "Epoch 442/1500\n",
      "5/5 [==============================] - 4s 846ms/step - loss: 0.1743 - val_loss: 0.2380\n",
      "Epoch 443/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1739 - val_loss: 0.2469\n",
      "Epoch 444/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.1782 - val_loss: 0.2304\n",
      "Epoch 445/1500\n",
      "5/5 [==============================] - 4s 867ms/step - loss: 0.1972 - val_loss: 0.2345\n",
      "Epoch 446/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1830 - val_loss: 0.2503\n",
      "Epoch 447/1500\n",
      "5/5 [==============================] - 4s 875ms/step - loss: 0.1851 - val_loss: 0.2793\n",
      "Epoch 448/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.1875 - val_loss: 0.2619\n",
      "Epoch 449/1500\n",
      "5/5 [==============================] - 5s 883ms/step - loss: 0.1905 - val_loss: 0.2893\n",
      "Epoch 450/1500\n",
      "5/5 [==============================] - 4s 860ms/step - loss: 0.1973 - val_loss: 0.2563\n",
      "Epoch 451/1500\n",
      "5/5 [==============================] - 4s 878ms/step - loss: 0.1919 - val_loss: 0.2572\n",
      "Epoch 452/1500\n",
      "5/5 [==============================] - 5s 994ms/step - loss: 0.1821 - val_loss: 0.2575\n",
      "Epoch 453/1500\n",
      "5/5 [==============================] - 4s 887ms/step - loss: 0.1801 - val_loss: 0.2524\n",
      "Epoch 454/1500\n",
      "5/5 [==============================] - 5s 896ms/step - loss: 0.1785 - val_loss: 0.2422\n",
      "Epoch 455/1500\n",
      "5/5 [==============================] - 5s 891ms/step - loss: 0.1723 - val_loss: 0.2336\n",
      "Epoch 456/1500\n",
      "5/5 [==============================] - 5s 894ms/step - loss: 0.1984 - val_loss: 0.2652\n",
      "Epoch 457/1500\n",
      "5/5 [==============================] - 5s 891ms/step - loss: 0.1819 - val_loss: 0.2923\n",
      "Epoch 458/1500\n",
      "5/5 [==============================] - 4s 877ms/step - loss: 0.1856 - val_loss: 0.2768\n",
      "Epoch 459/1500\n",
      "5/5 [==============================] - 4s 873ms/step - loss: 0.1785 - val_loss: 0.2809\n",
      "Epoch 460/1500\n",
      "5/5 [==============================] - 5s 913ms/step - loss: 0.1802 - val_loss: 0.2699\n",
      "Epoch 461/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1815 - val_loss: 0.2714\n",
      "Epoch 462/1500\n",
      "5/5 [==============================] - 4s 861ms/step - loss: 0.1898 - val_loss: 0.2646\n",
      "Epoch 463/1500\n",
      "5/5 [==============================] - 4s 867ms/step - loss: 0.2097 - val_loss: 0.2442\n",
      "Epoch 464/1500\n",
      "5/5 [==============================] - 5s 911ms/step - loss: 0.1890 - val_loss: 0.2496\n",
      "Epoch 465/1500\n",
      "5/5 [==============================] - 5s 897ms/step - loss: 0.1912 - val_loss: 0.2370\n",
      "Epoch 466/1500\n",
      "5/5 [==============================] - 5s 916ms/step - loss: 0.1800 - val_loss: 0.2439\n",
      "Epoch 467/1500\n",
      "5/5 [==============================] - 5s 909ms/step - loss: 0.1769 - val_loss: 0.2281\n",
      "Epoch 468/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.1895 - val_loss: 0.2365\n",
      "Epoch 469/1500\n",
      "5/5 [==============================] - 4s 873ms/step - loss: 0.2075 - val_loss: 0.2596\n",
      "Epoch 470/1500\n",
      "5/5 [==============================] - 4s 861ms/step - loss: 0.2526 - val_loss: 0.2653\n",
      "Epoch 471/1500\n",
      "5/5 [==============================] - 4s 863ms/step - loss: 0.2257 - val_loss: 0.3331\n",
      "Epoch 472/1500\n",
      "5/5 [==============================] - 4s 865ms/step - loss: 0.2798 - val_loss: 0.3277\n",
      "Epoch 473/1500\n",
      "5/5 [==============================] - 4s 867ms/step - loss: 0.2768 - val_loss: 0.3333\n",
      "Epoch 474/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2689 - val_loss: 0.2956\n",
      "Epoch 475/1500\n",
      "5/5 [==============================] - 4s 873ms/step - loss: 0.2351 - val_loss: 0.2790\n",
      "Epoch 476/1500\n",
      "5/5 [==============================] - 5s 901ms/step - loss: 0.2245 - val_loss: 0.2744\n",
      "Epoch 477/1500\n",
      "5/5 [==============================] - 5s 989ms/step - loss: 0.2135 - val_loss: 0.2589\n",
      "Epoch 478/1500\n",
      "5/5 [==============================] - 4s 871ms/step - loss: 0.2029 - val_loss: 0.2592\n",
      "Epoch 479/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1965 - val_loss: 0.2622\n",
      "Epoch 480/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.1958 - val_loss: 0.2475\n",
      "Epoch 481/1500\n",
      "5/5 [==============================] - 4s 888ms/step - loss: 0.1915 - val_loss: 0.2407\n",
      "Epoch 482/1500\n",
      "5/5 [==============================] - 4s 881ms/step - loss: 0.1923 - val_loss: 0.2391\n",
      "Epoch 483/1500\n",
      "5/5 [==============================] - 4s 872ms/step - loss: 0.1852 - val_loss: 0.2370\n",
      "Epoch 484/1500\n",
      "5/5 [==============================] - 5s 895ms/step - loss: 0.1789 - val_loss: 0.2388\n",
      "Epoch 485/1500\n",
      "5/5 [==============================] - 4s 871ms/step - loss: 0.1798 - val_loss: 0.2413\n",
      "Epoch 486/1500\n",
      "5/5 [==============================] - 4s 861ms/step - loss: 0.1778 - val_loss: 0.2420\n",
      "Epoch 487/1500\n",
      "5/5 [==============================] - 4s 881ms/step - loss: 0.1769 - val_loss: 0.2520\n",
      "Epoch 488/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1786 - val_loss: 0.2428\n",
      "Epoch 489/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1750 - val_loss: 0.2339\n",
      "Epoch 490/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1852 - val_loss: 0.2273\n",
      "Epoch 491/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.1930 - val_loss: 0.2215\n",
      "Epoch 492/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1912 - val_loss: 0.2404\n",
      "Epoch 493/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.1857 - val_loss: 0.2173\n",
      "Epoch 494/1500\n",
      "5/5 [==============================] - 5s 980ms/step - loss: 0.1793 - val_loss: 0.2082\n",
      "Epoch 495/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1780 - val_loss: 0.2191\n",
      "Epoch 496/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1787 - val_loss: 0.2297\n",
      "Epoch 497/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.1743 - val_loss: 0.2356\n",
      "Epoch 498/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1722 - val_loss: 0.2409\n",
      "Epoch 499/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.1694 - val_loss: 0.2464\n",
      "Epoch 500/1500\n",
      "5/5 [==============================] - 4s 865ms/step - loss: 0.1922 - val_loss: 0.3130\n",
      "Epoch 501/1500\n",
      "5/5 [==============================] - 4s 858ms/step - loss: 0.2062 - val_loss: 0.2662\n",
      "Epoch 502/1500\n",
      "5/5 [==============================] - 4s 862ms/step - loss: 0.1862 - val_loss: 0.2419\n",
      "Epoch 503/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1936 - val_loss: 0.2486\n",
      "Epoch 504/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.2007 - val_loss: 0.2338\n",
      "Epoch 505/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1808 - val_loss: 0.2461\n",
      "Epoch 506/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1841 - val_loss: 0.2340\n",
      "Epoch 507/1500\n",
      "5/5 [==============================] - 4s 854ms/step - loss: 0.1795 - val_loss: 0.2572\n",
      "Epoch 508/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.2202 - val_loss: 0.2539\n",
      "Epoch 509/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.2063 - val_loss: 0.2414\n",
      "Epoch 510/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1838 - val_loss: 0.2390\n",
      "Epoch 511/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1776 - val_loss: 0.2398\n",
      "Epoch 512/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.1789 - val_loss: 0.2390\n",
      "Epoch 513/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1766 - val_loss: 0.2400\n",
      "Epoch 514/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1746 - val_loss: 0.2459\n",
      "Epoch 515/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1727 - val_loss: 0.2408\n",
      "Epoch 516/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1821 - val_loss: 0.2370\n",
      "Epoch 517/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1788 - val_loss: 0.2353\n",
      "Epoch 518/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.1742 - val_loss: 0.2334\n",
      "Epoch 519/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.1704 - val_loss: 0.2343\n",
      "Epoch 520/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1676 - val_loss: 0.2336\n",
      "Epoch 521/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1660 - val_loss: 0.2356\n",
      "Epoch 522/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1654 - val_loss: 0.2283\n",
      "Epoch 523/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1683 - val_loss: 0.2383\n",
      "Epoch 524/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1672 - val_loss: 0.2473\n",
      "Epoch 525/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1724 - val_loss: 0.2427\n",
      "Epoch 526/1500\n",
      "5/5 [==============================] - 4s 852ms/step - loss: 0.1689 - val_loss: 0.2311\n",
      "Epoch 527/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1657 - val_loss: 0.2247\n",
      "Epoch 528/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1668 - val_loss: 0.2275\n",
      "Epoch 529/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1906 - val_loss: 0.2368\n",
      "Epoch 530/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1863 - val_loss: 0.2751\n",
      "Epoch 531/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1844 - val_loss: 0.2597\n",
      "Epoch 532/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1771 - val_loss: 0.2369\n",
      "Epoch 533/1500\n",
      "5/5 [==============================] - 4s 807ms/step - loss: 0.1674 - val_loss: 0.2282\n",
      "Epoch 534/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1681 - val_loss: 0.2292\n",
      "Epoch 535/1500\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.1655 - val_loss: 0.2405\n",
      "Epoch 536/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1650 - val_loss: 0.2363\n",
      "Epoch 537/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.1621 - val_loss: 0.2254\n",
      "Epoch 538/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1598 - val_loss: 0.2266\n",
      "Epoch 539/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.1581 - val_loss: 0.2331\n",
      "Epoch 540/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1583 - val_loss: 0.2346\n",
      "Epoch 541/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1588 - val_loss: 0.2447\n",
      "Epoch 542/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1594 - val_loss: 0.2326\n",
      "Epoch 543/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.1687 - val_loss: 0.2325\n",
      "Epoch 544/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1656 - val_loss: 0.2416\n",
      "Epoch 545/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1599 - val_loss: 0.2385\n",
      "Epoch 546/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1600 - val_loss: 0.2286\n",
      "Epoch 547/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1573 - val_loss: 0.2275\n",
      "Epoch 548/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1562 - val_loss: 0.2321\n",
      "Epoch 549/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1558 - val_loss: 0.2416\n",
      "Epoch 550/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1565 - val_loss: 0.2360\n",
      "Epoch 551/1500\n",
      "5/5 [==============================] - 4s 811ms/step - loss: 0.1573 - val_loss: 0.2349\n",
      "Epoch 552/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1559 - val_loss: 0.2358\n",
      "Epoch 553/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.1569 - val_loss: 0.2430\n",
      "Epoch 554/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1597 - val_loss: 0.2430\n",
      "Epoch 555/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1621 - val_loss: 0.2386\n",
      "Epoch 556/1500\n",
      "5/5 [==============================] - 4s 811ms/step - loss: 0.1874 - val_loss: 0.2412\n",
      "Epoch 557/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1729 - val_loss: 0.2624\n",
      "Epoch 558/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1746 - val_loss: 0.2397\n",
      "Epoch 559/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1708 - val_loss: 0.2454\n",
      "Epoch 560/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1666 - val_loss: 0.2426\n",
      "Epoch 561/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1690 - val_loss: 0.2417\n",
      "Epoch 562/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1620 - val_loss: 0.2415\n",
      "Epoch 563/1500\n",
      "5/5 [==============================] - 4s 784ms/step - loss: 0.1591 - val_loss: 0.2403\n",
      "Epoch 564/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1599 - val_loss: 0.2518\n",
      "Epoch 565/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1660 - val_loss: 0.2411\n",
      "Epoch 566/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1724 - val_loss: 0.2837\n",
      "Epoch 567/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1754 - val_loss: 0.2549\n",
      "Epoch 568/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.1681 - val_loss: 0.2643\n",
      "Epoch 569/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1661 - val_loss: 0.2541\n",
      "Epoch 570/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1813 - val_loss: 0.2706\n",
      "Epoch 571/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1792 - val_loss: 0.2734\n",
      "Epoch 572/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1759 - val_loss: 0.2613\n",
      "Epoch 573/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.1682 - val_loss: 0.2526\n",
      "Epoch 574/1500\n",
      "5/5 [==============================] - 4s 782ms/step - loss: 0.1633 - val_loss: 0.2398\n",
      "Epoch 575/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1609 - val_loss: 0.2408\n",
      "Epoch 576/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1575 - val_loss: 0.2371\n",
      "Epoch 577/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1545 - val_loss: 0.2357\n",
      "Epoch 578/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1529 - val_loss: 0.2513\n",
      "Epoch 579/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.1721 - val_loss: 0.2839\n",
      "Epoch 580/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.1776 - val_loss: 0.3099\n",
      "Epoch 581/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1772 - val_loss: 0.2929\n",
      "Epoch 582/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1650 - val_loss: 0.2506\n",
      "Epoch 583/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1822 - val_loss: 0.2537\n",
      "Epoch 584/1500\n",
      "5/5 [==============================] - 5s 976ms/step - loss: 0.2293 - val_loss: 0.2082\n",
      "Epoch 585/1500\n",
      "5/5 [==============================] - 5s 952ms/step - loss: 0.2005 - val_loss: 0.1932\n",
      "Epoch 586/1500\n",
      "5/5 [==============================] - 4s 883ms/step - loss: 0.1917 - val_loss: 0.1931\n",
      "Epoch 587/1500\n",
      "5/5 [==============================] - 5s 976ms/step - loss: 0.1816 - val_loss: 0.1881\n",
      "Epoch 588/1500\n",
      "5/5 [==============================] - 4s 773ms/step - loss: 0.1793 - val_loss: 0.2026\n",
      "Epoch 589/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1754 - val_loss: 0.2030\n",
      "Epoch 590/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1670 - val_loss: 0.2118\n",
      "Epoch 591/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1667 - val_loss: 0.2211\n",
      "Epoch 592/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1661 - val_loss: 0.2250\n",
      "Epoch 593/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1624 - val_loss: 0.2300\n",
      "Epoch 594/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1896 - val_loss: 0.2443\n",
      "Epoch 595/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1913 - val_loss: 0.2231\n",
      "Epoch 596/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.1721 - val_loss: 0.2312\n",
      "Epoch 597/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1679 - val_loss: 0.2543\n",
      "Epoch 598/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.2158 - val_loss: 0.3026\n",
      "Epoch 599/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.2085 - val_loss: 0.2889\n",
      "Epoch 600/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.2098 - val_loss: 0.2881\n",
      "Epoch 601/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.1959 - val_loss: 0.2962\n",
      "Epoch 602/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1973 - val_loss: 0.2768\n",
      "Epoch 603/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1841 - val_loss: 0.2707\n",
      "Epoch 604/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1769 - val_loss: 0.2632\n",
      "Epoch 605/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1716 - val_loss: 0.2558\n",
      "Epoch 606/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1677 - val_loss: 0.2533\n",
      "Epoch 607/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.1636 - val_loss: 0.2437\n",
      "Epoch 608/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.1659 - val_loss: 0.2490\n",
      "Epoch 609/1500\n",
      "5/5 [==============================] - 4s 811ms/step - loss: 0.1785 - val_loss: 0.2394\n",
      "Epoch 610/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1671 - val_loss: 0.2280\n",
      "Epoch 611/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1609 - val_loss: 0.2235\n",
      "Epoch 612/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1623 - val_loss: 0.2330\n",
      "Epoch 613/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1793 - val_loss: 0.2944\n",
      "Epoch 614/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.2088 - val_loss: 0.2582\n",
      "Epoch 615/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1840 - val_loss: 0.2510\n",
      "Epoch 616/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1760 - val_loss: 0.2358\n",
      "Epoch 617/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1666 - val_loss: 0.2462\n",
      "Epoch 618/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1650 - val_loss: 0.2487\n",
      "Epoch 619/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1628 - val_loss: 0.2386\n",
      "Epoch 620/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1604 - val_loss: 0.2350\n",
      "Epoch 621/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1595 - val_loss: 0.2295\n",
      "Epoch 622/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1574 - val_loss: 0.2333\n",
      "Epoch 623/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1579 - val_loss: 0.2335\n",
      "Epoch 624/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1562 - val_loss: 0.2290\n",
      "Epoch 625/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1552 - val_loss: 0.2285\n",
      "Epoch 626/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1529 - val_loss: 0.2385\n",
      "Epoch 627/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1543 - val_loss: 0.2384\n",
      "Epoch 628/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1533 - val_loss: 0.2339\n",
      "Epoch 629/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1547 - val_loss: 0.2281\n",
      "Epoch 630/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1530 - val_loss: 0.2335\n",
      "Epoch 631/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1515 - val_loss: 0.2295\n",
      "Epoch 632/1500\n",
      "5/5 [==============================] - 4s 784ms/step - loss: 0.1506 - val_loss: 0.2477\n",
      "Epoch 633/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1573 - val_loss: 0.2499\n",
      "Epoch 634/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1595 - val_loss: 0.2400\n",
      "Epoch 635/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1504 - val_loss: 0.2405\n",
      "Epoch 636/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1553 - val_loss: 0.2710\n",
      "Epoch 637/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1550 - val_loss: 0.2801\n",
      "Epoch 638/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1585 - val_loss: 0.2794\n",
      "Epoch 639/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1545 - val_loss: 0.2782\n",
      "Epoch 640/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1551 - val_loss: 0.2659\n",
      "Epoch 641/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1562 - val_loss: 0.2445\n",
      "Epoch 642/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.1542 - val_loss: 0.2305\n",
      "Epoch 643/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1500 - val_loss: 0.2756\n",
      "Epoch 644/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.2026 - val_loss: 0.2903\n",
      "Epoch 645/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1935 - val_loss: 0.2408\n",
      "Epoch 646/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.1774 - val_loss: 0.2430\n",
      "Epoch 647/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1723 - val_loss: 0.2679\n",
      "Epoch 648/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1719 - val_loss: 0.2748\n",
      "Epoch 649/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1692 - val_loss: 0.2763\n",
      "Epoch 650/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1652 - val_loss: 0.2841\n",
      "Epoch 651/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1611 - val_loss: 0.2619\n",
      "Epoch 652/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1578 - val_loss: 0.2574\n",
      "Epoch 653/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1536 - val_loss: 0.2561\n",
      "Epoch 654/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1531 - val_loss: 0.2476\n",
      "Epoch 655/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1493 - val_loss: 0.2462\n",
      "Epoch 656/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1498 - val_loss: 0.2387\n",
      "Epoch 657/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1486 - val_loss: 0.2470\n",
      "Epoch 658/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1475 - val_loss: 0.2398\n",
      "Epoch 659/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1484 - val_loss: 0.2413\n",
      "Epoch 660/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1475 - val_loss: 0.2397\n",
      "Epoch 661/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1495 - val_loss: 0.2571\n",
      "Epoch 662/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1566 - val_loss: 0.2924\n",
      "Epoch 663/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1663 - val_loss: 0.2836\n",
      "Epoch 664/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1781 - val_loss: 0.2775\n",
      "Epoch 665/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1759 - val_loss: 0.2392\n",
      "Epoch 666/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1589 - val_loss: 0.2427\n",
      "Epoch 667/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1522 - val_loss: 0.2374\n",
      "Epoch 668/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1527 - val_loss: 0.2344\n",
      "Epoch 669/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1530 - val_loss: 0.2560\n",
      "Epoch 670/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.2099 - val_loss: 0.3238\n",
      "Epoch 671/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1994 - val_loss: 0.2594\n",
      "Epoch 672/1500\n",
      "5/5 [==============================] - 4s 784ms/step - loss: 0.1711 - val_loss: 0.2360\n",
      "Epoch 673/1500\n",
      "5/5 [==============================] - 4s 783ms/step - loss: 0.1660 - val_loss: 0.2428\n",
      "Epoch 674/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1621 - val_loss: 0.2378\n",
      "Epoch 675/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1586 - val_loss: 0.2328\n",
      "Epoch 676/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1557 - val_loss: 0.2214\n",
      "Epoch 677/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1526 - val_loss: 0.2233\n",
      "Epoch 678/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1506 - val_loss: 0.2230\n",
      "Epoch 679/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1505 - val_loss: 0.2167\n",
      "Epoch 680/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1505 - val_loss: 0.2200\n",
      "Epoch 681/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1473 - val_loss: 0.2207\n",
      "Epoch 682/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1458 - val_loss: 0.2214\n",
      "Epoch 683/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.1457 - val_loss: 0.2350\n",
      "Epoch 684/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1461 - val_loss: 0.2212\n",
      "Epoch 685/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1465 - val_loss: 0.2249\n",
      "Epoch 686/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1439 - val_loss: 0.2205\n",
      "Epoch 687/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1475 - val_loss: 0.2196\n",
      "Epoch 688/1500\n",
      "5/5 [==============================] - 4s 846ms/step - loss: 0.1437 - val_loss: 0.2224\n",
      "Epoch 689/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1444 - val_loss: 0.2363\n",
      "Epoch 690/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1450 - val_loss: 0.2298\n",
      "Epoch 691/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1439 - val_loss: 0.2370\n",
      "Epoch 692/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1445 - val_loss: 0.2287\n",
      "Epoch 693/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1591 - val_loss: 0.2378\n",
      "Epoch 694/1500\n",
      "5/5 [==============================] - 4s 785ms/step - loss: 0.1558 - val_loss: 0.2385\n",
      "Epoch 695/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1528 - val_loss: 0.2300\n",
      "Epoch 696/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1496 - val_loss: 0.2357\n",
      "Epoch 697/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1460 - val_loss: 0.2321\n",
      "Epoch 698/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1417 - val_loss: 0.2255\n",
      "Epoch 699/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1400 - val_loss: 0.2287\n",
      "Epoch 700/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1412 - val_loss: 0.2343\n",
      "Epoch 701/1500\n",
      "5/5 [==============================] - 4s 781ms/step - loss: 0.1432 - val_loss: 0.2227\n",
      "Epoch 702/1500\n",
      "5/5 [==============================] - 4s 786ms/step - loss: 0.1420 - val_loss: 0.2375\n",
      "Epoch 703/1500\n",
      "5/5 [==============================] - 4s 783ms/step - loss: 0.1452 - val_loss: 0.2247\n",
      "Epoch 704/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1435 - val_loss: 0.2493\n",
      "Epoch 705/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1459 - val_loss: 0.2269\n",
      "Epoch 706/1500\n",
      "5/5 [==============================] - 4s 785ms/step - loss: 0.1469 - val_loss: 0.2386\n",
      "Epoch 707/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.1418 - val_loss: 0.3293\n",
      "Epoch 708/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.2908 - val_loss: 0.3160\n",
      "Epoch 709/1500\n",
      "5/5 [==============================] - 4s 786ms/step - loss: 0.2067 - val_loss: 0.3050\n",
      "Epoch 710/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.2105 - val_loss: 0.2847\n",
      "Epoch 711/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1935 - val_loss: 0.2759\n",
      "Epoch 712/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1845 - val_loss: 0.2690\n",
      "Epoch 713/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1721 - val_loss: 0.2489\n",
      "Epoch 714/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1624 - val_loss: 0.2372\n",
      "Epoch 715/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1583 - val_loss: 0.2312\n",
      "Epoch 716/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1521 - val_loss: 0.2361\n",
      "Epoch 717/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1516 - val_loss: 0.2280\n",
      "Epoch 718/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1499 - val_loss: 0.2260\n",
      "Epoch 719/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.1493 - val_loss: 0.2339\n",
      "Epoch 720/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1472 - val_loss: 0.2253\n",
      "Epoch 721/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1448 - val_loss: 0.2457\n",
      "Epoch 722/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1533 - val_loss: 0.3033\n",
      "Epoch 723/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1693 - val_loss: 0.3186\n",
      "Epoch 724/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1616 - val_loss: 0.2992\n",
      "Epoch 725/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1538 - val_loss: 0.2738\n",
      "Epoch 726/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1488 - val_loss: 0.3098\n",
      "Epoch 727/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.2290 - val_loss: 0.3709\n",
      "Epoch 728/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.2239 - val_loss: 0.2782\n",
      "Epoch 729/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1831 - val_loss: 0.2490\n",
      "Epoch 730/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1720 - val_loss: 0.2424\n",
      "Epoch 731/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1601 - val_loss: 0.2345\n",
      "Epoch 732/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1554 - val_loss: 0.2391\n",
      "Epoch 733/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1543 - val_loss: 0.2302\n",
      "Epoch 734/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1500 - val_loss: 0.2307\n",
      "Epoch 735/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1504 - val_loss: 0.2251\n",
      "Epoch 736/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1459 - val_loss: 0.2261\n",
      "Epoch 737/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1425 - val_loss: 0.2273\n",
      "Epoch 738/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1423 - val_loss: 0.2145\n",
      "Epoch 739/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1417 - val_loss: 0.2167\n",
      "Epoch 740/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1404 - val_loss: 0.2232\n",
      "Epoch 741/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1398 - val_loss: 0.2276\n",
      "Epoch 742/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1401 - val_loss: 0.2285\n",
      "Epoch 743/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1396 - val_loss: 0.2304\n",
      "Epoch 744/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1413 - val_loss: 0.2240\n",
      "Epoch 745/1500\n",
      "5/5 [==============================] - 4s 774ms/step - loss: 0.1395 - val_loss: 0.2251\n",
      "Epoch 746/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1401 - val_loss: 0.2395\n",
      "Epoch 747/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1426 - val_loss: 0.2400\n",
      "Epoch 748/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1526 - val_loss: 0.2728\n",
      "Epoch 749/1500\n",
      "5/5 [==============================] - 4s 807ms/step - loss: 0.1675 - val_loss: 0.2358\n",
      "Epoch 750/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1640 - val_loss: 0.2355\n",
      "Epoch 751/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.1542 - val_loss: 0.2395\n",
      "Epoch 752/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1505 - val_loss: 0.2390\n",
      "Epoch 753/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1511 - val_loss: 0.2608\n",
      "Epoch 754/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1525 - val_loss: 0.2335\n",
      "Epoch 755/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1451 - val_loss: 0.2529\n",
      "Epoch 756/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1435 - val_loss: 0.2353\n",
      "Epoch 757/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1415 - val_loss: 0.2357\n",
      "Epoch 758/1500\n",
      "5/5 [==============================] - 4s 784ms/step - loss: 0.1388 - val_loss: 0.2364\n",
      "Epoch 759/1500\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 0.1394 - val_loss: 0.2261\n",
      "Epoch 760/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1360 - val_loss: 0.2278\n",
      "Epoch 761/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1398 - val_loss: 0.2349\n",
      "Epoch 762/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.2303 - val_loss: 0.3000\n",
      "Epoch 763/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.2488 - val_loss: 0.2079\n",
      "Epoch 764/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1860 - val_loss: 0.2905\n",
      "Epoch 765/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.2093 - val_loss: 0.2964\n",
      "Epoch 766/1500\n",
      "5/5 [==============================] - 4s 811ms/step - loss: 0.1955 - val_loss: 0.2739\n",
      "Epoch 767/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1903 - val_loss: 0.2706\n",
      "Epoch 768/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1906 - val_loss: 0.2804\n",
      "Epoch 769/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1869 - val_loss: 0.2749\n",
      "Epoch 770/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1747 - val_loss: 0.2688\n",
      "Epoch 771/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1686 - val_loss: 0.2530\n",
      "Epoch 772/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1647 - val_loss: 0.2352\n",
      "Epoch 773/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1620 - val_loss: 0.2308\n",
      "Epoch 774/1500\n",
      "5/5 [==============================] - 5s 957ms/step - loss: 0.1591 - val_loss: 0.2460\n",
      "Epoch 775/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.2017 - val_loss: 0.2832\n",
      "Epoch 776/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.2060 - val_loss: 0.2821\n",
      "Epoch 777/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.1938 - val_loss: 0.2568\n",
      "Epoch 778/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1793 - val_loss: 0.2670\n",
      "Epoch 779/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1846 - val_loss: 0.2764\n",
      "Epoch 780/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1879 - val_loss: 0.2592\n",
      "Epoch 781/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1811 - val_loss: 0.2566\n",
      "Epoch 782/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.1721 - val_loss: 0.2464\n",
      "Epoch 783/1500\n",
      "5/5 [==============================] - 4s 849ms/step - loss: 0.1640 - val_loss: 0.2384\n",
      "Epoch 784/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1575 - val_loss: 0.2509\n",
      "Epoch 785/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1736 - val_loss: 0.2890\n",
      "Epoch 786/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1771 - val_loss: 0.2618\n",
      "Epoch 787/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1737 - val_loss: 0.2477\n",
      "Epoch 788/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.1626 - val_loss: 0.2414\n",
      "Epoch 789/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1546 - val_loss: 0.2349\n",
      "Epoch 790/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1525 - val_loss: 0.2208\n",
      "Epoch 791/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1484 - val_loss: 0.2147\n",
      "Epoch 792/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1466 - val_loss: 0.2117\n",
      "Epoch 793/1500\n",
      "5/5 [==============================] - 4s 860ms/step - loss: 0.1440 - val_loss: 0.2104\n",
      "Epoch 794/1500\n",
      "5/5 [==============================] - 4s 896ms/step - loss: 0.1408 - val_loss: 0.2154\n",
      "Epoch 795/1500\n",
      "5/5 [==============================] - 5s 966ms/step - loss: 0.1440 - val_loss: 0.2297\n",
      "Epoch 796/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.1426 - val_loss: 0.2244\n",
      "Epoch 797/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1399 - val_loss: 0.2205\n",
      "Epoch 798/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1388 - val_loss: 0.2188\n",
      "Epoch 799/1500\n",
      "5/5 [==============================] - 4s 783ms/step - loss: 0.1377 - val_loss: 0.2241\n",
      "Epoch 800/1500\n",
      "5/5 [==============================] - 4s 785ms/step - loss: 0.1400 - val_loss: 0.2284\n",
      "Epoch 801/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.1397 - val_loss: 0.2298\n",
      "Epoch 802/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1406 - val_loss: 0.2217\n",
      "Epoch 803/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1414 - val_loss: 0.2395\n",
      "Epoch 804/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.1470 - val_loss: 0.2209\n",
      "Epoch 805/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.1475 - val_loss: 0.2124\n",
      "Epoch 806/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1594 - val_loss: 0.2178\n",
      "Epoch 807/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1531 - val_loss: 0.2151\n",
      "Epoch 808/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1458 - val_loss: 0.2162\n",
      "Epoch 809/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1441 - val_loss: 0.2095\n",
      "Epoch 810/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1381 - val_loss: 0.2127\n",
      "Epoch 811/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1367 - val_loss: 0.2056\n",
      "Epoch 812/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1417 - val_loss: 0.2072\n",
      "Epoch 813/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1463 - val_loss: 0.2197\n",
      "Epoch 814/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1430 - val_loss: 0.2165\n",
      "Epoch 815/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1424 - val_loss: 0.2209\n",
      "Epoch 816/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1368 - val_loss: 0.2150\n",
      "Epoch 817/1500\n",
      "5/5 [==============================] - 4s 773ms/step - loss: 0.1361 - val_loss: 0.2138\n",
      "Epoch 818/1500\n",
      "5/5 [==============================] - 4s 784ms/step - loss: 0.1468 - val_loss: 0.2095\n",
      "Epoch 819/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1406 - val_loss: 0.2160\n",
      "Epoch 820/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1363 - val_loss: 0.2078\n",
      "Epoch 821/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1358 - val_loss: 0.2159\n",
      "Epoch 822/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1337 - val_loss: 0.2173\n",
      "Epoch 823/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1331 - val_loss: 0.2169\n",
      "Epoch 824/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1335 - val_loss: 0.2158\n",
      "Epoch 825/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1417 - val_loss: 0.2155\n",
      "Epoch 826/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1503 - val_loss: 0.2292\n",
      "Epoch 827/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1421 - val_loss: 0.2075\n",
      "Epoch 828/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1425 - val_loss: 0.2153\n",
      "Epoch 829/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1418 - val_loss: 0.2157\n",
      "Epoch 830/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1430 - val_loss: 0.2308\n",
      "Epoch 831/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1519 - val_loss: 0.2248\n",
      "Epoch 832/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.1510 - val_loss: 0.2305\n",
      "Epoch 833/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1429 - val_loss: 0.2173\n",
      "Epoch 834/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1400 - val_loss: 0.2187\n",
      "Epoch 835/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1382 - val_loss: 0.2163\n",
      "Epoch 836/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1324 - val_loss: 0.2107\n",
      "Epoch 837/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1336 - val_loss: 0.2327\n",
      "Epoch 838/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1356 - val_loss: 0.2115\n",
      "Epoch 839/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1358 - val_loss: 0.2248\n",
      "Epoch 840/1500\n",
      "5/5 [==============================] - 4s 771ms/step - loss: 0.1350 - val_loss: 0.2227\n",
      "Epoch 841/1500\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 0.1322 - val_loss: 0.2230\n",
      "Epoch 842/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1327 - val_loss: 0.2322\n",
      "Epoch 843/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1654 - val_loss: 0.2814\n",
      "Epoch 844/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1710 - val_loss: 0.2528\n",
      "Epoch 845/1500\n",
      "5/5 [==============================] - 4s 786ms/step - loss: 0.1576 - val_loss: 0.2522\n",
      "Epoch 846/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1512 - val_loss: 0.2314\n",
      "Epoch 847/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1749 - val_loss: 0.2403\n",
      "Epoch 848/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1608 - val_loss: 0.2140\n",
      "Epoch 849/1500\n",
      "5/5 [==============================] - 4s 786ms/step - loss: 0.1498 - val_loss: 0.2188\n",
      "Epoch 850/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1427 - val_loss: 0.2179\n",
      "Epoch 851/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1417 - val_loss: 0.2191\n",
      "Epoch 852/1500\n",
      "5/5 [==============================] - 4s 784ms/step - loss: 0.1348 - val_loss: 0.2201\n",
      "Epoch 853/1500\n",
      "5/5 [==============================] - 4s 774ms/step - loss: 0.1332 - val_loss: 0.2362\n",
      "Epoch 854/1500\n",
      "5/5 [==============================] - 4s 778ms/step - loss: 0.1701 - val_loss: 0.2951\n",
      "Epoch 855/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1767 - val_loss: 0.2563\n",
      "Epoch 856/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1545 - val_loss: 0.2379\n",
      "Epoch 857/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1496 - val_loss: 0.2346\n",
      "Epoch 858/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1416 - val_loss: 0.2388\n",
      "Epoch 859/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1813 - val_loss: 0.2618\n",
      "Epoch 860/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1796 - val_loss: 0.2401\n",
      "Epoch 861/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1670 - val_loss: 0.2265\n",
      "Epoch 862/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1533 - val_loss: 0.2180\n",
      "Epoch 863/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.1424 - val_loss: 0.2109\n",
      "Epoch 864/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.1362 - val_loss: 0.2112\n",
      "Epoch 865/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1362 - val_loss: 0.2102\n",
      "Epoch 866/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1342 - val_loss: 0.2154\n",
      "Epoch 867/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1323 - val_loss: 0.2110\n",
      "Epoch 868/1500\n",
      "5/5 [==============================] - 4s 784ms/step - loss: 0.1298 - val_loss: 0.2132\n",
      "Epoch 869/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1297 - val_loss: 0.2192\n",
      "Epoch 870/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1569 - val_loss: 0.3051\n",
      "Epoch 871/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1749 - val_loss: 0.2509\n",
      "Epoch 872/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1549 - val_loss: 0.2351\n",
      "Epoch 873/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1478 - val_loss: 0.2315\n",
      "Epoch 874/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1418 - val_loss: 0.2256\n",
      "Epoch 875/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1393 - val_loss: 0.2282\n",
      "Epoch 876/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1384 - val_loss: 0.2246\n",
      "Epoch 877/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1379 - val_loss: 0.2549\n",
      "Epoch 878/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.2119 - val_loss: 0.3133\n",
      "Epoch 879/1500\n",
      "5/5 [==============================] - 4s 811ms/step - loss: 0.1986 - val_loss: 0.2838\n",
      "Epoch 880/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1820 - val_loss: 0.2723\n",
      "Epoch 881/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1719 - val_loss: 0.2375\n",
      "Epoch 882/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1677 - val_loss: 0.2346\n",
      "Epoch 883/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1608 - val_loss: 0.2165\n",
      "Epoch 884/1500\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 0.1533 - val_loss: 0.2195\n",
      "Epoch 885/1500\n",
      "5/5 [==============================] - 4s 777ms/step - loss: 0.1463 - val_loss: 0.2047\n",
      "Epoch 886/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.1423 - val_loss: 0.2050\n",
      "Epoch 887/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1437 - val_loss: 0.1958\n",
      "Epoch 888/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1408 - val_loss: 0.1955\n",
      "Epoch 889/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1368 - val_loss: 0.1941\n",
      "Epoch 890/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1340 - val_loss: 0.2010\n",
      "Epoch 891/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1307 - val_loss: 0.1975\n",
      "Epoch 892/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1294 - val_loss: 0.2054\n",
      "Epoch 893/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1283 - val_loss: 0.2102\n",
      "Epoch 894/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1271 - val_loss: 0.2120\n",
      "Epoch 895/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1258 - val_loss: 0.2119\n",
      "Epoch 896/1500\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 0.1257 - val_loss: 0.2126\n",
      "Epoch 897/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1242 - val_loss: 0.2094\n",
      "Epoch 898/1500\n",
      "5/5 [==============================] - 4s 786ms/step - loss: 0.1248 - val_loss: 0.2147\n",
      "Epoch 899/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1236 - val_loss: 0.2161\n",
      "Epoch 900/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1342 - val_loss: 0.2189\n",
      "Epoch 901/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1472 - val_loss: 0.2502\n",
      "Epoch 902/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1410 - val_loss: 0.2201\n",
      "Epoch 903/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1366 - val_loss: 0.2380\n",
      "Epoch 904/1500\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.1388 - val_loss: 0.2198\n",
      "Epoch 905/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1320 - val_loss: 0.2213\n",
      "Epoch 906/1500\n",
      "5/5 [==============================] - 4s 766ms/step - loss: 0.1275 - val_loss: 0.2073\n",
      "Epoch 907/1500\n",
      "5/5 [==============================] - 4s 780ms/step - loss: 0.1325 - val_loss: 0.2190\n",
      "Epoch 908/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1288 - val_loss: 0.2150\n",
      "Epoch 909/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1298 - val_loss: 0.2421\n",
      "Epoch 910/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1319 - val_loss: 0.2167\n",
      "Epoch 911/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1409 - val_loss: 0.2429\n",
      "Epoch 912/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1448 - val_loss: 0.2174\n",
      "Epoch 913/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1300 - val_loss: 0.2237\n",
      "Epoch 914/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1308 - val_loss: 0.2246\n",
      "Epoch 915/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1265 - val_loss: 0.2072\n",
      "Epoch 916/1500\n",
      "5/5 [==============================] - 4s 783ms/step - loss: 0.1270 - val_loss: 0.2681\n",
      "Epoch 917/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.2421 - val_loss: 0.3299\n",
      "Epoch 918/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1804 - val_loss: 0.2801\n",
      "Epoch 919/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1796 - val_loss: 0.2673\n",
      "Epoch 920/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1725 - val_loss: 0.2445\n",
      "Epoch 921/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1583 - val_loss: 0.3035\n",
      "Epoch 922/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1715 - val_loss: 0.2735\n",
      "Epoch 923/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1489 - val_loss: 0.2458\n",
      "Epoch 924/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.1550 - val_loss: 0.2273\n",
      "Epoch 925/1500\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 0.1444 - val_loss: 0.2337\n",
      "Epoch 926/1500\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 0.1641 - val_loss: 0.2177\n",
      "Epoch 927/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1552 - val_loss: 0.2018\n",
      "Epoch 928/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1422 - val_loss: 0.2045\n",
      "Epoch 929/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1400 - val_loss: 0.2058\n",
      "Epoch 930/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1362 - val_loss: 0.2144\n",
      "Epoch 931/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1338 - val_loss: 0.2187\n",
      "Epoch 932/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1341 - val_loss: 0.2196\n",
      "Epoch 933/1500\n",
      "5/5 [==============================] - 4s 773ms/step - loss: 0.1348 - val_loss: 0.2207\n",
      "Epoch 934/1500\n",
      "5/5 [==============================] - 4s 784ms/step - loss: 0.1344 - val_loss: 0.2331\n",
      "Epoch 935/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1359 - val_loss: 0.2298\n",
      "Epoch 936/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1323 - val_loss: 0.2229\n",
      "Epoch 937/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1307 - val_loss: 0.2194\n",
      "Epoch 938/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1300 - val_loss: 0.2073\n",
      "Epoch 939/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1277 - val_loss: 0.2243\n",
      "Epoch 940/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1315 - val_loss: 0.2676\n",
      "Epoch 941/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1399 - val_loss: 0.2624\n",
      "Epoch 942/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.1370 - val_loss: 0.2546\n",
      "Epoch 943/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1319 - val_loss: 0.2331\n",
      "Epoch 944/1500\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 0.1495 - val_loss: 0.2303\n",
      "Epoch 945/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1517 - val_loss: 0.2146\n",
      "Epoch 946/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1752 - val_loss: 0.3325\n",
      "Epoch 947/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.2041 - val_loss: 0.2804\n",
      "Epoch 948/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1737 - val_loss: 0.2514\n",
      "Epoch 949/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1576 - val_loss: 0.2403\n",
      "Epoch 950/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1483 - val_loss: 0.2362\n",
      "Epoch 951/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1439 - val_loss: 0.2237\n",
      "Epoch 952/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1398 - val_loss: 0.2138\n",
      "Epoch 953/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1362 - val_loss: 0.2169\n",
      "Epoch 954/1500\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 0.1357 - val_loss: 0.2230\n",
      "Epoch 955/1500\n",
      "5/5 [==============================] - 4s 785ms/step - loss: 0.1351 - val_loss: 0.2162\n",
      "Epoch 956/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1318 - val_loss: 0.2142\n",
      "Epoch 957/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1314 - val_loss: 0.2110\n",
      "Epoch 958/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1275 - val_loss: 0.2160\n",
      "Epoch 959/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1273 - val_loss: 0.2107\n",
      "Epoch 960/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1281 - val_loss: 0.2116\n",
      "Epoch 961/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1272 - val_loss: 0.2106\n",
      "Epoch 962/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1275 - val_loss: 0.2288\n",
      "Epoch 963/1500\n",
      "5/5 [==============================] - 4s 811ms/step - loss: 0.1340 - val_loss: 0.2166\n",
      "Epoch 964/1500\n",
      "5/5 [==============================] - 4s 777ms/step - loss: 0.1345 - val_loss: 0.2200\n",
      "Epoch 965/1500\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 0.1279 - val_loss: 0.2005\n",
      "Epoch 966/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1592 - val_loss: 0.2000\n",
      "Epoch 967/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.1741 - val_loss: 0.1825\n",
      "Epoch 968/1500\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.1553 - val_loss: 0.1742\n",
      "Epoch 969/1500\n",
      "5/5 [==============================] - 4s 765ms/step - loss: 0.1669 - val_loss: 0.1910\n",
      "Epoch 970/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1572 - val_loss: 0.1978\n",
      "Epoch 971/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.1439 - val_loss: 0.2005\n",
      "Epoch 972/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1382 - val_loss: 0.1936\n",
      "Epoch 973/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1326 - val_loss: 0.1938\n",
      "Epoch 974/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1289 - val_loss: 0.1977\n",
      "Epoch 975/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.1292 - val_loss: 0.2005\n",
      "Epoch 976/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1250 - val_loss: 0.2080\n",
      "Epoch 977/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1237 - val_loss: 0.2069\n",
      "Epoch 978/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1231 - val_loss: 0.2077\n",
      "Epoch 979/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1210 - val_loss: 0.2046\n",
      "Epoch 980/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1223 - val_loss: 0.2083\n",
      "Epoch 981/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1517 - val_loss: 0.2236\n",
      "Epoch 982/1500\n",
      "5/5 [==============================] - 4s 777ms/step - loss: 0.1753 - val_loss: 0.1810\n",
      "Epoch 983/1500\n",
      "5/5 [==============================] - 4s 782ms/step - loss: 0.1488 - val_loss: 0.1950\n",
      "Epoch 984/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1528 - val_loss: 0.1939\n",
      "Epoch 985/1500\n",
      "5/5 [==============================] - 4s 807ms/step - loss: 0.1430 - val_loss: 0.2175\n",
      "Epoch 986/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1539 - val_loss: 0.2118\n",
      "Epoch 987/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1770 - val_loss: 0.3141\n",
      "Epoch 988/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.2266 - val_loss: 0.2851\n",
      "Epoch 989/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.2011 - val_loss: 0.2542\n",
      "Epoch 990/1500\n",
      "5/5 [==============================] - 4s 781ms/step - loss: 0.1807 - val_loss: 0.2513\n",
      "Epoch 991/1500\n",
      "5/5 [==============================] - 4s 785ms/step - loss: 0.1619 - val_loss: 0.2492\n",
      "Epoch 992/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1524 - val_loss: 0.2334\n",
      "Epoch 993/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1460 - val_loss: 0.2281\n",
      "Epoch 994/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1403 - val_loss: 0.2155\n",
      "Epoch 995/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1409 - val_loss: 0.2114\n",
      "Epoch 996/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1374 - val_loss: 0.2057\n",
      "Epoch 997/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1333 - val_loss: 0.2043\n",
      "Epoch 998/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1331 - val_loss: 0.2019\n",
      "Epoch 999/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1329 - val_loss: 0.2008\n",
      "Epoch 1000/1500\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 0.1293 - val_loss: 0.2028\n",
      "Epoch 1001/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1270 - val_loss: 0.2005\n",
      "Epoch 1002/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1267 - val_loss: 0.2032\n",
      "Epoch 1003/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1262 - val_loss: 0.2079\n",
      "Epoch 1004/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1244 - val_loss: 0.2080\n",
      "Epoch 1005/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1229 - val_loss: 0.2091\n",
      "Epoch 1006/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1217 - val_loss: 0.2267\n",
      "Epoch 1007/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1554 - val_loss: 0.2725\n",
      "Epoch 1008/1500\n",
      "5/5 [==============================] - 4s 772ms/step - loss: 0.1591 - val_loss: 0.2380\n",
      "Epoch 1009/1500\n",
      "5/5 [==============================] - 4s 776ms/step - loss: 0.1457 - val_loss: 0.2280\n",
      "Epoch 1010/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1379 - val_loss: 0.2477\n",
      "Epoch 1011/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1425 - val_loss: 0.2542\n",
      "Epoch 1012/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1543 - val_loss: 0.2209\n",
      "Epoch 1013/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1388 - val_loss: 0.1970\n",
      "Epoch 1014/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1346 - val_loss: 0.1901\n",
      "Epoch 1015/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1307 - val_loss: 0.1892\n",
      "Epoch 1016/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1289 - val_loss: 0.2039\n",
      "Epoch 1017/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1278 - val_loss: 0.2087\n",
      "Epoch 1018/1500\n",
      "5/5 [==============================] - 4s 771ms/step - loss: 0.1252 - val_loss: 0.2092\n",
      "Epoch 1019/1500\n",
      "5/5 [==============================] - 4s 782ms/step - loss: 0.1244 - val_loss: 0.2024\n",
      "Epoch 1020/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1241 - val_loss: 0.2086\n",
      "Epoch 1021/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.1241 - val_loss: 0.2098\n",
      "Epoch 1022/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1211 - val_loss: 0.2322\n",
      "Epoch 1023/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1664 - val_loss: 0.2538\n",
      "Epoch 1024/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1618 - val_loss: 0.2329\n",
      "Epoch 1025/1500\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 0.1672 - val_loss: 0.2418\n",
      "Epoch 1026/1500\n",
      "5/5 [==============================] - 4s 777ms/step - loss: 0.1667 - val_loss: 0.2274\n",
      "Epoch 1027/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.1578 - val_loss: 0.2031\n",
      "Epoch 1028/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1483 - val_loss: 0.2047\n",
      "Epoch 1029/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1428 - val_loss: 0.2094\n",
      "Epoch 1030/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1373 - val_loss: 0.2100\n",
      "Epoch 1031/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1317 - val_loss: 0.2050\n",
      "Epoch 1032/1500\n",
      "5/5 [==============================] - 4s 777ms/step - loss: 0.1294 - val_loss: 0.2035\n",
      "Epoch 1033/1500\n",
      "5/5 [==============================] - 4s 778ms/step - loss: 0.1263 - val_loss: 0.2020\n",
      "Epoch 1034/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1244 - val_loss: 0.2135\n",
      "Epoch 1035/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1803 - val_loss: 0.2535\n",
      "Epoch 1036/1500\n",
      "5/5 [==============================] - 4s 788ms/step - loss: 0.1504 - val_loss: 0.2539\n",
      "Epoch 1037/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1453 - val_loss: 0.2508\n",
      "Epoch 1038/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1377 - val_loss: 0.2333\n",
      "Epoch 1039/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1297 - val_loss: 0.2194\n",
      "Epoch 1040/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1246 - val_loss: 0.2106\n",
      "Epoch 1041/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1225 - val_loss: 0.2042\n",
      "Epoch 1042/1500\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 0.1207 - val_loss: 0.2010\n",
      "Epoch 1043/1500\n",
      "5/5 [==============================] - 4s 782ms/step - loss: 0.1191 - val_loss: 0.1975\n",
      "Epoch 1044/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1583 - val_loss: 0.1949\n",
      "Epoch 1045/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1541 - val_loss: 0.1837\n",
      "Epoch 1046/1500\n",
      "5/5 [==============================] - 4s 909ms/step - loss: 0.1489 - val_loss: 0.1697\n",
      "Epoch 1047/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1500 - val_loss: 0.1784\n",
      "Epoch 1048/1500\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 0.1427 - val_loss: 0.1867\n",
      "Epoch 1049/1500\n",
      "5/5 [==============================] - 4s 773ms/step - loss: 0.1326 - val_loss: 0.1987\n",
      "Epoch 1050/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1302 - val_loss: 0.1917\n",
      "Epoch 1051/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1216 - val_loss: 0.1976\n",
      "Epoch 1052/1500\n",
      "5/5 [==============================] - 4s 789ms/step - loss: 0.1222 - val_loss: 0.2068\n",
      "Epoch 1053/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.1226 - val_loss: 0.2220\n",
      "Epoch 1054/1500\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.1216 - val_loss: 0.2159\n",
      "Epoch 1055/1500\n",
      "5/5 [==============================] - 4s 770ms/step - loss: 0.1203 - val_loss: 0.2094\n",
      "Epoch 1056/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1277 - val_loss: 0.2192\n",
      "Epoch 1057/1500\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.1356 - val_loss: 0.1977\n",
      "Epoch 1058/1500\n",
      "5/5 [==============================] - 4s 801ms/step - loss: 0.1280 - val_loss: 0.1854\n",
      "Epoch 1059/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1268 - val_loss: 0.1880\n",
      "Epoch 1060/1500\n",
      "5/5 [==============================] - 4s 800ms/step - loss: 0.1213 - val_loss: 0.1968\n",
      "Epoch 1061/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.1183 - val_loss: 0.2264\n",
      "Epoch 1062/1500\n",
      "5/5 [==============================] - 4s 782ms/step - loss: 0.1361 - val_loss: 0.2756\n",
      "Epoch 1063/1500\n",
      "5/5 [==============================] - 4s 776ms/step - loss: 0.1438 - val_loss: 0.2368\n",
      "Epoch 1064/1500\n",
      "5/5 [==============================] - 4s 783ms/step - loss: 0.1312 - val_loss: 0.2201\n",
      "Epoch 1065/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1254 - val_loss: 0.2139\n",
      "Epoch 1066/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1224 - val_loss: 0.2150\n",
      "Epoch 1067/1500\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.1198 - val_loss: 0.2099\n",
      "Epoch 1068/1500\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.1168 - val_loss: 0.2089\n",
      "Epoch 1069/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1167 - val_loss: 0.2095\n",
      "Epoch 1070/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1162 - val_loss: 0.2126\n",
      "Epoch 1071/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.2078 - val_loss: 0.2948\n",
      "Epoch 1072/1500\n",
      "5/5 [==============================] - 4s 777ms/step - loss: 0.4036 - val_loss: 0.5365\n",
      "Epoch 1073/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.3421 - val_loss: 0.3196\n",
      "Epoch 1074/1500\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.2360 - val_loss: 0.2908\n",
      "Epoch 1075/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.2137 - val_loss: 0.2746\n",
      "Epoch 1076/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1995 - val_loss: 0.2645\n",
      "Epoch 1077/1500\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1818 - val_loss: 0.2477\n",
      "Epoch 1078/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.1720 - val_loss: 0.2429\n",
      "Epoch 1079/1500\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.1630 - val_loss: 0.2327\n",
      "Epoch 1080/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1551 - val_loss: 0.2298\n",
      "Epoch 1081/1500\n",
      "5/5 [==============================] - 4s 782ms/step - loss: 0.1500 - val_loss: 0.2269\n",
      "Epoch 1082/1500\n",
      "5/5 [==============================] - 4s 786ms/step - loss: 0.1463 - val_loss: 0.2203\n",
      "Epoch 1083/1500\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.1414 - val_loss: 0.2172\n",
      "Epoch 1084/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1394 - val_loss: 0.2148\n",
      "Epoch 1085/1500\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.1373 - val_loss: 0.2151\n",
      "Epoch 1086/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1347 - val_loss: 0.2149\n",
      "Epoch 1087/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1330 - val_loss: 0.2118\n",
      "Epoch 1088/1500\n",
      "5/5 [==============================] - 4s 790ms/step - loss: 0.1304 - val_loss: 0.2107\n",
      "Epoch 1089/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1291 - val_loss: 0.2117\n",
      "Epoch 1090/1500\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.1276 - val_loss: 0.2105\n",
      "Epoch 1091/1500\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.1263 - val_loss: 0.2097\n",
      "Epoch 1092/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1253 - val_loss: 0.2204\n",
      "Epoch 1093/1500\n",
      "5/5 [==============================] - 4s 863ms/step - loss: 0.1405 - val_loss: 0.2531\n",
      "Epoch 1094/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1511 - val_loss: 0.2271\n",
      "Epoch 1095/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1403 - val_loss: 0.2021\n",
      "Epoch 1096/1500\n",
      "5/5 [==============================] - 4s 855ms/step - loss: 0.1647 - val_loss: 0.2680\n",
      "Epoch 1097/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1743 - val_loss: 0.2476\n",
      "Epoch 1098/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1569 - val_loss: 0.2180\n",
      "Epoch 1099/1500\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.1498 - val_loss: 0.2147\n",
      "Epoch 1100/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1445 - val_loss: 0.2152\n",
      "Epoch 1101/1500\n",
      "5/5 [==============================] - 4s 811ms/step - loss: 0.1446 - val_loss: 0.2261\n",
      "Epoch 1102/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1444 - val_loss: 0.2159\n",
      "Epoch 1103/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1342 - val_loss: 0.2042\n",
      "Epoch 1104/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1286 - val_loss: 0.2006\n",
      "Epoch 1105/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1279 - val_loss: 0.2116\n",
      "Epoch 1106/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.1437 - val_loss: 0.2605\n",
      "Epoch 1107/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1514 - val_loss: 0.2264\n",
      "Epoch 1108/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1361 - val_loss: 0.2127\n",
      "Epoch 1109/1500\n",
      "5/5 [==============================] - 4s 859ms/step - loss: 0.1305 - val_loss: 0.2065\n",
      "Epoch 1110/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1264 - val_loss: 0.2029\n",
      "Epoch 1111/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1232 - val_loss: 0.2022\n",
      "Epoch 1112/1500\n",
      "5/5 [==============================] - 4s 846ms/step - loss: 0.1238 - val_loss: 0.2037\n",
      "Epoch 1113/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1253 - val_loss: 0.2162\n",
      "Epoch 1114/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1242 - val_loss: 0.2142\n",
      "Epoch 1115/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1225 - val_loss: 0.2097\n",
      "Epoch 1116/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1193 - val_loss: 0.2060\n",
      "Epoch 1117/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1189 - val_loss: 0.2044\n",
      "Epoch 1118/1500\n",
      "5/5 [==============================] - 4s 873ms/step - loss: 0.1177 - val_loss: 0.2035\n",
      "Epoch 1119/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1166 - val_loss: 0.2047\n",
      "Epoch 1120/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.1176 - val_loss: 0.2037\n",
      "Epoch 1121/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1171 - val_loss: 0.2036\n",
      "Epoch 1122/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1162 - val_loss: 0.2032\n",
      "Epoch 1123/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1153 - val_loss: 0.2024\n",
      "Epoch 1124/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1193 - val_loss: 0.2155\n",
      "Epoch 1125/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.1292 - val_loss: 0.2670\n",
      "Epoch 1126/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1358 - val_loss: 0.2650\n",
      "Epoch 1127/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1319 - val_loss: 0.2547\n",
      "Epoch 1128/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.1255 - val_loss: 0.2393\n",
      "Epoch 1129/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1304 - val_loss: 0.2119\n",
      "Epoch 1130/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1236 - val_loss: 0.1967\n",
      "Epoch 1131/1500\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.1252 - val_loss: 0.1956\n",
      "Epoch 1132/1500\n",
      "5/5 [==============================] - 4s 855ms/step - loss: 0.1233 - val_loss: 0.2008\n",
      "Epoch 1133/1500\n",
      "5/5 [==============================] - 4s 852ms/step - loss: 0.1208 - val_loss: 0.2046\n",
      "Epoch 1134/1500\n",
      "5/5 [==============================] - 4s 872ms/step - loss: 0.1211 - val_loss: 0.2083\n",
      "Epoch 1135/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1281 - val_loss: 0.2141\n",
      "Epoch 1136/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1284 - val_loss: 0.2037\n",
      "Epoch 1137/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.1232 - val_loss: 0.1949\n",
      "Epoch 1138/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1232 - val_loss: 0.1856\n",
      "Epoch 1139/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1454 - val_loss: 0.2269\n",
      "Epoch 1140/1500\n",
      "5/5 [==============================] - 4s 857ms/step - loss: 0.1812 - val_loss: 0.1938\n",
      "Epoch 1141/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1505 - val_loss: 0.1788\n",
      "Epoch 1142/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1345 - val_loss: 0.1874\n",
      "Epoch 1143/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1293 - val_loss: 0.1904\n",
      "Epoch 1144/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1232 - val_loss: 0.1887\n",
      "Epoch 1145/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.1206 - val_loss: 0.1947\n",
      "Epoch 1146/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1190 - val_loss: 0.1987\n",
      "Epoch 1147/1500\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.1167 - val_loss: 0.1965\n",
      "Epoch 1148/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1151 - val_loss: 0.1948\n",
      "Epoch 1149/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1145 - val_loss: 0.1946\n",
      "Epoch 1150/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1131 - val_loss: 0.1993\n",
      "Epoch 1151/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1128 - val_loss: 0.2012\n",
      "Epoch 1152/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1125 - val_loss: 0.2056\n",
      "Epoch 1153/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.1118 - val_loss: 0.2137\n",
      "Epoch 1154/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.1136 - val_loss: 0.2501\n",
      "Epoch 1155/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1246 - val_loss: 0.2418\n",
      "Epoch 1156/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1199 - val_loss: 0.2343\n",
      "Epoch 1157/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.1171 - val_loss: 0.2223\n",
      "Epoch 1158/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1213 - val_loss: 0.2177\n",
      "Epoch 1159/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1185 - val_loss: 0.2069\n",
      "Epoch 1160/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.1155 - val_loss: 0.2066\n",
      "Epoch 1161/1500\n",
      "5/5 [==============================] - 4s 807ms/step - loss: 0.1131 - val_loss: 0.2068\n",
      "Epoch 1162/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1149 - val_loss: 0.2092\n",
      "Epoch 1163/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1120 - val_loss: 0.2082\n",
      "Epoch 1164/1500\n",
      "5/5 [==============================] - 4s 850ms/step - loss: 0.1141 - val_loss: 0.2100\n",
      "Epoch 1165/1500\n",
      "5/5 [==============================] - 4s 858ms/step - loss: 0.1110 - val_loss: 0.2052\n",
      "Epoch 1166/1500\n",
      "5/5 [==============================] - 4s 867ms/step - loss: 0.1099 - val_loss: 0.2129\n",
      "Epoch 1167/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1098 - val_loss: 0.2077\n",
      "Epoch 1168/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1111 - val_loss: 0.2270\n",
      "Epoch 1169/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1105 - val_loss: 0.2190\n",
      "Epoch 1170/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1096 - val_loss: 0.2207\n",
      "Epoch 1171/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1115 - val_loss: 0.2097\n",
      "Epoch 1172/1500\n",
      "5/5 [==============================] - 4s 811ms/step - loss: 0.1077 - val_loss: 0.2135\n",
      "Epoch 1173/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1067 - val_loss: 0.2045\n",
      "Epoch 1174/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1077 - val_loss: 0.2111\n",
      "Epoch 1175/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1099 - val_loss: 0.2015\n",
      "Epoch 1176/1500\n",
      "5/5 [==============================] - 4s 854ms/step - loss: 0.1072 - val_loss: 0.2123\n",
      "Epoch 1177/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1482 - val_loss: 0.2365\n",
      "Epoch 1178/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1277 - val_loss: 0.2349\n",
      "Epoch 1179/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1218 - val_loss: 0.2200\n",
      "Epoch 1180/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1195 - val_loss: 0.2225\n",
      "Epoch 1181/1500\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.1172 - val_loss: 0.2173\n",
      "Epoch 1182/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1183 - val_loss: 0.2144\n",
      "Epoch 1183/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1413 - val_loss: 0.2057\n",
      "Epoch 1184/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1340 - val_loss: 0.1935\n",
      "Epoch 1185/1500\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.1218 - val_loss: 0.2099\n",
      "Epoch 1186/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1436 - val_loss: 0.2668\n",
      "Epoch 1187/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1532 - val_loss: 0.2615\n",
      "Epoch 1188/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1922 - val_loss: 0.3028\n",
      "Epoch 1189/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1637 - val_loss: 0.2930\n",
      "Epoch 1190/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.1603 - val_loss: 0.2672\n",
      "Epoch 1191/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1381 - val_loss: 0.2367\n",
      "Epoch 1192/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1248 - val_loss: 0.2107\n",
      "Epoch 1193/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1254 - val_loss: 0.1983\n",
      "Epoch 1194/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1305 - val_loss: 0.1879\n",
      "Epoch 1195/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1303 - val_loss: 0.2043\n",
      "Epoch 1196/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1256 - val_loss: 0.2066\n",
      "Epoch 1197/1500\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.1243 - val_loss: 0.1984\n",
      "Epoch 1198/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1188 - val_loss: 0.2034\n",
      "Epoch 1199/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1166 - val_loss: 0.1957\n",
      "Epoch 1200/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1228 - val_loss: 0.1969\n",
      "Epoch 1201/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1288 - val_loss: 0.1943\n",
      "Epoch 1202/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.1211 - val_loss: 0.2063\n",
      "Epoch 1203/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1152 - val_loss: 0.2031\n",
      "Epoch 1204/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1141 - val_loss: 0.2015\n",
      "Epoch 1205/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1126 - val_loss: 0.2012\n",
      "Epoch 1206/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1103 - val_loss: 0.2017\n",
      "Epoch 1207/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1092 - val_loss: 0.2021\n",
      "Epoch 1208/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1101 - val_loss: 0.2020\n",
      "Epoch 1209/1500\n",
      "5/5 [==============================] - 4s 805ms/step - loss: 0.1114 - val_loss: 0.2048\n",
      "Epoch 1210/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1099 - val_loss: 0.2092\n",
      "Epoch 1211/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1078 - val_loss: 0.2027\n",
      "Epoch 1212/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.1072 - val_loss: 0.1997\n",
      "Epoch 1213/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1081 - val_loss: 0.2068\n",
      "Epoch 1214/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.1071 - val_loss: 0.2068\n",
      "Epoch 1215/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1055 - val_loss: 0.2062\n",
      "Epoch 1216/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1065 - val_loss: 0.2125\n",
      "Epoch 1217/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.1046 - val_loss: 0.2153\n",
      "Epoch 1218/1500\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.1049 - val_loss: 0.2219\n",
      "Epoch 1219/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1059 - val_loss: 0.2114\n",
      "Epoch 1220/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.1048 - val_loss: 0.2157\n",
      "Epoch 1221/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1054 - val_loss: 0.2063\n",
      "Epoch 1222/1500\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.1053 - val_loss: 0.2204\n",
      "Epoch 1223/1500\n",
      "5/5 [==============================] - 4s 862ms/step - loss: 0.1049 - val_loss: 0.2129\n",
      "Epoch 1224/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1047 - val_loss: 0.2182\n",
      "Epoch 1225/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1041 - val_loss: 0.2065\n",
      "Epoch 1226/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1290 - val_loss: 0.2405\n",
      "Epoch 1227/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1540 - val_loss: 0.2243\n",
      "Epoch 1228/1500\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.1328 - val_loss: 0.2111\n",
      "Epoch 1229/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.1238 - val_loss: 0.1997\n",
      "Epoch 1230/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1167 - val_loss: 0.2124\n",
      "Epoch 1231/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.1148 - val_loss: 0.2040\n",
      "Epoch 1232/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1113 - val_loss: 0.2116\n",
      "Epoch 1233/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1093 - val_loss: 0.2117\n",
      "Epoch 1234/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1213 - val_loss: 0.2185\n",
      "Epoch 1235/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1165 - val_loss: 0.2024\n",
      "Epoch 1236/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.1102 - val_loss: 0.1975\n",
      "Epoch 1237/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1111 - val_loss: 0.1988\n",
      "Epoch 1238/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1101 - val_loss: 0.1981\n",
      "Epoch 1239/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.1069 - val_loss: 0.2070\n",
      "Epoch 1240/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1046 - val_loss: 0.1995\n",
      "Epoch 1241/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.1039 - val_loss: 0.1952\n",
      "Epoch 1242/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1039 - val_loss: 0.1976\n",
      "Epoch 1243/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1017 - val_loss: 0.2029\n",
      "Epoch 1244/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1044 - val_loss: 0.2148\n",
      "Epoch 1245/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1057 - val_loss: 0.2141\n",
      "Epoch 1246/1500\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.1050 - val_loss: 0.2295\n",
      "Epoch 1247/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.1144 - val_loss: 0.2094\n",
      "Epoch 1248/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.1057 - val_loss: 0.2154\n",
      "Epoch 1249/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1032 - val_loss: 0.2123\n",
      "Epoch 1250/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1012 - val_loss: 0.2121\n",
      "Epoch 1251/1500\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.1009 - val_loss: 0.2149\n",
      "Epoch 1252/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.0997 - val_loss: 0.2097\n",
      "Epoch 1253/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.0984 - val_loss: 0.2114\n",
      "Epoch 1254/1500\n",
      "5/5 [==============================] - 4s 794ms/step - loss: 0.0975 - val_loss: 0.2115\n",
      "Epoch 1255/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.0982 - val_loss: 0.2160\n",
      "Epoch 1256/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.1004 - val_loss: 0.2236\n",
      "Epoch 1257/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1055 - val_loss: 0.2130\n",
      "Epoch 1258/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.1042 - val_loss: 0.2289\n",
      "Epoch 1259/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1199 - val_loss: 0.2313\n",
      "Epoch 1260/1500\n",
      "5/5 [==============================] - 4s 846ms/step - loss: 0.1147 - val_loss: 0.2071\n",
      "Epoch 1261/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1126 - val_loss: 0.1963\n",
      "Epoch 1262/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1062 - val_loss: 0.1970\n",
      "Epoch 1263/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1011 - val_loss: 0.2058\n",
      "Epoch 1264/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.1008 - val_loss: 0.2064\n",
      "Epoch 1265/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.0994 - val_loss: 0.2061\n",
      "Epoch 1266/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.0995 - val_loss: 0.2063\n",
      "Epoch 1267/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.0963 - val_loss: 0.2126\n",
      "Epoch 1268/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.0975 - val_loss: 0.2097\n",
      "Epoch 1269/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.0966 - val_loss: 0.2116\n",
      "Epoch 1270/1500\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.0986 - val_loss: 0.2157\n",
      "Epoch 1271/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1019 - val_loss: 0.2424\n",
      "Epoch 1272/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1109 - val_loss: 0.2221\n",
      "Epoch 1273/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.1061 - val_loss: 0.2426\n",
      "Epoch 1274/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1096 - val_loss: 0.2216\n",
      "Epoch 1275/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1026 - val_loss: 0.2305\n",
      "Epoch 1276/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1069 - val_loss: 0.2506\n",
      "Epoch 1277/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.2128 - val_loss: 0.2239\n",
      "Epoch 1278/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.2012 - val_loss: 0.1885\n",
      "Epoch 1279/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.1565 - val_loss: 0.1798\n",
      "Epoch 1280/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1402 - val_loss: 0.1910\n",
      "Epoch 1281/1500\n",
      "5/5 [==============================] - 4s 849ms/step - loss: 0.1424 - val_loss: 0.2958\n",
      "Epoch 1282/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1607 - val_loss: 0.2660\n",
      "Epoch 1283/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1734 - val_loss: 0.2768\n",
      "Epoch 1284/1500\n",
      "5/5 [==============================] - 4s 876ms/step - loss: 0.1642 - val_loss: 0.2142\n",
      "Epoch 1285/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1423 - val_loss: 0.2162\n",
      "Epoch 1286/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1339 - val_loss: 0.2012\n",
      "Epoch 1287/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.1240 - val_loss: 0.1876\n",
      "Epoch 1288/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1199 - val_loss: 0.1887\n",
      "Epoch 1289/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1160 - val_loss: 0.2028\n",
      "Epoch 1290/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.1386 - val_loss: 0.2487\n",
      "Epoch 1291/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1574 - val_loss: 0.2424\n",
      "Epoch 1292/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1756 - val_loss: 0.3109\n",
      "Epoch 1293/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.2238 - val_loss: 0.3174\n",
      "Epoch 1294/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1972 - val_loss: 0.3181\n",
      "Epoch 1295/1500\n",
      "5/5 [==============================] - 4s 871ms/step - loss: 0.1852 - val_loss: 0.2897\n",
      "Epoch 1296/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1666 - val_loss: 0.2616\n",
      "Epoch 1297/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1491 - val_loss: 0.2457\n",
      "Epoch 1298/1500\n",
      "5/5 [==============================] - 4s 854ms/step - loss: 0.1421 - val_loss: 0.2344\n",
      "Epoch 1299/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1332 - val_loss: 0.2174\n",
      "Epoch 1300/1500\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1268 - val_loss: 0.2095\n",
      "Epoch 1301/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.1208 - val_loss: 0.2106\n",
      "Epoch 1302/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1191 - val_loss: 0.2175\n",
      "Epoch 1303/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1179 - val_loss: 0.2088\n",
      "Epoch 1304/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1153 - val_loss: 0.2040\n",
      "Epoch 1305/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1192 - val_loss: 0.2080\n",
      "Epoch 1306/1500\n",
      "5/5 [==============================] - 4s 881ms/step - loss: 0.1225 - val_loss: 0.2002\n",
      "Epoch 1307/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.1159 - val_loss: 0.2062\n",
      "Epoch 1308/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1146 - val_loss: 0.2041\n",
      "Epoch 1309/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.1091 - val_loss: 0.2000\n",
      "Epoch 1310/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.1092 - val_loss: 0.2049\n",
      "Epoch 1311/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.1066 - val_loss: 0.2063\n",
      "Epoch 1312/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1063 - val_loss: 0.2072\n",
      "Epoch 1313/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.1054 - val_loss: 0.2103\n",
      "Epoch 1314/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.1049 - val_loss: 0.2104\n",
      "Epoch 1315/1500\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.1036 - val_loss: 0.2051\n",
      "Epoch 1316/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.1034 - val_loss: 0.2087\n",
      "Epoch 1317/1500\n",
      "5/5 [==============================] - 4s 872ms/step - loss: 0.1040 - val_loss: 0.2083\n",
      "Epoch 1318/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.1032 - val_loss: 0.2100\n",
      "Epoch 1319/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1021 - val_loss: 0.2112\n",
      "Epoch 1320/1500\n",
      "5/5 [==============================] - 4s 852ms/step - loss: 0.1021 - val_loss: 0.2119\n",
      "Epoch 1321/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1009 - val_loss: 0.2089\n",
      "Epoch 1322/1500\n",
      "5/5 [==============================] - 4s 820ms/step - loss: 0.1004 - val_loss: 0.2106\n",
      "Epoch 1323/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1002 - val_loss: 0.2113\n",
      "Epoch 1324/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.0991 - val_loss: 0.2207\n",
      "Epoch 1325/1500\n",
      "5/5 [==============================] - 4s 853ms/step - loss: 0.1004 - val_loss: 0.2124\n",
      "Epoch 1326/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.0994 - val_loss: 0.2182\n",
      "Epoch 1327/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.0995 - val_loss: 0.2159\n",
      "Epoch 1328/1500\n",
      "5/5 [==============================] - 4s 855ms/step - loss: 0.0976 - val_loss: 0.2260\n",
      "Epoch 1329/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.0994 - val_loss: 0.2282\n",
      "Epoch 1330/1500\n",
      "5/5 [==============================] - 4s 854ms/step - loss: 0.0996 - val_loss: 0.2286\n",
      "Epoch 1331/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.0999 - val_loss: 0.2265\n",
      "Epoch 1332/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.0986 - val_loss: 0.2141\n",
      "Epoch 1333/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.0971 - val_loss: 0.2228\n",
      "Epoch 1334/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.0987 - val_loss: 0.2176\n",
      "Epoch 1335/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.0999 - val_loss: 0.2209\n",
      "Epoch 1336/1500\n",
      "5/5 [==============================] - 4s 872ms/step - loss: 0.1011 - val_loss: 0.2147\n",
      "Epoch 1337/1500\n",
      "5/5 [==============================] - 4s 863ms/step - loss: 0.1021 - val_loss: 0.2244\n",
      "Epoch 1338/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.0995 - val_loss: 0.2179\n",
      "Epoch 1339/1500\n",
      "5/5 [==============================] - 4s 850ms/step - loss: 0.0979 - val_loss: 0.2287\n",
      "Epoch 1340/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.0987 - val_loss: 0.2180\n",
      "Epoch 1341/1500\n",
      "5/5 [==============================] - 4s 860ms/step - loss: 0.0987 - val_loss: 0.2208\n",
      "Epoch 1342/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.0968 - val_loss: 0.2151\n",
      "Epoch 1343/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.0967 - val_loss: 0.2665\n",
      "Epoch 1344/1500\n",
      "5/5 [==============================] - 4s 852ms/step - loss: 0.1890 - val_loss: 0.2960\n",
      "Epoch 1345/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.1499 - val_loss: 0.2722\n",
      "Epoch 1346/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1420 - val_loss: 0.2421\n",
      "Epoch 1347/1500\n",
      "5/5 [==============================] - 4s 876ms/step - loss: 0.1218 - val_loss: 0.2007\n",
      "Epoch 1348/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.2138 - val_loss: 0.3232\n",
      "Epoch 1349/1500\n",
      "5/5 [==============================] - 4s 859ms/step - loss: 0.2582 - val_loss: 0.1995\n",
      "Epoch 1350/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1845 - val_loss: 0.1987\n",
      "Epoch 1351/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.1482 - val_loss: 0.2162\n",
      "Epoch 1352/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1529 - val_loss: 0.2099\n",
      "Epoch 1353/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.1378 - val_loss: 0.2212\n",
      "Epoch 1354/1500\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.1322 - val_loss: 0.2180\n",
      "Epoch 1355/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.1257 - val_loss: 0.2208\n",
      "Epoch 1356/1500\n",
      "5/5 [==============================] - 4s 854ms/step - loss: 0.1247 - val_loss: 0.2216\n",
      "Epoch 1357/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1195 - val_loss: 0.2166\n",
      "Epoch 1358/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1159 - val_loss: 0.2054\n",
      "Epoch 1359/1500\n",
      "5/5 [==============================] - 4s 853ms/step - loss: 0.1257 - val_loss: 0.1899\n",
      "Epoch 1360/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.1299 - val_loss: 0.2136\n",
      "Epoch 1361/1500\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.1398 - val_loss: 0.2020\n",
      "Epoch 1362/1500\n",
      "5/5 [==============================] - 4s 855ms/step - loss: 0.1252 - val_loss: 0.2046\n",
      "Epoch 1363/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.1226 - val_loss: 0.2022\n",
      "Epoch 1364/1500\n",
      "5/5 [==============================] - 4s 849ms/step - loss: 0.1169 - val_loss: 0.2006\n",
      "Epoch 1365/1500\n",
      "5/5 [==============================] - 4s 846ms/step - loss: 0.1127 - val_loss: 0.2028\n",
      "Epoch 1366/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1121 - val_loss: 0.2060\n",
      "Epoch 1367/1500\n",
      "5/5 [==============================] - 4s 850ms/step - loss: 0.1098 - val_loss: 0.2145\n",
      "Epoch 1368/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1280 - val_loss: 0.2773\n",
      "Epoch 1369/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1396 - val_loss: 0.2397\n",
      "Epoch 1370/1500\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.1191 - val_loss: 0.2220\n",
      "Epoch 1371/1500\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.1155 - val_loss: 0.2149\n",
      "Epoch 1372/1500\n",
      "5/5 [==============================] - 4s 859ms/step - loss: 0.1111 - val_loss: 0.2095\n",
      "Epoch 1373/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1091 - val_loss: 0.2097\n",
      "Epoch 1374/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1076 - val_loss: 0.2068\n",
      "Epoch 1375/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1047 - val_loss: 0.2016\n",
      "Epoch 1376/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.1030 - val_loss: 0.2019\n",
      "Epoch 1377/1500\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.1022 - val_loss: 0.2078\n",
      "Epoch 1378/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1009 - val_loss: 0.2092\n",
      "Epoch 1379/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.0999 - val_loss: 0.2054\n",
      "Epoch 1380/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.0999 - val_loss: 0.2034\n",
      "Epoch 1381/1500\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.1016 - val_loss: 0.2040\n",
      "Epoch 1382/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1008 - val_loss: 0.2097\n",
      "Epoch 1383/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1006 - val_loss: 0.2117\n",
      "Epoch 1384/1500\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.0995 - val_loss: 0.2089\n",
      "Epoch 1385/1500\n",
      "5/5 [==============================] - 4s 870ms/step - loss: 0.0982 - val_loss: 0.2044\n",
      "Epoch 1386/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.0988 - val_loss: 0.2131\n",
      "Epoch 1387/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.0993 - val_loss: 0.2374\n",
      "Epoch 1388/1500\n",
      "5/5 [==============================] - 4s 847ms/step - loss: 0.1263 - val_loss: 0.3024\n",
      "Epoch 1389/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1341 - val_loss: 0.2499\n",
      "Epoch 1390/1500\n",
      "5/5 [==============================] - 4s 849ms/step - loss: 0.1058 - val_loss: 0.2256\n",
      "Epoch 1391/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1068 - val_loss: 0.2022\n",
      "Epoch 1392/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1091 - val_loss: 0.2022\n",
      "Epoch 1393/1500\n",
      "5/5 [==============================] - 4s 871ms/step - loss: 0.1032 - val_loss: 0.1984\n",
      "Epoch 1394/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1004 - val_loss: 0.2044\n",
      "Epoch 1395/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.1003 - val_loss: 0.2039\n",
      "Epoch 1396/1500\n",
      "5/5 [==============================] - 4s 854ms/step - loss: 0.0997 - val_loss: 0.2082\n",
      "Epoch 1397/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.0987 - val_loss: 0.2110\n",
      "Epoch 1398/1500\n",
      "5/5 [==============================] - 4s 857ms/step - loss: 0.1014 - val_loss: 0.2118\n",
      "Epoch 1399/1500\n",
      "5/5 [==============================] - 5s 875ms/step - loss: 0.1009 - val_loss: 0.2129\n",
      "Epoch 1400/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.0988 - val_loss: 0.2149\n",
      "Epoch 1401/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.0996 - val_loss: 0.2230\n",
      "Epoch 1402/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.0978 - val_loss: 0.2205\n",
      "Epoch 1403/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.0974 - val_loss: 0.2151\n",
      "Epoch 1404/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.0951 - val_loss: 0.2218\n",
      "Epoch 1405/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.0947 - val_loss: 0.2228\n",
      "Epoch 1406/1500\n",
      "5/5 [==============================] - 4s 849ms/step - loss: 0.0934 - val_loss: 0.2161\n",
      "Epoch 1407/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.0923 - val_loss: 0.2140\n",
      "Epoch 1408/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.0922 - val_loss: 0.2175\n",
      "Epoch 1409/1500\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.0956 - val_loss: 0.2111\n",
      "Epoch 1410/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.0962 - val_loss: 0.2192\n",
      "Epoch 1411/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.0954 - val_loss: 0.2181\n",
      "Epoch 1412/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.0931 - val_loss: 0.2225\n",
      "Epoch 1413/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.0935 - val_loss: 0.2208\n",
      "Epoch 1414/1500\n",
      "5/5 [==============================] - 4s 846ms/step - loss: 0.0968 - val_loss: 0.1997\n",
      "Epoch 1415/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.0946 - val_loss: 0.2046\n",
      "Epoch 1416/1500\n",
      "5/5 [==============================] - 4s 850ms/step - loss: 0.0940 - val_loss: 0.2153\n",
      "Epoch 1417/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.0928 - val_loss: 0.2405\n",
      "Epoch 1418/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1590 - val_loss: 0.3291\n",
      "Epoch 1419/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.1422 - val_loss: 0.2769\n",
      "Epoch 1420/1500\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.1211 - val_loss: 0.2492\n",
      "Epoch 1421/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.1155 - val_loss: 0.2244\n",
      "Epoch 1422/1500\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.1060 - val_loss: 0.2169\n",
      "Epoch 1423/1500\n",
      "5/5 [==============================] - 4s 854ms/step - loss: 0.1024 - val_loss: 0.2102\n",
      "Epoch 1424/1500\n",
      "5/5 [==============================] - 4s 860ms/step - loss: 0.0997 - val_loss: 0.2115\n",
      "Epoch 1425/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.0997 - val_loss: 0.2079\n",
      "Epoch 1426/1500\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.0986 - val_loss: 0.2470\n",
      "Epoch 1427/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1659 - val_loss: 0.3481\n",
      "Epoch 1428/1500\n",
      "5/5 [==============================] - 4s 853ms/step - loss: 0.1705 - val_loss: 0.2399\n",
      "Epoch 1429/1500\n",
      "5/5 [==============================] - 4s 858ms/step - loss: 0.1300 - val_loss: 0.2503\n",
      "Epoch 1430/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1223 - val_loss: 0.2288\n",
      "Epoch 1431/1500\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.1115 - val_loss: 0.2448\n",
      "Epoch 1432/1500\n",
      "5/5 [==============================] - 4s 853ms/step - loss: 0.1784 - val_loss: 0.2827\n",
      "Epoch 1433/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1575 - val_loss: 0.2474\n",
      "Epoch 1434/1500\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 0.1380 - val_loss: 0.2405\n",
      "Epoch 1435/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1248 - val_loss: 0.2336\n",
      "Epoch 1436/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1155 - val_loss: 0.2157\n",
      "Epoch 1437/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.1092 - val_loss: 0.2054\n",
      "Epoch 1438/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.1058 - val_loss: 0.2041\n",
      "Epoch 1439/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.1140 - val_loss: 0.2231\n",
      "Epoch 1440/1500\n",
      "5/5 [==============================] - 4s 858ms/step - loss: 0.1101 - val_loss: 0.2291\n",
      "Epoch 1441/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1037 - val_loss: 0.2277\n",
      "Epoch 1442/1500\n",
      "5/5 [==============================] - 4s 845ms/step - loss: 0.0993 - val_loss: 0.2169\n",
      "Epoch 1443/1500\n",
      "5/5 [==============================] - 4s 833ms/step - loss: 0.0961 - val_loss: 0.2134\n",
      "Epoch 1444/1500\n",
      "5/5 [==============================] - 4s 857ms/step - loss: 0.0971 - val_loss: 0.2113\n",
      "Epoch 1445/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.0957 - val_loss: 0.2120\n",
      "Epoch 1446/1500\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.0952 - val_loss: 0.2295\n",
      "Epoch 1447/1500\n",
      "5/5 [==============================] - 4s 864ms/step - loss: 0.0946 - val_loss: 0.2327\n",
      "Epoch 1448/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.0950 - val_loss: 0.2341\n",
      "Epoch 1449/1500\n",
      "5/5 [==============================] - 4s 869ms/step - loss: 0.0998 - val_loss: 0.2174\n",
      "Epoch 1450/1500\n",
      "5/5 [==============================] - 4s 852ms/step - loss: 0.0968 - val_loss: 0.2484\n",
      "Epoch 1451/1500\n",
      "5/5 [==============================] - 4s 850ms/step - loss: 0.1519 - val_loss: 0.3650\n",
      "Epoch 1452/1500\n",
      "5/5 [==============================] - 4s 889ms/step - loss: 0.1721 - val_loss: 0.2430\n",
      "Epoch 1453/1500\n",
      "5/5 [==============================] - 4s 814ms/step - loss: 0.1169 - val_loss: 0.2498\n",
      "Epoch 1454/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.1391 - val_loss: 0.2226\n",
      "Epoch 1455/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1147 - val_loss: 0.2082\n",
      "Epoch 1456/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.1076 - val_loss: 0.1962\n",
      "Epoch 1457/1500\n",
      "5/5 [==============================] - 4s 900ms/step - loss: 0.1393 - val_loss: 0.1955\n",
      "Epoch 1458/1500\n",
      "5/5 [==============================] - 4s 855ms/step - loss: 0.1470 - val_loss: 0.1940\n",
      "Epoch 1459/1500\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.1347 - val_loss: 0.2403\n",
      "Epoch 1460/1500\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.1461 - val_loss: 0.2224\n",
      "Epoch 1461/1500\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.1352 - val_loss: 0.2346\n",
      "Epoch 1462/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.1242 - val_loss: 0.2453\n",
      "Epoch 1463/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.1141 - val_loss: 0.2310\n",
      "Epoch 1464/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1101 - val_loss: 0.2194\n",
      "Epoch 1465/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1095 - val_loss: 0.1971\n",
      "Epoch 1466/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1103 - val_loss: 0.1868\n",
      "Epoch 1467/1500\n",
      "5/5 [==============================] - 4s 846ms/step - loss: 0.1058 - val_loss: 0.2087\n",
      "Epoch 1468/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1123 - val_loss: 0.2138\n",
      "Epoch 1469/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.1080 - val_loss: 0.2160\n",
      "Epoch 1470/1500\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.1063 - val_loss: 0.2180\n",
      "Epoch 1471/1500\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.1072 - val_loss: 0.2088\n",
      "Epoch 1472/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.1016 - val_loss: 0.2101\n",
      "Epoch 1473/1500\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.1019 - val_loss: 0.2109\n",
      "Epoch 1474/1500\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.1012 - val_loss: 0.2131\n",
      "Epoch 1475/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.0974 - val_loss: 0.2096\n",
      "Epoch 1476/1500\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.0955 - val_loss: 0.2141\n",
      "Epoch 1477/1500\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.0945 - val_loss: 0.2150\n",
      "Epoch 1478/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.0934 - val_loss: 0.2157\n",
      "Epoch 1479/1500\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.0932 - val_loss: 0.2174\n",
      "Epoch 1480/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.0924 - val_loss: 0.2190\n",
      "Epoch 1481/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.0925 - val_loss: 0.2205\n",
      "Epoch 1482/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.0931 - val_loss: 0.2230\n",
      "Epoch 1483/1500\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.0919 - val_loss: 0.2363\n",
      "Epoch 1484/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.1065 - val_loss: 0.2855\n",
      "Epoch 1485/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1141 - val_loss: 0.2788\n",
      "Epoch 1486/1500\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.1056 - val_loss: 0.2530\n",
      "Epoch 1487/1500\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.1007 - val_loss: 0.2281\n",
      "Epoch 1488/1500\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.0959 - val_loss: 0.2155\n",
      "Epoch 1489/1500\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.0953 - val_loss: 0.2187\n",
      "Epoch 1490/1500\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.1172 - val_loss: 0.2601\n",
      "Epoch 1491/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.2018 - val_loss: 0.5057\n",
      "Epoch 1492/1500\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 0.2634 - val_loss: 0.3063\n",
      "Epoch 1493/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1630 - val_loss: 0.2330\n",
      "Epoch 1494/1500\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.1351 - val_loss: 0.2166\n",
      "Epoch 1495/1500\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.1283 - val_loss: 0.2177\n",
      "Epoch 1496/1500\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.1226 - val_loss: 0.2024\n",
      "Epoch 1497/1500\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.1194 - val_loss: 0.2008\n",
      "Epoch 1498/1500\n",
      "5/5 [==============================] - 4s 832ms/step - loss: 0.1114 - val_loss: 0.2035\n",
      "Epoch 1499/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1067 - val_loss: 0.2042\n",
      "Epoch 1500/1500\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1039 - val_loss: 0.2057\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 0.1697\n",
      "0.16972872614860535\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.LSTM(units = 1024, activation = \"relu\", return_sequences = True)(input)\n",
    "    x = layers.LSTM(units = 1024, activation = \"relu\", return_sequences = True)(x)\n",
    "    x = layers.LSTM(units = 512, activation = \"relu\", return_sequences = True)(x)\n",
    "\n",
    "    # 中間層最後のreturn_sequencesは、Falseにする\n",
    "    # 出力は一つなので、中間層の最後で次元数を落として出力できるようにしている\n",
    "    x = layers.LSTM(units = 512, activation = \"relu\", return_sequences = True)(x)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "# ミニバッチ学習 \n",
    "batch_size = len(train_x) // 4\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "\n",
    "# モデル構造の出力\n",
    "model.summary()\n",
    "\n",
    "# val_lossが一番低いモデルを保存している\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "# 学習データ、テストデータ、バッチサイズ、エポック、保存ポイントの設定\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = batch_size, epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 757ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8938e7ef10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "2.0375919342041016\n",
      "0.4616570472717285\n",
      "1.20890474319458\n",
      "0.3563652038574219\n",
      "0.27797794342041016\n",
      "0.3665475845336914\n",
      "0.022635087370872498\n",
      "0.09368133544921875\n",
      "0.06367743015289307\n",
      "0.5813674926757812\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "SINGLE_SE = list()\n",
    "\n",
    "def single_sa(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        c = a - b\n",
    "        output.append(float(abs(c[0])))\n",
    "\n",
    "    return output\n",
    "\n",
    "# 標準化を元の縮尺に戻す関数\n",
    "def decode(x):\n",
    "    return x * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"]\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    SINGLE_SE.append(single_sa(decode(x), decode(y)))\n",
    "    print(SINGLE_SE[-1][-1])\n",
    "    \n",
    "# SINGLE_SE[0]\n",
    "    \n",
    "min_SINGLE_SE = list()\n",
    "max_SINGLE_SE = list()\n",
    "\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    decode_min = min(SINGLE_SE[i])\n",
    "    decode_min_index = SINGLE_SE[i].index(min(SINGLE_SE[i]))\n",
    "    decode_max = max(SINGLE_SE[i])\n",
    "    decode_max_index = SINGLE_SE[i].index(max(SINGLE_SE[i]))\n",
    "    min_SINGLE_SE.append([decode_min, decode_min_index])\n",
    "    max_SINGLE_SE.append([decode_max, decode_max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 12番目 0.073784%, max : 2番目 21.677%\n",
      "min : 17番目 0.16996%, max : 1番目 19.006%\n",
      "min : 17番目 0.010042%, max : 0番目 18.46%\n",
      "min : 7番目 0.030151%, max : 0番目 6.3995%\n",
      "min : 17番目 0.19062%, max : 4番目 13.154%\n",
      "min : 14番目 0.11348%, max : 1番目 32.907%\n",
      "min : 23番目 0.022635%, max : 4番目 30.822%\n",
      "min : 11番目 0.081562%, max : 1番目 59.107%\n",
      "min : 1番目 0.028246%, max : 0番目 16.003%\n",
      "min : 21番目 0.20636%, max : 3番目 18.315%\n"
     ]
    }
   ],
   "source": [
    "# 各入力データの1〜24(SPILT_SIZE)の中の最大、最小(上からグラフのソート順になってる)\n",
    "for a ,b in zip(min_SINGLE_SE,max_SINGLE_SE):\n",
    "    print(f\"min : {a[1]}番目 {a[0]:.5}%, max : {b[1]}番目 {b[0]:.5}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 2番目 -17.536%, max : 3番目 21.909%\n",
      "min : 1番目 -14.865%, max : 3番目 18.553%\n",
      "min : 5番目 -2.11%, max : 0番目 22.601%\n",
      "min : 0番目 -2.2587%, max : 3番目 8.9915%\n",
      "min : 4番目 -9.0134%, max : 2番目 11.145%\n",
      "min : 1番目 -28.766%, max : 2番目 22.514%\n",
      "min : 4番目 -26.681%, max : 0番目 24.934%\n",
      "min : 1番目 -54.966%, max : 2番目 15.677%\n",
      "min : 0番目 -11.863%, max : 7番目 7.3986%\n",
      "min : 6番目 0.85163%, max : 3番目 22.456%\n"
     ]
    }
   ],
   "source": [
    "# 各入力データの1〜24(SPILT_SIZE)の中の最大、最小(上からグラフのソート順になってる)\n",
    "for a ,b in zip(min_SINGLE_SE,max_SINGLE_SE):\n",
    "    print(f\"min : {a[1]}番目 {a[0]:.5}%, max : {b[1]}番目 {b[0]:.5}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6639042] 4.701496236845483\n",
      "[-4.549385] -4.087727875951666\n",
      "[-3.084021] -1.875116342494989\n",
      "[5.4670167] 5.11065154553301\n",
      "[-4.9881535] -5.266131407811356\n",
      "[-13.019691] -13.386238954730098\n",
      "[-0.16275835] -0.18539343328339886\n",
      "[-11.553953] -11.460272081297521\n",
      "[1.2039547] 1.14027731628719\n",
      "[12.789329] 12.207961293590904\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(pre, ans):\n",
    "    print(decode(x[-1]), decode(y[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "# 各検証データの予測と正解のMSEをとる\n",
    "def mse(x, y):\n",
    "    tmp = 0.0\n",
    "    for a, b in zip(x, y):\n",
    "        tmp += (a - b) ** 2\n",
    "    tmp /= len(x)\n",
    "    return tmp\n",
    "# 各検証データに含まれるNヶ月の各予測と正解の二乗和誤差を算出する\n",
    "def single_se(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        output.append((a - b) ** 2)\n",
    "\n",
    "    return output\n",
    "\n",
    "MSE = []\n",
    "SINGLE_SE = []\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    MSE.append(mse(x, y))\n",
    "    SINGLE_SE.append(single_se(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSEの最小値：[0.02139824]、最大値：[0.6766705]\n",
      "\n",
      "0個目の検証用データにおけるSingle MSEの最小値：[2.0960215e-05]、最大値：[1.8091338]\n",
      "1個目の検証用データにおけるSingle MSEの最小値：[0.00011121]、最大値：[1.3907962]\n",
      "2個目の検証用データにおけるSingle MSEの最小値：[3.8826227e-07]、最大値：[1.3120136]\n",
      "3個目の検証用データにおけるSingle MSEの最小値：[3.5001567e-06]、最大値：[0.15767992]\n",
      "4個目の検証用データにおけるSingle MSEの最小値：[0.00013991]、最大値：[0.6662126]\n",
      "5個目の検証用データにおけるSingle MSEの最小値：[4.958292e-05]、最大値：[4.169263]\n",
      "6個目の検証用データにおけるSingle MSEの最小値：[1.9725198e-06]、最大値：[3.657662]\n",
      "7個目の検証用データにおけるSingle MSEの最小値：[2.5614028e-05]、最大値：[13.451243]\n",
      "8個目の検証用データにおけるSingle MSEの最小値：[3.0716592e-06]、最大値：[0.9860603]\n",
      "9個目の検証用データにおけるSingle MSEの最小値：[0.00016395]、最大値：[1.2914829]\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSEの最小値：{min(MSE)}、最大値：{max(MSE)}\")\n",
    "print()\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    print(f\"{i}個目の検証用データにおけるSingle MSEの最小値：{min(SINGLE_SE[i])}、最大値：{max(SINGLE_SE[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM(多層)sequence=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 24, 3)]           0         \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 24, 1024)          4210688   \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 24, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 24, 512)           3147776   \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 512)               2099200   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,850,881\n",
      "Trainable params: 17,850,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.5378 - val_loss: 1.1196\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5123 - val_loss: 1.2012\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6051 - val_loss: 1.0579\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5122 - val_loss: 1.0766\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5268 - val_loss: 1.0813\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5304 - val_loss: 1.0823\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5307 - val_loss: 1.0816\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5295 - val_loss: 1.0790\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5275 - val_loss: 1.0734\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5246 - val_loss: 1.0631\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5209 - val_loss: 1.0459\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5159 - val_loss: 1.0362\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5096 - val_loss: 1.0557\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5018 - val_loss: 1.0496\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4938 - val_loss: 1.1666\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4938 - val_loss: 1.2903\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4882 - val_loss: 0.9874\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5840 - val_loss: 1.3365\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5290 - val_loss: 1.2645\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5297 - val_loss: 1.1973\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5200 - val_loss: 1.1552\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5145 - val_loss: 1.1306\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5121 - val_loss: 1.1166\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5109 - val_loss: 1.1085\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5101 - val_loss: 1.1038\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5092 - val_loss: 1.1011\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5080 - val_loss: 1.0993\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5065 - val_loss: 1.0984\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5050 - val_loss: 1.0980\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5039 - val_loss: 1.0976\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5033 - val_loss: 1.0953\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5025 - val_loss: 1.0915\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5009 - val_loss: 1.0884\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5000 - val_loss: 1.0867\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4995 - val_loss: 1.0861\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4982 - val_loss: 1.0872\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4961 - val_loss: 1.0898\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4945 - val_loss: 1.0933\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4935 - val_loss: 1.0955\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4925 - val_loss: 1.0972\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4916 - val_loss: 1.1016\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4909 - val_loss: 1.1077\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4897 - val_loss: 1.1142\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4881 - val_loss: 1.1160\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4861 - val_loss: 1.1144\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4840 - val_loss: 1.1201\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4823 - val_loss: 1.1329\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4802 - val_loss: 1.1351\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4772 - val_loss: 1.1126\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4739 - val_loss: 1.1733\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4697 - val_loss: 1.0163\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4745 - val_loss: 1.2706\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4840 - val_loss: 1.1858\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4668 - val_loss: 1.0612\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4742 - val_loss: 1.0606\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4686 - val_loss: 1.1624\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4590 - val_loss: 1.2454\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4622 - val_loss: 1.2400\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4547 - val_loss: 1.1732\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4557 - val_loss: 1.2463\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4447 - val_loss: 1.2681\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4463 - val_loss: 1.2226\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4426 - val_loss: 1.2811\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4360 - val_loss: 1.3359\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4288 - val_loss: 1.3565\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4939 - val_loss: 1.4324\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5623 - val_loss: 1.2781\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5369 - val_loss: 1.1991\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5210 - val_loss: 1.1739\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5187 - val_loss: 1.1572\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5149 - val_loss: 1.1436\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5098 - val_loss: 1.1331\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5059 - val_loss: 1.1239\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5034 - val_loss: 1.1152\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5021 - val_loss: 1.1068\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5015 - val_loss: 1.0987\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5013 - val_loss: 1.0912\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5008 - val_loss: 1.0856\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5000 - val_loss: 1.0829\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4990 - val_loss: 1.0830\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4983 - val_loss: 1.0855\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4978 - val_loss: 1.0902\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4971 - val_loss: 1.0969\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4960 - val_loss: 1.1059\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4949 - val_loss: 1.1166\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4940 - val_loss: 1.1249\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4930 - val_loss: 1.1265\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4914 - val_loss: 1.1230\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4899 - val_loss: 1.1192\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4886 - val_loss: 1.1238\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4867 - val_loss: 1.1412\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4844 - val_loss: 1.1494\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4811 - val_loss: 1.1261\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4770 - val_loss: 1.1937\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4703 - val_loss: 0.9020\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7099 - val_loss: 1.5289\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5569 - val_loss: 1.3887\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5290 - val_loss: 1.2586\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4955 - val_loss: 1.1943\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4887 - val_loss: 1.1662\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4931 - val_loss: 1.1507\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4976 - val_loss: 1.1398\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5000 - val_loss: 1.1309\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5005 - val_loss: 1.1236\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4995 - val_loss: 1.1176\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4977 - val_loss: 1.1131\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4957 - val_loss: 1.1099\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4941 - val_loss: 1.1079\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4930 - val_loss: 1.1068\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4924 - val_loss: 1.1064\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4922 - val_loss: 1.1066\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4921 - val_loss: 1.1071\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4916 - val_loss: 1.1076\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4907 - val_loss: 1.1083\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4898 - val_loss: 1.1095\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4892 - val_loss: 1.1116\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4887 - val_loss: 1.1143\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4879 - val_loss: 1.1174\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4866 - val_loss: 1.1215\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4850 - val_loss: 1.1271\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4835 - val_loss: 1.1344\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4822 - val_loss: 1.1421\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4808 - val_loss: 1.1487\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4790 - val_loss: 1.1536\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4764 - val_loss: 1.1575\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4732 - val_loss: 1.1629\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4696 - val_loss: 1.1815\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4645 - val_loss: 1.2556\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4584 - val_loss: 1.3555\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4619 - val_loss: 1.4091\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5288 - val_loss: 1.2825\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4844 - val_loss: 1.2350\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4814 - val_loss: 1.2129\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4821 - val_loss: 1.1964\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4796 - val_loss: 1.1826\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4753 - val_loss: 1.1726\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4721 - val_loss: 1.1655\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4700 - val_loss: 1.1585\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4679 - val_loss: 1.1485\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4658 - val_loss: 1.1348\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4620 - val_loss: 1.1183\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4572 - val_loss: 1.0999\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4557 - val_loss: 1.0797\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4535 - val_loss: 1.0708\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4489 - val_loss: 1.0840\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4445 - val_loss: 1.1064\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4378 - val_loss: 1.1348\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4308 - val_loss: 1.1618\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4233 - val_loss: 1.1787\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4148 - val_loss: 1.1968\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4107 - val_loss: 1.2255\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4077 - val_loss: 1.2313\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4042 - val_loss: 1.2548\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4010 - val_loss: 1.2846\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4160 - val_loss: 1.2823\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4341 - val_loss: 1.2740\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4546 - val_loss: 1.2670\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4329 - val_loss: 1.2668\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4194 - val_loss: 1.2716\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4229 - val_loss: 1.2724\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4088 - val_loss: 1.3138\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4052 - val_loss: 1.3389\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3916 - val_loss: 1.3540\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3875 - val_loss: 1.3674\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3861 - val_loss: 1.3859\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3782 - val_loss: 1.4161\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3762 - val_loss: 1.4735\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3725 - val_loss: 1.5563\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3663 - val_loss: 1.5881\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3719 - val_loss: 1.6122\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3574 - val_loss: 1.6588\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3642 - val_loss: 1.5723\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3584 - val_loss: 1.5499\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3641 - val_loss: 1.5899\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3515 - val_loss: 1.6831\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3479 - val_loss: 1.7251\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3406 - val_loss: 1.7886\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3346 - val_loss: 1.8026\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3337 - val_loss: 1.7626\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3281 - val_loss: 1.7751\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3203 - val_loss: 1.8745\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3135 - val_loss: 1.9696\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3098 - val_loss: 2.0605\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3002 - val_loss: 2.0406\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3117 - val_loss: 2.1499\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2871 - val_loss: 2.2599\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3698 - val_loss: 1.9330\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4574 - val_loss: 1.5492\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3648 - val_loss: 1.4607\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3824 - val_loss: 1.4124\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3911 - val_loss: 1.3684\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3880 - val_loss: 1.3397\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3823 - val_loss: 1.3301\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3769 - val_loss: 1.3326\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3653 - val_loss: 1.3869\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3614 - val_loss: 1.3724\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3479 - val_loss: 1.3645\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3504 - val_loss: 1.5050\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3458 - val_loss: 1.4553\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3436 - val_loss: 1.7402\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3537 - val_loss: 1.5238\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3555 - val_loss: 1.5771\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3634 - val_loss: 1.6199\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3628 - val_loss: 1.7228\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3548 - val_loss: 1.8493\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3462 - val_loss: 2.0099\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3394 - val_loss: 2.1679\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3391 - val_loss: 2.2095\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3395 - val_loss: 2.0992\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3282 - val_loss: 1.9511\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3230 - val_loss: 1.8211\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3213 - val_loss: 1.7555\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3193 - val_loss: 1.7462\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3132 - val_loss: 1.7800\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3083 - val_loss: 1.8205\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3028 - val_loss: 1.8346\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2975 - val_loss: 1.8586\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2930 - val_loss: 1.8770\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2895 - val_loss: 1.8702\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2869 - val_loss: 1.9102\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2833 - val_loss: 1.9358\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2803 - val_loss: 2.0228\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2762 - val_loss: 2.0298\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2714 - val_loss: 2.0983\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2688 - val_loss: 2.0275\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2658 - val_loss: 2.0752\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2611 - val_loss: 2.0731\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2518 - val_loss: 2.1634\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2452 - val_loss: 2.1739\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2438 - val_loss: 2.3422\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2427 - val_loss: 2.0948\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2865 - val_loss: 2.1192\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3294 - val_loss: 1.8717\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2845 - val_loss: 1.8425\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3222 - val_loss: 1.8329\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3050 - val_loss: 1.8769\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2978 - val_loss: 1.9932\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2973 - val_loss: 2.1253\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2816 - val_loss: 2.1784\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2687 - val_loss: 2.1807\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2669 - val_loss: 2.1557\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2547 - val_loss: 2.1856\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2476 - val_loss: 2.1001\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2426 - val_loss: 2.0891\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2310 - val_loss: 2.1838\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2188 - val_loss: 2.2441\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2152 - val_loss: 2.1626\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2096 - val_loss: 2.3932\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2078 - val_loss: 2.2554\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2134 - val_loss: 2.0447\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2024 - val_loss: 2.3030\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2439 - val_loss: 2.1669\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1942 - val_loss: 2.0102\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2223 - val_loss: 2.1152\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1806 - val_loss: 2.3198\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2037 - val_loss: 2.0871\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2095 - val_loss: 2.0032\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1869 - val_loss: 2.1284\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1725 - val_loss: 2.3033\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1900 - val_loss: 2.0704\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1581 - val_loss: 2.0455\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1609 - val_loss: 2.0610\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1555 - val_loss: 2.1011\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1498 - val_loss: 2.0767\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1303 - val_loss: 2.0994\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1324 - val_loss: 2.1769\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1301 - val_loss: 2.1499\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - val_loss: 2.0812\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - val_loss: 2.0286\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - val_loss: 2.0560\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - val_loss: 2.0700\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - val_loss: 2.0039\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - val_loss: 2.0779\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - val_loss: 1.9605\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1419 - val_loss: 1.9898\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - val_loss: 1.9396\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - val_loss: 1.9365\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - val_loss: 2.0135\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - val_loss: 2.0780\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0917 - val_loss: 2.0336\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0863 - val_loss: 1.9553\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0888 - val_loss: 1.9028\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0795 - val_loss: 2.1066\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0893 - val_loss: 1.9716\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0781 - val_loss: 1.9976\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0794 - val_loss: 1.9470\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0765 - val_loss: 1.9486\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0855 - val_loss: 1.8831\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0806 - val_loss: 2.1095\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0865 - val_loss: 1.9770\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0704 - val_loss: 2.0301\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0643 - val_loss: 2.1238\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0677 - val_loss: 1.8699\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0639 - val_loss: 1.9427\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0660 - val_loss: 1.9856\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0643 - val_loss: 2.1524\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0684 - val_loss: 2.0047\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0926 - val_loss: 2.1910\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1254 - val_loss: 2.0211\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0896 - val_loss: 1.8759\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.7876\n",
      "0.7875882983207703\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.LSTM(units = 1024, activation = \"relu\", return_sequences = True)(input)\n",
    "    x = layers.LSTM(units = 1024, activation = \"relu\", return_sequences = True)(x)\n",
    "    x = layers.LSTM(units = 512, activation = \"relu\", return_sequences = True)(x)\n",
    "    # x = layers.LSTM(units = 512, activation = \"relu\", return_sequences = True)(x)\n",
    "    \n",
    "\n",
    "    # 中間層最後のreturn_sequencesは、Falseにする\n",
    "    # 出力は一つなので、中間層の最後で次元数を落として出力できるようにしている\n",
    "    x = layers.LSTM(units = 512, activation = \"relu\", return_sequences = True)(x)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "model.summary()\n",
    "\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "history = model.fit(x = train_x, y = train_y[:, -1], batch_size = len(x), epochs = 1500,\n",
    "                    validation_data = (test_x, test_y[:, -1]), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd97f215850>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューロン数を減らして　作成1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 24, 3)]           0         \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 24, 128)           67584     \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 24, 128)           131584    \n",
      "                                                                 \n",
      " lstm_38 (LSTM)              (None, 24, 64)            49408     \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 24, 64)            33024     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 24, 1)             65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 281,665\n",
      "Trainable params: 281,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "5/5 [==============================] - 12s 305ms/step - loss: 0.8241 - val_loss: 0.9819\n",
      "Epoch 2/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8209 - val_loss: 0.9795\n",
      "Epoch 3/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.8184 - val_loss: 0.9773\n",
      "Epoch 4/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.8162 - val_loss: 0.9751\n",
      "Epoch 5/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8140 - val_loss: 0.9729\n",
      "Epoch 6/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8118 - val_loss: 0.9705\n",
      "Epoch 7/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.8091 - val_loss: 0.9679\n",
      "Epoch 8/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.8064 - val_loss: 0.9648\n",
      "Epoch 9/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.8032 - val_loss: 0.9610\n",
      "Epoch 10/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.7993 - val_loss: 0.9569\n",
      "Epoch 11/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7951 - val_loss: 0.9523\n",
      "Epoch 12/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7903 - val_loss: 0.9471\n",
      "Epoch 13/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7861 - val_loss: 0.9420\n",
      "Epoch 14/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.7819 - val_loss: 0.9375\n",
      "Epoch 15/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.7788 - val_loss: 0.9343\n",
      "Epoch 16/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7775 - val_loss: 0.9319\n",
      "Epoch 17/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.7763 - val_loss: 0.9302\n",
      "Epoch 18/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7748 - val_loss: 0.9291\n",
      "Epoch 19/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7733 - val_loss: 0.9276\n",
      "Epoch 20/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.7721 - val_loss: 0.9259\n",
      "Epoch 21/1500\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.7707 - val_loss: 0.9241\n",
      "Epoch 22/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.7698 - val_loss: 0.9224\n",
      "Epoch 23/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.7691 - val_loss: 0.9216\n",
      "Epoch 24/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.7682 - val_loss: 0.9208\n",
      "Epoch 25/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7678 - val_loss: 0.9197\n",
      "Epoch 26/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7669 - val_loss: 0.9196\n",
      "Epoch 27/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7663 - val_loss: 0.9191\n",
      "Epoch 28/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7656 - val_loss: 0.9181\n",
      "Epoch 29/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7658 - val_loss: 0.9175\n",
      "Epoch 30/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7646 - val_loss: 0.9170\n",
      "Epoch 31/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7640 - val_loss: 0.9163\n",
      "Epoch 32/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.7632 - val_loss: 0.9146\n",
      "Epoch 33/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.7624 - val_loss: 0.9134\n",
      "Epoch 34/1500\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.7615 - val_loss: 0.9126\n",
      "Epoch 35/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.7606 - val_loss: 0.9119\n",
      "Epoch 36/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7600 - val_loss: 0.9111\n",
      "Epoch 37/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7594 - val_loss: 0.9104\n",
      "Epoch 38/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7588 - val_loss: 0.9096\n",
      "Epoch 39/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7577 - val_loss: 0.9086\n",
      "Epoch 40/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7570 - val_loss: 0.9082\n",
      "Epoch 41/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.7562 - val_loss: 0.9071\n",
      "Epoch 42/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.7554 - val_loss: 0.9070\n",
      "Epoch 43/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7547 - val_loss: 0.9063\n",
      "Epoch 44/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.7546 - val_loss: 0.9065\n",
      "Epoch 45/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.7537 - val_loss: 0.9055\n",
      "Epoch 46/1500\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.7526 - val_loss: 0.9048\n",
      "Epoch 47/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7523 - val_loss: 0.9036\n",
      "Epoch 48/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7519 - val_loss: 0.9043\n",
      "Epoch 49/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7513 - val_loss: 0.9035\n",
      "Epoch 50/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7504 - val_loss: 0.9032\n",
      "Epoch 51/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7500 - val_loss: 0.9029\n",
      "Epoch 52/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7496 - val_loss: 0.9016\n",
      "Epoch 53/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7489 - val_loss: 0.9015\n",
      "Epoch 54/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.7485 - val_loss: 0.9016\n",
      "Epoch 55/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.7488 - val_loss: 0.9024\n",
      "Epoch 56/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7505 - val_loss: 0.9009\n",
      "Epoch 57/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.7489 - val_loss: 0.9014\n",
      "Epoch 58/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7474 - val_loss: 0.9019\n",
      "Epoch 59/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.7478 - val_loss: 0.8998\n",
      "Epoch 60/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.7460 - val_loss: 0.8993\n",
      "Epoch 61/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7459 - val_loss: 0.8993\n",
      "Epoch 62/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7454 - val_loss: 0.9000\n",
      "Epoch 63/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.7451 - val_loss: 0.8999\n",
      "Epoch 64/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7445 - val_loss: 0.8987\n",
      "Epoch 65/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7438 - val_loss: 0.8980\n",
      "Epoch 66/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.7434 - val_loss: 0.8997\n",
      "Epoch 67/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.7471 - val_loss: 0.9014\n",
      "Epoch 68/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.7448 - val_loss: 0.8993\n",
      "Epoch 69/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7442 - val_loss: 0.8977\n",
      "Epoch 70/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.7430 - val_loss: 0.8979\n",
      "Epoch 71/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7435 - val_loss: 0.8972\n",
      "Epoch 72/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.7425 - val_loss: 0.8974\n",
      "Epoch 73/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7423 - val_loss: 0.8960\n",
      "Epoch 74/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7412 - val_loss: 0.8952\n",
      "Epoch 75/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7407 - val_loss: 0.8951\n",
      "Epoch 76/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.7401 - val_loss: 0.8953\n",
      "Epoch 77/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.7397 - val_loss: 0.8955\n",
      "Epoch 78/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.7393 - val_loss: 0.8960\n",
      "Epoch 79/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.7390 - val_loss: 0.8958\n",
      "Epoch 80/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.7386 - val_loss: 0.8956\n",
      "Epoch 81/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7383 - val_loss: 0.8951\n",
      "Epoch 82/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7378 - val_loss: 0.8949\n",
      "Epoch 83/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7377 - val_loss: 0.8942\n",
      "Epoch 84/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7374 - val_loss: 0.8943\n",
      "Epoch 85/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.7370 - val_loss: 0.8946\n",
      "Epoch 86/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.7366 - val_loss: 0.8959\n",
      "Epoch 87/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7380 - val_loss: 0.8976\n",
      "Epoch 88/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.7375 - val_loss: 0.8971\n",
      "Epoch 89/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7368 - val_loss: 0.8940\n",
      "Epoch 90/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7363 - val_loss: 0.8928\n",
      "Epoch 91/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7357 - val_loss: 0.8925\n",
      "Epoch 92/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.7354 - val_loss: 0.8929\n",
      "Epoch 93/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.7353 - val_loss: 0.8930\n",
      "Epoch 94/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7348 - val_loss: 0.8921\n",
      "Epoch 95/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7342 - val_loss: 0.8917\n",
      "Epoch 96/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.7345 - val_loss: 0.8925\n",
      "Epoch 97/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.7354 - val_loss: 0.8919\n",
      "Epoch 98/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.7343 - val_loss: 0.8926\n",
      "Epoch 99/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7335 - val_loss: 0.8930\n",
      "Epoch 100/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.7334 - val_loss: 0.8926\n",
      "Epoch 101/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7328 - val_loss: 0.8917\n",
      "Epoch 102/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7325 - val_loss: 0.8908\n",
      "Epoch 103/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.7319 - val_loss: 0.8908\n",
      "Epoch 104/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.7320 - val_loss: 0.8917\n",
      "Epoch 105/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.7314 - val_loss: 0.8927\n",
      "Epoch 106/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.7309 - val_loss: 0.8910\n",
      "Epoch 107/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.7309 - val_loss: 0.8910\n",
      "Epoch 108/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7302 - val_loss: 0.8901\n",
      "Epoch 109/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7294 - val_loss: 0.8899\n",
      "Epoch 110/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.7288 - val_loss: 0.8898\n",
      "Epoch 111/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7277 - val_loss: 0.8892\n",
      "Epoch 112/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.7271 - val_loss: 0.8894\n",
      "Epoch 113/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7265 - val_loss: 0.8902\n",
      "Epoch 114/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.7295 - val_loss: 0.8936\n",
      "Epoch 115/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.7259 - val_loss: 0.8894\n",
      "Epoch 116/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7230 - val_loss: 0.8873\n",
      "Epoch 117/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7226 - val_loss: 0.8873\n",
      "Epoch 118/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.7200 - val_loss: 0.8950\n",
      "Epoch 119/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.7242 - val_loss: 0.8874\n",
      "Epoch 120/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7217 - val_loss: 0.8819\n",
      "Epoch 121/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7183 - val_loss: 0.8811\n",
      "Epoch 122/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7160 - val_loss: 0.8798\n",
      "Epoch 123/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7137 - val_loss: 0.8774\n",
      "Epoch 124/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7109 - val_loss: 0.8766\n",
      "Epoch 125/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.7084 - val_loss: 0.8834\n",
      "Epoch 126/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.7065 - val_loss: 0.8843\n",
      "Epoch 127/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.7091 - val_loss: 0.8775\n",
      "Epoch 128/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7032 - val_loss: 0.8744\n",
      "Epoch 129/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.7038 - val_loss: 0.8785\n",
      "Epoch 130/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7015 - val_loss: 0.8734\n",
      "Epoch 131/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6997 - val_loss: 0.8729\n",
      "Epoch 132/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6941 - val_loss: 0.8759\n",
      "Epoch 133/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.7028 - val_loss: 0.8803\n",
      "Epoch 134/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6990 - val_loss: 0.8749\n",
      "Epoch 135/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6996 - val_loss: 0.8715\n",
      "Epoch 136/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.6975 - val_loss: 0.8746\n",
      "Epoch 137/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.6977 - val_loss: 0.8740\n",
      "Epoch 138/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.6951 - val_loss: 0.8719\n",
      "Epoch 139/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.6921 - val_loss: 0.8718\n",
      "Epoch 140/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.6912 - val_loss: 0.8725\n",
      "Epoch 141/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.6888 - val_loss: 0.8675\n",
      "Epoch 142/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.6935 - val_loss: 0.8733\n",
      "Epoch 143/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6935 - val_loss: 0.8674\n",
      "Epoch 144/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.6903 - val_loss: 0.8662\n",
      "Epoch 145/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6852 - val_loss: 0.8661\n",
      "Epoch 146/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6846 - val_loss: 0.8657\n",
      "Epoch 147/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.6814 - val_loss: 0.8671\n",
      "Epoch 148/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6810 - val_loss: 0.8650\n",
      "Epoch 149/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6787 - val_loss: 0.8639\n",
      "Epoch 150/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6785 - val_loss: 0.8615\n",
      "Epoch 151/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6761 - val_loss: 0.8663\n",
      "Epoch 152/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6768 - val_loss: 0.8685\n",
      "Epoch 153/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6783 - val_loss: 0.8679\n",
      "Epoch 154/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6750 - val_loss: 0.8595\n",
      "Epoch 155/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6741 - val_loss: 0.8583\n",
      "Epoch 156/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6736 - val_loss: 0.8570\n",
      "Epoch 157/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6700 - val_loss: 0.8569\n",
      "Epoch 158/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6719 - val_loss: 0.8542\n",
      "Epoch 159/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6689 - val_loss: 0.8525\n",
      "Epoch 160/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.6660 - val_loss: 0.8545\n",
      "Epoch 161/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.6655 - val_loss: 0.8554\n",
      "Epoch 162/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6644 - val_loss: 0.8556\n",
      "Epoch 163/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6639 - val_loss: 0.8576\n",
      "Epoch 164/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6660 - val_loss: 0.8597\n",
      "Epoch 165/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6665 - val_loss: 0.8579\n",
      "Epoch 166/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6659 - val_loss: 0.8479\n",
      "Epoch 167/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.6633 - val_loss: 0.8484\n",
      "Epoch 168/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6622 - val_loss: 0.8554\n",
      "Epoch 169/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6636 - val_loss: 0.8608\n",
      "Epoch 170/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6636 - val_loss: 0.8622\n",
      "Epoch 171/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6674 - val_loss: 0.8632\n",
      "Epoch 172/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.6663 - val_loss: 0.8581\n",
      "Epoch 173/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6596 - val_loss: 0.8583\n",
      "Epoch 174/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.6599 - val_loss: 0.8543\n",
      "Epoch 175/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6648 - val_loss: 0.8627\n",
      "Epoch 176/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6694 - val_loss: 0.8533\n",
      "Epoch 177/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6654 - val_loss: 0.8473\n",
      "Epoch 178/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6623 - val_loss: 0.8448\n",
      "Epoch 179/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6609 - val_loss: 0.8420\n",
      "Epoch 180/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6556 - val_loss: 0.8398\n",
      "Epoch 181/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6592 - val_loss: 0.8398\n",
      "Epoch 182/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.6514 - val_loss: 0.8319\n",
      "Epoch 183/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6489 - val_loss: 0.8262\n",
      "Epoch 184/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6441 - val_loss: 0.8196\n",
      "Epoch 185/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6429 - val_loss: 0.8136\n",
      "Epoch 186/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6382 - val_loss: 0.8035\n",
      "Epoch 187/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6383 - val_loss: 0.8958\n",
      "Epoch 188/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6640 - val_loss: 0.8500\n",
      "Epoch 189/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.6776 - val_loss: 0.8568\n",
      "Epoch 190/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6715 - val_loss: 0.8335\n",
      "Epoch 191/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6568 - val_loss: 0.8376\n",
      "Epoch 192/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.6521 - val_loss: 0.8370\n",
      "Epoch 193/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6517 - val_loss: 0.8358\n",
      "Epoch 194/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6532 - val_loss: 0.8312\n",
      "Epoch 195/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6457 - val_loss: 0.8267\n",
      "Epoch 196/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6433 - val_loss: 0.8246\n",
      "Epoch 197/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6407 - val_loss: 0.8208\n",
      "Epoch 198/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6361 - val_loss: 0.8149\n",
      "Epoch 199/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6348 - val_loss: 0.8067\n",
      "Epoch 200/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6304 - val_loss: 0.7974\n",
      "Epoch 201/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6254 - val_loss: 0.7814\n",
      "Epoch 202/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6267 - val_loss: 0.7737\n",
      "Epoch 203/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6167 - val_loss: 0.8129\n",
      "Epoch 204/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6333 - val_loss: 0.7770\n",
      "Epoch 205/1500\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.6233 - val_loss: 0.7682\n",
      "Epoch 206/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.6117 - val_loss: 0.7743\n",
      "Epoch 207/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6214 - val_loss: 0.8056\n",
      "Epoch 208/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6536 - val_loss: 0.7984\n",
      "Epoch 209/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.6356 - val_loss: 0.7759\n",
      "Epoch 210/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.6395 - val_loss: 0.8023\n",
      "Epoch 211/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.6452 - val_loss: 0.7990\n",
      "Epoch 212/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.6337 - val_loss: 0.8222\n",
      "Epoch 213/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.6387 - val_loss: 0.7862\n",
      "Epoch 214/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.6329 - val_loss: 0.7818\n",
      "Epoch 215/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6267 - val_loss: 0.7699\n",
      "Epoch 216/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6190 - val_loss: 0.7585\n",
      "Epoch 217/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6128 - val_loss: 0.7877\n",
      "Epoch 218/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6142 - val_loss: 0.7941\n",
      "Epoch 219/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6208 - val_loss: 0.7874\n",
      "Epoch 220/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6126 - val_loss: 0.7853\n",
      "Epoch 221/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.6240 - val_loss: 0.7760\n",
      "Epoch 222/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6138 - val_loss: 0.7575\n",
      "Epoch 223/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6148 - val_loss: 0.7484\n",
      "Epoch 224/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6029 - val_loss: 0.7413\n",
      "Epoch 225/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5963 - val_loss: 0.7582\n",
      "Epoch 226/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5944 - val_loss: 0.7426\n",
      "Epoch 227/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5920 - val_loss: 0.7394\n",
      "Epoch 228/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5886 - val_loss: 0.7259\n",
      "Epoch 229/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5840 - val_loss: 0.7263\n",
      "Epoch 230/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.5801 - val_loss: 0.7224\n",
      "Epoch 231/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5762 - val_loss: 0.7112\n",
      "Epoch 232/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.5746 - val_loss: 0.7064\n",
      "Epoch 233/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5704 - val_loss: 0.7046\n",
      "Epoch 234/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5672 - val_loss: 0.7392\n",
      "Epoch 235/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.5752 - val_loss: 0.7060\n",
      "Epoch 236/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.5749 - val_loss: 0.7003\n",
      "Epoch 237/1500\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.5677 - val_loss: 0.7261\n",
      "Epoch 238/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5740 - val_loss: 0.7672\n",
      "Epoch 239/1500\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.6122 - val_loss: 0.7458\n",
      "Epoch 240/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.6090 - val_loss: 0.7589\n",
      "Epoch 241/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6023 - val_loss: 0.7540\n",
      "Epoch 242/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6003 - val_loss: 0.7365\n",
      "Epoch 243/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5988 - val_loss: 0.7394\n",
      "Epoch 244/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5907 - val_loss: 0.7270\n",
      "Epoch 245/1500\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.5872 - val_loss: 0.7039\n",
      "Epoch 246/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5760 - val_loss: 0.6834\n",
      "Epoch 247/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5744 - val_loss: 0.7678\n",
      "Epoch 248/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5863 - val_loss: 0.6849\n",
      "Epoch 249/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.5759 - val_loss: 0.6833\n",
      "Epoch 250/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5691 - val_loss: 0.6721\n",
      "Epoch 251/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5621 - val_loss: 0.6715\n",
      "Epoch 252/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5539 - val_loss: 0.6748\n",
      "Epoch 253/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5515 - val_loss: 0.6526\n",
      "Epoch 254/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5462 - val_loss: 0.6463\n",
      "Epoch 255/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.5392 - val_loss: 0.6550\n",
      "Epoch 256/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.5534 - val_loss: 0.6773\n",
      "Epoch 257/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.5719 - val_loss: 0.6776\n",
      "Epoch 258/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.5571 - val_loss: 0.6980\n",
      "Epoch 259/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5597 - val_loss: 0.6603\n",
      "Epoch 260/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.5462 - val_loss: 0.6492\n",
      "Epoch 261/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5422 - val_loss: 0.6451\n",
      "Epoch 262/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5338 - val_loss: 0.6348\n",
      "Epoch 263/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5291 - val_loss: 0.6306\n",
      "Epoch 264/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.5264 - val_loss: 0.6291\n",
      "Epoch 265/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5374 - val_loss: 0.6261\n",
      "Epoch 266/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5267 - val_loss: 0.6212\n",
      "Epoch 267/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5297 - val_loss: 0.6402\n",
      "Epoch 268/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5430 - val_loss: 0.6312\n",
      "Epoch 269/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5384 - val_loss: 0.6158\n",
      "Epoch 270/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5252 - val_loss: 0.6203\n",
      "Epoch 271/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.5351 - val_loss: 0.6484\n",
      "Epoch 272/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.5372 - val_loss: 0.6345\n",
      "Epoch 273/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5288 - val_loss: 0.6228\n",
      "Epoch 274/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.5426 - val_loss: 0.6253\n",
      "Epoch 275/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5443 - val_loss: 0.6075\n",
      "Epoch 276/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5381 - val_loss: 0.6267\n",
      "Epoch 277/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5282 - val_loss: 0.6126\n",
      "Epoch 278/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5236 - val_loss: 0.6081\n",
      "Epoch 279/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5148 - val_loss: 0.6013\n",
      "Epoch 280/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5143 - val_loss: 0.5997\n",
      "Epoch 281/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.5091 - val_loss: 0.5892\n",
      "Epoch 282/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.5035 - val_loss: 0.5822\n",
      "Epoch 283/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5036 - val_loss: 0.5839\n",
      "Epoch 284/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.4967 - val_loss: 0.5672\n",
      "Epoch 285/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4945 - val_loss: 0.5695\n",
      "Epoch 286/1500\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4935 - val_loss: 0.6077\n",
      "Epoch 287/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5116 - val_loss: 0.6132\n",
      "Epoch 288/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5446 - val_loss: 0.7357\n",
      "Epoch 289/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5580 - val_loss: 0.6366\n",
      "Epoch 290/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5447 - val_loss: 0.6404\n",
      "Epoch 291/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5509 - val_loss: 0.6428\n",
      "Epoch 292/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5373 - val_loss: 0.6328\n",
      "Epoch 293/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5367 - val_loss: 0.6023\n",
      "Epoch 294/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5215 - val_loss: 0.5862\n",
      "Epoch 295/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5115 - val_loss: 0.5766\n",
      "Epoch 296/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5100 - val_loss: 0.5815\n",
      "Epoch 297/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5239 - val_loss: 0.6136\n",
      "Epoch 298/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.5340 - val_loss: 0.6095\n",
      "Epoch 299/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5317 - val_loss: 0.5969\n",
      "Epoch 300/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.5142 - val_loss: 0.5989\n",
      "Epoch 301/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5191 - val_loss: 0.5902\n",
      "Epoch 302/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5108 - val_loss: 0.6008\n",
      "Epoch 303/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5141 - val_loss: 0.5719\n",
      "Epoch 304/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.5027 - val_loss: 0.5838\n",
      "Epoch 305/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5060 - val_loss: 0.5772\n",
      "Epoch 306/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4958 - val_loss: 0.5610\n",
      "Epoch 307/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4926 - val_loss: 0.5643\n",
      "Epoch 308/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4848 - val_loss: 0.5535\n",
      "Epoch 309/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.4803 - val_loss: 0.5555\n",
      "Epoch 310/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4768 - val_loss: 0.5417\n",
      "Epoch 311/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4751 - val_loss: 0.5725\n",
      "Epoch 312/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4948 - val_loss: 0.5398\n",
      "Epoch 313/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4874 - val_loss: 0.5493\n",
      "Epoch 314/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4861 - val_loss: 0.5480\n",
      "Epoch 315/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4758 - val_loss: 0.5329\n",
      "Epoch 316/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4746 - val_loss: 0.5424\n",
      "Epoch 317/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4706 - val_loss: 0.5357\n",
      "Epoch 318/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4664 - val_loss: 0.5344\n",
      "Epoch 319/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.4631 - val_loss: 0.5256\n",
      "Epoch 320/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4634 - val_loss: 0.5403\n",
      "Epoch 321/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.4619 - val_loss: 0.5181\n",
      "Epoch 322/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4556 - val_loss: 0.5142\n",
      "Epoch 323/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.4520 - val_loss: 0.5075\n",
      "Epoch 324/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4665 - val_loss: 0.5343\n",
      "Epoch 325/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4796 - val_loss: 0.5271\n",
      "Epoch 326/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4835 - val_loss: 0.5261\n",
      "Epoch 327/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4710 - val_loss: 0.5292\n",
      "Epoch 328/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4683 - val_loss: 0.5111\n",
      "Epoch 329/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4589 - val_loss: 0.5061\n",
      "Epoch 330/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4546 - val_loss: 0.5067\n",
      "Epoch 331/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4617 - val_loss: 0.5070\n",
      "Epoch 332/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4821 - val_loss: 0.5171\n",
      "Epoch 333/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4555 - val_loss: 0.5335\n",
      "Epoch 334/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4572 - val_loss: 0.5026\n",
      "Epoch 335/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.4452 - val_loss: 0.4954\n",
      "Epoch 336/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4414 - val_loss: 0.4945\n",
      "Epoch 337/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4393 - val_loss: 0.4969\n",
      "Epoch 338/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4410 - val_loss: 0.4998\n",
      "Epoch 339/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4503 - val_loss: 0.4959\n",
      "Epoch 340/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4559 - val_loss: 0.4867\n",
      "Epoch 341/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4418 - val_loss: 0.4925\n",
      "Epoch 342/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4381 - val_loss: 0.4954\n",
      "Epoch 343/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4322 - val_loss: 0.4842\n",
      "Epoch 344/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4289 - val_loss: 0.4858\n",
      "Epoch 345/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4266 - val_loss: 0.4751\n",
      "Epoch 346/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4234 - val_loss: 0.4858\n",
      "Epoch 347/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4249 - val_loss: 0.4910\n",
      "Epoch 348/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4334 - val_loss: 0.4827\n",
      "Epoch 349/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4301 - val_loss: 0.4785\n",
      "Epoch 350/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4259 - val_loss: 0.5026\n",
      "Epoch 351/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4253 - val_loss: 0.4843\n",
      "Epoch 352/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4249 - val_loss: 0.4936\n",
      "Epoch 353/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4272 - val_loss: 0.4858\n",
      "Epoch 354/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4164 - val_loss: 0.4746\n",
      "Epoch 355/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4136 - val_loss: 0.5046\n",
      "Epoch 356/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4454 - val_loss: 0.5065\n",
      "Epoch 357/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4377 - val_loss: 0.4866\n",
      "Epoch 358/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4297 - val_loss: 0.4838\n",
      "Epoch 359/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4274 - val_loss: 0.4844\n",
      "Epoch 360/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4253 - val_loss: 0.4948\n",
      "Epoch 361/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4653 - val_loss: 0.4813\n",
      "Epoch 362/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4947 - val_loss: 0.5257\n",
      "Epoch 363/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4836 - val_loss: 0.5310\n",
      "Epoch 364/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4659 - val_loss: 0.5219\n",
      "Epoch 365/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4559 - val_loss: 0.5064\n",
      "Epoch 366/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4731 - val_loss: 0.5568\n",
      "Epoch 367/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4512 - val_loss: 0.5074\n",
      "Epoch 368/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4465 - val_loss: 0.4998\n",
      "Epoch 369/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4407 - val_loss: 0.5087\n",
      "Epoch 370/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4316 - val_loss: 0.4788\n",
      "Epoch 371/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4254 - val_loss: 0.4790\n",
      "Epoch 372/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4292 - val_loss: 0.4949\n",
      "Epoch 373/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4233 - val_loss: 0.4711\n",
      "Epoch 374/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4151 - val_loss: 0.4676\n",
      "Epoch 375/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4137 - val_loss: 0.4566\n",
      "Epoch 376/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4116 - val_loss: 0.4579\n",
      "Epoch 377/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4046 - val_loss: 0.4595\n",
      "Epoch 378/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4091 - val_loss: 0.4648\n",
      "Epoch 379/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4080 - val_loss: 0.4566\n",
      "Epoch 380/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4011 - val_loss: 0.4539\n",
      "Epoch 381/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4003 - val_loss: 0.4564\n",
      "Epoch 382/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4004 - val_loss: 0.4585\n",
      "Epoch 383/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4108 - val_loss: 0.4929\n",
      "Epoch 384/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4328 - val_loss: 0.4814\n",
      "Epoch 385/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4188 - val_loss: 0.5013\n",
      "Epoch 386/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4172 - val_loss: 0.4707\n",
      "Epoch 387/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4178 - val_loss: 0.4767\n",
      "Epoch 388/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4930 - val_loss: 0.5196\n",
      "Epoch 389/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4452 - val_loss: 0.4940\n",
      "Epoch 390/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4550 - val_loss: 0.4876\n",
      "Epoch 391/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4387 - val_loss: 0.4620\n",
      "Epoch 392/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4290 - val_loss: 0.4656\n",
      "Epoch 393/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4209 - val_loss: 0.4682\n",
      "Epoch 394/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4201 - val_loss: 0.4529\n",
      "Epoch 395/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4138 - val_loss: 0.4529\n",
      "Epoch 396/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4088 - val_loss: 0.4466\n",
      "Epoch 397/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4039 - val_loss: 0.4460\n",
      "Epoch 398/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4004 - val_loss: 0.4375\n",
      "Epoch 399/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3952 - val_loss: 0.4400\n",
      "Epoch 400/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3936 - val_loss: 0.4387\n",
      "Epoch 401/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3923 - val_loss: 0.4347\n",
      "Epoch 402/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3902 - val_loss: 0.4323\n",
      "Epoch 403/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3875 - val_loss: 0.4413\n",
      "Epoch 404/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3889 - val_loss: 0.4392\n",
      "Epoch 405/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3843 - val_loss: 0.4439\n",
      "Epoch 406/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3854 - val_loss: 0.4477\n",
      "Epoch 407/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3882 - val_loss: 0.4391\n",
      "Epoch 408/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3822 - val_loss: 0.4653\n",
      "Epoch 409/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4495 - val_loss: 0.4746\n",
      "Epoch 410/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4350 - val_loss: 0.4979\n",
      "Epoch 411/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4293 - val_loss: 0.4602\n",
      "Epoch 412/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4278 - val_loss: 0.4780\n",
      "Epoch 413/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4308 - val_loss: 0.4639\n",
      "Epoch 414/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4251 - val_loss: 0.4703\n",
      "Epoch 415/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4171 - val_loss: 0.4492\n",
      "Epoch 416/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4124 - val_loss: 0.4467\n",
      "Epoch 417/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3961 - val_loss: 0.4409\n",
      "Epoch 418/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3923 - val_loss: 0.4381\n",
      "Epoch 419/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3948 - val_loss: 0.4349\n",
      "Epoch 420/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4024 - val_loss: 0.4385\n",
      "Epoch 421/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3923 - val_loss: 0.4359\n",
      "Epoch 422/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3947 - val_loss: 0.4304\n",
      "Epoch 423/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3885 - val_loss: 0.4317\n",
      "Epoch 424/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3850 - val_loss: 0.4283\n",
      "Epoch 425/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3975 - val_loss: 0.4486\n",
      "Epoch 426/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3963 - val_loss: 0.4421\n",
      "Epoch 427/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3856 - val_loss: 0.4448\n",
      "Epoch 428/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3829 - val_loss: 0.4342\n",
      "Epoch 429/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4059 - val_loss: 0.4907\n",
      "Epoch 430/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4194 - val_loss: 0.4779\n",
      "Epoch 431/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4017 - val_loss: 0.4477\n",
      "Epoch 432/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3924 - val_loss: 0.4522\n",
      "Epoch 433/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3886 - val_loss: 0.4401\n",
      "Epoch 434/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3795 - val_loss: 0.4364\n",
      "Epoch 435/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3844 - val_loss: 0.4581\n",
      "Epoch 436/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3835 - val_loss: 0.4319\n",
      "Epoch 437/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3854 - val_loss: 0.4276\n",
      "Epoch 438/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3780 - val_loss: 0.4343\n",
      "Epoch 439/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3794 - val_loss: 0.4337\n",
      "Epoch 440/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3751 - val_loss: 0.4220\n",
      "Epoch 441/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3743 - val_loss: 0.4294\n",
      "Epoch 442/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3758 - val_loss: 0.4270\n",
      "Epoch 443/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3703 - val_loss: 0.4226\n",
      "Epoch 444/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3679 - val_loss: 0.4166\n",
      "Epoch 445/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3680 - val_loss: 0.4158\n",
      "Epoch 446/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3660 - val_loss: 0.4100\n",
      "Epoch 447/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3629 - val_loss: 0.4133\n",
      "Epoch 448/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3609 - val_loss: 0.4142\n",
      "Epoch 449/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3606 - val_loss: 0.4094\n",
      "Epoch 450/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3640 - val_loss: 0.4146\n",
      "Epoch 451/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3689 - val_loss: 0.4373\n",
      "Epoch 452/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3704 - val_loss: 0.4434\n",
      "Epoch 453/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3751 - val_loss: 0.4276\n",
      "Epoch 454/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3673 - val_loss: 0.4354\n",
      "Epoch 455/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3680 - val_loss: 0.4196\n",
      "Epoch 456/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3619 - val_loss: 0.4168\n",
      "Epoch 457/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3619 - val_loss: 0.4528\n",
      "Epoch 458/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5223 - val_loss: 0.5601\n",
      "Epoch 459/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4818 - val_loss: 0.4832\n",
      "Epoch 460/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4356 - val_loss: 0.4878\n",
      "Epoch 461/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4273 - val_loss: 0.4816\n",
      "Epoch 462/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4367 - val_loss: 0.4736\n",
      "Epoch 463/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4173 - val_loss: 0.4722\n",
      "Epoch 464/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4170 - val_loss: 0.4516\n",
      "Epoch 465/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.4028 - val_loss: 0.4405\n",
      "Epoch 466/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3976 - val_loss: 0.4415\n",
      "Epoch 467/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3878 - val_loss: 0.4240\n",
      "Epoch 468/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3796 - val_loss: 0.4161\n",
      "Epoch 469/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3728 - val_loss: 0.4101\n",
      "Epoch 470/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3732 - val_loss: 0.4168\n",
      "Epoch 471/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3734 - val_loss: 0.4149\n",
      "Epoch 472/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3754 - val_loss: 0.4128\n",
      "Epoch 473/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3755 - val_loss: 0.4239\n",
      "Epoch 474/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3709 - val_loss: 0.4205\n",
      "Epoch 475/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3694 - val_loss: 0.4153\n",
      "Epoch 476/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3640 - val_loss: 0.4094\n",
      "Epoch 477/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3607 - val_loss: 0.4174\n",
      "Epoch 478/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3779 - val_loss: 0.4416\n",
      "Epoch 479/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3723 - val_loss: 0.4159\n",
      "Epoch 480/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3610 - val_loss: 0.4158\n",
      "Epoch 481/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3599 - val_loss: 0.4046\n",
      "Epoch 482/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3683 - val_loss: 0.4374\n",
      "Epoch 483/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4084 - val_loss: 0.4485\n",
      "Epoch 484/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3923 - val_loss: 0.4546\n",
      "Epoch 485/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3838 - val_loss: 0.4154\n",
      "Epoch 486/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3661 - val_loss: 0.4152\n",
      "Epoch 487/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3634 - val_loss: 0.4084\n",
      "Epoch 488/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3567 - val_loss: 0.4016\n",
      "Epoch 489/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3510 - val_loss: 0.4031\n",
      "Epoch 490/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3505 - val_loss: 0.4107\n",
      "Epoch 491/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3469 - val_loss: 0.4095\n",
      "Epoch 492/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3477 - val_loss: 0.4107\n",
      "Epoch 493/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3512 - val_loss: 0.4158\n",
      "Epoch 494/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3525 - val_loss: 0.4164\n",
      "Epoch 495/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3540 - val_loss: 0.4035\n",
      "Epoch 496/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3489 - val_loss: 0.4117\n",
      "Epoch 497/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3523 - val_loss: 0.4098\n",
      "Epoch 498/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3561 - val_loss: 0.3950\n",
      "Epoch 499/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3544 - val_loss: 0.4042\n",
      "Epoch 500/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3504 - val_loss: 0.4105\n",
      "Epoch 501/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3479 - val_loss: 0.4000\n",
      "Epoch 502/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3456 - val_loss: 0.3959\n",
      "Epoch 503/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3618 - val_loss: 0.4115\n",
      "Epoch 504/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3538 - val_loss: 0.4063\n",
      "Epoch 505/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3476 - val_loss: 0.4024\n",
      "Epoch 506/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3508 - val_loss: 0.4201\n",
      "Epoch 507/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3466 - val_loss: 0.4154\n",
      "Epoch 508/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3814 - val_loss: 0.4357\n",
      "Epoch 509/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3685 - val_loss: 0.3915\n",
      "Epoch 510/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3617 - val_loss: 0.3964\n",
      "Epoch 511/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3549 - val_loss: 0.3909\n",
      "Epoch 512/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3556 - val_loss: 0.4088\n",
      "Epoch 513/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3768 - val_loss: 0.4375\n",
      "Epoch 514/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.4066 - val_loss: 0.4028\n",
      "Epoch 515/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3631 - val_loss: 0.4156\n",
      "Epoch 516/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3569 - val_loss: 0.4193\n",
      "Epoch 517/1500\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3642 - val_loss: 0.4080\n",
      "Epoch 518/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3802 - val_loss: 0.4249\n",
      "Epoch 519/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3737 - val_loss: 0.4032\n",
      "Epoch 520/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3578 - val_loss: 0.3938\n",
      "Epoch 521/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3525 - val_loss: 0.3998\n",
      "Epoch 522/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3618 - val_loss: 0.4322\n",
      "Epoch 523/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3655 - val_loss: 0.4058\n",
      "Epoch 524/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3519 - val_loss: 0.3946\n",
      "Epoch 525/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3475 - val_loss: 0.3811\n",
      "Epoch 526/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.3441 - val_loss: 0.3799\n",
      "Epoch 527/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3544 - val_loss: 0.4139\n",
      "Epoch 528/1500\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.3661 - val_loss: 0.4048\n",
      "Epoch 529/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.3935 - val_loss: 0.4352\n",
      "Epoch 530/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3760 - val_loss: 0.4065\n",
      "Epoch 531/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3697 - val_loss: 0.4040\n",
      "Epoch 532/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3564 - val_loss: 0.4006\n",
      "Epoch 533/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.3565 - val_loss: 0.3911\n",
      "Epoch 534/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3446 - val_loss: 0.3815\n",
      "Epoch 535/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.3409 - val_loss: 0.3839\n",
      "Epoch 536/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3396 - val_loss: 0.3849\n",
      "Epoch 537/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3347 - val_loss: 0.3815\n",
      "Epoch 538/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3360 - val_loss: 0.3816\n",
      "Epoch 539/1500\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.3538 - val_loss: 0.3883\n",
      "Epoch 540/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3441 - val_loss: 0.3891\n",
      "Epoch 541/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3736 - val_loss: 0.4379\n",
      "Epoch 542/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3723 - val_loss: 0.3966\n",
      "Epoch 543/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3588 - val_loss: 0.4129\n",
      "Epoch 544/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4139 - val_loss: 0.4772\n",
      "Epoch 545/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3973 - val_loss: 0.5116\n",
      "Epoch 546/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4033 - val_loss: 0.4377\n",
      "Epoch 547/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.3949 - val_loss: 0.4988\n",
      "Epoch 548/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.4542 - val_loss: 0.4758\n",
      "Epoch 549/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4086 - val_loss: 0.4586\n",
      "Epoch 550/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4065 - val_loss: 0.4419\n",
      "Epoch 551/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3830 - val_loss: 0.4245\n",
      "Epoch 552/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3786 - val_loss: 0.4195\n",
      "Epoch 553/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3755 - val_loss: 0.4072\n",
      "Epoch 554/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.3611 - val_loss: 0.4028\n",
      "Epoch 555/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3577 - val_loss: 0.3975\n",
      "Epoch 556/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3519 - val_loss: 0.3992\n",
      "Epoch 557/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3484 - val_loss: 0.3890\n",
      "Epoch 558/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3424 - val_loss: 0.3883\n",
      "Epoch 559/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3398 - val_loss: 0.3914\n",
      "Epoch 560/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3365 - val_loss: 0.3884\n",
      "Epoch 561/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3395 - val_loss: 0.3840\n",
      "Epoch 562/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3399 - val_loss: 0.3852\n",
      "Epoch 563/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3358 - val_loss: 0.3895\n",
      "Epoch 564/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3340 - val_loss: 0.3857\n",
      "Epoch 565/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3358 - val_loss: 0.3979\n",
      "Epoch 566/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3375 - val_loss: 0.4106\n",
      "Epoch 567/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3424 - val_loss: 0.3912\n",
      "Epoch 568/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.3375 - val_loss: 0.4028\n",
      "Epoch 569/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3490 - val_loss: 0.4037\n",
      "Epoch 570/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3464 - val_loss: 0.3871\n",
      "Epoch 571/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3392 - val_loss: 0.3804\n",
      "Epoch 572/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3338 - val_loss: 0.3872\n",
      "Epoch 573/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3319 - val_loss: 0.3851\n",
      "Epoch 574/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3290 - val_loss: 0.3806\n",
      "Epoch 575/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3303 - val_loss: 0.3811\n",
      "Epoch 576/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3285 - val_loss: 0.3819\n",
      "Epoch 577/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3381 - val_loss: 0.3823\n",
      "Epoch 578/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3301 - val_loss: 0.3879\n",
      "Epoch 579/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3247 - val_loss: 0.3821\n",
      "Epoch 580/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3251 - val_loss: 0.3783\n",
      "Epoch 581/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3224 - val_loss: 0.3819\n",
      "Epoch 582/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3244 - val_loss: 0.3755\n",
      "Epoch 583/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3192 - val_loss: 0.3725\n",
      "Epoch 584/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3184 - val_loss: 0.3792\n",
      "Epoch 585/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.3169 - val_loss: 0.3701\n",
      "Epoch 586/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3180 - val_loss: 0.3788\n",
      "Epoch 587/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3241 - val_loss: 0.3940\n",
      "Epoch 588/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3242 - val_loss: 0.3791\n",
      "Epoch 589/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3328 - val_loss: 0.3763\n",
      "Epoch 590/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3219 - val_loss: 0.3730\n",
      "Epoch 591/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3193 - val_loss: 0.3855\n",
      "Epoch 592/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3169 - val_loss: 0.3772\n",
      "Epoch 593/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3152 - val_loss: 0.3765\n",
      "Epoch 594/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3302 - val_loss: 0.3953\n",
      "Epoch 595/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3349 - val_loss: 0.3675\n",
      "Epoch 596/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3191 - val_loss: 0.3759\n",
      "Epoch 597/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3182 - val_loss: 0.3734\n",
      "Epoch 598/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3341 - val_loss: 0.3875\n",
      "Epoch 599/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3353 - val_loss: 0.3748\n",
      "Epoch 600/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3183 - val_loss: 0.3805\n",
      "Epoch 601/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3172 - val_loss: 0.3739\n",
      "Epoch 602/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3150 - val_loss: 0.3712\n",
      "Epoch 603/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3120 - val_loss: 0.3677\n",
      "Epoch 604/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3107 - val_loss: 0.3669\n",
      "Epoch 605/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3101 - val_loss: 0.3678\n",
      "Epoch 606/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3101 - val_loss: 0.3728\n",
      "Epoch 607/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3200 - val_loss: 0.3896\n",
      "Epoch 608/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3140 - val_loss: 0.3650\n",
      "Epoch 609/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3117 - val_loss: 0.3777\n",
      "Epoch 610/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3267 - val_loss: 0.3771\n",
      "Epoch 611/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3370 - val_loss: 0.4005\n",
      "Epoch 612/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.3446 - val_loss: 0.5051\n",
      "Epoch 613/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3933 - val_loss: 0.4793\n",
      "Epoch 614/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3658 - val_loss: 0.4227\n",
      "Epoch 615/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3500 - val_loss: 0.3919\n",
      "Epoch 616/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.3465 - val_loss: 0.3822\n",
      "Epoch 617/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3366 - val_loss: 0.3795\n",
      "Epoch 618/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3306 - val_loss: 0.3740\n",
      "Epoch 619/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3275 - val_loss: 0.3699\n",
      "Epoch 620/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3277 - val_loss: 0.3681\n",
      "Epoch 621/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3254 - val_loss: 0.3733\n",
      "Epoch 622/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3366 - val_loss: 0.3706\n",
      "Epoch 623/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3257 - val_loss: 0.3653\n",
      "Epoch 624/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3257 - val_loss: 0.3661\n",
      "Epoch 625/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3237 - val_loss: 0.3574\n",
      "Epoch 626/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3172 - val_loss: 0.3601\n",
      "Epoch 627/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3165 - val_loss: 0.3645\n",
      "Epoch 628/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3137 - val_loss: 0.3707\n",
      "Epoch 629/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3143 - val_loss: 0.3725\n",
      "Epoch 630/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.3100 - val_loss: 0.3635\n",
      "Epoch 631/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3191 - val_loss: 0.3818\n",
      "Epoch 632/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3301 - val_loss: 0.3844\n",
      "Epoch 633/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3262 - val_loss: 0.3885\n",
      "Epoch 634/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3281 - val_loss: 0.3999\n",
      "Epoch 635/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3247 - val_loss: 0.3947\n",
      "Epoch 636/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3226 - val_loss: 0.3839\n",
      "Epoch 637/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3190 - val_loss: 0.3792\n",
      "Epoch 638/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3169 - val_loss: 0.3754\n",
      "Epoch 639/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3239 - val_loss: 0.3840\n",
      "Epoch 640/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3153 - val_loss: 0.3941\n",
      "Epoch 641/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3172 - val_loss: 0.3762\n",
      "Epoch 642/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3110 - val_loss: 0.3809\n",
      "Epoch 643/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3114 - val_loss: 0.3666\n",
      "Epoch 644/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3071 - val_loss: 0.3750\n",
      "Epoch 645/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3092 - val_loss: 0.3780\n",
      "Epoch 646/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3075 - val_loss: 0.3743\n",
      "Epoch 647/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3109 - val_loss: 0.3682\n",
      "Epoch 648/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3098 - val_loss: 0.3754\n",
      "Epoch 649/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3067 - val_loss: 0.3672\n",
      "Epoch 650/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3049 - val_loss: 0.3643\n",
      "Epoch 651/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3011 - val_loss: 0.3635\n",
      "Epoch 652/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2995 - val_loss: 0.3701\n",
      "Epoch 653/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3011 - val_loss: 0.3731\n",
      "Epoch 654/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3033 - val_loss: 0.3836\n",
      "Epoch 655/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2996 - val_loss: 0.3660\n",
      "Epoch 656/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2998 - val_loss: 0.3782\n",
      "Epoch 657/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3302 - val_loss: 0.4386\n",
      "Epoch 658/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3332 - val_loss: 0.3763\n",
      "Epoch 659/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3158 - val_loss: 0.3568\n",
      "Epoch 660/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3103 - val_loss: 0.3890\n",
      "Epoch 661/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3154 - val_loss: 0.3679\n",
      "Epoch 662/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3115 - val_loss: 0.3653\n",
      "Epoch 663/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.3110 - val_loss: 0.3581\n",
      "Epoch 664/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3042 - val_loss: 0.3577\n",
      "Epoch 665/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3089 - val_loss: 0.3659\n",
      "Epoch 666/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3189 - val_loss: 0.3904\n",
      "Epoch 667/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3446 - val_loss: 0.3974\n",
      "Epoch 668/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3423 - val_loss: 0.3627\n",
      "Epoch 669/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3268 - val_loss: 0.3561\n",
      "Epoch 670/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.3076 - val_loss: 0.3492\n",
      "Epoch 671/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3090 - val_loss: 0.3597\n",
      "Epoch 672/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3139 - val_loss: 0.3803\n",
      "Epoch 673/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3118 - val_loss: 0.3703\n",
      "Epoch 674/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.3117 - val_loss: 0.3472\n",
      "Epoch 675/1500\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.3058 - val_loss: 0.3469\n",
      "Epoch 676/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3024 - val_loss: 0.3562\n",
      "Epoch 677/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3000 - val_loss: 0.3524\n",
      "Epoch 678/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2972 - val_loss: 0.3511\n",
      "Epoch 679/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3011 - val_loss: 0.3560\n",
      "Epoch 680/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2973 - val_loss: 0.3547\n",
      "Epoch 681/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2926 - val_loss: 0.3488\n",
      "Epoch 682/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2912 - val_loss: 0.3514\n",
      "Epoch 683/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2911 - val_loss: 0.3601\n",
      "Epoch 684/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2918 - val_loss: 0.3530\n",
      "Epoch 685/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2895 - val_loss: 0.3540\n",
      "Epoch 686/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2904 - val_loss: 0.3503\n",
      "Epoch 687/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2899 - val_loss: 0.3484\n",
      "Epoch 688/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2871 - val_loss: 0.3492\n",
      "Epoch 689/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2859 - val_loss: 0.3479\n",
      "Epoch 690/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2874 - val_loss: 0.3465\n",
      "Epoch 691/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.2874 - val_loss: 0.3456\n",
      "Epoch 692/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2863 - val_loss: 0.3587\n",
      "Epoch 693/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3077 - val_loss: 0.4239\n",
      "Epoch 694/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3292 - val_loss: 0.3736\n",
      "Epoch 695/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3101 - val_loss: 0.3590\n",
      "Epoch 696/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.3136 - val_loss: 0.3571\n",
      "Epoch 697/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3091 - val_loss: 0.3705\n",
      "Epoch 698/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3133 - val_loss: 0.3571\n",
      "Epoch 699/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3122 - val_loss: 0.3541\n",
      "Epoch 700/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3033 - val_loss: 0.3730\n",
      "Epoch 701/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3037 - val_loss: 0.3459\n",
      "Epoch 702/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.3026 - val_loss: 0.3681\n",
      "Epoch 703/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3095 - val_loss: 0.3541\n",
      "Epoch 704/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2964 - val_loss: 0.3459\n",
      "Epoch 705/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3085 - val_loss: 0.3920\n",
      "Epoch 706/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3219 - val_loss: 0.3591\n",
      "Epoch 707/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3021 - val_loss: 0.3403\n",
      "Epoch 708/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3062 - val_loss: 0.3754\n",
      "Epoch 709/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3165 - val_loss: 0.3483\n",
      "Epoch 710/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3004 - val_loss: 0.3478\n",
      "Epoch 711/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2969 - val_loss: 0.3480\n",
      "Epoch 712/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.2934 - val_loss: 0.3446\n",
      "Epoch 713/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2919 - val_loss: 0.3406\n",
      "Epoch 714/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2897 - val_loss: 0.3396\n",
      "Epoch 715/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.2861 - val_loss: 0.3402\n",
      "Epoch 716/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.2872 - val_loss: 0.3361\n",
      "Epoch 717/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2901 - val_loss: 0.3343\n",
      "Epoch 718/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2859 - val_loss: 0.3386\n",
      "Epoch 719/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.2850 - val_loss: 0.3374\n",
      "Epoch 720/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2831 - val_loss: 0.3365\n",
      "Epoch 721/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.2897 - val_loss: 0.3354\n",
      "Epoch 722/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2904 - val_loss: 0.3351\n",
      "Epoch 723/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2846 - val_loss: 0.3448\n",
      "Epoch 724/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2888 - val_loss: 0.3396\n",
      "Epoch 725/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2893 - val_loss: 0.3457\n",
      "Epoch 726/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2914 - val_loss: 0.3455\n",
      "Epoch 727/1500\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.2882 - val_loss: 0.3474\n",
      "Epoch 728/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3340 - val_loss: 0.3479\n",
      "Epoch 729/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3098 - val_loss: 0.4337\n",
      "Epoch 730/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3356 - val_loss: 0.3664\n",
      "Epoch 731/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3169 - val_loss: 0.3846\n",
      "Epoch 732/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3208 - val_loss: 0.3502\n",
      "Epoch 733/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.3185 - val_loss: 0.4309\n",
      "Epoch 734/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3504 - val_loss: 0.3969\n",
      "Epoch 735/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3289 - val_loss: 0.3819\n",
      "Epoch 736/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3149 - val_loss: 0.3576\n",
      "Epoch 737/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3081 - val_loss: 0.3652\n",
      "Epoch 738/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3145 - val_loss: 0.3876\n",
      "Epoch 739/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.3129 - val_loss: 0.3643\n",
      "Epoch 740/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3149 - val_loss: 0.3998\n",
      "Epoch 741/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3239 - val_loss: 0.3878\n",
      "Epoch 742/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3211 - val_loss: 0.3611\n",
      "Epoch 743/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.3063 - val_loss: 0.3708\n",
      "Epoch 744/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3101 - val_loss: 0.3577\n",
      "Epoch 745/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3084 - val_loss: 0.3494\n",
      "Epoch 746/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2904 - val_loss: 0.3565\n",
      "Epoch 747/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3017 - val_loss: 0.3926\n",
      "Epoch 748/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3432 - val_loss: 0.3869\n",
      "Epoch 749/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3380 - val_loss: 0.3858\n",
      "Epoch 750/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3294 - val_loss: 0.3805\n",
      "Epoch 751/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3217 - val_loss: 0.3727\n",
      "Epoch 752/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3085 - val_loss: 0.3618\n",
      "Epoch 753/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3012 - val_loss: 0.3614\n",
      "Epoch 754/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3072 - val_loss: 0.3695\n",
      "Epoch 755/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3075 - val_loss: 0.3573\n",
      "Epoch 756/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3029 - val_loss: 0.3674\n",
      "Epoch 757/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3019 - val_loss: 0.3560\n",
      "Epoch 758/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2957 - val_loss: 0.3547\n",
      "Epoch 759/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2927 - val_loss: 0.3439\n",
      "Epoch 760/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2899 - val_loss: 0.3385\n",
      "Epoch 761/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2999 - val_loss: 0.3518\n",
      "Epoch 762/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2992 - val_loss: 0.3490\n",
      "Epoch 763/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2984 - val_loss: 0.3708\n",
      "Epoch 764/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3006 - val_loss: 0.3554\n",
      "Epoch 765/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.3106 - val_loss: 0.3534\n",
      "Epoch 766/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3252 - val_loss: 0.4375\n",
      "Epoch 767/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3591 - val_loss: 0.4173\n",
      "Epoch 768/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3598 - val_loss: 0.3916\n",
      "Epoch 769/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3487 - val_loss: 0.3994\n",
      "Epoch 770/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3449 - val_loss: 0.3682\n",
      "Epoch 771/1500\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3241 - val_loss: 0.3554\n",
      "Epoch 772/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3143 - val_loss: 0.3414\n",
      "Epoch 773/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3072 - val_loss: 0.3408\n",
      "Epoch 774/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3021 - val_loss: 0.3392\n",
      "Epoch 775/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2999 - val_loss: 0.3375\n",
      "Epoch 776/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2968 - val_loss: 0.3394\n",
      "Epoch 777/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.2952 - val_loss: 0.3377\n",
      "Epoch 778/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2913 - val_loss: 0.3345\n",
      "Epoch 779/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2891 - val_loss: 0.3336\n",
      "Epoch 780/1500\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2885 - val_loss: 0.3360\n",
      "Epoch 781/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2870 - val_loss: 0.3332\n",
      "Epoch 782/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2870 - val_loss: 0.3341\n",
      "Epoch 783/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2858 - val_loss: 0.3359\n",
      "Epoch 784/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2848 - val_loss: 0.3357\n",
      "Epoch 785/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2844 - val_loss: 0.3333\n",
      "Epoch 786/1500\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2822 - val_loss: 0.3316\n",
      "Epoch 787/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2817 - val_loss: 0.3267\n",
      "Epoch 788/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2796 - val_loss: 0.3273\n",
      "Epoch 789/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2782 - val_loss: 0.3314\n",
      "Epoch 790/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2805 - val_loss: 0.3359\n",
      "Epoch 791/1500\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.2813 - val_loss: 0.3307\n",
      "Epoch 792/1500\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2793 - val_loss: 0.3283\n",
      "Epoch 793/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2808 - val_loss: 0.3348\n",
      "Epoch 794/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2797 - val_loss: 0.3425\n",
      "Epoch 795/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2823 - val_loss: 0.3317\n",
      "Epoch 796/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2788 - val_loss: 0.3265\n",
      "Epoch 797/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2775 - val_loss: 0.3277\n",
      "Epoch 798/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2752 - val_loss: 0.3317\n",
      "Epoch 799/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2769 - val_loss: 0.3278\n",
      "Epoch 800/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2813 - val_loss: 0.3285\n",
      "Epoch 801/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2877 - val_loss: 0.3292\n",
      "Epoch 802/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2824 - val_loss: 0.3331\n",
      "Epoch 803/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2817 - val_loss: 0.3252\n",
      "Epoch 804/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2783 - val_loss: 0.3246\n",
      "Epoch 805/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2745 - val_loss: 0.3253\n",
      "Epoch 806/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2742 - val_loss: 0.3271\n",
      "Epoch 807/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2713 - val_loss: 0.3252\n",
      "Epoch 808/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2719 - val_loss: 0.3247\n",
      "Epoch 809/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2716 - val_loss: 0.3274\n",
      "Epoch 810/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2718 - val_loss: 0.3274\n",
      "Epoch 811/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2709 - val_loss: 0.3349\n",
      "Epoch 812/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2799 - val_loss: 0.3836\n",
      "Epoch 813/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3064 - val_loss: 0.3443\n",
      "Epoch 814/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2873 - val_loss: 0.3302\n",
      "Epoch 815/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2808 - val_loss: 0.3490\n",
      "Epoch 816/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2809 - val_loss: 0.3360\n",
      "Epoch 817/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2771 - val_loss: 0.3305\n",
      "Epoch 818/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2863 - val_loss: 0.3679\n",
      "Epoch 819/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3577 - val_loss: 0.3827\n",
      "Epoch 820/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3750 - val_loss: 0.3740\n",
      "Epoch 821/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3195 - val_loss: 0.3476\n",
      "Epoch 822/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3177 - val_loss: 0.4036\n",
      "Epoch 823/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.3400 - val_loss: 0.3880\n",
      "Epoch 824/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3252 - val_loss: 0.3707\n",
      "Epoch 825/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3309 - val_loss: 0.3700\n",
      "Epoch 826/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3192 - val_loss: 0.3702\n",
      "Epoch 827/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3104 - val_loss: 0.3853\n",
      "Epoch 828/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3211 - val_loss: 0.3796\n",
      "Epoch 829/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3233 - val_loss: 0.3705\n",
      "Epoch 830/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.3076 - val_loss: 0.3519\n",
      "Epoch 831/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2968 - val_loss: 0.3435\n",
      "Epoch 832/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2889 - val_loss: 0.3399\n",
      "Epoch 833/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2860 - val_loss: 0.3308\n",
      "Epoch 834/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2851 - val_loss: 0.3293\n",
      "Epoch 835/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2825 - val_loss: 0.3337\n",
      "Epoch 836/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2832 - val_loss: 0.3261\n",
      "Epoch 837/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2827 - val_loss: 0.3348\n",
      "Epoch 838/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2859 - val_loss: 0.3332\n",
      "Epoch 839/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2862 - val_loss: 0.3560\n",
      "Epoch 840/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3064 - val_loss: 0.3507\n",
      "Epoch 841/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2977 - val_loss: 0.3449\n",
      "Epoch 842/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2883 - val_loss: 0.3325\n",
      "Epoch 843/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2840 - val_loss: 0.3335\n",
      "Epoch 844/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2847 - val_loss: 0.3340\n",
      "Epoch 845/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2824 - val_loss: 0.3302\n",
      "Epoch 846/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2779 - val_loss: 0.3272\n",
      "Epoch 847/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2758 - val_loss: 0.3246\n",
      "Epoch 848/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2753 - val_loss: 0.3294\n",
      "Epoch 849/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2792 - val_loss: 0.3323\n",
      "Epoch 850/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2786 - val_loss: 0.3312\n",
      "Epoch 851/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2728 - val_loss: 0.3264\n",
      "Epoch 852/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.2737 - val_loss: 0.3213\n",
      "Epoch 853/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2715 - val_loss: 0.3220\n",
      "Epoch 854/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2709 - val_loss: 0.3194\n",
      "Epoch 855/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2753 - val_loss: 0.3206\n",
      "Epoch 856/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2777 - val_loss: 0.3630\n",
      "Epoch 857/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2979 - val_loss: 0.3618\n",
      "Epoch 858/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2905 - val_loss: 0.3358\n",
      "Epoch 859/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2877 - val_loss: 0.3333\n",
      "Epoch 860/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2823 - val_loss: 0.3377\n",
      "Epoch 861/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2862 - val_loss: 0.3460\n",
      "Epoch 862/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2821 - val_loss: 0.3449\n",
      "Epoch 863/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2815 - val_loss: 0.3383\n",
      "Epoch 864/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2796 - val_loss: 0.3275\n",
      "Epoch 865/1500\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2767 - val_loss: 0.3272\n",
      "Epoch 866/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2714 - val_loss: 0.3255\n",
      "Epoch 867/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2704 - val_loss: 0.3239\n",
      "Epoch 868/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2698 - val_loss: 0.3211\n",
      "Epoch 869/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2690 - val_loss: 0.3206\n",
      "Epoch 870/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.2668 - val_loss: 0.3178\n",
      "Epoch 871/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2705 - val_loss: 0.3236\n",
      "Epoch 872/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2733 - val_loss: 0.3202\n",
      "Epoch 873/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2685 - val_loss: 0.3203\n",
      "Epoch 874/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2678 - val_loss: 0.3183\n",
      "Epoch 875/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2687 - val_loss: 0.3225\n",
      "Epoch 876/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2659 - val_loss: 0.3152\n",
      "Epoch 877/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2657 - val_loss: 0.3205\n",
      "Epoch 878/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2675 - val_loss: 0.3169\n",
      "Epoch 879/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2654 - val_loss: 0.3156\n",
      "Epoch 880/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2643 - val_loss: 0.3178\n",
      "Epoch 881/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2643 - val_loss: 0.3145\n",
      "Epoch 882/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2648 - val_loss: 0.3152\n",
      "Epoch 883/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2645 - val_loss: 0.3175\n",
      "Epoch 884/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2639 - val_loss: 0.3174\n",
      "Epoch 885/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2625 - val_loss: 0.3178\n",
      "Epoch 886/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2647 - val_loss: 0.3162\n",
      "Epoch 887/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2627 - val_loss: 0.3234\n",
      "Epoch 888/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2755 - val_loss: 0.3342\n",
      "Epoch 889/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2778 - val_loss: 0.3308\n",
      "Epoch 890/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2758 - val_loss: 0.3311\n",
      "Epoch 891/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2763 - val_loss: 0.3228\n",
      "Epoch 892/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2701 - val_loss: 0.3308\n",
      "Epoch 893/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2706 - val_loss: 0.3369\n",
      "Epoch 894/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2829 - val_loss: 0.3373\n",
      "Epoch 895/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2994 - val_loss: 0.3728\n",
      "Epoch 896/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3135 - val_loss: 0.3697\n",
      "Epoch 897/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2970 - val_loss: 0.3522\n",
      "Epoch 898/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2880 - val_loss: 0.3343\n",
      "Epoch 899/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2772 - val_loss: 0.3364\n",
      "Epoch 900/1500\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2751 - val_loss: 0.3284\n",
      "Epoch 901/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2928 - val_loss: 0.3279\n",
      "Epoch 902/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2881 - val_loss: 0.3292\n",
      "Epoch 903/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2766 - val_loss: 0.3293\n",
      "Epoch 904/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2783 - val_loss: 0.3358\n",
      "Epoch 905/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2720 - val_loss: 0.3173\n",
      "Epoch 906/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2688 - val_loss: 0.3285\n",
      "Epoch 907/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2870 - val_loss: 0.3392\n",
      "Epoch 908/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2796 - val_loss: 0.3293\n",
      "Epoch 909/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2767 - val_loss: 0.3259\n",
      "Epoch 910/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2718 - val_loss: 0.3200\n",
      "Epoch 911/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2680 - val_loss: 0.3202\n",
      "Epoch 912/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2692 - val_loss: 0.3265\n",
      "Epoch 913/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2703 - val_loss: 0.3260\n",
      "Epoch 914/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2874 - val_loss: 0.3660\n",
      "Epoch 915/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3040 - val_loss: 0.3411\n",
      "Epoch 916/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2789 - val_loss: 0.3139\n",
      "Epoch 917/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2702 - val_loss: 0.3098\n",
      "Epoch 918/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2712 - val_loss: 0.3027\n",
      "Epoch 919/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2649 - val_loss: 0.3090\n",
      "Epoch 920/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2672 - val_loss: 0.3088\n",
      "Epoch 921/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2667 - val_loss: 0.3035\n",
      "Epoch 922/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2676 - val_loss: 0.3017\n",
      "Epoch 923/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2633 - val_loss: 0.3018\n",
      "Epoch 924/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2627 - val_loss: 0.3072\n",
      "Epoch 925/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2616 - val_loss: 0.3053\n",
      "Epoch 926/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2600 - val_loss: 0.3055\n",
      "Epoch 927/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2591 - val_loss: 0.3028\n",
      "Epoch 928/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2590 - val_loss: 0.3046\n",
      "Epoch 929/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2572 - val_loss: 0.3040\n",
      "Epoch 930/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2577 - val_loss: 0.3038\n",
      "Epoch 931/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2575 - val_loss: 0.3067\n",
      "Epoch 932/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2570 - val_loss: 0.3082\n",
      "Epoch 933/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2582 - val_loss: 0.3044\n",
      "Epoch 934/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2585 - val_loss: 0.3026\n",
      "Epoch 935/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2577 - val_loss: 0.3038\n",
      "Epoch 936/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2580 - val_loss: 0.3018\n",
      "Epoch 937/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2594 - val_loss: 0.3079\n",
      "Epoch 938/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2589 - val_loss: 0.3089\n",
      "Epoch 939/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2580 - val_loss: 0.3059\n",
      "Epoch 940/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2561 - val_loss: 0.3085\n",
      "Epoch 941/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2563 - val_loss: 0.3069\n",
      "Epoch 942/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2600 - val_loss: 0.3040\n",
      "Epoch 943/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2557 - val_loss: 0.3041\n",
      "Epoch 944/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2589 - val_loss: 0.3134\n",
      "Epoch 945/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2602 - val_loss: 0.3080\n",
      "Epoch 946/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2591 - val_loss: 0.3076\n",
      "Epoch 947/1500\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2566 - val_loss: 0.3112\n",
      "Epoch 948/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2574 - val_loss: 0.3133\n",
      "Epoch 949/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2591 - val_loss: 0.3119\n",
      "Epoch 950/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2563 - val_loss: 0.3071\n",
      "Epoch 951/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2591 - val_loss: 0.3138\n",
      "Epoch 952/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2572 - val_loss: 0.3105\n",
      "Epoch 953/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2563 - val_loss: 0.3063\n",
      "Epoch 954/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2601 - val_loss: 0.3107\n",
      "Epoch 955/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2598 - val_loss: 0.3061\n",
      "Epoch 956/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.2553 - val_loss: 0.3000\n",
      "Epoch 957/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2632 - val_loss: 0.3167\n",
      "Epoch 958/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2659 - val_loss: 0.3204\n",
      "Epoch 959/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.2748 - val_loss: 0.3223\n",
      "Epoch 960/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2721 - val_loss: 0.3079\n",
      "Epoch 961/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2611 - val_loss: 0.3155\n",
      "Epoch 962/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2608 - val_loss: 0.3099\n",
      "Epoch 963/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2701 - val_loss: 0.3203\n",
      "Epoch 964/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2624 - val_loss: 0.3163\n",
      "Epoch 965/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2612 - val_loss: 0.3075\n",
      "Epoch 966/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2571 - val_loss: 0.3077\n",
      "Epoch 967/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2574 - val_loss: 0.3057\n",
      "Epoch 968/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2557 - val_loss: 0.3050\n",
      "Epoch 969/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2544 - val_loss: 0.3067\n",
      "Epoch 970/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2615 - val_loss: 0.3511\n",
      "Epoch 971/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3257 - val_loss: 0.4008\n",
      "Epoch 972/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3324 - val_loss: 0.3254\n",
      "Epoch 973/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2915 - val_loss: 0.3152\n",
      "Epoch 974/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2758 - val_loss: 0.3314\n",
      "Epoch 975/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2734 - val_loss: 0.3114\n",
      "Epoch 976/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2646 - val_loss: 0.3061\n",
      "Epoch 977/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2619 - val_loss: 0.3046\n",
      "Epoch 978/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.2583 - val_loss: 0.2992\n",
      "Epoch 979/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2610 - val_loss: 0.3003\n",
      "Epoch 980/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2564 - val_loss: 0.2973\n",
      "Epoch 981/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2551 - val_loss: 0.2985\n",
      "Epoch 982/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2537 - val_loss: 0.2973\n",
      "Epoch 983/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2525 - val_loss: 0.2990\n",
      "Epoch 984/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2514 - val_loss: 0.2976\n",
      "Epoch 985/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2552 - val_loss: 0.3008\n",
      "Epoch 986/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2562 - val_loss: 0.2997\n",
      "Epoch 987/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2545 - val_loss: 0.2981\n",
      "Epoch 988/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2607 - val_loss: 0.3078\n",
      "Epoch 989/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2616 - val_loss: 0.3087\n",
      "Epoch 990/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2598 - val_loss: 0.3035\n",
      "Epoch 991/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.2548 - val_loss: 0.2968\n",
      "Epoch 992/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2541 - val_loss: 0.2949\n",
      "Epoch 993/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2521 - val_loss: 0.3121\n",
      "Epoch 994/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2826 - val_loss: 0.3384\n",
      "Epoch 995/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2885 - val_loss: 0.3040\n",
      "Epoch 996/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2708 - val_loss: 0.3235\n",
      "Epoch 997/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2769 - val_loss: 0.3077\n",
      "Epoch 998/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2664 - val_loss: 0.3040\n",
      "Epoch 999/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2633 - val_loss: 0.3055\n",
      "Epoch 1000/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2595 - val_loss: 0.3020\n",
      "Epoch 1001/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2578 - val_loss: 0.2985\n",
      "Epoch 1002/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2546 - val_loss: 0.2984\n",
      "Epoch 1003/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2532 - val_loss: 0.2990\n",
      "Epoch 1004/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2543 - val_loss: 0.3120\n",
      "Epoch 1005/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2691 - val_loss: 0.3109\n",
      "Epoch 1006/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2677 - val_loss: 0.3010\n",
      "Epoch 1007/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2556 - val_loss: 0.2942\n",
      "Epoch 1008/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2550 - val_loss: 0.2957\n",
      "Epoch 1009/1500\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2536 - val_loss: 0.2970\n",
      "Epoch 1010/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2526 - val_loss: 0.2986\n",
      "Epoch 1011/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2508 - val_loss: 0.3035\n",
      "Epoch 1012/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2783 - val_loss: 0.3754\n",
      "Epoch 1013/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3269 - val_loss: 0.3252\n",
      "Epoch 1014/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2776 - val_loss: 0.3041\n",
      "Epoch 1015/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2632 - val_loss: 0.3034\n",
      "Epoch 1016/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2668 - val_loss: 0.3033\n",
      "Epoch 1017/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2590 - val_loss: 0.2995\n",
      "Epoch 1018/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2560 - val_loss: 0.2987\n",
      "Epoch 1019/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2593 - val_loss: 0.3137\n",
      "Epoch 1020/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2661 - val_loss: 0.2993\n",
      "Epoch 1021/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2634 - val_loss: 0.2990\n",
      "Epoch 1022/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2652 - val_loss: 0.2926\n",
      "Epoch 1023/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2633 - val_loss: 0.3264\n",
      "Epoch 1024/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2874 - val_loss: 0.3053\n",
      "Epoch 1025/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2727 - val_loss: 0.2991\n",
      "Epoch 1026/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2680 - val_loss: 0.2972\n",
      "Epoch 1027/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2630 - val_loss: 0.2967\n",
      "Epoch 1028/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2604 - val_loss: 0.2963\n",
      "Epoch 1029/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2590 - val_loss: 0.2945\n",
      "Epoch 1030/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2648 - val_loss: 0.3119\n",
      "Epoch 1031/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2691 - val_loss: 0.3097\n",
      "Epoch 1032/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2593 - val_loss: 0.3038\n",
      "Epoch 1033/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2624 - val_loss: 0.3094\n",
      "Epoch 1034/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2614 - val_loss: 0.3019\n",
      "Epoch 1035/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2558 - val_loss: 0.3036\n",
      "Epoch 1036/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2564 - val_loss: 0.3055\n",
      "Epoch 1037/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2554 - val_loss: 0.2994\n",
      "Epoch 1038/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2657 - val_loss: 0.3087\n",
      "Epoch 1039/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2597 - val_loss: 0.3052\n",
      "Epoch 1040/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2662 - val_loss: 0.3071\n",
      "Epoch 1041/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2667 - val_loss: 0.3015\n",
      "Epoch 1042/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2602 - val_loss: 0.2961\n",
      "Epoch 1043/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2553 - val_loss: 0.2934\n",
      "Epoch 1044/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2537 - val_loss: 0.2916\n",
      "Epoch 1045/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2500 - val_loss: 0.2946\n",
      "Epoch 1046/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2511 - val_loss: 0.2931\n",
      "Epoch 1047/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.2505 - val_loss: 0.2902\n",
      "Epoch 1048/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2530 - val_loss: 0.2952\n",
      "Epoch 1049/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2503 - val_loss: 0.2927\n",
      "Epoch 1050/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2542 - val_loss: 0.2926\n",
      "Epoch 1051/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2576 - val_loss: 0.2909\n",
      "Epoch 1052/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2631 - val_loss: 0.2889\n",
      "Epoch 1053/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2596 - val_loss: 0.2869\n",
      "Epoch 1054/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2537 - val_loss: 0.2862\n",
      "Epoch 1055/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2523 - val_loss: 0.2951\n",
      "Epoch 1056/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3051 - val_loss: 0.3334\n",
      "Epoch 1057/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2987 - val_loss: 0.3357\n",
      "Epoch 1058/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2819 - val_loss: 0.3049\n",
      "Epoch 1059/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2833 - val_loss: 0.3423\n",
      "Epoch 1060/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2898 - val_loss: 0.3272\n",
      "Epoch 1061/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2698 - val_loss: 0.3163\n",
      "Epoch 1062/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2674 - val_loss: 0.3159\n",
      "Epoch 1063/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2706 - val_loss: 0.3235\n",
      "Epoch 1064/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2694 - val_loss: 0.3193\n",
      "Epoch 1065/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2625 - val_loss: 0.3036\n",
      "Epoch 1066/1500\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2601 - val_loss: 0.2974\n",
      "Epoch 1067/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2588 - val_loss: 0.3009\n",
      "Epoch 1068/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2529 - val_loss: 0.2913\n",
      "Epoch 1069/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2507 - val_loss: 0.2893\n",
      "Epoch 1070/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2493 - val_loss: 0.2919\n",
      "Epoch 1071/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2489 - val_loss: 0.2908\n",
      "Epoch 1072/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2468 - val_loss: 0.2873\n",
      "Epoch 1073/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2472 - val_loss: 0.2877\n",
      "Epoch 1074/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2466 - val_loss: 0.2846\n",
      "Epoch 1075/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2454 - val_loss: 0.2850\n",
      "Epoch 1076/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2458 - val_loss: 0.2873\n",
      "Epoch 1077/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2469 - val_loss: 0.2916\n",
      "Epoch 1078/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2493 - val_loss: 0.2918\n",
      "Epoch 1079/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.2483 - val_loss: 0.2881\n",
      "Epoch 1080/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2452 - val_loss: 0.2848\n",
      "Epoch 1081/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2455 - val_loss: 0.2842\n",
      "Epoch 1082/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2442 - val_loss: 0.2836\n",
      "Epoch 1083/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2433 - val_loss: 0.2841\n",
      "Epoch 1084/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2436 - val_loss: 0.2840\n",
      "Epoch 1085/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.2441 - val_loss: 0.2830\n",
      "Epoch 1086/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2437 - val_loss: 0.2818\n",
      "Epoch 1087/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2424 - val_loss: 0.2831\n",
      "Epoch 1088/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2421 - val_loss: 0.2839\n",
      "Epoch 1089/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2420 - val_loss: 0.2835\n",
      "Epoch 1090/1500\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2416 - val_loss: 0.2849\n",
      "Epoch 1091/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.2450 - val_loss: 0.2942\n",
      "Epoch 1092/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2577 - val_loss: 0.2954\n",
      "Epoch 1093/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2626 - val_loss: 0.2917\n",
      "Epoch 1094/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2522 - val_loss: 0.2884\n",
      "Epoch 1095/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2539 - val_loss: 0.3028\n",
      "Epoch 1096/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2520 - val_loss: 0.2823\n",
      "Epoch 1097/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.2479 - val_loss: 0.2806\n",
      "Epoch 1098/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2475 - val_loss: 0.2820\n",
      "Epoch 1099/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2449 - val_loss: 0.2872\n",
      "Epoch 1100/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2457 - val_loss: 0.2889\n",
      "Epoch 1101/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2457 - val_loss: 0.2837\n",
      "Epoch 1102/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2459 - val_loss: 0.2806\n",
      "Epoch 1103/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2418 - val_loss: 0.2839\n",
      "Epoch 1104/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2492 - val_loss: 0.2951\n",
      "Epoch 1105/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2530 - val_loss: 0.2885\n",
      "Epoch 1106/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2482 - val_loss: 0.2870\n",
      "Epoch 1107/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2463 - val_loss: 0.2897\n",
      "Epoch 1108/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2458 - val_loss: 0.2885\n",
      "Epoch 1109/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2437 - val_loss: 0.2853\n",
      "Epoch 1110/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2545 - val_loss: 0.2959\n",
      "Epoch 1111/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2593 - val_loss: 0.2792\n",
      "Epoch 1112/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2596 - val_loss: 0.2777\n",
      "Epoch 1113/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2481 - val_loss: 0.2810\n",
      "Epoch 1114/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2506 - val_loss: 0.2774\n",
      "Epoch 1115/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.2468 - val_loss: 0.2838\n",
      "Epoch 1116/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2485 - val_loss: 0.2892\n",
      "Epoch 1117/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2468 - val_loss: 0.3132\n",
      "Epoch 1118/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2950 - val_loss: 0.3603\n",
      "Epoch 1119/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2943 - val_loss: 0.3107\n",
      "Epoch 1120/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2706 - val_loss: 0.3165\n",
      "Epoch 1121/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2647 - val_loss: 0.3022\n",
      "Epoch 1122/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2578 - val_loss: 0.3018\n",
      "Epoch 1123/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2539 - val_loss: 0.2992\n",
      "Epoch 1124/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2558 - val_loss: 0.2882\n",
      "Epoch 1125/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2533 - val_loss: 0.2818\n",
      "Epoch 1126/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.2496 - val_loss: 0.2795\n",
      "Epoch 1127/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2445 - val_loss: 0.2794\n",
      "Epoch 1128/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2549 - val_loss: 0.2978\n",
      "Epoch 1129/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2586 - val_loss: 0.2880\n",
      "Epoch 1130/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2506 - val_loss: 0.2910\n",
      "Epoch 1131/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2530 - val_loss: 0.2998\n",
      "Epoch 1132/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2570 - val_loss: 0.2952\n",
      "Epoch 1133/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2584 - val_loss: 0.2854\n",
      "Epoch 1134/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2516 - val_loss: 0.2967\n",
      "Epoch 1135/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2476 - val_loss: 0.2930\n",
      "Epoch 1136/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2480 - val_loss: 0.2862\n",
      "Epoch 1137/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2463 - val_loss: 0.2901\n",
      "Epoch 1138/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2485 - val_loss: 0.2893\n",
      "Epoch 1139/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2457 - val_loss: 0.2842\n",
      "Epoch 1140/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2420 - val_loss: 0.2815\n",
      "Epoch 1141/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2398 - val_loss: 0.2814\n",
      "Epoch 1142/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2426 - val_loss: 0.2844\n",
      "Epoch 1143/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2420 - val_loss: 0.2785\n",
      "Epoch 1144/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2399 - val_loss: 0.2800\n",
      "Epoch 1145/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2415 - val_loss: 0.2861\n",
      "Epoch 1146/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2520 - val_loss: 0.3079\n",
      "Epoch 1147/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2530 - val_loss: 0.2981\n",
      "Epoch 1148/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2546 - val_loss: 0.2931\n",
      "Epoch 1149/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2476 - val_loss: 0.2838\n",
      "Epoch 1150/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2526 - val_loss: 0.2955\n",
      "Epoch 1151/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2628 - val_loss: 0.2708\n",
      "Epoch 1152/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2464 - val_loss: 0.2724\n",
      "Epoch 1153/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2458 - val_loss: 0.2877\n",
      "Epoch 1154/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2956 - val_loss: 0.3535\n",
      "Epoch 1155/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3148 - val_loss: 0.3179\n",
      "Epoch 1156/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2881 - val_loss: 0.3525\n",
      "Epoch 1157/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3458 - val_loss: 0.3409\n",
      "Epoch 1158/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3064 - val_loss: 0.3219\n",
      "Epoch 1159/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2946 - val_loss: 0.3002\n",
      "Epoch 1160/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2735 - val_loss: 0.3113\n",
      "Epoch 1161/1500\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2793 - val_loss: 0.3042\n",
      "Epoch 1162/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2702 - val_loss: 0.2934\n",
      "Epoch 1163/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2603 - val_loss: 0.2954\n",
      "Epoch 1164/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2597 - val_loss: 0.2946\n",
      "Epoch 1165/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2546 - val_loss: 0.2882\n",
      "Epoch 1166/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2512 - val_loss: 0.2853\n",
      "Epoch 1167/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2486 - val_loss: 0.2811\n",
      "Epoch 1168/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2477 - val_loss: 0.2831\n",
      "Epoch 1169/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2461 - val_loss: 0.2853\n",
      "Epoch 1170/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2452 - val_loss: 0.2808\n",
      "Epoch 1171/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2434 - val_loss: 0.2790\n",
      "Epoch 1172/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2443 - val_loss: 0.2789\n",
      "Epoch 1173/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2432 - val_loss: 0.2857\n",
      "Epoch 1174/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2489 - val_loss: 0.2882\n",
      "Epoch 1175/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2513 - val_loss: 0.2878\n",
      "Epoch 1176/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2479 - val_loss: 0.2837\n",
      "Epoch 1177/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.2442 - val_loss: 0.2843\n",
      "Epoch 1178/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2453 - val_loss: 0.2849\n",
      "Epoch 1179/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2425 - val_loss: 0.2810\n",
      "Epoch 1180/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2405 - val_loss: 0.2813\n",
      "Epoch 1181/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2406 - val_loss: 0.2796\n",
      "Epoch 1182/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2409 - val_loss: 0.2790\n",
      "Epoch 1183/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.2654 - val_loss: 0.3018\n",
      "Epoch 1184/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3440 - val_loss: 0.4703\n",
      "Epoch 1185/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3693 - val_loss: 0.3874\n",
      "Epoch 1186/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3186 - val_loss: 0.3504\n",
      "Epoch 1187/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2953 - val_loss: 0.3654\n",
      "Epoch 1188/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3080 - val_loss: 0.3506\n",
      "Epoch 1189/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2913 - val_loss: 0.3331\n",
      "Epoch 1190/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2822 - val_loss: 0.3195\n",
      "Epoch 1191/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2727 - val_loss: 0.3055\n",
      "Epoch 1192/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2637 - val_loss: 0.3046\n",
      "Epoch 1193/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2630 - val_loss: 0.2961\n",
      "Epoch 1194/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2543 - val_loss: 0.2927\n",
      "Epoch 1195/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2531 - val_loss: 0.2901\n",
      "Epoch 1196/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2500 - val_loss: 0.2901\n",
      "Epoch 1197/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2494 - val_loss: 0.2898\n",
      "Epoch 1198/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2490 - val_loss: 0.2876\n",
      "Epoch 1199/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2483 - val_loss: 0.2860\n",
      "Epoch 1200/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2485 - val_loss: 0.2855\n",
      "Epoch 1201/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2491 - val_loss: 0.2873\n",
      "Epoch 1202/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2459 - val_loss: 0.2876\n",
      "Epoch 1203/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2459 - val_loss: 0.2851\n",
      "Epoch 1204/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2438 - val_loss: 0.2829\n",
      "Epoch 1205/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2478 - val_loss: 0.2909\n",
      "Epoch 1206/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2480 - val_loss: 0.2864\n",
      "Epoch 1207/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2520 - val_loss: 0.3021\n",
      "Epoch 1208/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2583 - val_loss: 0.2829\n",
      "Epoch 1209/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2551 - val_loss: 0.2734\n",
      "Epoch 1210/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2509 - val_loss: 0.2718\n",
      "Epoch 1211/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2470 - val_loss: 0.2728\n",
      "Epoch 1212/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2432 - val_loss: 0.2793\n",
      "Epoch 1213/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2439 - val_loss: 0.2795\n",
      "Epoch 1214/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2439 - val_loss: 0.2791\n",
      "Epoch 1215/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2417 - val_loss: 0.2779\n",
      "Epoch 1216/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2407 - val_loss: 0.2765\n",
      "Epoch 1217/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2401 - val_loss: 0.2777\n",
      "Epoch 1218/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2403 - val_loss: 0.2785\n",
      "Epoch 1219/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2400 - val_loss: 0.2772\n",
      "Epoch 1220/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2387 - val_loss: 0.2771\n",
      "Epoch 1221/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2388 - val_loss: 0.2746\n",
      "Epoch 1222/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2369 - val_loss: 0.2791\n",
      "Epoch 1223/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2422 - val_loss: 0.2862\n",
      "Epoch 1224/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2518 - val_loss: 0.2953\n",
      "Epoch 1225/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2647 - val_loss: 0.3031\n",
      "Epoch 1226/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2507 - val_loss: 0.3044\n",
      "Epoch 1227/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2548 - val_loss: 0.2917\n",
      "Epoch 1228/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2519 - val_loss: 0.2897\n",
      "Epoch 1229/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2453 - val_loss: 0.2818\n",
      "Epoch 1230/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2418 - val_loss: 0.2826\n",
      "Epoch 1231/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.2401 - val_loss: 0.2792\n",
      "Epoch 1232/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2391 - val_loss: 0.2782\n",
      "Epoch 1233/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2402 - val_loss: 0.2787\n",
      "Epoch 1234/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2401 - val_loss: 0.2764\n",
      "Epoch 1235/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2386 - val_loss: 0.2828\n",
      "Epoch 1236/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2637 - val_loss: 0.2925\n",
      "Epoch 1237/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2459 - val_loss: 0.2958\n",
      "Epoch 1238/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2528 - val_loss: 0.2901\n",
      "Epoch 1239/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2803 - val_loss: 0.3473\n",
      "Epoch 1240/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2922 - val_loss: 0.2925\n",
      "Epoch 1241/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2521 - val_loss: 0.2967\n",
      "Epoch 1242/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2556 - val_loss: 0.2961\n",
      "Epoch 1243/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2501 - val_loss: 0.2889\n",
      "Epoch 1244/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2453 - val_loss: 0.2909\n",
      "Epoch 1245/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2422 - val_loss: 0.2864\n",
      "Epoch 1246/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.2420 - val_loss: 0.2824\n",
      "Epoch 1247/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2390 - val_loss: 0.2794\n",
      "Epoch 1248/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2395 - val_loss: 0.2779\n",
      "Epoch 1249/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2403 - val_loss: 0.2750\n",
      "Epoch 1250/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2372 - val_loss: 0.2754\n",
      "Epoch 1251/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2374 - val_loss: 0.2787\n",
      "Epoch 1252/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2377 - val_loss: 0.2820\n",
      "Epoch 1253/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2441 - val_loss: 0.2778\n",
      "Epoch 1254/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2388 - val_loss: 0.2778\n",
      "Epoch 1255/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2398 - val_loss: 0.2755\n",
      "Epoch 1256/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2359 - val_loss: 0.2741\n",
      "Epoch 1257/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2361 - val_loss: 0.2722\n",
      "Epoch 1258/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2421 - val_loss: 0.2852\n",
      "Epoch 1259/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2419 - val_loss: 0.2779\n",
      "Epoch 1260/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2384 - val_loss: 0.2747\n",
      "Epoch 1261/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2371 - val_loss: 0.2719\n",
      "Epoch 1262/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.2357 - val_loss: 0.2704\n",
      "Epoch 1263/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2340 - val_loss: 0.2679\n",
      "Epoch 1264/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2331 - val_loss: 0.2702\n",
      "Epoch 1265/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2338 - val_loss: 0.2759\n",
      "Epoch 1266/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2456 - val_loss: 0.2852\n",
      "Epoch 1267/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2427 - val_loss: 0.2690\n",
      "Epoch 1268/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.2391 - val_loss: 0.2704\n",
      "Epoch 1269/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2709 - val_loss: 0.3016\n",
      "Epoch 1270/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2763 - val_loss: 0.3064\n",
      "Epoch 1271/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2602 - val_loss: 0.2812\n",
      "Epoch 1272/1500\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.2655 - val_loss: 0.3063\n",
      "Epoch 1273/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2704 - val_loss: 0.3038\n",
      "Epoch 1274/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2858 - val_loss: 0.3289\n",
      "Epoch 1275/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2979 - val_loss: 0.2786\n",
      "Epoch 1276/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2667 - val_loss: 0.2842\n",
      "Epoch 1277/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2625 - val_loss: 0.2945\n",
      "Epoch 1278/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2817 - val_loss: 0.3257\n",
      "Epoch 1279/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2795 - val_loss: 0.3032\n",
      "Epoch 1280/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2650 - val_loss: 0.2931\n",
      "Epoch 1281/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2651 - val_loss: 0.2863\n",
      "Epoch 1282/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2556 - val_loss: 0.2913\n",
      "Epoch 1283/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2498 - val_loss: 0.2927\n",
      "Epoch 1284/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2456 - val_loss: 0.2845\n",
      "Epoch 1285/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2427 - val_loss: 0.2857\n",
      "Epoch 1286/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2424 - val_loss: 0.2807\n",
      "Epoch 1287/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2406 - val_loss: 0.2779\n",
      "Epoch 1288/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2373 - val_loss: 0.2736\n",
      "Epoch 1289/1500\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2366 - val_loss: 0.2743\n",
      "Epoch 1290/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2359 - val_loss: 0.2749\n",
      "Epoch 1291/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2347 - val_loss: 0.2752\n",
      "Epoch 1292/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2340 - val_loss: 0.2734\n",
      "Epoch 1293/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2341 - val_loss: 0.2742\n",
      "Epoch 1294/1500\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2334 - val_loss: 0.2747\n",
      "Epoch 1295/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2346 - val_loss: 0.2801\n",
      "Epoch 1296/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2471 - val_loss: 0.3044\n",
      "Epoch 1297/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2587 - val_loss: 0.2701\n",
      "Epoch 1298/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.2486 - val_loss: 0.2604\n",
      "Epoch 1299/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2436 - val_loss: 0.2676\n",
      "Epoch 1300/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2431 - val_loss: 0.2692\n",
      "Epoch 1301/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2392 - val_loss: 0.2678\n",
      "Epoch 1302/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2367 - val_loss: 0.2700\n",
      "Epoch 1303/1500\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2362 - val_loss: 0.2660\n",
      "Epoch 1304/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2343 - val_loss: 0.2688\n",
      "Epoch 1305/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2331 - val_loss: 0.2702\n",
      "Epoch 1306/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2330 - val_loss: 0.2696\n",
      "Epoch 1307/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2314 - val_loss: 0.2701\n",
      "Epoch 1308/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2317 - val_loss: 0.2685\n",
      "Epoch 1309/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.2309 - val_loss: 0.2662\n",
      "Epoch 1310/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2311 - val_loss: 0.2671\n",
      "Epoch 1311/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2322 - val_loss: 0.2634\n",
      "Epoch 1312/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2297 - val_loss: 0.2647\n",
      "Epoch 1313/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2295 - val_loss: 0.2649\n",
      "Epoch 1314/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2291 - val_loss: 0.2619\n",
      "Epoch 1315/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2293 - val_loss: 0.2608\n",
      "Epoch 1316/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2301 - val_loss: 0.2614\n",
      "Epoch 1317/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2299 - val_loss: 0.2601\n",
      "Epoch 1318/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2286 - val_loss: 0.2616\n",
      "Epoch 1319/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2279 - val_loss: 0.2623\n",
      "Epoch 1320/1500\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.2284 - val_loss: 0.2622\n",
      "Epoch 1321/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2310 - val_loss: 0.2624\n",
      "Epoch 1322/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2306 - val_loss: 0.2662\n",
      "Epoch 1323/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2320 - val_loss: 0.2638\n",
      "Epoch 1324/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2331 - val_loss: 0.2614\n",
      "Epoch 1325/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2301 - val_loss: 0.2638\n",
      "Epoch 1326/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2317 - val_loss: 0.2702\n",
      "Epoch 1327/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2381 - val_loss: 0.2785\n",
      "Epoch 1328/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2478 - val_loss: 0.2679\n",
      "Epoch 1329/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2349 - val_loss: 0.2655\n",
      "Epoch 1330/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2343 - val_loss: 0.2685\n",
      "Epoch 1331/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2342 - val_loss: 0.2692\n",
      "Epoch 1332/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2340 - val_loss: 0.2620\n",
      "Epoch 1333/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2312 - val_loss: 0.2643\n",
      "Epoch 1334/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2330 - val_loss: 0.2837\n",
      "Epoch 1335/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2700 - val_loss: 0.3461\n",
      "Epoch 1336/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2792 - val_loss: 0.2824\n",
      "Epoch 1337/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2449 - val_loss: 0.2851\n",
      "Epoch 1338/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2452 - val_loss: 0.2789\n",
      "Epoch 1339/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2379 - val_loss: 0.2693\n",
      "Epoch 1340/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2351 - val_loss: 0.2705\n",
      "Epoch 1341/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2354 - val_loss: 0.2681\n",
      "Epoch 1342/1500\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2312 - val_loss: 0.2762\n",
      "Epoch 1343/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2640 - val_loss: 0.2860\n",
      "Epoch 1344/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2514 - val_loss: 0.3015\n",
      "Epoch 1345/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2647 - val_loss: 0.3268\n",
      "Epoch 1346/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2828 - val_loss: 0.2757\n",
      "Epoch 1347/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.2594 - val_loss: 0.2720\n",
      "Epoch 1348/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2507 - val_loss: 0.2711\n",
      "Epoch 1349/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2448 - val_loss: 0.2689\n",
      "Epoch 1350/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2385 - val_loss: 0.2703\n",
      "Epoch 1351/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2353 - val_loss: 0.2630\n",
      "Epoch 1352/1500\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.2352 - val_loss: 0.2637\n",
      "Epoch 1353/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2321 - val_loss: 0.2650\n",
      "Epoch 1354/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2307 - val_loss: 0.2647\n",
      "Epoch 1355/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2344 - val_loss: 0.2655\n",
      "Epoch 1356/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2352 - val_loss: 0.2625\n",
      "Epoch 1357/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2321 - val_loss: 0.2599\n",
      "Epoch 1358/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2364 - val_loss: 0.2777\n",
      "Epoch 1359/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2400 - val_loss: 0.2605\n",
      "Epoch 1360/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2318 - val_loss: 0.2641\n",
      "Epoch 1361/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2334 - val_loss: 0.2593\n",
      "Epoch 1362/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2378 - val_loss: 0.2764\n",
      "Epoch 1363/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.2475 - val_loss: 0.2746\n",
      "Epoch 1364/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2383 - val_loss: 0.2718\n",
      "Epoch 1365/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2352 - val_loss: 0.2641\n",
      "Epoch 1366/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2320 - val_loss: 0.2679\n",
      "Epoch 1367/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2389 - val_loss: 0.2762\n",
      "Epoch 1368/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2536 - val_loss: 0.3140\n",
      "Epoch 1369/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2800 - val_loss: 0.2948\n",
      "Epoch 1370/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2540 - val_loss: 0.2692\n",
      "Epoch 1371/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2421 - val_loss: 0.2745\n",
      "Epoch 1372/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2393 - val_loss: 0.2719\n",
      "Epoch 1373/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2454 - val_loss: 0.2724\n",
      "Epoch 1374/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2439 - val_loss: 0.2744\n",
      "Epoch 1375/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2419 - val_loss: 0.2620\n",
      "Epoch 1376/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2473 - val_loss: 0.2647\n",
      "Epoch 1377/1500\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2375 - val_loss: 0.2647\n",
      "Epoch 1378/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2346 - val_loss: 0.2634\n",
      "Epoch 1379/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2360 - val_loss: 0.2897\n",
      "Epoch 1380/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2432 - val_loss: 0.2700\n",
      "Epoch 1381/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2438 - val_loss: 0.2687\n",
      "Epoch 1382/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2437 - val_loss: 0.2638\n",
      "Epoch 1383/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2397 - val_loss: 0.2656\n",
      "Epoch 1384/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2365 - val_loss: 0.2616\n",
      "Epoch 1385/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2363 - val_loss: 0.2775\n",
      "Epoch 1386/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.2448 - val_loss: 0.2686\n",
      "Epoch 1387/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2351 - val_loss: 0.2628\n",
      "Epoch 1388/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2451 - val_loss: 0.2607\n",
      "Epoch 1389/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2452 - val_loss: 0.3187\n",
      "Epoch 1390/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2824 - val_loss: 0.2875\n",
      "Epoch 1391/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2510 - val_loss: 0.2677\n",
      "Epoch 1392/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2446 - val_loss: 0.2825\n",
      "Epoch 1393/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2446 - val_loss: 0.2745\n",
      "Epoch 1394/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2377 - val_loss: 0.2639\n",
      "Epoch 1395/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2364 - val_loss: 0.2596\n",
      "Epoch 1396/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.2351 - val_loss: 0.2589\n",
      "Epoch 1397/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2340 - val_loss: 0.2634\n",
      "Epoch 1398/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2324 - val_loss: 0.2605\n",
      "Epoch 1399/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2302 - val_loss: 0.2631\n",
      "Epoch 1400/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2282 - val_loss: 0.2635\n",
      "Epoch 1401/1500\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2293 - val_loss: 0.2634\n",
      "Epoch 1402/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2276 - val_loss: 0.2659\n",
      "Epoch 1403/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2450 - val_loss: 0.2980\n",
      "Epoch 1404/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2650 - val_loss: 0.2896\n",
      "Epoch 1405/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.2525 - val_loss: 0.3025\n",
      "Epoch 1406/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2517 - val_loss: 0.2859\n",
      "Epoch 1407/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2460 - val_loss: 0.2763\n",
      "Epoch 1408/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2384 - val_loss: 0.2568\n",
      "Epoch 1409/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2385 - val_loss: 0.2586\n",
      "Epoch 1410/1500\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2363 - val_loss: 0.2563\n",
      "Epoch 1411/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2298 - val_loss: 0.2652\n",
      "Epoch 1412/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2287 - val_loss: 0.2644\n",
      "Epoch 1413/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2305 - val_loss: 0.2598\n",
      "Epoch 1414/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2275 - val_loss: 0.2555\n",
      "Epoch 1415/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2280 - val_loss: 0.2567\n",
      "Epoch 1416/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2361 - val_loss: 0.2914\n",
      "Epoch 1417/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2582 - val_loss: 0.2802\n",
      "Epoch 1418/1500\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2417 - val_loss: 0.2760\n",
      "Epoch 1419/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2512 - val_loss: 0.3212\n",
      "Epoch 1420/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2641 - val_loss: 0.2815\n",
      "Epoch 1421/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2455 - val_loss: 0.2767\n",
      "Epoch 1422/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2590 - val_loss: 0.2800\n",
      "Epoch 1423/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2492 - val_loss: 0.2799\n",
      "Epoch 1424/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2480 - val_loss: 0.2680\n",
      "Epoch 1425/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2402 - val_loss: 0.2628\n",
      "Epoch 1426/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2350 - val_loss: 0.2614\n",
      "Epoch 1427/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2306 - val_loss: 0.2610\n",
      "Epoch 1428/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2273 - val_loss: 0.2602\n",
      "Epoch 1429/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2270 - val_loss: 0.2589\n",
      "Epoch 1430/1500\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2255 - val_loss: 0.2591\n",
      "Epoch 1431/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2246 - val_loss: 0.2604\n",
      "Epoch 1432/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2388 - val_loss: 0.2723\n",
      "Epoch 1433/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2450 - val_loss: 0.2760\n",
      "Epoch 1434/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2417 - val_loss: 0.2748\n",
      "Epoch 1435/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2425 - val_loss: 0.2934\n",
      "Epoch 1436/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2422 - val_loss: 0.2656\n",
      "Epoch 1437/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2353 - val_loss: 0.2727\n",
      "Epoch 1438/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2336 - val_loss: 0.2637\n",
      "Epoch 1439/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2302 - val_loss: 0.2639\n",
      "Epoch 1440/1500\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2267 - val_loss: 0.2690\n",
      "Epoch 1441/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2303 - val_loss: 0.2653\n",
      "Epoch 1442/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2316 - val_loss: 0.2564\n",
      "Epoch 1443/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2261 - val_loss: 0.2561\n",
      "Epoch 1444/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2251 - val_loss: 0.2578\n",
      "Epoch 1445/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.2270 - val_loss: 0.2612\n",
      "Epoch 1446/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2286 - val_loss: 0.2620\n",
      "Epoch 1447/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2253 - val_loss: 0.2574\n",
      "Epoch 1448/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2235 - val_loss: 0.2544\n",
      "Epoch 1449/1500\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2227 - val_loss: 0.2530\n",
      "Epoch 1450/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2209 - val_loss: 0.2515\n",
      "Epoch 1451/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2213 - val_loss: 0.2516\n",
      "Epoch 1452/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2212 - val_loss: 0.2518\n",
      "Epoch 1453/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2269 - val_loss: 0.2569\n",
      "Epoch 1454/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2287 - val_loss: 0.2573\n",
      "Epoch 1455/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2255 - val_loss: 0.2558\n",
      "Epoch 1456/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2253 - val_loss: 0.2532\n",
      "Epoch 1457/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2213 - val_loss: 0.2571\n",
      "Epoch 1458/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2218 - val_loss: 0.2566\n",
      "Epoch 1459/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2204 - val_loss: 0.2567\n",
      "Epoch 1460/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2204 - val_loss: 0.2539\n",
      "Epoch 1461/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2209 - val_loss: 0.2533\n",
      "Epoch 1462/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2212 - val_loss: 0.2498\n",
      "Epoch 1463/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2244 - val_loss: 0.2565\n",
      "Epoch 1464/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2269 - val_loss: 0.2527\n",
      "Epoch 1465/1500\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2216 - val_loss: 0.2529\n",
      "Epoch 1466/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2268 - val_loss: 0.2580\n",
      "Epoch 1467/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2367 - val_loss: 0.2695\n",
      "Epoch 1468/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2425 - val_loss: 0.2530\n",
      "Epoch 1469/1500\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2245 - val_loss: 0.2636\n",
      "Epoch 1470/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2256 - val_loss: 0.2606\n",
      "Epoch 1471/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2240 - val_loss: 0.2620\n",
      "Epoch 1472/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2239 - val_loss: 0.2611\n",
      "Epoch 1473/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2232 - val_loss: 0.2545\n",
      "Epoch 1474/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2213 - val_loss: 0.2533\n",
      "Epoch 1475/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2192 - val_loss: 0.2495\n",
      "Epoch 1476/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2175 - val_loss: 0.2461\n",
      "Epoch 1477/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.2169 - val_loss: 0.2434\n",
      "Epoch 1478/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2170 - val_loss: 0.2468\n",
      "Epoch 1479/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2180 - val_loss: 0.2466\n",
      "Epoch 1480/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2181 - val_loss: 0.2443\n",
      "Epoch 1481/1500\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2162 - val_loss: 0.2473\n",
      "Epoch 1482/1500\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2162 - val_loss: 0.2512\n",
      "Epoch 1483/1500\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2220 - val_loss: 0.2622\n",
      "Epoch 1484/1500\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2301 - val_loss: 0.2559\n",
      "Epoch 1485/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2233 - val_loss: 0.2504\n",
      "Epoch 1486/1500\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2205 - val_loss: 0.2501\n",
      "Epoch 1487/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2200 - val_loss: 0.2495\n",
      "Epoch 1488/1500\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2183 - val_loss: 0.2504\n",
      "Epoch 1489/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2168 - val_loss: 0.2476\n",
      "Epoch 1490/1500\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2165 - val_loss: 0.2476\n",
      "Epoch 1491/1500\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.2152 - val_loss: 0.2458\n",
      "Epoch 1492/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2164 - val_loss: 0.2458\n",
      "Epoch 1493/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2163 - val_loss: 0.2439\n",
      "Epoch 1494/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2162 - val_loss: 0.2437\n",
      "Epoch 1495/1500\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2149 - val_loss: 0.2400\n",
      "Epoch 1496/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2150 - val_loss: 0.2403\n",
      "Epoch 1497/1500\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2173 - val_loss: 0.2411\n",
      "Epoch 1498/1500\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2180 - val_loss: 0.2482\n",
      "Epoch 1499/1500\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2190 - val_loss: 0.2445\n",
      "Epoch 1500/1500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2185 - val_loss: 0.2446\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.2400\n",
      "0.23997576534748077\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.LSTM(units = 128, activation = \"relu\", return_sequences = True)(input)\n",
    "    x = layers.LSTM(units = 128, activation = \"relu\", return_sequences = True)(x)\n",
    "    x = layers.LSTM(units = 64, activation = \"relu\", return_sequences = True)(x)\n",
    "\n",
    "    # 中間層最後のreturn_sequencesは、Falseにする\n",
    "    # 出力は一つなので、中間層の最後で次元数を落として出力できるようにしている\n",
    "    x = layers.LSTM(units = 64, activation = \"relu\", return_sequences = True)(x)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "# ミニバッチ学習 \n",
    "batch_size = len(train_x) // 4\n",
    "\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "\n",
    "# モデル構造の出力\n",
    "model.summary()\n",
    "\n",
    "# val_lossが一番低いモデルを保存している\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "# 学習データ、テストデータ、バッチサイズ、エポック、保存ポイントの設定\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = batch_size, epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # モデルを継続したまま、エポックを続けることができる     3回目6000回　回した\n",
    "# model.compile(loss = losses.MeanSquaredError(),\n",
    "#               # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "#               optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "\n",
    "# # モデル構造の出力\n",
    "# model.summary()\n",
    "\n",
    "# # val_lossが一番低いモデルを保存している\n",
    "# mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "#                                 monitor = \"val_loss\",\n",
    "#                                 mode = \"min\",\n",
    "#                                 save_best_only = True)\n",
    "# # 学習データ、テストデータ、バッチサイズ、エポック、保存ポイントの設定\n",
    "# history = model.fit(x = train_x, y = train_y, batch_size = batch_size, epochs = 1500,\n",
    "#                     validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "# model = models.load_model(\"model.keras\")\n",
    "# print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f89d11385e0>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "2.0375919342041016\n",
      "0.4616570472717285\n",
      "1.20890474319458\n",
      "0.3563652038574219\n",
      "0.27797794342041016\n",
      "0.3665475845336914\n",
      "0.022635087370872498\n",
      "0.09368133544921875\n",
      "0.06367743015289307\n",
      "0.5813674926757812\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "SINGLE_SE = list()\n",
    "\n",
    "def single_sa(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        c = a - b\n",
    "        output.append(float(abs(c[0])))\n",
    "\n",
    "    return output\n",
    "\n",
    "# 標準化を元の縮尺に戻す関数\n",
    "def decode(x):\n",
    "    return x * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"]\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    SINGLE_SE.append(single_sa(decode(x), decode(y)))\n",
    "    print(SINGLE_SE[-1][-1])\n",
    "    \n",
    "# SINGLE_SE[0]\n",
    "    \n",
    "min_SINGLE_SE = list()\n",
    "max_SINGLE_SE = list()\n",
    "\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    decode_min = min(SINGLE_SE[i])\n",
    "    decode_min_index = SINGLE_SE[i].index(min(SINGLE_SE[i]))\n",
    "    decode_max = max(SINGLE_SE[i])\n",
    "    decode_max_index = SINGLE_SE[i].index(max(SINGLE_SE[i]))\n",
    "    min_SINGLE_SE.append([decode_min, decode_min_index])\n",
    "    max_SINGLE_SE.append([decode_max, decode_max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 12番目 0.073784%, max : 2番目 21.677%\n",
      "min : 17番目 0.16996%, max : 1番目 19.006%\n",
      "min : 17番目 0.010042%, max : 0番目 18.46%\n",
      "min : 7番目 0.030151%, max : 0番目 6.3995%\n",
      "min : 17番目 0.19062%, max : 4番目 13.154%\n",
      "min : 14番目 0.11348%, max : 1番目 32.907%\n",
      "min : 23番目 0.022635%, max : 4番目 30.822%\n",
      "min : 11番目 0.081562%, max : 1番目 59.107%\n",
      "min : 1番目 0.028246%, max : 0番目 16.003%\n",
      "min : 21番目 0.20636%, max : 3番目 18.315%\n"
     ]
    }
   ],
   "source": [
    "# 各入力データの1〜24(SPILT_SIZE)の中の最大、最小(上からグラフのソート順になってる)\n",
    "for a ,b in zip(min_SINGLE_SE,max_SINGLE_SE):\n",
    "    print(f\"min : {a[1]}番目 {a[0]:.5}%, max : {b[1]}番目 {b[0]:.5}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "# 各検証データの予測と正解のMSEをとる\n",
    "def mse(x, y):\n",
    "    tmp = 0.0\n",
    "    for a, b in zip(x, y):\n",
    "        tmp += (a - b) ** 2\n",
    "    tmp /= len(x)\n",
    "    return tmp\n",
    "# 各検証データに含まれるNヶ月の各予測と正解の二乗和誤差を算出する\n",
    "def single_se(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        output.append((a - b) ** 2)\n",
    "\n",
    "    return output\n",
    "\n",
    "MSE = []\n",
    "SINGLE_SE = []\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    MSE.append(mse(x, y))\n",
    "    SINGLE_SE.append(single_se(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSEの最小値：[0.02139824]、最大値：[0.6766705]\n",
      "\n",
      "0個目の検証用データにおけるSingle MSEの最小値：[2.0960215e-05]、最大値：[1.8091338]\n",
      "1個目の検証用データにおけるSingle MSEの最小値：[0.00011121]、最大値：[1.3907962]\n",
      "2個目の検証用データにおけるSingle MSEの最小値：[3.8826227e-07]、最大値：[1.3120136]\n",
      "3個目の検証用データにおけるSingle MSEの最小値：[3.5001567e-06]、最大値：[0.15767992]\n",
      "4個目の検証用データにおけるSingle MSEの最小値：[0.00013991]、最大値：[0.6662126]\n",
      "5個目の検証用データにおけるSingle MSEの最小値：[4.958292e-05]、最大値：[4.169263]\n",
      "6個目の検証用データにおけるSingle MSEの最小値：[1.9725198e-06]、最大値：[3.657662]\n",
      "7個目の検証用データにおけるSingle MSEの最小値：[2.5614028e-05]、最大値：[13.451243]\n",
      "8個目の検証用データにおけるSingle MSEの最小値：[3.0716592e-06]、最大値：[0.9860603]\n",
      "9個目の検証用データにおけるSingle MSEの最小値：[0.00016395]、最大値：[1.2914829]\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSEの最小値：{min(MSE)}、最大値：{max(MSE)}\")\n",
    "print()\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    print(f\"{i}個目の検証用データにおけるSingle MSEの最小値：{min(SINGLE_SE[i])}、最大値：{max(SINGLE_SE[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューロン数を減らして作成2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 24, 3)]           0         \n",
      "                                                                 \n",
      " lstm_40 (LSTM)              (None, 24, 256)           266240    \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 24, 256)           525312    \n",
      "                                                                 \n",
      " lstm_42 (LSTM)              (None, 24, 128)           197120    \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 24, 128)           131584    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 24, 1)             129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,120,385\n",
      "Trainable params: 1,120,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "5/5 [==============================] - 5s 306ms/step - loss: 0.8239 - val_loss: 0.9815\n",
      "Epoch 2/1500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.8205 - val_loss: 0.9787\n",
      "Epoch 3/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.8171 - val_loss: 0.9754\n",
      "Epoch 4/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.8132 - val_loss: 0.9714\n",
      "Epoch 5/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.8087 - val_loss: 0.9667\n",
      "Epoch 6/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.8039 - val_loss: 0.9609\n",
      "Epoch 7/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.7984 - val_loss: 0.9546\n",
      "Epoch 8/1500\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.7931 - val_loss: 0.9491\n",
      "Epoch 9/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.7897 - val_loss: 0.9439\n",
      "Epoch 10/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.7853 - val_loss: 0.9390\n",
      "Epoch 11/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.7793 - val_loss: 0.9377\n",
      "Epoch 12/1500\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.7769 - val_loss: 0.9370\n",
      "Epoch 13/1500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.7756 - val_loss: 0.9316\n",
      "Epoch 14/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.7728 - val_loss: 0.9279\n",
      "Epoch 15/1500\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.7710 - val_loss: 0.9259\n",
      "Epoch 16/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.7691 - val_loss: 0.9238\n",
      "Epoch 17/1500\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.7674 - val_loss: 0.9215\n",
      "Epoch 18/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.7664 - val_loss: 0.9204\n",
      "Epoch 19/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.7680 - val_loss: 0.9192\n",
      "Epoch 20/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.7646 - val_loss: 0.9180\n",
      "Epoch 21/1500\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.7626 - val_loss: 0.9186\n",
      "Epoch 22/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.7622 - val_loss: 0.9141\n",
      "Epoch 23/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.7604 - val_loss: 0.9114\n",
      "Epoch 24/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.7584 - val_loss: 0.9104\n",
      "Epoch 25/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.7569 - val_loss: 0.9100\n",
      "Epoch 26/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.7559 - val_loss: 0.9094\n",
      "Epoch 27/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.7551 - val_loss: 0.9083\n",
      "Epoch 28/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.7540 - val_loss: 0.9065\n",
      "Epoch 29/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.7535 - val_loss: 0.9056\n",
      "Epoch 30/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.7526 - val_loss: 0.9055\n",
      "Epoch 31/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.7520 - val_loss: 0.9050\n",
      "Epoch 32/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.7510 - val_loss: 0.9042\n",
      "Epoch 33/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.7509 - val_loss: 0.9037\n",
      "Epoch 34/1500\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.7495 - val_loss: 0.9031\n",
      "Epoch 35/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.7488 - val_loss: 0.9023\n",
      "Epoch 36/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.7487 - val_loss: 0.9013\n",
      "Epoch 37/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.7476 - val_loss: 0.9020\n",
      "Epoch 38/1500\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.7472 - val_loss: 0.9004\n",
      "Epoch 39/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.7471 - val_loss: 0.8992\n",
      "Epoch 40/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.7467 - val_loss: 0.8998\n",
      "Epoch 41/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.7454 - val_loss: 0.8996\n",
      "Epoch 42/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.7450 - val_loss: 0.8984\n",
      "Epoch 43/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.7438 - val_loss: 0.8970\n",
      "Epoch 44/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.7430 - val_loss: 0.8973\n",
      "Epoch 45/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.7428 - val_loss: 0.8976\n",
      "Epoch 46/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.7428 - val_loss: 0.8991\n",
      "Epoch 47/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.7481 - val_loss: 0.8985\n",
      "Epoch 48/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.7416 - val_loss: 0.8965\n",
      "Epoch 49/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.7427 - val_loss: 0.8938\n",
      "Epoch 50/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.7405 - val_loss: 0.8956\n",
      "Epoch 51/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.7400 - val_loss: 0.8936\n",
      "Epoch 52/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.7392 - val_loss: 0.8937\n",
      "Epoch 53/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.7386 - val_loss: 0.8935\n",
      "Epoch 54/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.7383 - val_loss: 0.8942\n",
      "Epoch 55/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.7372 - val_loss: 0.8929\n",
      "Epoch 56/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.7367 - val_loss: 0.8925\n",
      "Epoch 57/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.7358 - val_loss: 0.8932\n",
      "Epoch 58/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.7357 - val_loss: 0.8925\n",
      "Epoch 59/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.7348 - val_loss: 0.8933\n",
      "Epoch 60/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.7371 - val_loss: 0.8917\n",
      "Epoch 61/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.7361 - val_loss: 0.8965\n",
      "Epoch 62/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.7362 - val_loss: 0.8896\n",
      "Epoch 63/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.7344 - val_loss: 0.8899\n",
      "Epoch 64/1500\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.7332 - val_loss: 0.8889\n",
      "Epoch 65/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.7323 - val_loss: 0.8888\n",
      "Epoch 66/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.7311 - val_loss: 0.8879\n",
      "Epoch 67/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.7305 - val_loss: 0.8883\n",
      "Epoch 68/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.7292 - val_loss: 0.8907\n",
      "Epoch 69/1500\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.7288 - val_loss: 0.8874\n",
      "Epoch 70/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.7272 - val_loss: 0.8868\n",
      "Epoch 71/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.7266 - val_loss: 0.8873\n",
      "Epoch 72/1500\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.7250 - val_loss: 0.8859\n",
      "Epoch 73/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.7224 - val_loss: 0.8826\n",
      "Epoch 74/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.7218 - val_loss: 0.8870\n",
      "Epoch 75/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.7265 - val_loss: 0.8833\n",
      "Epoch 76/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.7197 - val_loss: 0.8801\n",
      "Epoch 77/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.7190 - val_loss: 0.8832\n",
      "Epoch 78/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.7188 - val_loss: 0.8821\n",
      "Epoch 79/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.7166 - val_loss: 0.8817\n",
      "Epoch 80/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.7149 - val_loss: 0.8808\n",
      "Epoch 81/1500\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.7107 - val_loss: 0.8783\n",
      "Epoch 82/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.7069 - val_loss: 0.8754\n",
      "Epoch 83/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.7018 - val_loss: 0.8747\n",
      "Epoch 84/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.6970 - val_loss: 0.8900\n",
      "Epoch 85/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.7101 - val_loss: 0.8703\n",
      "Epoch 86/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.6992 - val_loss: 0.8720\n",
      "Epoch 87/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.6964 - val_loss: 0.8673\n",
      "Epoch 88/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6876 - val_loss: 0.8699\n",
      "Epoch 89/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.6854 - val_loss: 0.8678\n",
      "Epoch 90/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.6803 - val_loss: 0.8641\n",
      "Epoch 91/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6796 - val_loss: 0.8654\n",
      "Epoch 92/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.6772 - val_loss: 0.8678\n",
      "Epoch 93/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.6799 - val_loss: 0.8599\n",
      "Epoch 94/1500\n",
      "5/5 [==============================] - 1s 92ms/step - loss: 0.6752 - val_loss: 0.8586\n",
      "Epoch 95/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.6746 - val_loss: 0.8580\n",
      "Epoch 96/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.6713 - val_loss: 0.8631\n",
      "Epoch 97/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.6714 - val_loss: 0.8593\n",
      "Epoch 98/1500\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.6712 - val_loss: 0.8620\n",
      "Epoch 99/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6664 - val_loss: 0.8724\n",
      "Epoch 100/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.6762 - val_loss: 0.8560\n",
      "Epoch 101/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.6743 - val_loss: 0.8603\n",
      "Epoch 102/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.6748 - val_loss: 0.8646\n",
      "Epoch 103/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.6715 - val_loss: 0.8600\n",
      "Epoch 104/1500\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.6651 - val_loss: 0.8564\n",
      "Epoch 105/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.6623 - val_loss: 0.8519\n",
      "Epoch 106/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.6589 - val_loss: 0.8522\n",
      "Epoch 107/1500\n",
      "5/5 [==============================] - 0s 107ms/step - loss: 0.6582 - val_loss: 0.8493\n",
      "Epoch 108/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.6593 - val_loss: 0.8599\n",
      "Epoch 109/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.6685 - val_loss: 0.8461\n",
      "Epoch 110/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.6670 - val_loss: 0.8559\n",
      "Epoch 111/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.6623 - val_loss: 0.8579\n",
      "Epoch 112/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.6608 - val_loss: 0.8518\n",
      "Epoch 113/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.6594 - val_loss: 0.8484\n",
      "Epoch 114/1500\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.6560 - val_loss: 0.8455\n",
      "Epoch 115/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.6544 - val_loss: 0.8468\n",
      "Epoch 116/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.6534 - val_loss: 0.8473\n",
      "Epoch 117/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.6511 - val_loss: 0.8449\n",
      "Epoch 118/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6507 - val_loss: 0.8498\n",
      "Epoch 119/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.6629 - val_loss: 0.8507\n",
      "Epoch 120/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.6556 - val_loss: 0.8476\n",
      "Epoch 121/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.6555 - val_loss: 0.8506\n",
      "Epoch 122/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.6574 - val_loss: 0.8470\n",
      "Epoch 123/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.6530 - val_loss: 0.8443\n",
      "Epoch 124/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.6539 - val_loss: 0.8423\n",
      "Epoch 125/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.6497 - val_loss: 0.8401\n",
      "Epoch 126/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.6455 - val_loss: 0.8393\n",
      "Epoch 127/1500\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.6447 - val_loss: 0.8439\n",
      "Epoch 128/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.6451 - val_loss: 0.8305\n",
      "Epoch 129/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.6443 - val_loss: 0.8268\n",
      "Epoch 130/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6422 - val_loss: 0.8334\n",
      "Epoch 131/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.6414 - val_loss: 0.8281\n",
      "Epoch 132/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.6397 - val_loss: 0.8259\n",
      "Epoch 133/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.6395 - val_loss: 0.8350\n",
      "Epoch 134/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.6383 - val_loss: 0.8249\n",
      "Epoch 135/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.6415 - val_loss: 0.8246\n",
      "Epoch 136/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.6412 - val_loss: 0.8180\n",
      "Epoch 137/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.6330 - val_loss: 0.8111\n",
      "Epoch 138/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.6300 - val_loss: 0.8065\n",
      "Epoch 139/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.6260 - val_loss: 0.8392\n",
      "Epoch 140/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.6402 - val_loss: 0.8318\n",
      "Epoch 141/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.6429 - val_loss: 0.8039\n",
      "Epoch 142/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.6368 - val_loss: 0.8068\n",
      "Epoch 143/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.6384 - val_loss: 0.8205\n",
      "Epoch 144/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.6418 - val_loss: 0.8022\n",
      "Epoch 145/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.6338 - val_loss: 0.8010\n",
      "Epoch 146/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.6294 - val_loss: 0.7897\n",
      "Epoch 147/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.6248 - val_loss: 0.7660\n",
      "Epoch 148/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6120 - val_loss: 0.7842\n",
      "Epoch 149/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.6187 - val_loss: 0.7859\n",
      "Epoch 150/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6173 - val_loss: 0.7907\n",
      "Epoch 151/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.6207 - val_loss: 0.7867\n",
      "Epoch 152/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.6167 - val_loss: 0.7803\n",
      "Epoch 153/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.6128 - val_loss: 0.7594\n",
      "Epoch 154/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.6025 - val_loss: 0.8719\n",
      "Epoch 155/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.6844 - val_loss: 0.7734\n",
      "Epoch 156/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.6222 - val_loss: 0.7881\n",
      "Epoch 157/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.6258 - val_loss: 0.7891\n",
      "Epoch 158/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.6253 - val_loss: 0.7843\n",
      "Epoch 159/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.6183 - val_loss: 0.7766\n",
      "Epoch 160/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.6135 - val_loss: 0.7630\n",
      "Epoch 161/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.6085 - val_loss: 0.7381\n",
      "Epoch 162/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.5982 - val_loss: 0.7304\n",
      "Epoch 163/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.5867 - val_loss: 0.7316\n",
      "Epoch 164/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.5940 - val_loss: 0.7586\n",
      "Epoch 165/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.6113 - val_loss: 0.7171\n",
      "Epoch 166/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.6047 - val_loss: 0.8792\n",
      "Epoch 167/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6247 - val_loss: 0.7439\n",
      "Epoch 168/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6017 - val_loss: 0.7690\n",
      "Epoch 169/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.6057 - val_loss: 0.7314\n",
      "Epoch 170/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.6006 - val_loss: 0.7178\n",
      "Epoch 171/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.5878 - val_loss: 0.7034\n",
      "Epoch 172/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.5794 - val_loss: 0.6900\n",
      "Epoch 173/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.5702 - val_loss: 0.6949\n",
      "Epoch 174/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.5705 - val_loss: 0.6760\n",
      "Epoch 175/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.5648 - val_loss: 0.6827\n",
      "Epoch 176/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.5627 - val_loss: 0.6787\n",
      "Epoch 177/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.5593 - val_loss: 0.6728\n",
      "Epoch 178/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.5588 - val_loss: 0.6829\n",
      "Epoch 179/1500\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.5580 - val_loss: 0.6809\n",
      "Epoch 180/1500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5619 - val_loss: 0.6873\n",
      "Epoch 181/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.5577 - val_loss: 0.6566\n",
      "Epoch 182/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.5470 - val_loss: 0.6520\n",
      "Epoch 183/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.5413 - val_loss: 0.6788\n",
      "Epoch 184/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.5552 - val_loss: 0.6776\n",
      "Epoch 185/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.5594 - val_loss: 0.6371\n",
      "Epoch 186/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.5394 - val_loss: 0.6282\n",
      "Epoch 187/1500\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.5326 - val_loss: 0.6168\n",
      "Epoch 188/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.5249 - val_loss: 0.6420\n",
      "Epoch 189/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.5432 - val_loss: 0.6082\n",
      "Epoch 190/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5211 - val_loss: 0.6154\n",
      "Epoch 191/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.5322 - val_loss: 0.6586\n",
      "Epoch 192/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.5525 - val_loss: 0.6185\n",
      "Epoch 193/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.5605 - val_loss: 0.6530\n",
      "Epoch 194/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.5541 - val_loss: 0.6199\n",
      "Epoch 195/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.5365 - val_loss: 0.6351\n",
      "Epoch 196/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.5344 - val_loss: 0.6143\n",
      "Epoch 197/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.5272 - val_loss: 0.5942\n",
      "Epoch 198/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.5317 - val_loss: 0.6386\n",
      "Epoch 199/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.5763 - val_loss: 0.7496\n",
      "Epoch 200/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.6184 - val_loss: 0.7618\n",
      "Epoch 201/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.6123 - val_loss: 0.7281\n",
      "Epoch 202/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.5987 - val_loss: 0.7103\n",
      "Epoch 203/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.6066 - val_loss: 0.6956\n",
      "Epoch 204/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.5788 - val_loss: 0.6826\n",
      "Epoch 205/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.5601 - val_loss: 0.6526\n",
      "Epoch 206/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.5494 - val_loss: 0.6295\n",
      "Epoch 207/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.5398 - val_loss: 0.6266\n",
      "Epoch 208/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.5340 - val_loss: 0.6223\n",
      "Epoch 209/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5284 - val_loss: 0.6296\n",
      "Epoch 210/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5273 - val_loss: 0.6301\n",
      "Epoch 211/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.5196 - val_loss: 0.6028\n",
      "Epoch 212/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.5113 - val_loss: 0.5891\n",
      "Epoch 213/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.5006 - val_loss: 0.5804\n",
      "Epoch 214/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4971 - val_loss: 0.5805\n",
      "Epoch 215/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.4947 - val_loss: 0.5597\n",
      "Epoch 216/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.4867 - val_loss: 0.5702\n",
      "Epoch 217/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.5052 - val_loss: 0.5518\n",
      "Epoch 218/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.4957 - val_loss: 0.5562\n",
      "Epoch 219/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.5276 - val_loss: 0.5616\n",
      "Epoch 220/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.5091 - val_loss: 0.6069\n",
      "Epoch 221/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.5097 - val_loss: 0.6087\n",
      "Epoch 222/1500\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.5008 - val_loss: 0.5809\n",
      "Epoch 223/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.5039 - val_loss: 0.5487\n",
      "Epoch 224/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.4919 - val_loss: 0.5606\n",
      "Epoch 225/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.4941 - val_loss: 0.5409\n",
      "Epoch 226/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.4983 - val_loss: 0.5759\n",
      "Epoch 227/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.5018 - val_loss: 0.5608\n",
      "Epoch 228/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.4883 - val_loss: 0.5597\n",
      "Epoch 229/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4886 - val_loss: 0.5500\n",
      "Epoch 230/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4756 - val_loss: 0.5744\n",
      "Epoch 231/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.4748 - val_loss: 0.5187\n",
      "Epoch 232/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.4685 - val_loss: 0.5122\n",
      "Epoch 233/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.4598 - val_loss: 0.5097\n",
      "Epoch 234/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.4538 - val_loss: 0.5067\n",
      "Epoch 235/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4510 - val_loss: 0.5099\n",
      "Epoch 236/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.4507 - val_loss: 0.5047\n",
      "Epoch 237/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4666 - val_loss: 0.5193\n",
      "Epoch 238/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4596 - val_loss: 0.5088\n",
      "Epoch 239/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.4477 - val_loss: 0.4936\n",
      "Epoch 240/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.4429 - val_loss: 0.4959\n",
      "Epoch 241/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.4357 - val_loss: 0.4837\n",
      "Epoch 242/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.4331 - val_loss: 0.4833\n",
      "Epoch 243/1500\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.4299 - val_loss: 0.4772\n",
      "Epoch 244/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.4295 - val_loss: 0.4911\n",
      "Epoch 245/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.4261 - val_loss: 0.4827\n",
      "Epoch 246/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.4294 - val_loss: 0.5665\n",
      "Epoch 247/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.4640 - val_loss: 0.5698\n",
      "Epoch 248/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4798 - val_loss: 0.5286\n",
      "Epoch 249/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4768 - val_loss: 0.5311\n",
      "Epoch 250/1500\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.4837 - val_loss: 0.5251\n",
      "Epoch 251/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4532 - val_loss: 0.5089\n",
      "Epoch 252/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.4563 - val_loss: 0.5110\n",
      "Epoch 253/1500\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.4688 - val_loss: 0.5183\n",
      "Epoch 254/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.4670 - val_loss: 0.5094\n",
      "Epoch 255/1500\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4837 - val_loss: 0.5475\n",
      "Epoch 256/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.4647 - val_loss: 0.5167\n",
      "Epoch 257/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.4504 - val_loss: 0.5016\n",
      "Epoch 258/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4390 - val_loss: 0.4970\n",
      "Epoch 259/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.4317 - val_loss: 0.4707\n",
      "Epoch 260/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4335 - val_loss: 0.4742\n",
      "Epoch 261/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.4268 - val_loss: 0.4701\n",
      "Epoch 262/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.4210 - val_loss: 0.4726\n",
      "Epoch 263/1500\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.4180 - val_loss: 0.4542\n",
      "Epoch 264/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.4064 - val_loss: 0.4443\n",
      "Epoch 265/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.4006 - val_loss: 0.4493\n",
      "Epoch 266/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.4043 - val_loss: 0.4611\n",
      "Epoch 267/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.4077 - val_loss: 0.4460\n",
      "Epoch 268/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.4281 - val_loss: 0.4610\n",
      "Epoch 269/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.4389 - val_loss: 0.5006\n",
      "Epoch 270/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.4684 - val_loss: 0.5093\n",
      "Epoch 271/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4685 - val_loss: 0.4881\n",
      "Epoch 272/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.4601 - val_loss: 0.4996\n",
      "Epoch 273/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4513 - val_loss: 0.4850\n",
      "Epoch 274/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4405 - val_loss: 0.4870\n",
      "Epoch 275/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.4355 - val_loss: 0.4745\n",
      "Epoch 276/1500\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.4244 - val_loss: 0.4605\n",
      "Epoch 277/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4139 - val_loss: 0.4601\n",
      "Epoch 278/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.4052 - val_loss: 0.4559\n",
      "Epoch 279/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.4015 - val_loss: 0.4525\n",
      "Epoch 280/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.3962 - val_loss: 0.4516\n",
      "Epoch 281/1500\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.3972 - val_loss: 0.6530\n",
      "Epoch 282/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.5505 - val_loss: 0.5001\n",
      "Epoch 283/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4663 - val_loss: 0.5552\n",
      "Epoch 284/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4801 - val_loss: 0.6271\n",
      "Epoch 285/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4985 - val_loss: 0.5794\n",
      "Epoch 286/1500\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4744 - val_loss: 0.5366\n",
      "Epoch 287/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4586 - val_loss: 0.5275\n",
      "Epoch 288/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4441 - val_loss: 0.5053\n",
      "Epoch 289/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4300 - val_loss: 0.4952\n",
      "Epoch 290/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4238 - val_loss: 0.4804\n",
      "Epoch 291/1500\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.4152 - val_loss: 0.4685\n",
      "Epoch 292/1500\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.4085 - val_loss: 0.4644\n",
      "Epoch 293/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.4055 - val_loss: 0.4556\n",
      "Epoch 294/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.4009 - val_loss: 0.4600\n",
      "Epoch 295/1500\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4000 - val_loss: 0.4718\n",
      "Epoch 296/1500\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4061 - val_loss: 0.4478\n",
      "Epoch 297/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4027 - val_loss: 0.4622\n",
      "Epoch 298/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.3983 - val_loss: 0.4758\n",
      "Epoch 299/1500\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4091 - val_loss: 0.4522\n",
      "Epoch 300/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4169 - val_loss: 0.4535\n",
      "Epoch 301/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.3889 - val_loss: 0.4708\n",
      "Epoch 302/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3883 - val_loss: 0.4435\n",
      "Epoch 303/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.3812 - val_loss: 0.4444\n",
      "Epoch 304/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3788 - val_loss: 0.4343\n",
      "Epoch 305/1500\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.3727 - val_loss: 0.4375\n",
      "Epoch 306/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3695 - val_loss: 0.4325\n",
      "Epoch 307/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3671 - val_loss: 0.4276\n",
      "Epoch 308/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.3810 - val_loss: 0.4548\n",
      "Epoch 309/1500\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.3832 - val_loss: 0.4349\n",
      "Epoch 310/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.3735 - val_loss: 0.4447\n",
      "Epoch 311/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.3676 - val_loss: 0.4319\n",
      "Epoch 312/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3649 - val_loss: 0.4206\n",
      "Epoch 313/1500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.3652 - val_loss: 0.4303\n",
      "Epoch 314/1500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.3750 - val_loss: 0.4284\n",
      "Epoch 315/1500\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.3666 - val_loss: 0.4283\n",
      "Epoch 316/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.3587 - val_loss: 0.4286\n",
      "Epoch 317/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.3571 - val_loss: 0.4229\n",
      "Epoch 318/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.3518 - val_loss: 0.4182\n",
      "Epoch 319/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.3524 - val_loss: 0.4103\n",
      "Epoch 320/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.3482 - val_loss: 0.4094\n",
      "Epoch 321/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3464 - val_loss: 0.4150\n",
      "Epoch 322/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3506 - val_loss: 0.4220\n",
      "Epoch 323/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.3601 - val_loss: 0.4226\n",
      "Epoch 324/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.3566 - val_loss: 0.4074\n",
      "Epoch 325/1500\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.3571 - val_loss: 0.4094\n",
      "Epoch 326/1500\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.3541 - val_loss: 0.4083\n",
      "Epoch 327/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.3510 - val_loss: 0.4022\n",
      "Epoch 328/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.3433 - val_loss: 0.4035\n",
      "Epoch 329/1500\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.3392 - val_loss: 0.3970\n",
      "Epoch 330/1500\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.3386 - val_loss: 0.3964\n",
      "Epoch 331/1500\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.3415 - val_loss: 0.4051\n",
      "Epoch 332/1500\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.3498 - val_loss: 0.4216\n",
      "Epoch 333/1500\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.3621 - val_loss: 0.3855\n",
      "Epoch 334/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.3473 - val_loss: 0.3973\n",
      "Epoch 335/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.3424 - val_loss: 0.3992\n",
      "Epoch 336/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3490 - val_loss: 0.3909\n",
      "Epoch 337/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3398 - val_loss: 0.3872\n",
      "Epoch 338/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.3408 - val_loss: 0.3897\n",
      "Epoch 339/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.3344 - val_loss: 0.3814\n",
      "Epoch 340/1500\n",
      "5/5 [==============================] - 1s 85ms/step - loss: 0.3431 - val_loss: 0.4165\n",
      "Epoch 341/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3475 - val_loss: 0.4248\n",
      "Epoch 342/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3801 - val_loss: 0.4825\n",
      "Epoch 343/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3780 - val_loss: 0.4260\n",
      "Epoch 344/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3800 - val_loss: 0.4402\n",
      "Epoch 345/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3723 - val_loss: 0.4270\n",
      "Epoch 346/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3781 - val_loss: 0.4955\n",
      "Epoch 347/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.3792 - val_loss: 0.4160\n",
      "Epoch 348/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3607 - val_loss: 0.4133\n",
      "Epoch 349/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3517 - val_loss: 0.3971\n",
      "Epoch 350/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3474 - val_loss: 0.4025\n",
      "Epoch 351/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3406 - val_loss: 0.3968\n",
      "Epoch 352/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3404 - val_loss: 0.3938\n",
      "Epoch 353/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3405 - val_loss: 0.3925\n",
      "Epoch 354/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.3360 - val_loss: 0.3812\n",
      "Epoch 355/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.3293 - val_loss: 0.3847\n",
      "Epoch 356/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.3279 - val_loss: 0.3922\n",
      "Epoch 357/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.3302 - val_loss: 0.3808\n",
      "Epoch 358/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3258 - val_loss: 0.3914\n",
      "Epoch 359/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.3276 - val_loss: 0.3806\n",
      "Epoch 360/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3367 - val_loss: 0.4280\n",
      "Epoch 361/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3427 - val_loss: 0.4002\n",
      "Epoch 362/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.3401 - val_loss: 0.4005\n",
      "Epoch 363/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.3645 - val_loss: 0.4154\n",
      "Epoch 364/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3519 - val_loss: 0.3869\n",
      "Epoch 365/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3410 - val_loss: 0.3929\n",
      "Epoch 366/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3303 - val_loss: 0.3843\n",
      "Epoch 367/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.3294 - val_loss: 0.3635\n",
      "Epoch 368/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3229 - val_loss: 0.3714\n",
      "Epoch 369/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3221 - val_loss: 0.3774\n",
      "Epoch 370/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3244 - val_loss: 0.3702\n",
      "Epoch 371/1500\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.3273 - val_loss: 0.3770\n",
      "Epoch 372/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3247 - val_loss: 0.3674\n",
      "Epoch 373/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3224 - val_loss: 0.3687\n",
      "Epoch 374/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3159 - val_loss: 0.3654\n",
      "Epoch 375/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3140 - val_loss: 0.3656\n",
      "Epoch 376/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3081 - val_loss: 0.3675\n",
      "Epoch 377/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3155 - val_loss: 0.3647\n",
      "Epoch 378/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.3170 - val_loss: 0.3602\n",
      "Epoch 379/1500\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.3152 - val_loss: 0.3794\n",
      "Epoch 380/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3374 - val_loss: 0.4028\n",
      "Epoch 381/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3374 - val_loss: 0.3707\n",
      "Epoch 382/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3246 - val_loss: 0.3711\n",
      "Epoch 383/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3221 - val_loss: 0.3634\n",
      "Epoch 384/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.3125 - val_loss: 0.3575\n",
      "Epoch 385/1500\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.3083 - val_loss: 0.3556\n",
      "Epoch 386/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3057 - val_loss: 0.3570\n",
      "Epoch 387/1500\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.3050 - val_loss: 0.3568\n",
      "Epoch 388/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.3013 - val_loss: 0.3552\n",
      "Epoch 389/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3002 - val_loss: 0.3564\n",
      "Epoch 390/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2971 - val_loss: 0.3609\n",
      "Epoch 391/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3039 - val_loss: 0.3873\n",
      "Epoch 392/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.3534 - val_loss: 0.3678\n",
      "Epoch 393/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.3383 - val_loss: 0.3565\n",
      "Epoch 394/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.3437 - val_loss: 0.3961\n",
      "Epoch 395/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3459 - val_loss: 0.4010\n",
      "Epoch 396/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.3427 - val_loss: 0.3778\n",
      "Epoch 397/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.3375 - val_loss: 0.3757\n",
      "Epoch 398/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3269 - val_loss: 0.3858\n",
      "Epoch 399/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3312 - val_loss: 0.3706\n",
      "Epoch 400/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3165 - val_loss: 0.3695\n",
      "Epoch 401/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.3158 - val_loss: 0.3631\n",
      "Epoch 402/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.3093 - val_loss: 0.3871\n",
      "Epoch 403/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3121 - val_loss: 0.3646\n",
      "Epoch 404/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.3098 - val_loss: 0.3584\n",
      "Epoch 405/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3048 - val_loss: 0.3626\n",
      "Epoch 406/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.3077 - val_loss: 0.3521\n",
      "Epoch 407/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3045 - val_loss: 0.3690\n",
      "Epoch 408/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3066 - val_loss: 0.3585\n",
      "Epoch 409/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.2995 - val_loss: 0.3572\n",
      "Epoch 410/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2986 - val_loss: 0.3559\n",
      "Epoch 411/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3004 - val_loss: 0.3523\n",
      "Epoch 412/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2954 - val_loss: 0.3643\n",
      "Epoch 413/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2937 - val_loss: 0.3476\n",
      "Epoch 414/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2910 - val_loss: 0.3505\n",
      "Epoch 415/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2889 - val_loss: 0.3454\n",
      "Epoch 416/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2879 - val_loss: 0.3450\n",
      "Epoch 417/1500\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.2855 - val_loss: 0.3457\n",
      "Epoch 418/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2859 - val_loss: 0.3466\n",
      "Epoch 419/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2855 - val_loss: 0.3430\n",
      "Epoch 420/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2847 - val_loss: 0.3386\n",
      "Epoch 421/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3035 - val_loss: 0.3549\n",
      "Epoch 422/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2961 - val_loss: 0.3454\n",
      "Epoch 423/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2876 - val_loss: 0.3416\n",
      "Epoch 424/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.3015 - val_loss: 0.3569\n",
      "Epoch 425/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.3309 - val_loss: 0.4885\n",
      "Epoch 426/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3872 - val_loss: 0.4138\n",
      "Epoch 427/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3570 - val_loss: 0.3876\n",
      "Epoch 428/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3409 - val_loss: 0.3869\n",
      "Epoch 429/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3431 - val_loss: 0.3631\n",
      "Epoch 430/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3252 - val_loss: 0.3548\n",
      "Epoch 431/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.3186 - val_loss: 0.3512\n",
      "Epoch 432/1500\n",
      "5/5 [==============================] - 1s 93ms/step - loss: 0.3067 - val_loss: 0.3532\n",
      "Epoch 433/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3021 - val_loss: 0.3492\n",
      "Epoch 434/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2957 - val_loss: 0.3418\n",
      "Epoch 435/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2995 - val_loss: 0.3414\n",
      "Epoch 436/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2956 - val_loss: 0.3407\n",
      "Epoch 437/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2949 - val_loss: 0.3448\n",
      "Epoch 438/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2924 - val_loss: 0.3463\n",
      "Epoch 439/1500\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.2918 - val_loss: 0.3336\n",
      "Epoch 440/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2863 - val_loss: 0.3349\n",
      "Epoch 441/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2862 - val_loss: 0.3412\n",
      "Epoch 442/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3020 - val_loss: 0.3664\n",
      "Epoch 443/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3031 - val_loss: 0.3743\n",
      "Epoch 444/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3027 - val_loss: 0.3481\n",
      "Epoch 445/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2925 - val_loss: 0.3475\n",
      "Epoch 446/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2896 - val_loss: 0.3503\n",
      "Epoch 447/1500\n",
      "5/5 [==============================] - 1s 85ms/step - loss: 0.2864 - val_loss: 0.3431\n",
      "Epoch 448/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2825 - val_loss: 0.3394\n",
      "Epoch 449/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2799 - val_loss: 0.3350\n",
      "Epoch 450/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2807 - val_loss: 0.3373\n",
      "Epoch 451/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2883 - val_loss: 0.3658\n",
      "Epoch 452/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3484 - val_loss: 0.4088\n",
      "Epoch 453/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3398 - val_loss: 0.3476\n",
      "Epoch 454/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3152 - val_loss: 0.3500\n",
      "Epoch 455/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.3059 - val_loss: 0.3797\n",
      "Epoch 456/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.3047 - val_loss: 0.3384\n",
      "Epoch 457/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3025 - val_loss: 0.3515\n",
      "Epoch 458/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2915 - val_loss: 0.3369\n",
      "Epoch 459/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2867 - val_loss: 0.3337\n",
      "Epoch 460/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2828 - val_loss: 0.3335\n",
      "Epoch 461/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2816 - val_loss: 0.3354\n",
      "Epoch 462/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2807 - val_loss: 0.3352\n",
      "Epoch 463/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2780 - val_loss: 0.3330\n",
      "Epoch 464/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2791 - val_loss: 0.3297\n",
      "Epoch 465/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2761 - val_loss: 0.3252\n",
      "Epoch 466/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2733 - val_loss: 0.3271\n",
      "Epoch 467/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2765 - val_loss: 0.3326\n",
      "Epoch 468/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2739 - val_loss: 0.3309\n",
      "Epoch 469/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2756 - val_loss: 0.3287\n",
      "Epoch 470/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2761 - val_loss: 0.3269\n",
      "Epoch 471/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2708 - val_loss: 0.3283\n",
      "Epoch 472/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2693 - val_loss: 0.3245\n",
      "Epoch 473/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2672 - val_loss: 0.3287\n",
      "Epoch 474/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2694 - val_loss: 0.3278\n",
      "Epoch 475/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2742 - val_loss: 0.3353\n",
      "Epoch 476/1500\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.2744 - val_loss: 0.3199\n",
      "Epoch 477/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2700 - val_loss: 0.3317\n",
      "Epoch 478/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2730 - val_loss: 0.3524\n",
      "Epoch 479/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3930 - val_loss: 0.4495\n",
      "Epoch 480/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3559 - val_loss: 0.3837\n",
      "Epoch 481/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3352 - val_loss: 0.3873\n",
      "Epoch 482/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.3279 - val_loss: 0.3726\n",
      "Epoch 483/1500\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.3204 - val_loss: 0.3461\n",
      "Epoch 484/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3038 - val_loss: 0.3454\n",
      "Epoch 485/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2999 - val_loss: 0.3374\n",
      "Epoch 486/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2952 - val_loss: 0.3423\n",
      "Epoch 487/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2993 - val_loss: 0.3620\n",
      "Epoch 488/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2964 - val_loss: 0.3422\n",
      "Epoch 489/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2883 - val_loss: 0.3362\n",
      "Epoch 490/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2831 - val_loss: 0.3353\n",
      "Epoch 491/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2837 - val_loss: 0.3457\n",
      "Epoch 492/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2862 - val_loss: 0.3393\n",
      "Epoch 493/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2894 - val_loss: 0.3962\n",
      "Epoch 494/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3015 - val_loss: 0.3504\n",
      "Epoch 495/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2961 - val_loss: 0.3698\n",
      "Epoch 496/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2884 - val_loss: 0.3357\n",
      "Epoch 497/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2831 - val_loss: 0.3524\n",
      "Epoch 498/1500\n",
      "5/5 [==============================] - 1s 93ms/step - loss: 0.2858 - val_loss: 0.3418\n",
      "Epoch 499/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2826 - val_loss: 0.3338\n",
      "Epoch 500/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2769 - val_loss: 0.3257\n",
      "Epoch 501/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2770 - val_loss: 0.3382\n",
      "Epoch 502/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3178 - val_loss: 0.4023\n",
      "Epoch 503/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3037 - val_loss: 0.3523\n",
      "Epoch 504/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2883 - val_loss: 0.3299\n",
      "Epoch 505/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.2964 - val_loss: 0.3563\n",
      "Epoch 506/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.3307 - val_loss: 0.3542\n",
      "Epoch 507/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3294 - val_loss: 0.3935\n",
      "Epoch 508/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3269 - val_loss: 0.3676\n",
      "Epoch 509/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3169 - val_loss: 0.3496\n",
      "Epoch 510/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3055 - val_loss: 0.3362\n",
      "Epoch 511/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2974 - val_loss: 0.3355\n",
      "Epoch 512/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2917 - val_loss: 0.3350\n",
      "Epoch 513/1500\n",
      "5/5 [==============================] - 1s 87ms/step - loss: 0.2861 - val_loss: 0.3256\n",
      "Epoch 514/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2790 - val_loss: 0.3240\n",
      "Epoch 515/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2761 - val_loss: 0.3219\n",
      "Epoch 516/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2732 - val_loss: 0.3226\n",
      "Epoch 517/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2706 - val_loss: 0.3208\n",
      "Epoch 518/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2701 - val_loss: 0.3233\n",
      "Epoch 519/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2856 - val_loss: 0.3397\n",
      "Epoch 520/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2933 - val_loss: 0.3366\n",
      "Epoch 521/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2854 - val_loss: 0.3296\n",
      "Epoch 522/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2740 - val_loss: 0.3315\n",
      "Epoch 523/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2737 - val_loss: 0.3349\n",
      "Epoch 524/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2861 - val_loss: 0.3459\n",
      "Epoch 525/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2900 - val_loss: 0.3422\n",
      "Epoch 526/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2849 - val_loss: 0.3267\n",
      "Epoch 527/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2786 - val_loss: 0.3293\n",
      "Epoch 528/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2761 - val_loss: 0.3196\n",
      "Epoch 529/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2686 - val_loss: 0.3258\n",
      "Epoch 530/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2838 - val_loss: 0.3279\n",
      "Epoch 531/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2867 - val_loss: 0.3124\n",
      "Epoch 532/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2812 - val_loss: 0.2997\n",
      "Epoch 533/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2862 - val_loss: 0.3085\n",
      "Epoch 534/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2795 - val_loss: 0.3062\n",
      "Epoch 535/1500\n",
      "5/5 [==============================] - 1s 86ms/step - loss: 0.2753 - val_loss: 0.3042\n",
      "Epoch 536/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2903 - val_loss: 0.3245\n",
      "Epoch 537/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2890 - val_loss: 0.3175\n",
      "Epoch 538/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2839 - val_loss: 0.2968\n",
      "Epoch 539/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2746 - val_loss: 0.3010\n",
      "Epoch 540/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2706 - val_loss: 0.2987\n",
      "Epoch 541/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2656 - val_loss: 0.2976\n",
      "Epoch 542/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.2632 - val_loss: 0.2966\n",
      "Epoch 543/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.2618 - val_loss: 0.2967\n",
      "Epoch 544/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2594 - val_loss: 0.3004\n",
      "Epoch 545/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2602 - val_loss: 0.2964\n",
      "Epoch 546/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.2577 - val_loss: 0.2956\n",
      "Epoch 547/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2566 - val_loss: 0.2986\n",
      "Epoch 548/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2580 - val_loss: 0.3086\n",
      "Epoch 549/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2603 - val_loss: 0.3013\n",
      "Epoch 550/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2607 - val_loss: 0.3166\n",
      "Epoch 551/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.3148 - val_loss: 0.3888\n",
      "Epoch 552/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.3111 - val_loss: 0.3508\n",
      "Epoch 553/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2919 - val_loss: 0.3347\n",
      "Epoch 554/1500\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.2915 - val_loss: 0.3265\n",
      "Epoch 555/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2812 - val_loss: 0.3474\n",
      "Epoch 556/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2830 - val_loss: 0.3237\n",
      "Epoch 557/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2818 - val_loss: 0.3692\n",
      "Epoch 558/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2781 - val_loss: 0.3240\n",
      "Epoch 559/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2653 - val_loss: 0.3124\n",
      "Epoch 560/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2645 - val_loss: 0.3135\n",
      "Epoch 561/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2626 - val_loss: 0.3105\n",
      "Epoch 562/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2641 - val_loss: 0.3083\n",
      "Epoch 563/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2604 - val_loss: 0.3032\n",
      "Epoch 564/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2572 - val_loss: 0.3024\n",
      "Epoch 565/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2546 - val_loss: 0.3015\n",
      "Epoch 566/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2547 - val_loss: 0.3013\n",
      "Epoch 567/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2548 - val_loss: 0.2993\n",
      "Epoch 568/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2531 - val_loss: 0.3014\n",
      "Epoch 569/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2536 - val_loss: 0.3038\n",
      "Epoch 570/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2726 - val_loss: 0.3242\n",
      "Epoch 571/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2701 - val_loss: 0.3082\n",
      "Epoch 572/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2623 - val_loss: 0.3015\n",
      "Epoch 573/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2581 - val_loss: 0.2990\n",
      "Epoch 574/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2579 - val_loss: 0.3014\n",
      "Epoch 575/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2531 - val_loss: 0.2972\n",
      "Epoch 576/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2528 - val_loss: 0.2963\n",
      "Epoch 577/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2524 - val_loss: 0.2956\n",
      "Epoch 578/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2576 - val_loss: 0.3135\n",
      "Epoch 579/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2585 - val_loss: 0.2990\n",
      "Epoch 580/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2587 - val_loss: 0.3077\n",
      "Epoch 581/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.2646 - val_loss: 0.3153\n",
      "Epoch 582/1500\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.2653 - val_loss: 0.3013\n",
      "Epoch 583/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2613 - val_loss: 0.2950\n",
      "Epoch 584/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2589 - val_loss: 0.2920\n",
      "Epoch 585/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2550 - val_loss: 0.2975\n",
      "Epoch 586/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2602 - val_loss: 0.3103\n",
      "Epoch 587/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2610 - val_loss: 0.2987\n",
      "Epoch 588/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2541 - val_loss: 0.3079\n",
      "Epoch 589/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2940 - val_loss: 0.3336\n",
      "Epoch 590/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2799 - val_loss: 0.3216\n",
      "Epoch 591/1500\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.2725 - val_loss: 0.3104\n",
      "Epoch 592/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2790 - val_loss: 0.3453\n",
      "Epoch 593/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2868 - val_loss: 0.3127\n",
      "Epoch 594/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2761 - val_loss: 0.3051\n",
      "Epoch 595/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2642 - val_loss: 0.3121\n",
      "Epoch 596/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2639 - val_loss: 0.3074\n",
      "Epoch 597/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2588 - val_loss: 0.3088\n",
      "Epoch 598/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2575 - val_loss: 0.2975\n",
      "Epoch 599/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2547 - val_loss: 0.2935\n",
      "Epoch 600/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2538 - val_loss: 0.3009\n",
      "Epoch 601/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2547 - val_loss: 0.2926\n",
      "Epoch 602/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.2539 - val_loss: 0.2936\n",
      "Epoch 603/1500\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.2525 - val_loss: 0.2890\n",
      "Epoch 604/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2493 - val_loss: 0.2903\n",
      "Epoch 605/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2685 - val_loss: 0.2911\n",
      "Epoch 606/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2591 - val_loss: 0.2830\n",
      "Epoch 607/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2549 - val_loss: 0.2767\n",
      "Epoch 608/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2547 - val_loss: 0.2803\n",
      "Epoch 609/1500\n",
      "5/5 [==============================] - 1s 95ms/step - loss: 0.2729 - val_loss: 0.2968\n",
      "Epoch 610/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2762 - val_loss: 0.2995\n",
      "Epoch 611/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2725 - val_loss: 0.2813\n",
      "Epoch 612/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2592 - val_loss: 0.2850\n",
      "Epoch 613/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2605 - val_loss: 0.2845\n",
      "Epoch 614/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2560 - val_loss: 0.2991\n",
      "Epoch 615/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2723 - val_loss: 0.3197\n",
      "Epoch 616/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2834 - val_loss: 0.3061\n",
      "Epoch 617/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2976 - val_loss: 0.3379\n",
      "Epoch 618/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.3150 - val_loss: 0.3266\n",
      "Epoch 619/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2965 - val_loss: 0.3246\n",
      "Epoch 620/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2891 - val_loss: 0.3305\n",
      "Epoch 621/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2854 - val_loss: 0.3174\n",
      "Epoch 622/1500\n",
      "5/5 [==============================] - 1s 91ms/step - loss: 0.2787 - val_loss: 0.3084\n",
      "Epoch 623/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2722 - val_loss: 0.3058\n",
      "Epoch 624/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2676 - val_loss: 0.3003\n",
      "Epoch 625/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2623 - val_loss: 0.2884\n",
      "Epoch 626/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2626 - val_loss: 0.2868\n",
      "Epoch 627/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2571 - val_loss: 0.2844\n",
      "Epoch 628/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2558 - val_loss: 0.2859\n",
      "Epoch 629/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2531 - val_loss: 0.2831\n",
      "Epoch 630/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2522 - val_loss: 0.2807\n",
      "Epoch 631/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2502 - val_loss: 0.2825\n",
      "Epoch 632/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2504 - val_loss: 0.2807\n",
      "Epoch 633/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2499 - val_loss: 0.2808\n",
      "Epoch 634/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2474 - val_loss: 0.2790\n",
      "Epoch 635/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2473 - val_loss: 0.2782\n",
      "Epoch 636/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2481 - val_loss: 0.2777\n",
      "Epoch 637/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2466 - val_loss: 0.2801\n",
      "Epoch 638/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2474 - val_loss: 0.2827\n",
      "Epoch 639/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2479 - val_loss: 0.2788\n",
      "Epoch 640/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2452 - val_loss: 0.2812\n",
      "Epoch 641/1500\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.2433 - val_loss: 0.2803\n",
      "Epoch 642/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2429 - val_loss: 0.2781\n",
      "Epoch 643/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2427 - val_loss: 0.2941\n",
      "Epoch 644/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2485 - val_loss: 0.2789\n",
      "Epoch 645/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2580 - val_loss: 0.2899\n",
      "Epoch 646/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2551 - val_loss: 0.2800\n",
      "Epoch 647/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2516 - val_loss: 0.2829\n",
      "Epoch 648/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2481 - val_loss: 0.2733\n",
      "Epoch 649/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2463 - val_loss: 0.2851\n",
      "Epoch 650/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2479 - val_loss: 0.2791\n",
      "Epoch 651/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2457 - val_loss: 0.2841\n",
      "Epoch 652/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2479 - val_loss: 0.2780\n",
      "Epoch 653/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2417 - val_loss: 0.2765\n",
      "Epoch 654/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.2404 - val_loss: 0.2710\n",
      "Epoch 655/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2429 - val_loss: 0.2701\n",
      "Epoch 656/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2415 - val_loss: 0.2734\n",
      "Epoch 657/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2400 - val_loss: 0.2734\n",
      "Epoch 658/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2408 - val_loss: 0.2701\n",
      "Epoch 659/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2380 - val_loss: 0.2717\n",
      "Epoch 660/1500\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.2374 - val_loss: 0.2698\n",
      "Epoch 661/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2376 - val_loss: 0.2720\n",
      "Epoch 662/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2380 - val_loss: 0.2718\n",
      "Epoch 663/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2380 - val_loss: 0.2710\n",
      "Epoch 664/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2374 - val_loss: 0.2671\n",
      "Epoch 665/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2388 - val_loss: 0.2772\n",
      "Epoch 666/1500\n",
      "5/5 [==============================] - 1s 84ms/step - loss: 0.2401 - val_loss: 0.2700\n",
      "Epoch 667/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2434 - val_loss: 0.2705\n",
      "Epoch 668/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2420 - val_loss: 0.2767\n",
      "Epoch 669/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2413 - val_loss: 0.2735\n",
      "Epoch 670/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2394 - val_loss: 0.2784\n",
      "Epoch 671/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2536 - val_loss: 0.2933\n",
      "Epoch 672/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2496 - val_loss: 0.2827\n",
      "Epoch 673/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2435 - val_loss: 0.2765\n",
      "Epoch 674/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2396 - val_loss: 0.2728\n",
      "Epoch 675/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2361 - val_loss: 0.2693\n",
      "Epoch 676/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2348 - val_loss: 0.2672\n",
      "Epoch 677/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2344 - val_loss: 0.2634\n",
      "Epoch 678/1500\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.2385 - val_loss: 0.2600\n",
      "Epoch 679/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2363 - val_loss: 0.2615\n",
      "Epoch 680/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2388 - val_loss: 0.2809\n",
      "Epoch 681/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2639 - val_loss: 0.2699\n",
      "Epoch 682/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2667 - val_loss: 0.3314\n",
      "Epoch 683/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2800 - val_loss: 0.2890\n",
      "Epoch 684/1500\n",
      "5/5 [==============================] - 1s 90ms/step - loss: 0.2609 - val_loss: 0.2803\n",
      "Epoch 685/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2559 - val_loss: 0.2908\n",
      "Epoch 686/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2505 - val_loss: 0.2745\n",
      "Epoch 687/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2463 - val_loss: 0.2722\n",
      "Epoch 688/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2404 - val_loss: 0.2694\n",
      "Epoch 689/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2422 - val_loss: 0.2876\n",
      "Epoch 690/1500\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.2790 - val_loss: 0.3017\n",
      "Epoch 691/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2771 - val_loss: 0.2896\n",
      "Epoch 692/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2672 - val_loss: 0.2782\n",
      "Epoch 693/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2571 - val_loss: 0.2807\n",
      "Epoch 694/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2528 - val_loss: 0.2864\n",
      "Epoch 695/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2512 - val_loss: 0.2767\n",
      "Epoch 696/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2449 - val_loss: 0.2639\n",
      "Epoch 697/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2471 - val_loss: 0.2710\n",
      "Epoch 698/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2467 - val_loss: 0.2701\n",
      "Epoch 699/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2394 - val_loss: 0.2718\n",
      "Epoch 700/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2706 - val_loss: 0.2864\n",
      "Epoch 701/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2544 - val_loss: 0.2695\n",
      "Epoch 702/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2457 - val_loss: 0.2671\n",
      "Epoch 703/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2443 - val_loss: 0.2625\n",
      "Epoch 704/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2432 - val_loss: 0.2712\n",
      "Epoch 705/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2543 - val_loss: 0.2767\n",
      "Epoch 706/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2507 - val_loss: 0.2687\n",
      "Epoch 707/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2459 - val_loss: 0.2638\n",
      "Epoch 708/1500\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.2400 - val_loss: 0.2692\n",
      "Epoch 709/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2421 - val_loss: 0.2637\n",
      "Epoch 710/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2396 - val_loss: 0.2634\n",
      "Epoch 711/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2412 - val_loss: 0.2706\n",
      "Epoch 712/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2486 - val_loss: 0.2868\n",
      "Epoch 713/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2829 - val_loss: 0.3119\n",
      "Epoch 714/1500\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.2771 - val_loss: 0.2865\n",
      "Epoch 715/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2628 - val_loss: 0.2687\n",
      "Epoch 716/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2491 - val_loss: 0.2676\n",
      "Epoch 717/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2542 - val_loss: 0.2554\n",
      "Epoch 718/1500\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 0.2473 - val_loss: 0.2537\n",
      "Epoch 719/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2410 - val_loss: 0.2555\n",
      "Epoch 720/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.2371 - val_loss: 0.2554\n",
      "Epoch 721/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2350 - val_loss: 0.2608\n",
      "Epoch 722/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.2336 - val_loss: 0.2532\n",
      "Epoch 723/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2493 - val_loss: 0.2667\n",
      "Epoch 724/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2625 - val_loss: 0.2519\n",
      "Epoch 725/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2484 - val_loss: 0.2468\n",
      "Epoch 726/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2423 - val_loss: 0.2592\n",
      "Epoch 727/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2498 - val_loss: 0.2745\n",
      "Epoch 728/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2483 - val_loss: 0.2546\n",
      "Epoch 729/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2438 - val_loss: 0.2603\n",
      "Epoch 730/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2397 - val_loss: 0.2620\n",
      "Epoch 731/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2368 - val_loss: 0.2575\n",
      "Epoch 732/1500\n",
      "5/5 [==============================] - 1s 95ms/step - loss: 0.2357 - val_loss: 0.2613\n",
      "Epoch 733/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2350 - val_loss: 0.2612\n",
      "Epoch 734/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2316 - val_loss: 0.2676\n",
      "Epoch 735/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2667 - val_loss: 0.2933\n",
      "Epoch 736/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.3118 - val_loss: 0.3648\n",
      "Epoch 737/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3306 - val_loss: 0.3329\n",
      "Epoch 738/1500\n",
      "5/5 [==============================] - 1s 84ms/step - loss: 0.3060 - val_loss: 0.3365\n",
      "Epoch 739/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3010 - val_loss: 0.3179\n",
      "Epoch 740/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2918 - val_loss: 0.3117\n",
      "Epoch 741/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2865 - val_loss: 0.3012\n",
      "Epoch 742/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2764 - val_loss: 0.3002\n",
      "Epoch 743/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2709 - val_loss: 0.2837\n",
      "Epoch 744/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2650 - val_loss: 0.2795\n",
      "Epoch 745/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2615 - val_loss: 0.2808\n",
      "Epoch 746/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2593 - val_loss: 0.3049\n",
      "Epoch 747/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2655 - val_loss: 0.3103\n",
      "Epoch 748/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2597 - val_loss: 0.2957\n",
      "Epoch 749/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.2527 - val_loss: 0.2855\n",
      "Epoch 750/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2491 - val_loss: 0.2799\n",
      "Epoch 751/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2443 - val_loss: 0.2771\n",
      "Epoch 752/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2428 - val_loss: 0.2791\n",
      "Epoch 753/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2409 - val_loss: 0.2699\n",
      "Epoch 754/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2391 - val_loss: 0.2692\n",
      "Epoch 755/1500\n",
      "5/5 [==============================] - 1s 88ms/step - loss: 0.2383 - val_loss: 0.2697\n",
      "Epoch 756/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2378 - val_loss: 0.2694\n",
      "Epoch 757/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2378 - val_loss: 0.2744\n",
      "Epoch 758/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2388 - val_loss: 0.2704\n",
      "Epoch 759/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2390 - val_loss: 0.2663\n",
      "Epoch 760/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2347 - val_loss: 0.2605\n",
      "Epoch 761/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2367 - val_loss: 0.2582\n",
      "Epoch 762/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2384 - val_loss: 0.2587\n",
      "Epoch 763/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2401 - val_loss: 0.2631\n",
      "Epoch 764/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2362 - val_loss: 0.2612\n",
      "Epoch 765/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2383 - val_loss: 0.2673\n",
      "Epoch 766/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.2427 - val_loss: 0.2692\n",
      "Epoch 767/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2381 - val_loss: 0.2667\n",
      "Epoch 768/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2352 - val_loss: 0.2647\n",
      "Epoch 769/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2329 - val_loss: 0.2616\n",
      "Epoch 770/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2304 - val_loss: 0.2634\n",
      "Epoch 771/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2299 - val_loss: 0.2632\n",
      "Epoch 772/1500\n",
      "5/5 [==============================] - 1s 91ms/step - loss: 0.2290 - val_loss: 0.2588\n",
      "Epoch 773/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2318 - val_loss: 0.2630\n",
      "Epoch 774/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2312 - val_loss: 0.2642\n",
      "Epoch 775/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2363 - val_loss: 0.2602\n",
      "Epoch 776/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2386 - val_loss: 0.2734\n",
      "Epoch 777/1500\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.2355 - val_loss: 0.2633\n",
      "Epoch 778/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2328 - val_loss: 0.2604\n",
      "Epoch 779/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2304 - val_loss: 0.2865\n",
      "Epoch 780/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2676 - val_loss: 0.3224\n",
      "Epoch 781/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2675 - val_loss: 0.2792\n",
      "Epoch 782/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2602 - val_loss: 0.2806\n",
      "Epoch 783/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2532 - val_loss: 0.2805\n",
      "Epoch 784/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2451 - val_loss: 0.2764\n",
      "Epoch 785/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2442 - val_loss: 0.2709\n",
      "Epoch 786/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2370 - val_loss: 0.2816\n",
      "Epoch 787/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2500 - val_loss: 0.2864\n",
      "Epoch 788/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2446 - val_loss: 0.2641\n",
      "Epoch 789/1500\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.2416 - val_loss: 0.2598\n",
      "Epoch 790/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2368 - val_loss: 0.2564\n",
      "Epoch 791/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2372 - val_loss: 0.2603\n",
      "Epoch 792/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2370 - val_loss: 0.2699\n",
      "Epoch 793/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2393 - val_loss: 0.2519\n",
      "Epoch 794/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2371 - val_loss: 0.2513\n",
      "Epoch 795/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2321 - val_loss: 0.2502\n",
      "Epoch 796/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2290 - val_loss: 0.2487\n",
      "Epoch 797/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2286 - val_loss: 0.2599\n",
      "Epoch 798/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2285 - val_loss: 0.2505\n",
      "Epoch 799/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2258 - val_loss: 0.2496\n",
      "Epoch 800/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2246 - val_loss: 0.2497\n",
      "Epoch 801/1500\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.2245 - val_loss: 0.2464\n",
      "Epoch 802/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2239 - val_loss: 0.2469\n",
      "Epoch 803/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2244 - val_loss: 0.2483\n",
      "Epoch 804/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2601 - val_loss: 0.3136\n",
      "Epoch 805/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.3235 - val_loss: 0.3107\n",
      "Epoch 806/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2881 - val_loss: 0.3108\n",
      "Epoch 807/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2695 - val_loss: 0.3020\n",
      "Epoch 808/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2624 - val_loss: 0.2785\n",
      "Epoch 809/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2479 - val_loss: 0.2586\n",
      "Epoch 810/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2405 - val_loss: 0.2577\n",
      "Epoch 811/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2386 - val_loss: 0.2517\n",
      "Epoch 812/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2340 - val_loss: 0.2490\n",
      "Epoch 813/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2309 - val_loss: 0.2488\n",
      "Epoch 814/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2299 - val_loss: 0.2526\n",
      "Epoch 815/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2415 - val_loss: 0.2789\n",
      "Epoch 816/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2448 - val_loss: 0.2657\n",
      "Epoch 817/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2376 - val_loss: 0.2599\n",
      "Epoch 818/1500\n",
      "5/5 [==============================] - 1s 89ms/step - loss: 0.2346 - val_loss: 0.2512\n",
      "Epoch 819/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2312 - val_loss: 0.2423\n",
      "Epoch 820/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.2282 - val_loss: 0.2412\n",
      "Epoch 821/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2276 - val_loss: 0.2423\n",
      "Epoch 822/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2259 - val_loss: 0.2424\n",
      "Epoch 823/1500\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.2244 - val_loss: 0.2438\n",
      "Epoch 824/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2234 - val_loss: 0.2447\n",
      "Epoch 825/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2235 - val_loss: 0.2431\n",
      "Epoch 826/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2224 - val_loss: 0.2424\n",
      "Epoch 827/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2225 - val_loss: 0.2446\n",
      "Epoch 828/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2222 - val_loss: 0.2477\n",
      "Epoch 829/1500\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.2214 - val_loss: 0.2490\n",
      "Epoch 830/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2217 - val_loss: 0.2462\n",
      "Epoch 831/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2198 - val_loss: 0.2445\n",
      "Epoch 832/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2212 - val_loss: 0.2469\n",
      "Epoch 833/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2210 - val_loss: 0.2479\n",
      "Epoch 834/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.2241 - val_loss: 0.2482\n",
      "Epoch 835/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2240 - val_loss: 0.2456\n",
      "Epoch 836/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2220 - val_loss: 0.2432\n",
      "Epoch 837/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2206 - val_loss: 0.2415\n",
      "Epoch 838/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2204 - val_loss: 0.2426\n",
      "Epoch 839/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2209 - val_loss: 0.2445\n",
      "Epoch 840/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2234 - val_loss: 0.2661\n",
      "Epoch 841/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2277 - val_loss: 0.2430\n",
      "Epoch 842/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2232 - val_loss: 0.2395\n",
      "Epoch 843/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2205 - val_loss: 0.2469\n",
      "Epoch 844/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2189 - val_loss: 0.2418\n",
      "Epoch 845/1500\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.2194 - val_loss: 0.2462\n",
      "Epoch 846/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2212 - val_loss: 0.2480\n",
      "Epoch 847/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2187 - val_loss: 0.2481\n",
      "Epoch 848/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2182 - val_loss: 0.2728\n",
      "Epoch 849/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2776 - val_loss: 0.3081\n",
      "Epoch 850/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2713 - val_loss: 0.2981\n",
      "Epoch 851/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2930 - val_loss: 0.3867\n",
      "Epoch 852/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.3093 - val_loss: 0.2966\n",
      "Epoch 853/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2521 - val_loss: 0.2779\n",
      "Epoch 854/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2520 - val_loss: 0.2706\n",
      "Epoch 855/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2479 - val_loss: 0.2649\n",
      "Epoch 856/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2370 - val_loss: 0.2603\n",
      "Epoch 857/1500\n",
      "5/5 [==============================] - 1s 88ms/step - loss: 0.2308 - val_loss: 0.2573\n",
      "Epoch 858/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2287 - val_loss: 0.2575\n",
      "Epoch 859/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2278 - val_loss: 0.2563\n",
      "Epoch 860/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2268 - val_loss: 0.2599\n",
      "Epoch 861/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2248 - val_loss: 0.2569\n",
      "Epoch 862/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2231 - val_loss: 0.2540\n",
      "Epoch 863/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2246 - val_loss: 0.2581\n",
      "Epoch 864/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2352 - val_loss: 0.2752\n",
      "Epoch 865/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2423 - val_loss: 0.2788\n",
      "Epoch 866/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2374 - val_loss: 0.2609\n",
      "Epoch 867/1500\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.2332 - val_loss: 0.2630\n",
      "Epoch 868/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2279 - val_loss: 0.2496\n",
      "Epoch 869/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2240 - val_loss: 0.2422\n",
      "Epoch 870/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2212 - val_loss: 0.2508\n",
      "Epoch 871/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2305 - val_loss: 0.2649\n",
      "Epoch 872/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2350 - val_loss: 0.2589\n",
      "Epoch 873/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2341 - val_loss: 0.2621\n",
      "Epoch 874/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2357 - val_loss: 0.2474\n",
      "Epoch 875/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2281 - val_loss: 0.2605\n",
      "Epoch 876/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2342 - val_loss: 0.2599\n",
      "Epoch 877/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2324 - val_loss: 0.2434\n",
      "Epoch 878/1500\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.2277 - val_loss: 0.2532\n",
      "Epoch 879/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2251 - val_loss: 0.2396\n",
      "Epoch 880/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2227 - val_loss: 0.2433\n",
      "Epoch 881/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2209 - val_loss: 0.2479\n",
      "Epoch 882/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2212 - val_loss: 0.2453\n",
      "Epoch 883/1500\n",
      "5/5 [==============================] - 1s 98ms/step - loss: 0.2188 - val_loss: 0.2427\n",
      "Epoch 884/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2170 - val_loss: 0.2417\n",
      "Epoch 885/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2167 - val_loss: 0.2385\n",
      "Epoch 886/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2159 - val_loss: 0.2376\n",
      "Epoch 887/1500\n",
      "5/5 [==============================] - 1s 96ms/step - loss: 0.2148 - val_loss: 0.2365\n",
      "Epoch 888/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2140 - val_loss: 0.2356\n",
      "Epoch 889/1500\n",
      "5/5 [==============================] - 1s 95ms/step - loss: 0.2145 - val_loss: 0.2334\n",
      "Epoch 890/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2148 - val_loss: 0.2378\n",
      "Epoch 891/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2152 - val_loss: 0.2336\n",
      "Epoch 892/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2145 - val_loss: 0.2355\n",
      "Epoch 893/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2141 - val_loss: 0.2400\n",
      "Epoch 894/1500\n",
      "5/5 [==============================] - 1s 91ms/step - loss: 0.2158 - val_loss: 0.2348\n",
      "Epoch 895/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2137 - val_loss: 0.2369\n",
      "Epoch 896/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2137 - val_loss: 0.2363\n",
      "Epoch 897/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2120 - val_loss: 0.2385\n",
      "Epoch 898/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2126 - val_loss: 0.2425\n",
      "Epoch 899/1500\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.2139 - val_loss: 0.2457\n",
      "Epoch 900/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2147 - val_loss: 0.2421\n",
      "Epoch 901/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2261 - val_loss: 0.2480\n",
      "Epoch 902/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2204 - val_loss: 0.2403\n",
      "Epoch 903/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2166 - val_loss: 0.2428\n",
      "Epoch 904/1500\n",
      "5/5 [==============================] - 1s 91ms/step - loss: 0.2149 - val_loss: 0.2407\n",
      "Epoch 905/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2142 - val_loss: 0.2340\n",
      "Epoch 906/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2122 - val_loss: 0.2329\n",
      "Epoch 907/1500\n",
      "5/5 [==============================] - 1s 95ms/step - loss: 0.2124 - val_loss: 0.2339\n",
      "Epoch 908/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2123 - val_loss: 0.2536\n",
      "Epoch 909/1500\n",
      "5/5 [==============================] - 1s 95ms/step - loss: 0.2418 - val_loss: 0.2588\n",
      "Epoch 910/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2489 - val_loss: 0.3145\n",
      "Epoch 911/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2945 - val_loss: 0.2967\n",
      "Epoch 912/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2955 - val_loss: 0.3351\n",
      "Epoch 913/1500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.3083 - val_loss: 0.3201\n",
      "Epoch 914/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2990 - val_loss: 0.2989\n",
      "Epoch 915/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2851 - val_loss: 0.2899\n",
      "Epoch 916/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2730 - val_loss: 0.2716\n",
      "Epoch 917/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2561 - val_loss: 0.2650\n",
      "Epoch 918/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2473 - val_loss: 0.2571\n",
      "Epoch 919/1500\n",
      "5/5 [==============================] - 1s 90ms/step - loss: 0.2408 - val_loss: 0.2489\n",
      "Epoch 920/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2350 - val_loss: 0.2501\n",
      "Epoch 921/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2315 - val_loss: 0.2500\n",
      "Epoch 922/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2260 - val_loss: 0.2515\n",
      "Epoch 923/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2258 - val_loss: 0.2561\n",
      "Epoch 924/1500\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 0.2231 - val_loss: 0.2508\n",
      "Epoch 925/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2289 - val_loss: 0.2735\n",
      "Epoch 926/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2427 - val_loss: 0.2685\n",
      "Epoch 927/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2353 - val_loss: 0.2628\n",
      "Epoch 928/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2281 - val_loss: 0.2620\n",
      "Epoch 929/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2231 - val_loss: 0.2543\n",
      "Epoch 930/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2213 - val_loss: 0.2540\n",
      "Epoch 931/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2212 - val_loss: 0.2518\n",
      "Epoch 932/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2189 - val_loss: 0.2478\n",
      "Epoch 933/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2183 - val_loss: 0.2488\n",
      "Epoch 934/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2203 - val_loss: 0.2463\n",
      "Epoch 935/1500\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 0.2202 - val_loss: 0.2568\n",
      "Epoch 936/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2212 - val_loss: 0.2476\n",
      "Epoch 937/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2283 - val_loss: 0.2601\n",
      "Epoch 938/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2244 - val_loss: 0.2479\n",
      "Epoch 939/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2171 - val_loss: 0.2417\n",
      "Epoch 940/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.2157 - val_loss: 0.2400\n",
      "Epoch 941/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2137 - val_loss: 0.2349\n",
      "Epoch 942/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2134 - val_loss: 0.2359\n",
      "Epoch 943/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2129 - val_loss: 0.2404\n",
      "Epoch 944/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2126 - val_loss: 0.2429\n",
      "Epoch 945/1500\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.2189 - val_loss: 0.2606\n",
      "Epoch 946/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2258 - val_loss: 0.2540\n",
      "Epoch 947/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2199 - val_loss: 0.2382\n",
      "Epoch 948/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2214 - val_loss: 0.2427\n",
      "Epoch 949/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2198 - val_loss: 0.2527\n",
      "Epoch 950/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.2193 - val_loss: 0.2456\n",
      "Epoch 951/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2138 - val_loss: 0.2378\n",
      "Epoch 952/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2119 - val_loss: 0.2453\n",
      "Epoch 953/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2198 - val_loss: 0.2528\n",
      "Epoch 954/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2229 - val_loss: 0.2363\n",
      "Epoch 955/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2347 - val_loss: 0.2567\n",
      "Epoch 956/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2567 - val_loss: 0.3253\n",
      "Epoch 957/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2875 - val_loss: 0.3034\n",
      "Epoch 958/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2536 - val_loss: 0.2641\n",
      "Epoch 959/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2399 - val_loss: 0.2806\n",
      "Epoch 960/1500\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.2422 - val_loss: 0.2522\n",
      "Epoch 961/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2321 - val_loss: 0.2471\n",
      "Epoch 962/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2269 - val_loss: 0.2442\n",
      "Epoch 963/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2228 - val_loss: 0.2459\n",
      "Epoch 964/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2213 - val_loss: 0.2573\n",
      "Epoch 965/1500\n",
      "5/5 [==============================] - 1s 91ms/step - loss: 0.2232 - val_loss: 0.2565\n",
      "Epoch 966/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2238 - val_loss: 0.2475\n",
      "Epoch 967/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2170 - val_loss: 0.2482\n",
      "Epoch 968/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2164 - val_loss: 0.2438\n",
      "Epoch 969/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2124 - val_loss: 0.2441\n",
      "Epoch 970/1500\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.2106 - val_loss: 0.2380\n",
      "Epoch 971/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2120 - val_loss: 0.2430\n",
      "Epoch 972/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2221 - val_loss: 0.2675\n",
      "Epoch 973/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2229 - val_loss: 0.2469\n",
      "Epoch 974/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2166 - val_loss: 0.2533\n",
      "Epoch 975/1500\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.2148 - val_loss: 0.2444\n",
      "Epoch 976/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2132 - val_loss: 0.2422\n",
      "Epoch 977/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2111 - val_loss: 0.2389\n",
      "Epoch 978/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2198 - val_loss: 0.2588\n",
      "Epoch 979/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2437 - val_loss: 0.2578\n",
      "Epoch 980/1500\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.2303 - val_loss: 0.2528\n",
      "Epoch 981/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2199 - val_loss: 0.2457\n",
      "Epoch 982/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2146 - val_loss: 0.2349\n",
      "Epoch 983/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.2101 - val_loss: 0.2351\n",
      "Epoch 984/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2094 - val_loss: 0.2335\n",
      "Epoch 985/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2090 - val_loss: 0.2382\n",
      "Epoch 986/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2163 - val_loss: 0.2376\n",
      "Epoch 987/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2139 - val_loss: 0.2338\n",
      "Epoch 988/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.2156 - val_loss: 0.2290\n",
      "Epoch 989/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2254 - val_loss: 0.3161\n",
      "Epoch 990/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.3545 - val_loss: 0.3800\n",
      "Epoch 991/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2890 - val_loss: 0.2892\n",
      "Epoch 992/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2481 - val_loss: 0.2878\n",
      "Epoch 993/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2555 - val_loss: 0.2842\n",
      "Epoch 994/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2406 - val_loss: 0.2631\n",
      "Epoch 995/1500\n",
      "5/5 [==============================] - 1s 96ms/step - loss: 0.2284 - val_loss: 0.2611\n",
      "Epoch 996/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2230 - val_loss: 0.2603\n",
      "Epoch 997/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2199 - val_loss: 0.2476\n",
      "Epoch 998/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2184 - val_loss: 0.2457\n",
      "Epoch 999/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2156 - val_loss: 0.2522\n",
      "Epoch 1000/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2452 - val_loss: 0.2856\n",
      "Epoch 1001/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2311 - val_loss: 0.2566\n",
      "Epoch 1002/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2226 - val_loss: 0.2510\n",
      "Epoch 1003/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2185 - val_loss: 0.2420\n",
      "Epoch 1004/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2166 - val_loss: 0.2458\n",
      "Epoch 1005/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2280 - val_loss: 0.3238\n",
      "Epoch 1006/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.2540 - val_loss: 0.2750\n",
      "Epoch 1007/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2262 - val_loss: 0.2505\n",
      "Epoch 1008/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2181 - val_loss: 0.2482\n",
      "Epoch 1009/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2168 - val_loss: 0.2383\n",
      "Epoch 1010/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2138 - val_loss: 0.2355\n",
      "Epoch 1011/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2088 - val_loss: 0.2407\n",
      "Epoch 1012/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2098 - val_loss: 0.2410\n",
      "Epoch 1013/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2087 - val_loss: 0.2354\n",
      "Epoch 1014/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2071 - val_loss: 0.2359\n",
      "Epoch 1015/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2055 - val_loss: 0.2291\n",
      "Epoch 1016/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2076 - val_loss: 0.2301\n",
      "Epoch 1017/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2134 - val_loss: 0.2338\n",
      "Epoch 1018/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2120 - val_loss: 0.2332\n",
      "Epoch 1019/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2094 - val_loss: 0.2569\n",
      "Epoch 1020/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2431 - val_loss: 0.2760\n",
      "Epoch 1021/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2306 - val_loss: 0.2428\n",
      "Epoch 1022/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2165 - val_loss: 0.2415\n",
      "Epoch 1023/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2171 - val_loss: 0.2514\n",
      "Epoch 1024/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2232 - val_loss: 0.2587\n",
      "Epoch 1025/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2204 - val_loss: 0.2587\n",
      "Epoch 1026/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2498 - val_loss: 0.2731\n",
      "Epoch 1027/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2431 - val_loss: 0.2519\n",
      "Epoch 1028/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2298 - val_loss: 0.2340\n",
      "Epoch 1029/1500\n",
      "5/5 [==============================] - 1s 87ms/step - loss: 0.2209 - val_loss: 0.2415\n",
      "Epoch 1030/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2152 - val_loss: 0.2352\n",
      "Epoch 1031/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2118 - val_loss: 0.2339\n",
      "Epoch 1032/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2080 - val_loss: 0.2455\n",
      "Epoch 1033/1500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.2078 - val_loss: 0.2354\n",
      "Epoch 1034/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2049 - val_loss: 0.2274\n",
      "Epoch 1035/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2032 - val_loss: 0.2305\n",
      "Epoch 1036/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.2042 - val_loss: 0.2350\n",
      "Epoch 1037/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2042 - val_loss: 0.2307\n",
      "Epoch 1038/1500\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.2035 - val_loss: 0.2298\n",
      "Epoch 1039/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2054 - val_loss: 0.2304\n",
      "Epoch 1040/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2022 - val_loss: 0.2290\n",
      "Epoch 1041/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2011 - val_loss: 0.2289\n",
      "Epoch 1042/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.2007 - val_loss: 0.2300\n",
      "Epoch 1043/1500\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.1998 - val_loss: 0.2245\n",
      "Epoch 1044/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2076 - val_loss: 0.2651\n",
      "Epoch 1045/1500\n",
      "5/5 [==============================] - 1s 96ms/step - loss: 0.2588 - val_loss: 0.3186\n",
      "Epoch 1046/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2812 - val_loss: 0.2853\n",
      "Epoch 1047/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2368 - val_loss: 0.2809\n",
      "Epoch 1048/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.2394 - val_loss: 0.2703\n",
      "Epoch 1049/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2397 - val_loss: 0.2537\n",
      "Epoch 1050/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2275 - val_loss: 0.2530\n",
      "Epoch 1051/1500\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.2250 - val_loss: 0.2413\n",
      "Epoch 1052/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2131 - val_loss: 0.2372\n",
      "Epoch 1053/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2082 - val_loss: 0.2380\n",
      "Epoch 1054/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2228 - val_loss: 0.2735\n",
      "Epoch 1055/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2504 - val_loss: 0.2669\n",
      "Epoch 1056/1500\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.2320 - val_loss: 0.2557\n",
      "Epoch 1057/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2259 - val_loss: 0.2492\n",
      "Epoch 1058/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2238 - val_loss: 0.2733\n",
      "Epoch 1059/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2267 - val_loss: 0.2328\n",
      "Epoch 1060/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2132 - val_loss: 0.2255\n",
      "Epoch 1061/1500\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.2088 - val_loss: 0.2240\n",
      "Epoch 1062/1500\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.2119 - val_loss: 0.2212\n",
      "Epoch 1063/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2090 - val_loss: 0.2209\n",
      "Epoch 1064/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2038 - val_loss: 0.2267\n",
      "Epoch 1065/1500\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.2075 - val_loss: 0.2374\n",
      "Epoch 1066/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2173 - val_loss: 0.2268\n",
      "Epoch 1067/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2052 - val_loss: 0.2282\n",
      "Epoch 1068/1500\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.2044 - val_loss: 0.2338\n",
      "Epoch 1069/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2308 - val_loss: 0.2517\n",
      "Epoch 1070/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2295 - val_loss: 0.2227\n",
      "Epoch 1071/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2160 - val_loss: 0.2366\n",
      "Epoch 1072/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2156 - val_loss: 0.2279\n",
      "Epoch 1073/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2110 - val_loss: 0.2407\n",
      "Epoch 1074/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.2129 - val_loss: 0.2255\n",
      "Epoch 1075/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2048 - val_loss: 0.2270\n",
      "Epoch 1076/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2040 - val_loss: 0.2238\n",
      "Epoch 1077/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2014 - val_loss: 0.2209\n",
      "Epoch 1078/1500\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.1995 - val_loss: 0.2241\n",
      "Epoch 1079/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.1982 - val_loss: 0.2234\n",
      "Epoch 1080/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1976 - val_loss: 0.2239\n",
      "Epoch 1081/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2012 - val_loss: 0.2287\n",
      "Epoch 1082/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2011 - val_loss: 0.2283\n",
      "Epoch 1083/1500\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.1981 - val_loss: 0.2311\n",
      "Epoch 1084/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1994 - val_loss: 0.2328\n",
      "Epoch 1085/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1981 - val_loss: 0.2290\n",
      "Epoch 1086/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.1969 - val_loss: 0.2233\n",
      "Epoch 1087/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1969 - val_loss: 0.2251\n",
      "Epoch 1088/1500\n",
      "5/5 [==============================] - 1s 87ms/step - loss: 0.2069 - val_loss: 0.2310\n",
      "Epoch 1089/1500\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.2099 - val_loss: 0.2450\n",
      "Epoch 1090/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2124 - val_loss: 0.2325\n",
      "Epoch 1091/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2151 - val_loss: 0.2225\n",
      "Epoch 1092/1500\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.2041 - val_loss: 0.2222\n",
      "Epoch 1093/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1990 - val_loss: 0.2211\n",
      "Epoch 1094/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2003 - val_loss: 0.2251\n",
      "Epoch 1095/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.1977 - val_loss: 0.2217\n",
      "Epoch 1096/1500\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.1956 - val_loss: 0.2189\n",
      "Epoch 1097/1500\n",
      "5/5 [==============================] - 1s 92ms/step - loss: 0.1952 - val_loss: 0.2300\n",
      "Epoch 1098/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2074 - val_loss: 0.2381\n",
      "Epoch 1099/1500\n",
      "5/5 [==============================] - 1s 96ms/step - loss: 0.2005 - val_loss: 0.2307\n",
      "Epoch 1100/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.1986 - val_loss: 0.2277\n",
      "Epoch 1101/1500\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.1976 - val_loss: 0.2257\n",
      "Epoch 1102/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2013 - val_loss: 0.2346\n",
      "Epoch 1103/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2030 - val_loss: 0.2252\n",
      "Epoch 1104/1500\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.1979 - val_loss: 0.2183\n",
      "Epoch 1105/1500\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.1956 - val_loss: 0.2182\n",
      "Epoch 1106/1500\n",
      "5/5 [==============================] - 1s 96ms/step - loss: 0.1995 - val_loss: 0.2486\n",
      "Epoch 1107/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2672 - val_loss: 0.3320\n",
      "Epoch 1108/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2518 - val_loss: 0.2584\n",
      "Epoch 1109/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2235 - val_loss: 0.2631\n",
      "Epoch 1110/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.2169 - val_loss: 0.2477\n",
      "Epoch 1111/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2152 - val_loss: 0.2361\n",
      "Epoch 1112/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2061 - val_loss: 0.2348\n",
      "Epoch 1113/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2068 - val_loss: 0.2529\n",
      "Epoch 1114/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2130 - val_loss: 0.2517\n",
      "Epoch 1115/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2084 - val_loss: 0.2322\n",
      "Epoch 1116/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2042 - val_loss: 0.2263\n",
      "Epoch 1117/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2034 - val_loss: 0.2353\n",
      "Epoch 1118/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2016 - val_loss: 0.2349\n",
      "Epoch 1119/1500\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.1992 - val_loss: 0.2308\n",
      "Epoch 1120/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1970 - val_loss: 0.2281\n",
      "Epoch 1121/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1960 - val_loss: 0.2218\n",
      "Epoch 1122/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1947 - val_loss: 0.2224\n",
      "Epoch 1123/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.1938 - val_loss: 0.2221\n",
      "Epoch 1124/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1951 - val_loss: 0.2216\n",
      "Epoch 1125/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1946 - val_loss: 0.2251\n",
      "Epoch 1126/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1956 - val_loss: 0.2326\n",
      "Epoch 1127/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1960 - val_loss: 0.2255\n",
      "Epoch 1128/1500\n",
      "5/5 [==============================] - 1s 90ms/step - loss: 0.1973 - val_loss: 0.2319\n",
      "Epoch 1129/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2053 - val_loss: 0.2326\n",
      "Epoch 1130/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1987 - val_loss: 0.2354\n",
      "Epoch 1131/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1967 - val_loss: 0.2236\n",
      "Epoch 1132/1500\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.1941 - val_loss: 0.2169\n",
      "Epoch 1133/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2015 - val_loss: 0.2313\n",
      "Epoch 1134/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2035 - val_loss: 0.2288\n",
      "Epoch 1135/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1980 - val_loss: 0.2313\n",
      "Epoch 1136/1500\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.1948 - val_loss: 0.2346\n",
      "Epoch 1137/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2004 - val_loss: 0.2345\n",
      "Epoch 1138/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1997 - val_loss: 0.2416\n",
      "Epoch 1139/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1991 - val_loss: 0.2304\n",
      "Epoch 1140/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1949 - val_loss: 0.2421\n",
      "Epoch 1141/1500\n",
      "5/5 [==============================] - 1s 90ms/step - loss: 0.1930 - val_loss: 0.2280\n",
      "Epoch 1142/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1906 - val_loss: 0.2313\n",
      "Epoch 1143/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1924 - val_loss: 0.2290\n",
      "Epoch 1144/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1898 - val_loss: 0.2288\n",
      "Epoch 1145/1500\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.2060 - val_loss: 0.2300\n",
      "Epoch 1146/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2482 - val_loss: 0.2918\n",
      "Epoch 1147/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2718 - val_loss: 0.2525\n",
      "Epoch 1148/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2431 - val_loss: 0.2567\n",
      "Epoch 1149/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.2401 - val_loss: 0.2470\n",
      "Epoch 1150/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2307 - val_loss: 0.2450\n",
      "Epoch 1151/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2213 - val_loss: 0.2440\n",
      "Epoch 1152/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2156 - val_loss: 0.2353\n",
      "Epoch 1153/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2110 - val_loss: 0.2388\n",
      "Epoch 1154/1500\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.2079 - val_loss: 0.2379\n",
      "Epoch 1155/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2069 - val_loss: 0.2377\n",
      "Epoch 1156/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2129 - val_loss: 0.2700\n",
      "Epoch 1157/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2436 - val_loss: 0.2659\n",
      "Epoch 1158/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2285 - val_loss: 0.2447\n",
      "Epoch 1159/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2137 - val_loss: 0.2365\n",
      "Epoch 1160/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2048 - val_loss: 0.2357\n",
      "Epoch 1161/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.2016 - val_loss: 0.2286\n",
      "Epoch 1162/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1972 - val_loss: 0.2233\n",
      "Epoch 1163/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.1954 - val_loss: 0.2218\n",
      "Epoch 1164/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1953 - val_loss: 0.2220\n",
      "Epoch 1165/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1948 - val_loss: 0.2688\n",
      "Epoch 1166/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2457 - val_loss: 0.2981\n",
      "Epoch 1167/1500\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.2263 - val_loss: 0.2434\n",
      "Epoch 1168/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2112 - val_loss: 0.2433\n",
      "Epoch 1169/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2201 - val_loss: 0.2650\n",
      "Epoch 1170/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2261 - val_loss: 0.2467\n",
      "Epoch 1171/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2155 - val_loss: 0.2914\n",
      "Epoch 1172/1500\n",
      "5/5 [==============================] - 1s 87ms/step - loss: 0.2356 - val_loss: 0.2565\n",
      "Epoch 1173/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2190 - val_loss: 0.2471\n",
      "Epoch 1174/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2096 - val_loss: 0.2456\n",
      "Epoch 1175/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2267 - val_loss: 0.2736\n",
      "Epoch 1176/1500\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.2356 - val_loss: 0.2470\n",
      "Epoch 1177/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2231 - val_loss: 0.2448\n",
      "Epoch 1178/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2176 - val_loss: 0.2386\n",
      "Epoch 1179/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2137 - val_loss: 0.2549\n",
      "Epoch 1180/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2123 - val_loss: 0.2381\n",
      "Epoch 1181/1500\n",
      "5/5 [==============================] - 1s 93ms/step - loss: 0.2020 - val_loss: 0.2304\n",
      "Epoch 1182/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1978 - val_loss: 0.2341\n",
      "Epoch 1183/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1957 - val_loss: 0.2346\n",
      "Epoch 1184/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.1944 - val_loss: 0.2333\n",
      "Epoch 1185/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.1930 - val_loss: 0.2358\n",
      "Epoch 1186/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1915 - val_loss: 0.2329\n",
      "Epoch 1187/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.1907 - val_loss: 0.2322\n",
      "Epoch 1188/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.1890 - val_loss: 0.2265\n",
      "Epoch 1189/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1896 - val_loss: 0.2254\n",
      "Epoch 1190/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1905 - val_loss: 0.2308\n",
      "Epoch 1191/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1889 - val_loss: 0.2310\n",
      "Epoch 1192/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1887 - val_loss: 0.2305\n",
      "Epoch 1193/1500\n",
      "5/5 [==============================] - 1s 95ms/step - loss: 0.1880 - val_loss: 0.2325\n",
      "Epoch 1194/1500\n",
      "5/5 [==============================] - 1s 94ms/step - loss: 0.1876 - val_loss: 0.2317\n",
      "Epoch 1195/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1868 - val_loss: 0.2495\n",
      "Epoch 1196/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2090 - val_loss: 0.2734\n",
      "Epoch 1197/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2030 - val_loss: 0.2482\n",
      "Epoch 1198/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2034 - val_loss: 0.2498\n",
      "Epoch 1199/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2023 - val_loss: 0.2302\n",
      "Epoch 1200/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1996 - val_loss: 0.2366\n",
      "Epoch 1201/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2097 - val_loss: 0.2383\n",
      "Epoch 1202/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2051 - val_loss: 0.2258\n",
      "Epoch 1203/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1990 - val_loss: 0.2228\n",
      "Epoch 1204/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.1925 - val_loss: 0.2257\n",
      "Epoch 1205/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2118 - val_loss: 0.2578\n",
      "Epoch 1206/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2199 - val_loss: 0.2250\n",
      "Epoch 1207/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1995 - val_loss: 0.2245\n",
      "Epoch 1208/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1951 - val_loss: 0.2253\n",
      "Epoch 1209/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.1940 - val_loss: 0.2226\n",
      "Epoch 1210/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1969 - val_loss: 0.2454\n",
      "Epoch 1211/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2026 - val_loss: 0.2381\n",
      "Epoch 1212/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2203 - val_loss: 0.3243\n",
      "Epoch 1213/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2369 - val_loss: 0.2348\n",
      "Epoch 1214/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2070 - val_loss: 0.2326\n",
      "Epoch 1215/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.2062 - val_loss: 0.2295\n",
      "Epoch 1216/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2004 - val_loss: 0.2203\n",
      "Epoch 1217/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1962 - val_loss: 0.2213\n",
      "Epoch 1218/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1955 - val_loss: 0.2266\n",
      "Epoch 1219/1500\n",
      "5/5 [==============================] - 1s 89ms/step - loss: 0.1925 - val_loss: 0.2298\n",
      "Epoch 1220/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1938 - val_loss: 0.2439\n",
      "Epoch 1221/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1983 - val_loss: 0.2353\n",
      "Epoch 1222/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1904 - val_loss: 0.2286\n",
      "Epoch 1223/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.1874 - val_loss: 0.2268\n",
      "Epoch 1224/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1873 - val_loss: 0.2453\n",
      "Epoch 1225/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2344 - val_loss: 0.2745\n",
      "Epoch 1226/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2205 - val_loss: 0.2311\n",
      "Epoch 1227/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2057 - val_loss: 0.2328\n",
      "Epoch 1228/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1998 - val_loss: 0.2180\n",
      "Epoch 1229/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2027 - val_loss: 0.2414\n",
      "Epoch 1230/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2106 - val_loss: 0.2541\n",
      "Epoch 1231/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2053 - val_loss: 0.2475\n",
      "Epoch 1232/1500\n",
      "5/5 [==============================] - 1s 88ms/step - loss: 0.1957 - val_loss: 0.2296\n",
      "Epoch 1233/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1926 - val_loss: 0.2252\n",
      "Epoch 1234/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1989 - val_loss: 0.2253\n",
      "Epoch 1235/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1917 - val_loss: 0.2233\n",
      "Epoch 1236/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.1900 - val_loss: 0.2257\n",
      "Epoch 1237/1500\n",
      "5/5 [==============================] - 1s 89ms/step - loss: 0.1868 - val_loss: 0.2220\n",
      "Epoch 1238/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1853 - val_loss: 0.2210\n",
      "Epoch 1239/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1852 - val_loss: 0.2226\n",
      "Epoch 1240/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.1839 - val_loss: 0.2271\n",
      "Epoch 1241/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1836 - val_loss: 0.2272\n",
      "Epoch 1242/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1835 - val_loss: 0.2277\n",
      "Epoch 1243/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1829 - val_loss: 0.2254\n",
      "Epoch 1244/1500\n",
      "5/5 [==============================] - 1s 89ms/step - loss: 0.1828 - val_loss: 0.2315\n",
      "Epoch 1245/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1832 - val_loss: 0.2298\n",
      "Epoch 1246/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1825 - val_loss: 0.2346\n",
      "Epoch 1247/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2033 - val_loss: 0.2396\n",
      "Epoch 1248/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2026 - val_loss: 0.2333\n",
      "Epoch 1249/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1987 - val_loss: 0.2304\n",
      "Epoch 1250/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1969 - val_loss: 0.2194\n",
      "Epoch 1251/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1897 - val_loss: 0.2214\n",
      "Epoch 1252/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.1853 - val_loss: 0.2217\n",
      "Epoch 1253/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1851 - val_loss: 0.2234\n",
      "Epoch 1254/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1843 - val_loss: 0.2393\n",
      "Epoch 1255/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2192 - val_loss: 0.2861\n",
      "Epoch 1256/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.2316 - val_loss: 0.2198\n",
      "Epoch 1257/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2023 - val_loss: 0.2243\n",
      "Epoch 1258/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.1986 - val_loss: 0.2390\n",
      "Epoch 1259/1500\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.1982 - val_loss: 0.2424\n",
      "Epoch 1260/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1934 - val_loss: 0.2344\n",
      "Epoch 1261/1500\n",
      "5/5 [==============================] - 1s 93ms/step - loss: 0.1897 - val_loss: 0.2244\n",
      "Epoch 1262/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1948 - val_loss: 0.2351\n",
      "Epoch 1263/1500\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.2013 - val_loss: 0.2775\n",
      "Epoch 1264/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2102 - val_loss: 0.2443\n",
      "Epoch 1265/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1920 - val_loss: 0.2338\n",
      "Epoch 1266/1500\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1915 - val_loss: 0.2353\n",
      "Epoch 1267/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1887 - val_loss: 0.2286\n",
      "Epoch 1268/1500\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.1851 - val_loss: 0.2271\n",
      "Epoch 1269/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.1836 - val_loss: 0.2214\n",
      "Epoch 1270/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1826 - val_loss: 0.2243\n",
      "Epoch 1271/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.1824 - val_loss: 0.2350\n",
      "Epoch 1272/1500\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 0.1834 - val_loss: 0.2311\n",
      "Epoch 1273/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1818 - val_loss: 0.2272\n",
      "Epoch 1274/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1814 - val_loss: 0.2264\n",
      "Epoch 1275/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1801 - val_loss: 0.2247\n",
      "Epoch 1276/1500\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.1800 - val_loss: 0.2243\n",
      "Epoch 1277/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1795 - val_loss: 0.2236\n",
      "Epoch 1278/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1791 - val_loss: 0.2255\n",
      "Epoch 1279/1500\n",
      "5/5 [==============================] - 1s 90ms/step - loss: 0.1795 - val_loss: 0.2278\n",
      "Epoch 1280/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.1794 - val_loss: 0.2277\n",
      "Epoch 1281/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.1799 - val_loss: 0.2241\n",
      "Epoch 1282/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1800 - val_loss: 0.2350\n",
      "Epoch 1283/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1792 - val_loss: 0.2276\n",
      "Epoch 1284/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.1790 - val_loss: 0.2239\n",
      "Epoch 1285/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1784 - val_loss: 0.2200\n",
      "Epoch 1286/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1780 - val_loss: 0.2225\n",
      "Epoch 1287/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.1777 - val_loss: 0.2276\n",
      "Epoch 1288/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1770 - val_loss: 0.2314\n",
      "Epoch 1289/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1781 - val_loss: 0.2340\n",
      "Epoch 1290/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1793 - val_loss: 0.2262\n",
      "Epoch 1291/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1790 - val_loss: 0.2222\n",
      "Epoch 1292/1500\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.1844 - val_loss: 0.2286\n",
      "Epoch 1293/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1832 - val_loss: 0.2445\n",
      "Epoch 1294/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1836 - val_loss: 0.2432\n",
      "Epoch 1295/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1883 - val_loss: 0.2288\n",
      "Epoch 1296/1500\n",
      "5/5 [==============================] - 1s 93ms/step - loss: 0.1889 - val_loss: 0.2288\n",
      "Epoch 1297/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1856 - val_loss: 0.2416\n",
      "Epoch 1298/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1830 - val_loss: 0.2725\n",
      "Epoch 1299/1500\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.2636 - val_loss: 0.2797\n",
      "Epoch 1300/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2272 - val_loss: 0.2600\n",
      "Epoch 1301/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2225 - val_loss: 0.2611\n",
      "Epoch 1302/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2077 - val_loss: 0.2463\n",
      "Epoch 1303/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2230 - val_loss: 0.2507\n",
      "Epoch 1304/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2101 - val_loss: 0.2495\n",
      "Epoch 1305/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2051 - val_loss: 0.2423\n",
      "Epoch 1306/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1982 - val_loss: 0.2336\n",
      "Epoch 1307/1500\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.1944 - val_loss: 0.2357\n",
      "Epoch 1308/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1935 - val_loss: 0.2337\n",
      "Epoch 1309/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.1908 - val_loss: 0.2386\n",
      "Epoch 1310/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2187 - val_loss: 0.2631\n",
      "Epoch 1311/1500\n",
      "5/5 [==============================] - 1s 94ms/step - loss: 0.2243 - val_loss: 0.2317\n",
      "Epoch 1312/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2099 - val_loss: 0.2324\n",
      "Epoch 1313/1500\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.2039 - val_loss: 0.2249\n",
      "Epoch 1314/1500\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.1941 - val_loss: 0.2286\n",
      "Epoch 1315/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.1929 - val_loss: 0.2269\n",
      "Epoch 1316/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1884 - val_loss: 0.2322\n",
      "Epoch 1317/1500\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.1868 - val_loss: 0.2295\n",
      "Epoch 1318/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1847 - val_loss: 0.2244\n",
      "Epoch 1319/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1845 - val_loss: 0.2188\n",
      "Epoch 1320/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1841 - val_loss: 0.2184\n",
      "Epoch 1321/1500\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2001 - val_loss: 0.2422\n",
      "Epoch 1322/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2123 - val_loss: 0.2451\n",
      "Epoch 1323/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2011 - val_loss: 0.2436\n",
      "Epoch 1324/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1916 - val_loss: 0.2372\n",
      "Epoch 1325/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1889 - val_loss: 0.2352\n",
      "Epoch 1326/1500\n",
      "5/5 [==============================] - 1s 87ms/step - loss: 0.1863 - val_loss: 0.2323\n",
      "Epoch 1327/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1834 - val_loss: 0.2375\n",
      "Epoch 1328/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1819 - val_loss: 0.2346\n",
      "Epoch 1329/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1809 - val_loss: 0.2308\n",
      "Epoch 1330/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.1798 - val_loss: 0.2313\n",
      "Epoch 1331/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1804 - val_loss: 0.2344\n",
      "Epoch 1332/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1791 - val_loss: 0.2402\n",
      "Epoch 1333/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1851 - val_loss: 0.2408\n",
      "Epoch 1334/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1896 - val_loss: 0.2328\n",
      "Epoch 1335/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1965 - val_loss: 0.2352\n",
      "Epoch 1336/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1970 - val_loss: 0.2414\n",
      "Epoch 1337/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.1925 - val_loss: 0.2537\n",
      "Epoch 1338/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1871 - val_loss: 0.2367\n",
      "Epoch 1339/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1849 - val_loss: 0.2359\n",
      "Epoch 1340/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1836 - val_loss: 0.2331\n",
      "Epoch 1341/1500\n",
      "5/5 [==============================] - 1s 90ms/step - loss: 0.1829 - val_loss: 0.2364\n",
      "Epoch 1342/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1797 - val_loss: 0.2332\n",
      "Epoch 1343/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1812 - val_loss: 0.2266\n",
      "Epoch 1344/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.1785 - val_loss: 0.2289\n",
      "Epoch 1345/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1766 - val_loss: 0.2308\n",
      "Epoch 1346/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2075 - val_loss: 0.2369\n",
      "Epoch 1347/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.2310 - val_loss: 0.2850\n",
      "Epoch 1348/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.2433 - val_loss: 0.3374\n",
      "Epoch 1349/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.3027 - val_loss: 0.3328\n",
      "Epoch 1350/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2733 - val_loss: 0.3095\n",
      "Epoch 1351/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2502 - val_loss: 0.2889\n",
      "Epoch 1352/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.2326 - val_loss: 0.2652\n",
      "Epoch 1353/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2260 - val_loss: 0.2610\n",
      "Epoch 1354/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2234 - val_loss: 0.2549\n",
      "Epoch 1355/1500\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.2205 - val_loss: 0.2495\n",
      "Epoch 1356/1500\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.2143 - val_loss: 0.2462\n",
      "Epoch 1357/1500\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.2096 - val_loss: 0.2494\n",
      "Epoch 1358/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2137 - val_loss: 0.2508\n",
      "Epoch 1359/1500\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.2111 - val_loss: 0.2472\n",
      "Epoch 1360/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.2089 - val_loss: 0.2491\n",
      "Epoch 1361/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2082 - val_loss: 0.2459\n",
      "Epoch 1362/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.2048 - val_loss: 0.2397\n",
      "Epoch 1363/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2004 - val_loss: 0.2363\n",
      "Epoch 1364/1500\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.1962 - val_loss: 0.2390\n",
      "Epoch 1365/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1942 - val_loss: 0.2365\n",
      "Epoch 1366/1500\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.1934 - val_loss: 0.2385\n",
      "Epoch 1367/1500\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1918 - val_loss: 0.2328\n",
      "Epoch 1368/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.1903 - val_loss: 0.2363\n",
      "Epoch 1369/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1903 - val_loss: 0.2369\n",
      "Epoch 1370/1500\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 0.1884 - val_loss: 0.2278\n",
      "Epoch 1371/1500\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 0.1901 - val_loss: 0.2200\n",
      "Epoch 1372/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.1951 - val_loss: 0.2173\n",
      "Epoch 1373/1500\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.1944 - val_loss: 0.2204\n",
      "Epoch 1374/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1914 - val_loss: 0.2272\n",
      "Epoch 1375/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.1871 - val_loss: 0.2296\n",
      "Epoch 1376/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.1870 - val_loss: 0.2294\n",
      "Epoch 1377/1500\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.1848 - val_loss: 0.2287\n",
      "Epoch 1378/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1845 - val_loss: 0.2215\n",
      "Epoch 1379/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1828 - val_loss: 0.2258\n",
      "Epoch 1380/1500\n",
      "5/5 [==============================] - 1s 96ms/step - loss: 0.1858 - val_loss: 0.2337\n",
      "Epoch 1381/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1843 - val_loss: 0.2193\n",
      "Epoch 1382/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.1831 - val_loss: 0.2128\n",
      "Epoch 1383/1500\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.1826 - val_loss: 0.2231\n",
      "Epoch 1384/1500\n",
      "5/5 [==============================] - 1s 91ms/step - loss: 0.1839 - val_loss: 0.2370\n",
      "Epoch 1385/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1869 - val_loss: 0.2283\n",
      "Epoch 1386/1500\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.1812 - val_loss: 0.2165\n",
      "Epoch 1387/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.1820 - val_loss: 0.2243\n",
      "Epoch 1388/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.1818 - val_loss: 0.2197\n",
      "Epoch 1389/1500\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.1800 - val_loss: 0.2206\n",
      "Epoch 1390/1500\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.1824 - val_loss: 0.2320\n",
      "Epoch 1391/1500\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.1818 - val_loss: 0.2297\n",
      "Epoch 1392/1500\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.1820 - val_loss: 0.2249\n",
      "Epoch 1393/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1836 - val_loss: 0.2238\n",
      "Epoch 1394/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1817 - val_loss: 0.2247\n",
      "Epoch 1395/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1778 - val_loss: 0.2169\n",
      "Epoch 1396/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.1771 - val_loss: 0.2236\n",
      "Epoch 1397/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1767 - val_loss: 0.2241\n",
      "Epoch 1398/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1752 - val_loss: 0.2229\n",
      "Epoch 1399/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1821 - val_loss: 0.2274\n",
      "Epoch 1400/1500\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.1866 - val_loss: 0.2580\n",
      "Epoch 1401/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2213 - val_loss: 0.3639\n",
      "Epoch 1402/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2472 - val_loss: 0.2635\n",
      "Epoch 1403/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.2015 - val_loss: 0.2401\n",
      "Epoch 1404/1500\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.1988 - val_loss: 0.2292\n",
      "Epoch 1405/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1916 - val_loss: 0.2289\n",
      "Epoch 1406/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1888 - val_loss: 0.2282\n",
      "Epoch 1407/1500\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.1847 - val_loss: 0.2276\n",
      "Epoch 1408/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.1814 - val_loss: 0.2351\n",
      "Epoch 1409/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1890 - val_loss: 0.2618\n",
      "Epoch 1410/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1989 - val_loss: 0.2438\n",
      "Epoch 1411/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1869 - val_loss: 0.2256\n",
      "Epoch 1412/1500\n",
      "5/5 [==============================] - 1s 88ms/step - loss: 0.1821 - val_loss: 0.2240\n",
      "Epoch 1413/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1807 - val_loss: 0.2232\n",
      "Epoch 1414/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1794 - val_loss: 0.2290\n",
      "Epoch 1415/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.1806 - val_loss: 0.2239\n",
      "Epoch 1416/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1796 - val_loss: 0.2248\n",
      "Epoch 1417/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1783 - val_loss: 0.2272\n",
      "Epoch 1418/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1762 - val_loss: 0.2226\n",
      "Epoch 1419/1500\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.1746 - val_loss: 0.2203\n",
      "Epoch 1420/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1765 - val_loss: 0.2320\n",
      "Epoch 1421/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2132 - val_loss: 0.2741\n",
      "Epoch 1422/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2005 - val_loss: 0.2615\n",
      "Epoch 1423/1500\n",
      "5/5 [==============================] - 1s 88ms/step - loss: 0.2255 - val_loss: 0.2573\n",
      "Epoch 1424/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1966 - val_loss: 0.2669\n",
      "Epoch 1425/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1998 - val_loss: 0.2357\n",
      "Epoch 1426/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.1970 - val_loss: 0.2302\n",
      "Epoch 1427/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1875 - val_loss: 0.2252\n",
      "Epoch 1428/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.1821 - val_loss: 0.2242\n",
      "Epoch 1429/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1812 - val_loss: 0.2264\n",
      "Epoch 1430/1500\n",
      "5/5 [==============================] - 1s 87ms/step - loss: 0.1786 - val_loss: 0.2370\n",
      "Epoch 1431/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1925 - val_loss: 0.2899\n",
      "Epoch 1432/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2082 - val_loss: 0.2639\n",
      "Epoch 1433/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1988 - val_loss: 0.2346\n",
      "Epoch 1434/1500\n",
      "5/5 [==============================] - 1s 87ms/step - loss: 0.1848 - val_loss: 0.2257\n",
      "Epoch 1435/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1955 - val_loss: 0.2389\n",
      "Epoch 1436/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2002 - val_loss: 0.2348\n",
      "Epoch 1437/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1884 - val_loss: 0.2341\n",
      "Epoch 1438/1500\n",
      "5/5 [==============================] - 1s 88ms/step - loss: 0.1831 - val_loss: 0.2260\n",
      "Epoch 1439/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1779 - val_loss: 0.2203\n",
      "Epoch 1440/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1782 - val_loss: 0.2145\n",
      "Epoch 1441/1500\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.1774 - val_loss: 0.2146\n",
      "Epoch 1442/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1784 - val_loss: 0.2183\n",
      "Epoch 1443/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1780 - val_loss: 0.2203\n",
      "Epoch 1444/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1767 - val_loss: 0.2157\n",
      "Epoch 1445/1500\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.1739 - val_loss: 0.2199\n",
      "Epoch 1446/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1756 - val_loss: 0.2183\n",
      "Epoch 1447/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1748 - val_loss: 0.2220\n",
      "Epoch 1448/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1766 - val_loss: 0.2175\n",
      "Epoch 1449/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.1734 - val_loss: 0.2252\n",
      "Epoch 1450/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1746 - val_loss: 0.2220\n",
      "Epoch 1451/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1730 - val_loss: 0.2167\n",
      "Epoch 1452/1500\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.1757 - val_loss: 0.2170\n",
      "Epoch 1453/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.1772 - val_loss: 0.2148\n",
      "Epoch 1454/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1729 - val_loss: 0.2207\n",
      "Epoch 1455/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1750 - val_loss: 0.2218\n",
      "Epoch 1456/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.1732 - val_loss: 0.2135\n",
      "Epoch 1457/1500\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1718 - val_loss: 0.2166\n",
      "Epoch 1458/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1708 - val_loss: 0.2245\n",
      "Epoch 1459/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1909 - val_loss: 0.2237\n",
      "Epoch 1460/1500\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.2196 - val_loss: 0.2814\n",
      "Epoch 1461/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.2248 - val_loss: 0.2405\n",
      "Epoch 1462/1500\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2009 - val_loss: 0.2283\n",
      "Epoch 1463/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.2024 - val_loss: 0.2361\n",
      "Epoch 1464/1500\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.1921 - val_loss: 0.2278\n",
      "Epoch 1465/1500\n",
      "5/5 [==============================] - 1s 91ms/step - loss: 0.1862 - val_loss: 0.2253\n",
      "Epoch 1466/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1828 - val_loss: 0.2186\n",
      "Epoch 1467/1500\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.1784 - val_loss: 0.2232\n",
      "Epoch 1468/1500\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.1771 - val_loss: 0.2249\n",
      "Epoch 1469/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1755 - val_loss: 0.2235\n",
      "Epoch 1470/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.1739 - val_loss: 0.2199\n",
      "Epoch 1471/1500\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.1733 - val_loss: 0.2175\n",
      "Epoch 1472/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1776 - val_loss: 0.2169\n",
      "Epoch 1473/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1798 - val_loss: 0.2096\n",
      "Epoch 1474/1500\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.1732 - val_loss: 0.2274\n",
      "Epoch 1475/1500\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1755 - val_loss: 0.2309\n",
      "Epoch 1476/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.1743 - val_loss: 0.2190\n",
      "Epoch 1477/1500\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.1784 - val_loss: 0.2134\n",
      "Epoch 1478/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1819 - val_loss: 0.2167\n",
      "Epoch 1479/1500\n",
      "5/5 [==============================] - 1s 89ms/step - loss: 0.1784 - val_loss: 0.2266\n",
      "Epoch 1480/1500\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.1756 - val_loss: 0.2362\n",
      "Epoch 1481/1500\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.1746 - val_loss: 0.2257\n",
      "Epoch 1482/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1719 - val_loss: 0.2248\n",
      "Epoch 1483/1500\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1723 - val_loss: 0.2192\n",
      "Epoch 1484/1500\n",
      "5/5 [==============================] - 1s 91ms/step - loss: 0.1714 - val_loss: 0.2164\n",
      "Epoch 1485/1500\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1716 - val_loss: 0.2188\n",
      "Epoch 1486/1500\n",
      "5/5 [==============================] - 1s 92ms/step - loss: 0.1707 - val_loss: 0.2193\n",
      "Epoch 1487/1500\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.1684 - val_loss: 0.2195\n",
      "Epoch 1488/1500\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1697 - val_loss: 0.2249\n",
      "Epoch 1489/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1686 - val_loss: 0.2165\n",
      "Epoch 1490/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1675 - val_loss: 0.2149\n",
      "Epoch 1491/1500\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.1674 - val_loss: 0.2166\n",
      "Epoch 1492/1500\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.1668 - val_loss: 0.2162\n",
      "Epoch 1493/1500\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.1675 - val_loss: 0.2229\n",
      "Epoch 1494/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1688 - val_loss: 0.2276\n",
      "Epoch 1495/1500\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 0.1700 - val_loss: 0.2312\n",
      "Epoch 1496/1500\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1693 - val_loss: 0.2218\n",
      "Epoch 1497/1500\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.1707 - val_loss: 0.2250\n",
      "Epoch 1498/1500\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.1693 - val_loss: 0.2216\n",
      "Epoch 1499/1500\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.1667 - val_loss: 0.2187\n",
      "Epoch 1500/1500\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.1696 - val_loss: 0.2292\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.2096\n",
      "0.20962901413440704\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # 入力層\n",
    "    input = layers.Input(shape = train_x.shape[1:])\n",
    "\n",
    "    # 中間層\n",
    "    x = layers.LSTM(units = 256, activation = \"relu\", return_sequences = True)(input)\n",
    "    x = layers.LSTM(units = 256, activation = \"relu\", return_sequences = True)(x)\n",
    "    x = layers.LSTM(units = 128, activation = \"relu\", return_sequences = True)(x)\n",
    "\n",
    "    # 中間層最後のreturn_sequencesは、Falseにする\n",
    "    # 出力は一つなので、中間層の最後で次元数を落として出力できるようにしている\n",
    "    x = layers.LSTM(units = 128, activation = \"relu\", return_sequences = True)(x)\n",
    "\n",
    "    # 出力層 全結合で、活性化関数は回帰にして出力している\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "# ミニバッチ学習 \n",
    "batch_size = len(train_x) // 4\n",
    "# モデルの定義をしている\n",
    "model = build_model()\n",
    "                # 損失関数MSE\n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "\n",
    "# モデル構造の出力\n",
    "model.summary()\n",
    "\n",
    "# val_lossが一番低いモデルを保存している\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "# 学習データ、テストデータ、バッチサイズ、エポック、保存ポイントの設定\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = batch_size, epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを継続したまま、エポックを続けることができる     \n",
    "model.compile(loss = losses.MeanSquaredError(),\n",
    "              # 最適化アルゴリズムAdam    学習率は0.0001に設定している\n",
    "              optimizer = optimizers.Adam(learning_rate = 0.0001))\n",
    "\n",
    "# モデル構造の出力\n",
    "model.summary()\n",
    "\n",
    "# val_lossが一番低いモデルを保存している\n",
    "mcp = callbacks.ModelCheckpoint(filepath = \"model.keras\",\n",
    "                                monitor = \"val_loss\",\n",
    "                                mode = \"min\",\n",
    "                                save_best_only = True)\n",
    "# 学習データ、テストデータ、バッチサイズ、エポック、保存ポイントの設定\n",
    "history = model.fit(x = train_x, y = train_y, batch_size = batch_size, epochs = 1500,\n",
    "                    validation_data = (test_x, test_y), callbacks = mcp)\n",
    "\n",
    "model = models.load_model(\"model.keras\")\n",
    "print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8957c7a850>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上で作ったmodelを使ってtestデータを使って予測をさせている\n",
    "p = model.predict(test_x)\n",
    "\n",
    "# 予測をした結果を、左から月ごとにソートを行いグラフにしている\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "tmp = list()\n",
    "for TI in test_index:\n",
    "    # インデックス番号　+　SPLIT_SIZEすることで、ランダムに抜き出した、データの年と月を出している\n",
    "    tmp.append(f'{int(csgo_datas[TI + SPLIT_SIZE][\"year\"])}/{int(csgo_datas[TI + SPLIT_SIZE][\"month\"]):02}')\n",
    "# 月を降順にソートする\n",
    "tmp = list(sorted([[T, i] for i, T in enumerate(tmp)], key = lambda x : x[0]))\n",
    "\n",
    "for i, (_, I) in enumerate(tmp):\n",
    "    ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\")\n",
    "    ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\")\n",
    "\n",
    "ax.scatter(i, p[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"red\", label = \"pred\")\n",
    "ax.scatter(i, test_y[tmp[I][1]][-1] * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"], color = \"blue\", label = \"answer\")\n",
    "ax.set_xticks(range(len(p)))\n",
    "ax.set_xticklabels([T[0] for T in tmp])\n",
    "ax.set_ylabel(\"gain(%)\")\n",
    "ax.set_xlabel(\"month\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "2.0375919342041016\n",
      "0.4616570472717285\n",
      "1.20890474319458\n",
      "0.3563652038574219\n",
      "0.27797794342041016\n",
      "0.3665475845336914\n",
      "0.022635087370872498\n",
      "0.09368133544921875\n",
      "0.06367743015289307\n",
      "0.5813674926757812\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "SINGLE_SE = list()\n",
    "\n",
    "def single_sa(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        c = a - b\n",
    "        output.append(float(abs(c[0])))\n",
    "\n",
    "    return output\n",
    "\n",
    "# 標準化を元の縮尺に戻す関数\n",
    "def decode(x):\n",
    "    return x * csgo_std_items[\"gain_percent\"] + csgo_mean_items[\"gain_percent\"]\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    SINGLE_SE.append(single_sa(decode(x), decode(y)))\n",
    "    print(SINGLE_SE[-1][-1])\n",
    "    \n",
    "# SINGLE_SE[0]\n",
    "    \n",
    "min_SINGLE_SE = list()\n",
    "max_SINGLE_SE = list()\n",
    "\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    decode_min = min(SINGLE_SE[i])\n",
    "    decode_min_index = SINGLE_SE[i].index(min(SINGLE_SE[i]))\n",
    "    decode_max = max(SINGLE_SE[i])\n",
    "    decode_max_index = SINGLE_SE[i].index(max(SINGLE_SE[i]))\n",
    "    min_SINGLE_SE.append([decode_min, decode_min_index])\n",
    "    max_SINGLE_SE.append([decode_max, decode_max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 12番目 0.073784%, max : 2番目 21.677%\n",
      "min : 17番目 0.16996%, max : 1番目 19.006%\n",
      "min : 17番目 0.010042%, max : 0番目 18.46%\n",
      "min : 7番目 0.030151%, max : 0番目 6.3995%\n",
      "min : 17番目 0.19062%, max : 4番目 13.154%\n",
      "min : 14番目 0.11348%, max : 1番目 32.907%\n",
      "min : 23番目 0.022635%, max : 4番目 30.822%\n",
      "min : 11番目 0.081562%, max : 1番目 59.107%\n",
      "min : 1番目 0.028246%, max : 0番目 16.003%\n",
      "min : 21番目 0.20636%, max : 3番目 18.315%\n"
     ]
    }
   ],
   "source": [
    "# 各入力データの1〜24(SPILT_SIZE)の中の最大、最小(上からグラフのソート順になってる)\n",
    "for a ,b in zip(min_SINGLE_SE,max_SINGLE_SE):\n",
    "    print(f\"min : {a[1]}番目 {a[0]:.5}%, max : {b[1]}番目 {b[0]:.5}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "# 各検証データの予測と正解のMSEをとる\n",
    "def mse(x, y):\n",
    "    tmp = 0.0\n",
    "    for a, b in zip(x, y):\n",
    "        tmp += (a - b) ** 2\n",
    "    tmp /= len(x)\n",
    "    return tmp\n",
    "# 各検証データに含まれるNヶ月の各予測と正解の二乗和誤差を算出する\n",
    "def single_se(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        output.append((a - b) ** 2)\n",
    "\n",
    "    return output\n",
    "\n",
    "MSE = []\n",
    "SINGLE_SE = []\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    MSE.append(mse(x, y))\n",
    "    SINGLE_SE.append(single_se(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSEの最小値：[0.02139824]、最大値：[0.6766705]\n",
      "\n",
      "0個目の検証用データにおけるSingle MSEの最小値：[2.0960215e-05]、最大値：[1.8091338]\n",
      "1個目の検証用データにおけるSingle MSEの最小値：[0.00011121]、最大値：[1.3907962]\n",
      "2個目の検証用データにおけるSingle MSEの最小値：[3.8826227e-07]、最大値：[1.3120136]\n",
      "3個目の検証用データにおけるSingle MSEの最小値：[3.5001567e-06]、最大値：[0.15767992]\n",
      "4個目の検証用データにおけるSingle MSEの最小値：[0.00013991]、最大値：[0.6662126]\n",
      "5個目の検証用データにおけるSingle MSEの最小値：[4.958292e-05]、最大値：[4.169263]\n",
      "6個目の検証用データにおけるSingle MSEの最小値：[1.9725198e-06]、最大値：[3.657662]\n",
      "7個目の検証用データにおけるSingle MSEの最小値：[2.5614028e-05]、最大値：[13.451243]\n",
      "8個目の検証用データにおけるSingle MSEの最小値：[3.0716592e-06]、最大値：[0.9860603]\n",
      "9個目の検証用データにおけるSingle MSEの最小値：[0.00016395]、最大値：[1.2914829]\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSEの最小値：{min(MSE)}、最大値：{max(MSE)}\")\n",
    "print()\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    print(f\"{i}個目の検証用データにおけるSingle MSEの最小値：{min(SINGLE_SE[i])}、最大値：{max(SINGLE_SE[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "pre = model.predict(test_x)\n",
    "ans = test_y\n",
    "\n",
    "# 各検証データの予測と正解のMSEをとる\n",
    "def mse(x, y):\n",
    "    tmp = 0.0\n",
    "    for a, b in zip(x, y):\n",
    "        tmp += (a - b) ** 2\n",
    "    tmp /= len(x)\n",
    "    return tmp\n",
    "# 各検証データに含まれるNヶ月の各予測と正解の二乗和誤差を算出する\n",
    "def single_se(x, y):\n",
    "    output = []\n",
    "    for a, b in zip(x, y):\n",
    "        output.append((a - b) ** 2)\n",
    "\n",
    "    return output\n",
    "\n",
    "MSE = []\n",
    "SINGLE_SE = []\n",
    "\n",
    "for x, y in zip(pre, ans):\n",
    "    MSE.append(mse(x, y))\n",
    "    SINGLE_SE.append(single_se(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSEの最小値：[0.02139824]、最大値：[0.6766705]\n",
      "\n",
      "0個目の検証用データにおけるSingle MSEの最小値：[2.0960215e-05]、最大値：[1.8091338]\n",
      "1個目の検証用データにおけるSingle MSEの最小値：[0.00011121]、最大値：[1.3907962]\n",
      "2個目の検証用データにおけるSingle MSEの最小値：[3.8826227e-07]、最大値：[1.3120136]\n",
      "3個目の検証用データにおけるSingle MSEの最小値：[3.5001567e-06]、最大値：[0.15767992]\n",
      "4個目の検証用データにおけるSingle MSEの最小値：[0.00013991]、最大値：[0.6662126]\n",
      "5個目の検証用データにおけるSingle MSEの最小値：[4.958292e-05]、最大値：[4.169263]\n",
      "6個目の検証用データにおけるSingle MSEの最小値：[1.9725198e-06]、最大値：[3.657662]\n",
      "7個目の検証用データにおけるSingle MSEの最小値：[2.5614028e-05]、最大値：[13.451243]\n",
      "8個目の検証用データにおけるSingle MSEの最小値：[3.0716592e-06]、最大値：[0.9860603]\n",
      "9個目の検証用データにおけるSingle MSEの最小値：[0.00016395]、最大値：[1.2914829]\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSEの最小値：{min(MSE)}、最大値：{max(MSE)}\")\n",
    "print()\n",
    "for i in range(len(SINGLE_SE)):\n",
    "    print(f\"{i}個目の検証用データにおけるSingle MSEの最小値：{min(SINGLE_SE[i])}、最大値：{max(SINGLE_SE[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2から23ヶ月のmseのグラフ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufefft', 'mse']\n",
      "['2', '0.413069099']\n",
      "['3', '0.384383827']\n",
      "['4', '0.873907566']\n",
      "['5', '0.755506814']\n",
      "['6', '0.562553227']\n",
      "['7', '0.746531188']\n",
      "['8', '0.467304856']\n",
      "['9', '0.346009761']\n",
      "['10', '0.375499427']\n",
      "['11', '0.297397971']\n",
      "['12', '0.376730233']\n",
      "['13', '0.326621324']\n",
      "['14', '0.282577604']\n",
      "['15', '0.196311235']\n",
      "['16', '0.211351916']\n",
      "['17', '0.188866809']\n",
      "['18', '0.304150939']\n",
      "['19', '0.249072403']\n",
      "['20', '0.38124913']\n",
      "['21', '0.108495615']\n",
      "['22', '0.219341561']\n",
      "['23', '0.316575348']\n"
     ]
    }
   ],
   "source": [
    "filename = 'dataset/t_mse_graf.csv'\n",
    "with open(filename, encoding='utf8', newline='') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    for row in csvreader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mse')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_csv = r'dataset/t_mse_graf.csv'\n",
    "\n",
    "rows = []\n",
    "with open(path_csv) as f:   \n",
    "    reader = csv.reader(f)\n",
    "    rows = [row for row in reader]\n",
    "\n",
    "header = rows.pop(0)\n",
    "\n",
    "data = np.float_(np.array(rows).T)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(data[0], data[1], linestyle='solid', marker='o')\n",
    "\n",
    "ax.set_xlabel(header[0])\n",
    "ax.set_ylabel(header[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf291",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
